{"cells":[{"cell_type":"markdown","metadata":{"id":"XxChZLAKliXg"},"source":["Content taken from GitHub repository hosting the code:\n","\n","https://github.com/matthewjohnson42/umass-cs685-finalproject\n","\n","Substantial modifications made to adapt to Colab training environment."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"U0NG9bOzleFZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715950268766,"user_tz":240,"elapsed":33304,"user":{"displayName":"Matthew Johnson","userId":"09672185346885346735"}},"outputId":"86d68ef1-20e0-439b-9cdc-57f582a8bf87"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":1}],"source":["from google.colab import drive\n","\n","import torch\n","import numpy as np\n","\n","import random\n","from typing import Optional\n","import time\n","import os\n","import gc\n","from xml.etree import ElementTree\n","\n","\n","drive.mount('/content/drive', force_remount=True)\n","root_filepath = '/content/drive/MyDrive/CS685-NLP-GroupProject/Code/singleNotebookFromPythonFilesStructure/'\n","is_remote_execution = True\n","\n","torch.device(\"cuda\")"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"sllajv_0n2Vu","executionInfo":{"status":"ok","timestamp":1715950268766,"user_tz":240,"elapsed":8,"user":{"displayName":"Matthew Johnson","userId":"09672185346885346735"}}},"outputs":[],"source":["SETimesByT5Vaswani2017Kocmi2018_0 = {\n","    'dataset_transformer_name': 'dataset_transformer_setimesbyt5',\n","    'model_name': 'transformer_vaswani2017',\n","    'trainer_name': 'model_trainer_kocmi2018',\n","    'latest_param_filename_tag': '1715741500',\n","    # corresponds to dictionary 'get' calls in the dataset_loader constructor\n","    'dataset_transformer_hyperparameters': {\n","        'sentence_length_min_percentile': 5,\n","        'sentence_length_max_percentile': 95,\n","        'parsed_dataset_filename': 'setimes_parsed-1715586293'\n","    },\n","    # corresponds to dictionary 'get' calls in the model constructor\n","    'model_hyperparameters': {\n","        'd_model': 256,\n","        'nhead': 8,\n","        # number of encoders is 3 times that of decoders, following Xue 2021 - ByT5 - Sec 3.1\n","        'num_encoder_layers': 9,\n","        'num_decoder_layers': 3,\n","        'dim_feedforward': 2048,\n","        'dropout': 0.1,\n","        'activation': torch.nn.functional.relu,\n","        'custom_encoder': None,\n","        'custom_decoder': None,\n","        'layer_norm_eps': 1e-5,\n","        'batch_first': True,\n","        'norm_first': False,\n","        'bias': True,\n","        'device': None,\n","        'dtype': None\n","    },\n","    # corresponds to dictionary 'get' calls in the trainer constructor\n","    'trainer_hyperparameters': {\n","        # optimization and lr schedule following Kocmi 2018 - Trivial TL - Sec 3\n","        'optimizer_name': 'Adam',\n","        'lr_scheduler_name': 'ExponentialLR',\n","        'initial_lr': 0.001,\n","        'exp_decay': 0.5,\n","        'epochs': 10,\n","        'epoch_starting_index': 1,\n","        'batch_size_limit': 175,\n","        'element_difference_limit': 19,\n","        'batch_starting_index': 0\n","    }\n","}\n","\n","SETimesByT5Vaswani2017Kocmi2018_1 = {\n","    'dataset_transformer_name': 'dataset_transformer_setimesbyt5',\n","    'model_name': 'transformer_vaswani2017',\n","    'trainer_name': 'model_trainer_kocmi2018',\n","    'latest_param_filename_tag': '1715741441',\n","    # corresponds to dictionary 'get' calls in the dataset_loader constructor\n","    'dataset_transformer_hyperparameters': {\n","        'sentence_length_min_percentile': 5,\n","        'sentence_length_max_percentile': 95,\n","        'parsed_dataset_filename': 'setimes_parsed-1715586974'\n","    },\n","    # corresponds to dictionary 'get' calls in the model constructor\n","    'model_hyperparameters': {\n","        'd_model': 256,\n","        'nhead': 8,\n","        # number of encoders is 3 times that of decoders, following Xue 2021 - ByT5 - Sec 3.1\n","        'num_encoder_layers': 9,\n","        'num_decoder_layers': 3,\n","        'dim_feedforward': 1796,\n","        'dropout': 0.1,\n","        'activation': torch.nn.functional.relu,\n","        'custom_encoder': None,\n","        'custom_decoder': None,\n","        'layer_norm_eps': 1e-5,\n","        'batch_first': True,\n","        'norm_first': False,\n","        'bias': True,\n","        'device': None,\n","        'dtype': None\n","    },\n","    # corresponds to dictionary 'get' calls in the trainer constructor\n","    'trainer_hyperparameters': {\n","        # optimization and lr schedule following Kocmi 2018 - Trivial TL - Sec 3\n","        'optimizer_name': 'Adam',\n","        'lr_scheduler_name': 'ExponentialLR',\n","        'initial_lr': 0.001,\n","        'exp_decay': 0.5,\n","        'epochs': 10,\n","        'epoch_starting_index': 1,\n","        'batch_size_limit': 250,\n","        'element_difference_limit': 19,\n","        'batch_starting_index': 84\n","    }\n","}\n","\n","SETimesByT5Vaswani2017Kocmi2018_2 = {\n","    'dataset_transformer_name': 'dataset_transformer_setimesbyt5',\n","    'model_name': 'transformer_vaswani2017',\n","    'trainer_name': 'model_trainer_kocmi2018',\n","    'latest_param_filename_tag': '1715672061',\n","    # corresponds to dictionary 'get' calls in the dataset_loader constructor\n","    'dataset_transformer_hyperparameters': {\n","        'sentence_length_min_percentile': 5,\n","        'sentence_length_max_percentile': 95,\n","        'parsed_dataset_filename': 'setimes_parsed-1715586361'\n","    },\n","    # corresponds to dictionary 'get' calls in the model constructor\n","    'model_hyperparameters': {\n","        'd_model': 128,\n","        'nhead': 8,\n","        # number of encoders is 3 times that of decoders, following Xue 2021 - ByT5 - Sec 3.1\n","        'num_encoder_layers': 9,\n","        'num_decoder_layers': 3,\n","        'dim_feedforward': 1024,\n","        'dropout': 0.1,\n","        'activation': torch.nn.functional.relu,\n","        'custom_encoder': None,\n","        'custom_decoder': None,\n","        'layer_norm_eps': 1e-5,\n","        'batch_first': True,\n","        'norm_first': False,\n","        'bias': True,\n","        'device': None,\n","        'dtype': None\n","    },\n","    # corresponds to dictionary 'get' calls in the trainer constructor\n","    'trainer_hyperparameters': {\n","        # optimization and lr schedule following Kocmi 2018 - Trivial TL - Sec 3\n","        'optimizer_name': 'Adam',\n","        'lr_scheduler_name': 'ExponentialLR',\n","        'initial_lr': 0.001,\n","        'exp_decay': 0.5,\n","        'epochs': 10,\n","        'epoch_starting_index': 1,\n","        'batch_size_limit': 400,\n","        'element_difference_limit': 19,\n","        'batch_starting_index': 0\n","    }\n","}\n","\n","NewsCommentaryByT5Vaswani2017Kocmi2018_0 = {\n","    'dataset_transformer_name': 'dataset_transformer_newscommentary',\n","    'model_name': 'transformer_vaswani2017',\n","    'trainer_name': 'model_trainer_kocmi2018',\n","    'latest_param_filename_tag': '1715937924',\n","    # corresponds to dictionary 'get' calls in the dataset_loader constructor\n","    'dataset_transformer_hyperparameters': {\n","        'sentence_length_min_percentile': 5,\n","        'sentence_length_max_percentile': 95,\n","        'parsed_dataset_filename': 'SMTNewsCommentary_parsed-1715949808'\n","    },\n","    # corresponds to dictionary 'get' calls in the model constructor\n","    'model_hyperparameters': {\n","        'd_model': 256,\n","        'nhead': 8,\n","        # number of encoders is 3 times that of decoders, following Xue 2021 - ByT5 - Sec 3.1\n","        'num_encoder_layers': 9,\n","        'num_decoder_layers': 3,\n","        'dim_feedforward': 2048,\n","        'dropout': 0.1,\n","        'activation': torch.nn.functional.relu,\n","        'custom_encoder': None,\n","        'custom_decoder': None,\n","        'layer_norm_eps': 1e-5,\n","        'batch_first': True,\n","        'norm_first': False,\n","        'bias': True,\n","        'device': None,\n","        'dtype': None\n","    },\n","    # corresponds to dictionary 'get' calls in the trainer constructor\n","    'trainer_hyperparameters': {\n","        # optimization and lr schedule following Kocmi 2018 - Trivial TL - Sec 3\n","        'optimizer_name': 'Adam',\n","        'lr_scheduler_name': 'ExponentialLR',\n","        'initial_lr': 0.0005,\n","        'exp_decay': 0.5,\n","        'epochs': 1,\n","        'epoch_starting_index': 0,\n","        'batch_size_limit': 175,\n","        'element_difference_limit': 19,\n","        'batch_starting_index': 0\n","    }\n","}\n","\n","NewsCommentaryByT5Vaswani2017Kocmi2018_1 = {\n","    'dataset_transformer_name': 'dataset_transformer_newscommentary',\n","    'model_name': 'transformer_vaswani2017',\n","    'trainer_name': 'model_trainer_kocmi2018',\n","    'latest_param_filename_tag': '1715937961',\n","    # corresponds to dictionary 'get' calls in the dataset_loader constructor\n","    'dataset_transformer_hyperparameters': {\n","        'sentence_length_min_percentile': 5,\n","        'sentence_length_max_percentile': 95,\n","        'parsed_dataset_filename': 'SMTNewsCommentary_parsed-1715949808'\n","    },\n","    # corresponds to dictionary 'get' calls in the model constructor\n","    'model_hyperparameters': {\n","        'd_model': 256,\n","        'nhead': 8,\n","        # number of encoders is 3 times that of decoders, following Xue 2021 - ByT5 - Sec 3.1\n","        'num_encoder_layers': 9,\n","        'num_decoder_layers': 3,\n","        'dim_feedforward': 1796,\n","        'dropout': 0.1,\n","        'activation': torch.nn.functional.relu,\n","        'custom_encoder': None,\n","        'custom_decoder': None,\n","        'layer_norm_eps': 1e-5,\n","        'batch_first': True,\n","        'norm_first': False,\n","        'bias': True,\n","        'device': None,\n","        'dtype': None\n","    },\n","    # corresponds to dictionary 'get' calls in the trainer constructor\n","    'trainer_hyperparameters': {\n","        # optimization and lr schedule following Kocmi 2018 - Trivial TL - Sec 3\n","        'optimizer_name': 'Adam',\n","        'lr_scheduler_name': 'ExponentialLR',\n","        'initial_lr': 0.0005,\n","        'exp_decay': 0.5,\n","        'epochs': 1,\n","        'epoch_starting_index': 0,\n","        'batch_size_limit': 250,\n","        'element_difference_limit': 19,\n","        'batch_starting_index': 0\n","    }\n","}\n","\n","NewsCommentaryByT5Vaswani2017Kocmi2018_2 = {\n","    'dataset_transformer_name': 'dataset_transformer_newscommentary',\n","    'model_name': 'transformer_vaswani2017',\n","    'trainer_name': 'model_trainer_kocmi2018',\n","    'latest_param_filename_tag': '1715936459',\n","    # corresponds to dictionary 'get' calls in the dataset_loader constructor\n","    'dataset_transformer_hyperparameters': {\n","        'sentence_length_min_percentile': 5,\n","        'sentence_length_max_percentile': 95,\n","        'parsed_dataset_filename': 'SMTNewsCommentary_parsed-1715949808'\n","    },\n","    # corresponds to dictionary 'get' calls in the model constructor\n","    'model_hyperparameters': {\n","        'd_model': 128,\n","        'nhead': 8,\n","        # number of encoders is 3 times that of decoders, following Xue 2021 - ByT5 - Sec 3.1\n","        'num_encoder_layers': 9,\n","        'num_decoder_layers': 3,\n","        'dim_feedforward': 1024,\n","        'dropout': 0.1,\n","        'activation': torch.nn.functional.relu,\n","        'custom_encoder': None,\n","        'custom_decoder': None,\n","        'layer_norm_eps': 1e-5,\n","        'batch_first': True,\n","        'norm_first': False,\n","        'bias': True,\n","        'device': None,\n","        'dtype': None\n","    },\n","    # corresponds to dictionary 'get' calls in the trainer constructor\n","    'trainer_hyperparameters': {\n","        # optimization and lr schedule following Kocmi 2018 - Trivial TL - Sec 3\n","        'optimizer_name': 'Adam',\n","        'lr_scheduler_name': 'ExponentialLR',\n","        'initial_lr': 0.0005,\n","        'exp_decay': 0.5,\n","        'epochs': 1,\n","        'epoch_starting_index': 0,\n","        'batch_size_limit': 400,\n","        'element_difference_limit': 19,\n","        'batch_starting_index': 0\n","    }\n","}\n","\n","english_char_mappings = {\n","    ord(\" \"): ord(\" \"),\n","    ord(\"e\"): ord(\"e\"),\n","    ord(\"t\"): ord(\"t\"),\n","    ord(\"a\"): ord(\"a\"),\n","    ord(\"i\"): ord(\"i\"),\n","    ord(\"o\"): ord(\"o\"),\n","    ord(\"n\"): ord(\"n\"),\n","    ord(\"r\"): ord(\"r\"),\n","    ord(\"s\"): ord(\"s\"),\n","    ord(\"h\"): ord(\"h\"),\n","    ord(\"l\"): ord(\"l\"),\n","    ord(\"d\"): ord(\"d\"),\n","    ord(\"c\"): ord(\"c\"),\n","    ord(\"u\"): ord(\"u\"),\n","    ord(\"m\"): ord(\"m\"),\n","    ord(\"p\"): ord(\"p\"),\n","    ord(\"f\"): ord(\"f\"),\n","    ord(\"g\"): ord(\"g\"),\n","    ord(\"y\"): ord(\"y\"),\n","    ord(\"b\"): ord(\"b\"),\n","    ord(\"w\"): ord(\"w\"),\n","    ord(\"v\"): ord(\"v\"),\n","    ord(\",\"): ord(\",\"),\n","    ord(\".\"): ord(\".\"),\n","    ord(\"k\"): ord(\"k\"),\n","    ord(\"T\"): ord(\"T\"),\n","    ord(\"S\"): ord(\"S\"),\n","    ord(\"0\"): ord(\"0\"),\n","    ord(\"A\"): ord(\"A\"),\n","    ord(\"-\"): ord(\"-\"),\n","    ord(\"B\"): ord(\"B\"),\n","    ord(\"M\"): ord(\"M\"),\n","    ord(\"\\\"\"): ord(\"\\\"\"),\n","    ord(\"E\"): ord(\"E\"),\n","    ord(\"P\"): ord(\"P\"),\n","    ord(\"C\"): ord(\"C\"),\n","    ord(\"I\"): ord(\"I\"),\n","    ord(\"1\"): ord(\"1\"),\n","    ord(\"'\"): ord(\"'\"),\n","    ord(\"j\"): ord(\"j\"),\n","    ord(\"2\"): ord(\"2\"),\n","    ord(\"R\"): ord(\"R\"),\n","    ord(\"U\"): ord(\"U\"),\n","    ord(\"K\"): ord(\"K\"),\n","    ord(\"D\"): ord(\"D\"),\n","    ord(\"x\"): ord(\"x\"),\n","    ord(\"H\"): ord(\"H\"),\n","    ord(\"F\"): ord(\"F\"),\n","    ord(\"N\"): ord(\"N\"),\n","    ord(\"G\"): ord(\"G\"),\n","    ord(\"/\"): ord(\"/\"),\n","    ord(\"O\"): ord(\"O\"),\n","    ord(\")\"): ord(\")\"),\n","    ord(\"(\"): ord(\"(\"),\n","    ord(\"9\"): ord(\"9\"),\n","    ord(\"W\"): ord(\"W\"),\n","    ord(\"z\"): ord(\"z\"),\n","    ord(\"5\"): ord(\"5\"),\n","    ord(\"3\"): ord(\"3\"),\n","    ord(\"J\"): ord(\"J\"),\n","    ord(\"4\"): ord(\"4\"),\n","    ord(\"q\"): ord(\"q\"),\n","    ord(\"L\"): ord(\"L\"),\n","    ord(\"6\"): ord(\"6\"),\n","    ord(\"7\"): ord(\"7\"),\n","    ord(\"8\"): ord(\"8\"),\n","    ord(\"V\"): ord(\"V\"),\n","    ord(\"[\"): ord(\"[\"),\n","    ord(\"]\"): ord(\"]\"),\n","    ord(\":\"): ord(\":\"),\n","    ord(\"Z\"): ord(\"Z\"),\n","    ord(\"%\"): ord(\"%\"),\n","    ord(\"Y\"): ord(\"Y\"),\n","    ord(\";\"): ord(\";\"),\n","    ord(\"–\"): ord(\"-\"),\n","    ord(\"?\"): ord(\"?\"),\n","    ord(\"X\"): ord(\"X\"),\n","    ord(\"$\"): ord(\"$\"),\n","    ord(\"’\"): ord(\"'\"),\n","    ord(\"Q\"): ord(\"Q\"),\n","    ord(\"…\"): ord(\"\\u0120\"),\n","    ord(\"!\"): ord(\"\\u0120\"),\n","    ord(\"&\"): ord(\"\\u0120\"),\n","    ord(\"ć\"): ord(\"\\u0120\"),\n","    ord(\"”\"): ord(\"\\\"\"),\n","    ord(\"é\"): ord(\"\\u0120\"),\n","    ord(\"“\"): ord(\"\\\"\"),\n","    ord(\"ı\"): ord(\"\\u0120\"),\n","    ord(\"ü\"): ord(\"\\u0120\"),\n","    ord(\"+\"): ord(\"\\u0120\"),\n","    ord(\"ç\"): ord(\"\\u0120\"),\n","    ord(\"ˈ\"): ord(\"'\"),\n","    ord(\"ö\"): ord(\"\\u0120\"),\n","    ord(\"ë\"): ord(\"\\u0120\"),\n","    ord(\"Ç\"): ord(\"\\u0120\"),\n","    ord(\"ğ\"): ord(\"\\u0120\"),\n","    ord(\"č\"): ord(\"\\u0120\"),\n","    ord(\"š\"): ord(\"\\u0120\"),\n","    ord(\"‘\"): ord(\"'\"),\n","    ord(\"ž\"): ord(\"\\u0120\"),\n","    ord(\"*\"): ord(\"\\u0120\"),\n","    ord(\"ş\"): ord(\"\\u0120\"),\n","    ord(\"б\"): ord(\"\\u0120\"),\n","    ord(\"Š\"): ord(\"\\u0120\"),\n","    ord(\"İ\"): ord(\"\\u0120\"),\n","    ord(\"à\"): ord(\"\\u0120\"),\n","    ord(\"г\"): ord(\"\\u0120\"),\n","    ord(\"ï\"): ord(\"\\u0120\"),\n","    ord(\"Ü\"): ord(\"\\u0120\"),\n","    ord(\"—\"): ord(\"-\"),\n","    ord(\"€\"): ord(\"\\u0120\"),\n","    ord(\"Ö\"): ord(\"\\u0120\"),\n","    ord(\"đ\"): ord(\"\\u0120\"),\n","    ord(\"\\\\\"): ord(\"\\u0120\"),\n","    ord(\"Ι\"): ord(\"\\u0120\"),\n","    ord(\"Α\"): ord(\"A\"),\n","    ord(\"`\"): ord(\"'\"),\n","    ord(\"_\"): ord(\"\\u0120\"),\n","    ord(\"=\"): ord(\"\\u0120\"),\n","    ord(\"@\"): ord(\"\\u0120\"),\n","    ord(\"А\"): ord(\"A\"),\n","    ord(\"ó\"): ord(\"\\u0120\"),\n","    ord(\"í\"): ord(\"\\u0120\"),\n","    ord(\"â\"): ord(\"\\u0120\"),\n","    ord(\"\\x80\"): ord(\"\\u0120\"),\n","    ord(\"Ž\"): ord(\"\\u0120\"),\n","    ord(\"Κ\"): ord(\"K\"),\n","    ord(\"Ο\"): ord(\"O\"),\n","    ord(\"р\"): ord(\"p\"),\n","    ord(\"Ş\"): ord(\"\\u0120\"),\n","    ord(\"á\"): ord(\"\\u0120\"),\n","    ord(\"у\"): ord(\"y\"),\n","    ord(\"\\x93\"): ord(\"\\u0120\"),\n","    ord(\"°\"): ord(\"\\u0120\"),\n","    ord(\"<\"): ord(\"\\u0120\"),\n","    ord(\"½\"): ord(\"\\u0120\"),\n","    ord(\"Т\"): ord(\"T\"),\n","    ord(\"ø\"): ord(\"\\u0120\"),\n","    ord(\"Ε\"): ord(\"E\"),\n","    ord(\"#\"): ord(\"\\u0120\"),\n","    ord(\"ý\"): ord(\"\\u0120\"),\n","    ord(\"л\"): ord(\"\\u0120\"),\n","    ord(\"я\"): ord(\"\\u0120\"),\n","    ord(\"�\"): ord(\"\\u0120\"),\n","    ord(\"º\"): ord(\"\\u0120\"),\n","    ord(\"ä\"): ord(\"\\u0120\"),\n","    ord(\"е\"): ord(\"e\"),\n","    ord(\"о\"): ord(\"o\"),\n","    ord(\"Đ\"): ord(\"\\u0120\"),\n","    ord(\"è\"): ord(\"\\u0120\"),\n","    ord(\"¾\"): ord(\"\\u0120\"),\n","    ord(\"\\x96\"): ord(\"\\u0120\"),\n","    ord(\"æ\"): ord(\"\\u0120\"),\n","    ord(\">\"): ord(\"\\u0120\"),\n","    ord(\"¦\"): ord(\"\\u0120\"),\n","    ord(\"μ\"): ord(\"\\u0120\"),\n","    ord(\"Č\"): ord(\"\\u0120\"),\n","    ord(\"ñ\"): ord(\"\\u0120\"),\n","    ord(\"х\"): ord(\"x\"),\n","    ord(\"М\"): ord(\"M\"),\n","    ord(\"É\"): ord(\"\\u0120\"),\n","    ord(\"±\"): ord(\"\\u0120\"),\n","    ord(\"£\"): ord(\"\\u0120\"),\n","    ord(\"{\"): ord(\"\\u0120\"),\n","    ord(\"}\"): ord(\"\\u0120\"),\n","    ord(\"ъ\"): ord(\"\\u0120\"),\n","    ord(\"а\"): ord(\"\\u0120\"),\n","    ord(\"и\"): ord(\"\\u0120\")\n","}\n","\n","turkish_char_mappings = {\n","    ord(\" \"): ord(\" \"),\n","    ord(\"a\"): ord(\"a\"),\n","    ord(\"e\"): ord(\"e\"),\n","    ord(\"i\"): ord(\"i\"),\n","    ord(\"n\"): ord(\"n\"),\n","    ord(\"r\"): ord(\"r\"),\n","    ord(\"l\"): ord(\"l\"),\n","    ord(\"ı\"): ord(\"ı\"),\n","    ord(\"k\"): ord(\"k\"),\n","    ord(\"d\"): ord(\"d\"),\n","    ord(\"t\"): ord(\"t\"),\n","    ord(\"s\"): ord(\"s\"),\n","    ord(\"u\"): ord(\"u\"),\n","    ord(\"m\"): ord(\"m\"),\n","    ord(\"y\"): ord(\"y\"),\n","    ord(\"o\"): ord(\"o\"),\n","    ord(\"ü\"): ord(\"ü\"),\n","    ord(\"b\"): ord(\"b\"),\n","    ord(\"ş\"): ord(\"ş\"),\n","    ord(\"v\"): ord(\"v\"),\n","    ord(\"g\"): ord(\"g\"),\n","    ord(\"z\"): ord(\"z\"),\n","    ord(\"ç\"): ord(\"ç\"),\n","    ord(\"ğ\"): ord(\"ğ\"),\n","    ord(\".\"): ord(\".\"),\n","    ord(\",\"): ord(\",\"),\n","    ord(\"c\"): ord(\"c\"),\n","    ord(\"h\"): ord(\"h\"),\n","    ord(\"p\"): ord(\"p\"),\n","    ord(\"ö\"): ord(\"ö\"),\n","    ord(\"'\"): ord(\"'\"),\n","    ord(\"B\"): ord(\"B\"),\n","    ord(\"A\"): ord(\"A\"),\n","    ord(\"f\"): ord(\"f\"),\n","    ord(\"S\"): ord(\"S\"),\n","    ord(\"K\"): ord(\"K\"),\n","    ord(\"0\"): ord(\"0\"),\n","    ord(\"\\\"\"): ord(\"\\\"\"),\n","    ord(\"T\"): ord(\"T\"),\n","    ord(\"M\"): ord(\"M\"),\n","    ord(\"1\"): ord(\"1\"),\n","    ord(\"P\"): ord(\"P\"),\n","    ord(\"D\"): ord(\"D\"),\n","    ord(\"H\"): ord(\"H\"),\n","    ord(\"2\"): ord(\"2\"),\n","    ord(\"E\"): ord(\"E\"),\n","    ord(\"R\"): ord(\"R\"),\n","    ord(\"-\"): ord(\"-\"),\n","    ord(\"G\"): ord(\"G\"),\n","    ord(\"j\"): ord(\"j\"),\n","    ord(\"Y\"): ord(\"Y\"),\n","    ord(\"C\"): ord(\"C\"),\n","    ord(\"İ\"): ord(\"İ\"),\n","    ord(\"O\"): ord(\"O\"),\n","    ord(\"/\"): ord(\"/\"),\n","    ord(\"F\"): ord(\"F\"),\n","    ord(\"N\"): ord(\"N\"),\n","    ord(\"9\"): ord(\"9\"),\n","    ord(\"5\"): ord(\"5\"),\n","    ord(\"3\"): ord(\"3\"),\n","    ord(\"I\"): ord(\"I\"),\n","    ord(\"4\"): ord(\"4\"),\n","    ord(\"L\"): ord(\"L\"),\n","    ord(\"6\"): ord(\"6\"),\n","    ord(\")\"): ord(\")\"),\n","    ord(\"(\"): ord(\"(\"),\n","    ord(\"7\"): ord(\"7\"),\n","    ord(\"8\"): ord(\"8\"),\n","    ord(\"U\"): ord(\"U\"),\n","    ord(\"V\"): ord(\"V\"),\n","    ord(\":\"): ord(\":\"),\n","    ord(\"[\"): ord(\"[\"),\n","    ord(\"]\"): ord(\"]\"),\n","    ord(\"’\"): ord(\"'\"),\n","    ord(\"Z\"): ord(\"Z\"),\n","    ord(\"Ç\"): ord(\"Ç\"),\n","    ord(\"J\"): ord(\"J\"),\n","    ord(\"Ü\"): ord(\"Ü\"),\n","    ord(\"Ş\"): ord(\"Ş\"),\n","    ord(\"Ö\"): ord(\"Ö\"),\n","    ord(\"%\"): ord(\"%\"),\n","    ord(\";\"): ord(\";\"),\n","    ord(\"w\"): ord(\"w\"),\n","    ord(\"W\"): ord(\"W\"),\n","    ord(\"â\"): ord(\"â\"),\n","    ord(\"–\"): ord(\"-\"),\n","    ord(\"?\"): ord(\"?\"),\n","    ord(\"x\"): ord(\"x\"),\n","    ord(\"“\"): ord(\"\\\"\"),\n","    ord(\"”\"): ord(\"\\\"\"),\n","    ord(\"X\"): ord(\"X\"),\n","    ord(\"q\"): ord(\"q\"),\n","    ord(\"î\"): ord(\"\\u0120\"),\n","    ord(\"&\"): ord(\"\\u0120\"),\n","    ord(\"!\"): ord(\"\\u0120\"),\n","    ord(\"ð\"): ord(\"\\u0120\"),\n","    ord(\"Q\"): ord(\"\\u0120\"),\n","    ord(\"+\"): ord(\"\\u0120\"),\n","    ord(\"þ\"): ord(\"\\u0120\"),\n","    ord(\"‘\"): ord(\"'\"),\n","    ord(\"é\"): ord(\"\\u0120\"),\n","    ord(\"º\"): ord(\"\\u0120\"),\n","    ord(\"ë\"): ord(\"\\u0120\"),\n","    ord(\"…\"): ord(\"\\u0120\"),\n","    ord(\"б\"): ord(\"\\u0120\"),\n","    ord(\"*\"): ord(\"\\u0120\"),\n","    ord(\"=\"): ord(\"\\u0120\"),\n","    ord(\"`\"): ord(\"'\"),\n","    ord(\"ć\"): ord(\"\\u0120\"),\n","    ord(\"û\"): ord(\"\\u0120\"),\n","    ord(\"Ý\"): ord(\"\\u0120\"),\n","    ord(\"г\"): ord(\"\\u0120\"),\n","    ord(\"—\"): ord(\"\\u0120\"),\n","    ord(\"\\\\\"): ord(\"\\u0120\"),\n","    ord(\"°\"): ord(\"\\u0120\"),\n","    ord(\"@\"): ord(\"\\u0120\"),\n","    ord(\"č\"): ord(\"\\u0120\"),\n","    ord(\"ó\"): ord(\"\\u0120\"),\n","    ord(\"š\"): ord(\"\\u0120\"),\n","    ord(\"р\"): ord(\"\\u0120\"),\n","    ord(\"_\"): ord(\"\\u0120\"),\n","    ord(\"{\"): ord(\"\\u0120\"),\n","    ord(\"#\"): ord(\"\\u0120\"),\n","    ord(\"^\"): ord(\"\\u0120\"),\n","    ord(\">\"): ord(\"\\u0120\"),\n","    ord(\"$\"): ord(\"\\u0120\"),\n","    ord(\"đ\"): ord(\"\\u0120\"),\n","    ord(\"í\"): ord(\"\\u0120\"),\n","    ord(\"ø\"): ord(\"\\u0120\"),\n","    ord(\"Š\"): ord(\"\\u0120\"),\n","    ord(\"ž\"): ord(\"\\u0120\"),\n","    ord(\"Þ\"): ord(\"\\u0120\"),\n","    ord(\"л\"): ord(\"\\u0120\"),\n","    ord(\"я\"): ord(\"\\u0120\"),\n","    ord(\"}\"): ord(\"\\u0120\"),\n","    ord(\"±\"): ord(\"\\u0120\"),\n","    ord(\"½\"): ord(\"\\u0120\"),\n","    ord(\"¾\"): ord(\"\\u0120\"),\n","    ord(\"ª\"): ord(\"\\u0120\"),\n","    ord(\"á\"): ord(\"\\u0120\"),\n","    ord(\"É\"): ord(\"\\u0120\"),\n","    ord(\"è\"): ord(\"\\u0120\"),\n","    ord(\"Ğ\"): ord(\"\\u0120\"),\n","    ord(\"ï\"): ord(\"\\u0120\"),\n","    ord(\"ñ\"): ord(\"\\u0120\"),\n","    ord(\"ý\"): ord(\"\\u0120\"),\n","    ord(\"Ž\"): ord(\"\\u0120\"),\n","    ord(\"μ\"): ord(\"\\u0120\"),\n","    ord(\"а\"): ord(\"\\u0120\"),\n","    ord(\"и\"): ord(\"\\u0120\"),\n","    ord(\"у\"): ord(\"\\u0120\"),\n","    ord(\"х\"): ord(\"\\u0120\"),\n","    ord(\"ъ\"): ord(\"\\u0120\"),\n","}\n","\n","enkk_english_character_mappings = {\n","    ord(\"Ġ\"): ord(\"\\u0120\"),\n","    ord(\"ġ\"): ord(\"\\u0120\"),\n","    ord(\"Ģ\"): ord(\"Ģ\"),\n","    ord(\"N\"): ord(\"N\"),\n","    ord(\"E\"): ord(\"E\"),\n","    ord(\"W\"): ord(\"W\"),\n","    ord(\" \"): ord(\" \"),\n","    ord(\"Y\"): ord(\"Y\"),\n","    ord(\"O\"): ord(\"O\"),\n","    ord(\"R\"): ord(\"R\"),\n","    ord(\"K\"): ord(\"K\"),\n","    ord(\"–\"): ord(\"-\"),\n","    ord(\"v\"): ord(\"v\"),\n","    ord(\"e\"): ord(\"e\"),\n","    ord(\"r\"): ord(\"r\"),\n","    ord(\"y\"): ord(\"y\"),\n","    ord(\"J\"): ord(\"J\"),\n","    ord(\"a\"): ord(\"a\"),\n","    ord(\"n\"): ord(\"n\"),\n","    ord(\"u\"): ord(\"u\"),\n","    ord(\",\"): ord(\",\"),\n","    ord(\"I\"): ord(\"I\"),\n","    ord(\"t\"): ord(\"t\"),\n","    ord(\"o\"): ord(\"o\"),\n","    ord(\"c\"): ord(\"c\"),\n","    ord(\"f\"): ord(\"f\"),\n","    ord(\"s\"): ord(\"s\"),\n","    ord(\"h\"): ord(\"h\"),\n","    ord(\"m\"): ord(\"m\"),\n","    ord(\"i\"): ord(\"i\"),\n","    ord(\"g\"): ord(\"g\"),\n","    ord(\".\"): ord(\".\"),\n","    ord(\"l\"): ord(\"l\"),\n","    ord(\"d\"): ord(\"d\"),\n","    ord(\";\"): ord(\";\"),\n","    ord(\"b\"): ord(\"b\"),\n","    ord(\"w\"): ord(\"w\"),\n","    ord(\"x\"): ord(\"x\"),\n","    ord(\"p\"): ord(\"p\"),\n","    ord(\"H\"): ord(\"H\"),\n","    ord(\"T\"): ord(\"T\"),\n","    ord(\"’\"): ord(\"'\"),\n","    ord(\"q\"): ord(\"q\"),\n","    ord(\"-\"): ord(\"-\"),\n","    ord(\"(\"): ord(\"(\"),\n","    ord(\"“\"): ord(\"\\\"\"),\n","    ord(\"”\"): ord(\"\\\"\"),\n","    ord(\")\"): ord(\")\"),\n","    ord(\"U\"): ord(\"U\"),\n","    ord(\"S\"): ord(\"S\"),\n","    ord(\"G\"): ord(\"G\"),\n","    ord(\"2\"): ord(\"2\"),\n","    ord(\"0\"): ord(\"0\"),\n","    ord(\"8\"): ord(\"8\"),\n","    ord(\"k\"): ord(\"k\"),\n","    ord(\"F\"): ord(\"F\"),\n","    ord(\"1\"): ord(\"1\"),\n","    ord(\"6\"): ord(\"6\"),\n","    ord(\"B\"): ord(\"B\"),\n","    ord(\"A\"): ord(\"A\"),\n","    ord(\"C\"): ord(\"C\"),\n","    ord(\"D\"): ord(\"D\"),\n","    ord(\"9\"): ord(\"9\"),\n","    ord(\"%\"): ord(\"%\"),\n","    ord(\"j\"): ord(\"j\"),\n","    ord(\"?\"): ord(\"?\"),\n","    ord(\"z\"): ord(\"z\"),\n","    ord(\"M\"): ord(\"M\"),\n","    ord(\":\"): ord(\":\"),\n","    ord(\"V\"): ord(\"V\"),\n","    ord(\"4\"): ord(\"4\"),\n","    ord(\"3\"): ord(\"3\"),\n","    ord(\"L\"): ord(\"L\"),\n","    ord(\"P\"): ord(\"P\"),\n","    ord(\"5\"): ord(\"5\"),\n","    ord(\"7\"): ord(\"7\"),\n","    ord(\"$\"): ord(\"\\u0120\"),\n","    ord(\"€\"): ord(\"\\u0120\"),\n","    ord(\"ñ\"): ord(\"\\u0120\"),\n","    ord(\"é\"): ord(\"\\u0120\"),\n","    ord(\"è\"): ord(\"\\u0120\"),\n","    ord(\"¥\"): ord(\"\\u0120\"),\n","    ord(\"&\"): ord(\"\\u0120\"),\n","    ord(\"—\"): ord(\"\\u0120\"),\n","    ord(\"Z\"): ord(\"Z\"),\n","    ord(\"X\"): ord(\"X\"),\n","    ord(\"ä\"): ord(\"\\u0120\"),\n","    ord(\"à\"): ord(\"\\u0120\"),\n","    ord(\"/\"): ord(\"\\u0120\"),\n","    ord(\"Q\"): ord(\"Q\"),\n","    ord(\"ç\"): ord(\"\\u0120\"),\n","    ord(\"É\"): ord(\"\\u0120\"),\n","    ord(\"!\"): ord(\"\\u0120\"),\n","    ord(\"á\"): ord(\"\\u0120\"),\n","    ord(\"š\"): ord(\"\\u0120\"),\n","    ord(\"í\"): ord(\"\\u0120\"),\n","    ord(\"ó\"): ord(\"\\u0120\"),\n","    ord(\"ğ\"): ord(\"\\u0120\"),\n","    ord(\"â\"): ord(\"\\u0120\"),\n","    ord(\"ü\"): ord(\"\\u0120\"),\n","    ord(\"ö\"): ord(\"\\u0120\"),\n","    ord(\"‘\"): ord(\"\\u0120\"),\n","    ord(\"#\"): ord(\"\\u0120\"),\n","    ord(\"ï\"): ord(\"\\u0120\"),\n","    ord(\"[\"): ord(\"\\u0120\"),\n","    ord(\"]\"): ord(\"\\u0120\"),\n","    ord(\"…\"): ord(\"\\u0120\"),\n","    ord(\"ð\"): ord(\"\\u0120\"),\n","    ord(\"ń\"): ord(\"\\u0120\"),\n","    ord(\"'\"): ord(\"'\"),\n","    ord(\"Á\"): ord(\"\\u0120\"),\n","    ord(\"î\"): ord(\"\\u0120\"),\n","    ord(\"ŏ\"): ord(\"\\u0120\"),\n","    ord(\"ê\"): ord(\"\\u0120\"),\n","    ord(\"+\"): ord(\"\\u0120\"),\n","    ord(\"ł\"): ord(\"\\u0120\"),\n","    ord(\"ô\"): ord(\"\\u0120\"),\n","    ord(\"£\"): ord(\"\\u0120\"),\n","    ord(\"Š\"): ord(\"\\u0120\")\n","}\n","\n","enkk_kazakh_character_mappings = {\n","    ord(\"Ġ\"): ord(\"\\u0120\"),\n","    ord(\"ġ\"): ord(\"\\u0120\"),\n","    ord(\"Ģ\"): ord(\"Ģ\"),\n","    ord(\"Н\"): ord(\"Н\"),\n","    ord(\"Ь\"): ord(\"Ь\"),\n","    ord(\"Ю\"): ord(\"Ю\"),\n","    ord(\"-\"): ord(\"-\"),\n","    ord(\"Й\"): ord(\"Й\"),\n","    ord(\"О\"): ord(\"О\"),\n","    ord(\"Р\"): ord(\"Р\"),\n","    ord(\"К\"): ord(\"К\"),\n","    ord(\" \"): ord(\" \"),\n","    ord(\"–\"): ord(\"–\"),\n","    ord(\"Ә\"): ord(\"Ә\"),\n","    ord(\"р\"): ord(\"р\"),\n","    ord(\"б\"): ord(\"б\"),\n","    ord(\"і\"): ord(\"і\"),\n","    ord(\"қ\"): ord(\"қ\"),\n","    ord(\"а\"): ord(\"а\"),\n","    ord(\"ң\"): ord(\"ң\"),\n","    ord(\"т\"): ord(\"т\"),\n","    ord(\"й\"): ord(\"й\"),\n","    ord(\"ы\"): ord(\"ы\"),\n","    ord(\"н\"): ord(\"н\"),\n","    ord(\"д\"): ord(\"д\"),\n","    ord(\",\"): ord(\",\"),\n","    ord(\"м\"): ord(\"м\"),\n","    ord(\"е\"): ord(\"е\"),\n","    ord(\"л\"): ord(\"л\"),\n","    ord(\"ғ\"): ord(\"ғ\"),\n","    ord(\"ж\"): ord(\"ж\"),\n","    ord(\"о\"): ord(\"о\"),\n","    ord(\"с\"): ord(\"с\"),\n","    ord(\".\"): ord(\".\"),\n","    ord(\"Э\"): ord(\"Э\"),\n","    ord(\"к\"): ord(\"к\"),\n","    ord(\"и\"): ord(\"и\"),\n","    ord(\"у\"): ord(\"у\"),\n","    ord(\";\"): ord(\";\"),\n","    ord(\"Г\"): ord(\"Г\"),\n","    ord(\"Т\"): ord(\"Т\"),\n","    ord(\"э\"): ord(\"э\"),\n","    ord(\"(\"): ord(\"(\"),\n","    ord(\"«\"): ord(\"«\"),\n","    ord(\"ш\"): ord(\"ш\"),\n","    ord(\"»\"): ord(\"»\"),\n","    ord(\"п\"): ord(\"п\"),\n","    ord(\")\"): ord(\")\"),\n","    ord(\"ө\"): ord(\"ө\"),\n","    ord(\"ұ\"): ord(\"ұ\"),\n","    ord(\"С\"): ord(\"С\"),\n","    ord(\"ү\"): ord(\"ү\"),\n","    ord(\"ф\"): ord(\"ф\"),\n","    ord(\"Е\"): ord(\"Е\"),\n","    ord(\"А\"): ord(\"А\"),\n","    ord(\"Қ\"): ord(\"Қ\"),\n","    ord(\"Ш\"): ord(\"Ш\"),\n","    ord(\"2\"): ord(\"2\"),\n","    ord(\"0\"): ord(\"0\"),\n","    ord(\"8\"): ord(\"8\"),\n","    ord(\"Ұ\"): ord(\"Ұ\"),\n","    ord(\"я\"): ord(\"я\"),\n","    ord(\"з\"): ord(\"з\"),\n","    ord(\"ь\"): ord(\"ь\"),\n","    ord(\"г\"): ord(\"г\"),\n","    ord(\"М\"): ord(\"М\"),\n","    ord(\"1\"): ord(\"1\"),\n","    ord(\"6\"): ord(\"6\"),\n","    ord(\"һ\"): ord(\"һ\"),\n","    ord(\"ә\"): ord(\"ә\"),\n","    ord(\"Б\"): ord(\"Б\"),\n","    ord(\"Д\"): ord(\"Д\"),\n","    ord(\"х\"): ord(\"х\"),\n","    ord(\"9\"): ord(\"9\"),\n","    ord(\"%\"): ord(\"%\"),\n","    ord(\"?\"): ord(\"?\"),\n","    ord(\"ц\"): ord(\"ц\"),\n","    ord(\"Ж\"): ord(\"Ж\"),\n","    ord(\":\"): ord(\":\"),\n","    ord(\"в\"): ord(\"в\"),\n","    ord(\"ю\"): ord(\"ю\"),\n","    ord(\"Х\"): ord(\"Х\"),\n","    ord(\"В\"): ord(\"В\"),\n","    ord(\"4\"): ord(\"4\"),\n","    ord(\"3\"): ord(\"3\"),\n","    ord(\"І\"): ord(\"І\"),\n","    ord(\"Ө\"): ord(\"Ө\"),\n","    ord(\"5\"): ord(\"5\"),\n","    ord(\"T\"): ord(\"T\"),\n","    ord(\"a\"): ord(\"a\"),\n","    ord(\"x\"): ord(\"x\"),\n","    ord(\"P\"): ord(\"P\"),\n","    ord(\"o\"): ord(\"o\"),\n","    ord(\"l\"): ord(\"l\"),\n","    ord(\"i\"): ord(\"i\"),\n","    ord(\"c\"): ord(\"c\"),\n","    ord(\"y\"): ord(\"y\"),\n","    ord(\"C\"): ord(\"C\"),\n","    ord(\"e\"): ord(\"e\"),\n","    ord(\"n\"): ord(\"n\"),\n","    ord(\"t\"): ord(\"t\"),\n","    ord(\"r\"): ord(\"r\"),\n","    ord(\"h\"): ord(\"h\"),\n","    ord(\"F\"): ord(\"F\"),\n","    ord(\"u\"): ord(\"u\"),\n","    ord(\"d\"): ord(\"d\"),\n","    ord(\"M\"): ord(\"M\"),\n","    ord(\"’\"): ord(\"\\u0120\"),\n","    ord(\"s\"): ord(\"s\"),\n","    ord(\"A\"): ord(\"A\"),\n","    ord(\"7\"): ord(\"7\"),\n","    ord(\"Я\"): ord(\"Я\"),\n","    ord(\"П\"): ord(\"П\"),\n","    ord(\"И\"): ord(\"И\"),\n","    ord(\"f\"): ord(\"f\"),\n","    ord(\"Ф\"): ord(\"Ф\"),\n","    ord(\"Л\"): ord(\"Л\"),\n","    ord(\"S\"): ord(\"S\"),\n","    ord(\"z\"): ord(\"z\"),\n","    ord(\"З\"): ord(\"З\"),\n","    ord(\"“\"): ord(\"\\\"\"),\n","    ord(\"”\"): ord(\"\\\"\"),\n","    ord(\"G\"): ord(\"G\"),\n","    ord(\"N\"): ord(\"N\"),\n","    ord(\"Ү\"): ord(\"Ү\"),\n","    ord(\"Ғ\"): ord(\"Ғ\"),\n","    ord(\"ч\"): ord(\"ч\"),\n","    ord(\"Ң\"): ord(\"\\u0120\"),\n","    ord(\"ъ\"): ord(\"ъ\"),\n","    ord(\"K\"): ord(\"\\u0120\"),\n","    ord(\"H\"): ord(\"H\"),\n","    ord(\"m\"): ord(\"m\"),\n","    ord(\"R\"): ord(\"R\"),\n","    ord(\"I\"): ord(\"I\"),\n","    ord(\"p\"): ord(\"p\"),\n","    ord(\"B\"): ord(\"B\"),\n","    ord(\"Ч\"): ord(\"Ч\"),\n","    ord(\"D\"): ord(\"D\"),\n","    ord(\"L\"): ord(\"L\"),\n","    ord(\"b\"): ord(\"b\"),\n","    ord(\"E\"): ord(\"E\"),\n","    ord(\"Ц\"): ord(\"Ц\"),\n","    ord(\"k\"): ord(\"k\"),\n","    ord(\"$\"): ord(\"\\u0120\"),\n","    ord(\"v\"): ord(\"v\"),\n","    ord(\"¥\"): ord(\"\\u0120\"),\n","    ord(\"У\"): ord(\"У\"),\n","    ord(\"g\"): ord(\"g\"),\n","    ord(\"Ы\"): ord(\"Ы\"),\n","    ord(\"w\"): ord(\"w\"),\n","    ord(\"q\"): ord(\"\\u0120\"),\n","    ord(\"'\"): ord(\"\\u0120\"),\n","    ord(\"Y\"): ord(\"\\u0120\"),\n","    ord(\"U\"): ord(\"U\"),\n","    ord(\"O\"): ord(\"O\"),\n","    ord(\"/\"): ord(\"/\"),\n","    ord(\"é\"): ord(\"\\u0120\"),\n","    ord(\"!\"): ord(\"\\u0120\"),\n","    ord(\"V\"): ord(\"V\"),\n","    ord(\"\\\"\"): ord(\"\\\"\"),\n","    ord(\"ü\"): ord(\"\\u0120\"),\n","    ord(\"Z\"): ord(\"\\u0120\"),\n","    ord(\"W\"): ord(\"W\"),\n","    ord(\"#\"): ord(\"\\u0120\"),\n","    ord(\"щ\"): ord(\"щ\"),\n","    ord(\"J\"): ord(\"\\u0120\"),\n","    ord(\"&\"): ord(\"\\u0120\"),\n","    ord(\"Q\"): ord(\"\\u0120\"),\n","    ord(\"X\"): ord(\"\\u0120\"),\n","    ord(\"�\"): ord(\"\\u0120\"),\n","    ord(\"ä\"): ord(\"\\u0120\"),\n","    ord(\"ё\"): ord(\"\\u0120\"),\n","    ord(\"ə\"): ord(\"\\u0120\"),\n","    ord(\"£\"): ord(\"\\u0120\"),\n","    ord(\"j\"): ord(\"\\u0120\"),\n","    ord(\"É\"): ord(\"\\u0120\"),\n","    ord(\"[\"): ord(\"\\u0120\"),\n","    ord(\"]\"): ord(\"\\u0120\"),\n","    ord(\"€\"): ord(\"\\u0120\"),\n","    ord(\"\\u200b\"): ord(\"\\u0120\"),\n","    ord(\"+\"): ord(\"\\u0120\")\n","}\n"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"RJAevV6XnuW1","executionInfo":{"status":"ok","timestamp":1715950268767,"user_tz":240,"elapsed":8,"user":{"displayName":"Matthew Johnson","userId":"09672185346885346735"}}},"outputs":[],"source":["class DatasetHolder:\n","\n","    def __init__(self):\n","        self.unknown_vocabulary_type = None\n","        self.padding_vocabulary_type = None\n","        self.end_of_sequence_type = None\n","        self.target_vocab = None\n","        self.target_vocab_array = None\n","        self.target_vocab_counts = None\n","        self.source_vocab = None\n","        self.source_vocab_array = None\n","        self.source_vocab_counts = None\n","        self.target_encodings = None\n","        self.target_encodings_train = None\n","        self.target_encodings_test = None\n","        self.source_encodings = None\n","        self.source_encodings_train = None\n","        self.source_encodings_test = None\n","        self.max_src_seq_obs = 0\n","        self.max_tgt_seq_obs = 0\n","\n","    def get_unknown_vocabulary_type(self):\n","        return self.unknown_vocabulary_type\n","\n","    def set_unknown_vocabulary_type(self, unknown_vocabulary_type):\n","        self.unknown_vocabulary_type = unknown_vocabulary_type\n","\n","    def get_padding_vocabulary_type(self):\n","        return self.padding_vocabulary_type\n","\n","    def set_padding_vocabulary_type(self, padding_vocabulary_type):\n","        self.padding_vocabulary_type = padding_vocabulary_type\n","\n","    def get_end_of_sequence_vocabulary_type(self):\n","        return self.end_of_sequence_type\n","\n","    def set_end_of_sequence_vocabulary_type(self, end_of_sequence_type):\n","        self.end_of_sequence_type = end_of_sequence_type\n","\n","    def get_target_vocab(self):\n","        return self.target_vocab\n","\n","    def set_target_vocab(self, target_vocab):\n","        self.target_vocab = target_vocab\n","\n","    def get_target_vocab_numpy(self):\n","        if self.target_vocab_array is None:\n","            self.target_vocab_array = np.array(self.target_vocab)\n","        return self.target_vocab_array\n","\n","    def get_target_vocab_counts(self):\n","        return self.target_vocab_counts\n","\n","    def set_target_vocab_counts(self, target_vocab_counts):\n","        self.target_vocab_counts = target_vocab_counts\n","\n","    def get_source_vocab(self):\n","        return self.source_vocab\n","\n","    def set_source_vocab(self, source_vocab):\n","        self.source_vocab = source_vocab\n","\n","    def get_source_vocab_numpy(self):\n","        if self.source_vocab_array is None:\n","            self.source_vocab_array = np.array(self.source_vocab)\n","        return self.source_vocab_array\n","\n","    def get_source_vocab_counts(self):\n","        return self.source_vocab_counts\n","\n","    def set_source_vocab_counts(self, source_vocab_counts):\n","        self.source_vocab_counts = source_vocab_counts\n","\n","    def get_target_encodings(self):\n","        return self.target_encodings\n","\n","    def set_target_encodings(self, target_encodings):\n","        del self.target_encodings\n","        self.target_encodings = target_encodings\n","        if is_remote_execution:\n","            torch.cuda.empty_cache()\n","\n","    def get_source_encodings(self):\n","        return self.source_encodings\n","\n","    def set_source_encodings(self, source_encodings):\n","        del self.source_encodings\n","        self.source_encodings = source_encodings\n","        if is_remote_execution:\n","            torch.cuda.empty_cache()\n","\n","    def get_target_encodings_train(self):\n","        return self.target_encodings_train\n","\n","    def set_target_encodings_train(self, target_encodings_train):\n","        del self.target_encodings_train\n","        self.target_encodings_train = target_encodings_train\n","        if is_remote_execution:\n","            torch.cuda.empty_cache()\n","\n","    def get_source_encodings_train(self):\n","        return self.source_encodings_train\n","\n","    def set_source_encodings_train(self, source_encodings_train):\n","        del self.source_encodings_train\n","        self.source_encodings_train = source_encodings_train\n","        if is_remote_execution:\n","            torch.cuda.empty_cache()\n","\n","    def get_target_encodings_test(self):\n","        return self.target_encodings_test\n","\n","    def set_target_encodings_test(self, target_encodings_test):\n","        del self.target_encodings_test\n","        self.target_encodings_test = target_encodings_test\n","        if is_remote_execution:\n","            torch.cuda.empty_cache()\n","\n","    def get_source_encodings_test(self):\n","        return self.source_encodings_test\n","\n","    def set_source_encodings_test(self, source_encodings_test):\n","        del self.source_encodings_test\n","        self.source_encodings_test = source_encodings_test\n","        if is_remote_execution:\n","            torch.cuda.empty_cache()\n","\n","    def get_max_src_seq_obs(self):\n","        return self.max_src_seq_obs\n","\n","    def set_max_src_seq_obs(self, max_src_seq_obs):\n","        self.max_src_seq_obs = max_src_seq_obs\n","\n","    def get_max_tgt_seq_obs(self):\n","        return self.max_tgt_seq_obs\n","\n","    def set_max_tgt_seq_obs(self, max_tgt_seq_obs):\n","        self.max_tgt_seq_obs = max_tgt_seq_obs\n","\n","\n","# class name matches file name\n","class dataset_transformer_setimesbyt5():\n","\n","    def __init__(self,\n","                 datasets_directory=root_filepath+\"resources\",\n","                 raw_dataset_directory=\"raw_datasets/setimes\",\n","                 parsed_dataset_directory=\"parsed_datasets/setimes\",\n","                 ids_filename='SETIMES.en-tr.ids',\n","                 en_filename='SETIMES.en-tr.en',\n","                 tr_filename='SETIMES.en-tr.tr',\n","                 dataset_hyperparameters=None):\n","        self.datasets_directory = datasets_directory\n","        self.raw_dataset_directory = raw_dataset_directory\n","        self.parsed_dataset_directory = parsed_dataset_directory\n","        self.ids_filename = ids_filename\n","        self.en_filename = en_filename\n","        self.tr_filename = tr_filename\n","        self.parsed_dataset_filename = None\n","        if 'parsed_dataset_filename' in dataset_hyperparameters:\n","            self.parsed_dataset_filename = dataset_hyperparameters['parsed_dataset_filename']\n","        self.sentence_length_min_percentile = None\n","        if 'sentence_length_min_percentile' in dataset_hyperparameters:\n","            self.sentence_length_min_percentile = dataset_hyperparameters['sentence_length_min_percentile']\n","        self.sentence_length_max_percentile = None\n","        if 'sentence_length_max_percentile' in dataset_hyperparameters:\n","            self.sentence_length_max_percentile = dataset_hyperparameters['sentence_length_max_percentile']\n","\n","    def read_dataset(self):\n","        dataset_holder = None\n","        if self.parsed_dataset_filename is not None:\n","            dataset_holder = torch.load(self.datasets_directory + \"/\"\n","                                        + self.parsed_dataset_directory + \"/\"\n","                                        + self.parsed_dataset_filename)\n","        else:\n","            target_sentences = list()\n","            source_sentences = list()\n","            index_file = open(self.datasets_directory + \"/\" + self.raw_dataset_directory + \"/\" + self.ids_filename)\n","            en_file = open(self.datasets_directory + \"/\" + self.raw_dataset_directory + \"/\" + self.en_filename)\n","            tr_file = open(self.datasets_directory + \"/\" + self.raw_dataset_directory + \"/\" + self.tr_filename)\n","            indices = list()\n","            en_sentences = list()\n","            tr_sentences = list()\n","            line_number = 1\n","            for line in index_file:\n","                line_segments = line.strip().split()\n","                if len(line_segments) != 4:\n","                    print(\"Line segmentation error on line \" + str(line_number))\n","                    print(\"Content: \" + line)\n","                    continue\n","                if line_segments[0].startswith(\"en\") and line_segments[1].startswith(\"tr\"):\n","                    indices.append((int(line_segments[2]), int(line_segments[3])))\n","                elif line_segments[0].startswith(\"tr\") and line_segments[1].startswith(\"en\"):\n","                    indices.append((int(line_segments[3]), int(line_segments[2])))\n","                else:\n","                    print(\"Index parsing error on line \" + str(line_number))\n","                    print(\"Content: \" + line)\n","                    continue\n","                line_number = line_number + 1\n","            for line in en_file:\n","                en_sentences.append(line.strip())\n","            for line in tr_file:\n","                tr_sentences.append(line.strip())\n","            for index in indices:\n","                target_sentences.append(en_sentences[index[0] - 1])\n","                source_sentences.append(tr_sentences[index[1] - 1])\n","            target_sentence_lengths = list()\n","            for sentence in target_sentences:\n","                target_sentence_lengths.append(len(sentence))\n","            source_sentence_lengths = list()\n","            for sentence in source_sentences:\n","                source_sentence_lengths.append(len(sentence))\n","            target_sentences_length_limited = list()\n","            source_sentences_length_limited = list()\n","            target_min_len = int(np.percentile(sorted(target_sentence_lengths), self.sentence_length_min_percentile))\n","            target_max_len = int(np.percentile(sorted(target_sentence_lengths), self.sentence_length_max_percentile))\n","            source_min_len = int(np.percentile(sorted(source_sentence_lengths), self.sentence_length_min_percentile))\n","            source_max_len = int(np.percentile(sorted(source_sentence_lengths), self.sentence_length_max_percentile))\n","            max_src_seq_obs = 0\n","            max_tgt_seq_obs = 0\n","            for i in range(0, len(target_sentences)):\n","                if (len(target_sentences[i]) > target_min_len and len(target_sentences[i]) <= target_max_len\n","                        and len(source_sentences[i]) > source_min_len and len(source_sentences[i]) <= source_max_len):\n","                    if len(source_sentences[i]) > max_src_seq_obs:\n","                        max_src_seq_obs = len(source_sentences[i])\n","                    if len(target_sentences[i]) > max_tgt_seq_obs:\n","                        max_tgt_seq_obs = len(target_sentences[i])\n","                    target_sentences_length_limited.append(target_sentences[i].translate(english_char_mappings))\n","                    source_sentences_length_limited.append(source_sentences[i].translate(turkish_char_mappings))\n","            dataset_holder = DatasetHolder()\n","            dataset_holder.set_max_src_seq_obs(max_src_seq_obs)\n","            dataset_holder.set_max_tgt_seq_obs(max_tgt_seq_obs)\n","            # encode to Pytorch tensors as raw UTF-8 character vocabulary\n","            # method replicated from Xue 2021 - ByT5 - Introduction, sec 3.1\n","            unknown_vocabulary_type = \"\\u0120\".encode('utf-8').decode('utf-8')\n","            padding_vocabulary_type = \"\\u0121\".encode('utf-8').decode('utf-8')\n","            end_of_sequence_vocabulary_type = \"\\u0122\".encode('utf-8').decode('utf-8')\n","            dataset_holder.set_unknown_vocabulary_type(unknown_vocabulary_type)\n","            dataset_holder.set_padding_vocabulary_type(padding_vocabulary_type)\n","            dataset_holder.set_end_of_sequence_vocabulary_type(end_of_sequence_vocabulary_type)\n","            target_vocab = list([unknown_vocabulary_type, padding_vocabulary_type, end_of_sequence_vocabulary_type])\n","            source_vocab = list([unknown_vocabulary_type, padding_vocabulary_type, end_of_sequence_vocabulary_type])\n","            target_encodings = list()\n","            source_encodings = list()\n","            for entry in target_sentences_length_limited:\n","                encoding = list()\n","                for character in entry:\n","                    if character not in target_vocab:\n","                        target_vocab.append(character)\n","                    encoding.append(target_vocab.index(character))\n","                encoding.append(target_vocab.index(end_of_sequence_vocabulary_type))\n","                target_encodings.append(torch.tensor(encoding))\n","            for entry in source_sentences_length_limited:\n","                encoding = list()\n","                for character in entry:\n","                    if character not in source_vocab:\n","                        source_vocab.append(character)\n","                    encoding.append(source_vocab.index(character))\n","                encoding.append(target_vocab.index(end_of_sequence_vocabulary_type))\n","                source_encodings.append(torch.tensor(encoding))\n","            # fix vocabulary indices using tuple type\n","            dataset_holder.set_target_vocab(tuple(target_vocab))\n","            dataset_holder.set_target_encodings(target_encodings)\n","            dataset_holder.set_source_vocab(tuple(source_vocab))\n","            dataset_holder.set_source_encodings(source_encodings)\n","            dataset_holder = DatasetUtils.create_dataset_segments(dataset_holder)\n","            torch.save(dataset_holder,\n","                       self.datasets_directory + \"/\" +\n","                       self.parsed_dataset_directory + \"/\" +\n","                       \"setimes_parsed-\" + str(int(time.time())))\n","        return dataset_holder\n","\n","\n","class dataset_transformer_newscommentary:\n","\n","    def __init__(self,\n","                 datasets_directory=root_filepath+\"resources\",\n","                 raw_dataset_directory=\"raw_datasets/SMTNewsCommentary\",\n","                 parsed_dataset_directory=\"parsed_datasets/SMTNewsCommentary\",\n","                 translations_file='News-Commentary.en-kk.tmx',\n","                 dataset_hyperparameters=None):\n","        self.datasets_directory = datasets_directory\n","        self.raw_dataset_directory = raw_dataset_directory\n","        self.parsed_dataset_directory = parsed_dataset_directory\n","        self.translations_file = translations_file\n","        self.parsed_dataset_filename = None\n","        if 'parsed_dataset_filename' in dataset_hyperparameters:\n","            self.parsed_dataset_filename = dataset_hyperparameters['parsed_dataset_filename']\n","        self.sentence_length_min_percentile = None\n","        if 'sentence_length_min_percentile' in dataset_hyperparameters:\n","            self.sentence_length_min_percentile = dataset_hyperparameters['sentence_length_min_percentile']\n","        self.sentence_length_max_percentile = None\n","        if 'sentence_length_max_percentile' in dataset_hyperparameters:\n","            self.sentence_length_max_percentile = dataset_hyperparameters['sentence_length_max_percentile']\n","\n","    def read_dataset(self):\n","        dataset_holder = None\n","        if self.parsed_dataset_filename is not None:\n","            dataset_holder = torch.load(self.datasets_directory + \"/\"\n","                                        + self.parsed_dataset_directory + \"/\"\n","                                        + self.parsed_dataset_filename)\n","        else:\n","            translations_filepath = self.datasets_directory + \"/\" + self.raw_dataset_directory + \"/\" + self.translations_file\n","            en_sentences = list()\n","            kk_sentences = list()\n","            body_element = ElementTree.parse(translations_filepath).getroot()[1]\n","            for i in range(0, len(body_element)):\n","                if len(body_element[i]) != 2 or len(body_element[i][0]) != 1 or len(body_element[i][1]) != 1:\n","                    print(f\"Error: translation entry {i} did not have expected structure\")\n","                    print(f\"Last English translation: {en_sentences[-1]}\")\n","                if (body_element[i][0].attrib['{http://www.w3.org/XML/1998/namespace}lang'] == 'en' and\n","                    body_element[i][1].attrib['{http://www.w3.org/XML/1998/namespace}lang'] == 'kk'):\n","                    en_sentences.append(body_element[i][0][0].text.strip())\n","                    kk_sentences.append(body_element[i][1][0].text.strip())\n","                elif (body_element[i][0].attrib['{http://www.w3.org/XML/1998/namespace}lang'] == 'kk' and\n","                      body_element[i][1].attrib['{http://www.w3.org/XML/1998/namespace}lang'] == 'en'):\n","                    kk_sentences.append(body_element[i][0][0].text.strip())\n","                    en_sentences.append(body_element[i][1][0].text.strip())\n","                else:\n","                    print(f\"Error: translation entry {i} did not have expected structure\")\n","                    print(f\"Last English translation: {en_sentences[-1]}\")\n","            en_sentence_lengths = list()\n","            for sentence in en_sentences:\n","                en_sentence_lengths.append(len(sentence))\n","            kk_sentence_lengths = list()\n","            for sentence in kk_sentences:\n","                kk_sentence_lengths.append(len(sentence))\n","            en_sentences_length_limited = list()\n","            kk_sentences_length_limited = list()\n","            en_min_len = int(np.percentile(sorted(en_sentence_lengths), self.sentence_length_min_percentile))\n","            en_max_len = 256 # matches max length from SETimes\n","            kk_min_len = int(np.percentile(sorted(kk_sentence_lengths), self.sentence_length_min_percentile))\n","            kk_max_len = int(np.percentile(sorted(kk_sentence_lengths), self.sentence_length_max_percentile))\n","            max_src_seq_obs = 0\n","            max_tgt_seq_obs = 0\n","            for i in range(0, len(en_sentences)):\n","                if (len(en_sentences[i]) > en_min_len and len(en_sentences[i]) <= en_max_len\n","                        and len(kk_sentences[i]) > kk_min_len and len(kk_sentences[i]) <= kk_max_len):\n","                    if len(kk_sentences[i]) > max_src_seq_obs:\n","                        max_src_seq_obs = len(kk_sentences[i])\n","                    if len(en_sentences[i]) > max_tgt_seq_obs:\n","                        max_tgt_seq_obs = len(en_sentences[i])\n","                    en_sentences_length_limited.append(en_sentences[i].translate(enkk_english_character_mappings))\n","                    kk_sentences_length_limited.append(kk_sentences[i].translate(enkk_kazakh_character_mappings))\n","            dataset_holder = DatasetHolder()\n","            dataset_holder.set_max_src_seq_obs(max_src_seq_obs)\n","            dataset_holder.set_max_tgt_seq_obs(max_tgt_seq_obs)\n","            # encode to Pytorch tensors as raw UTF-8 character vocabulary\n","            # method replicated from Xue 2021 - ByT5 - Introduction, sec 3.1\n","            unknown_vocabulary_type = \"\\u0120\".encode('utf-8').decode('utf-8')\n","            padding_vocabulary_type = \"\\u0121\".encode('utf-8').decode('utf-8')\n","            end_of_sequence_vocabulary_type = \"\\u0122\".encode('utf-8').decode('utf-8')\n","            dataset_holder.set_unknown_vocabulary_type(unknown_vocabulary_type)\n","            dataset_holder.set_padding_vocabulary_type(padding_vocabulary_type)\n","            dataset_holder.set_end_of_sequence_vocabulary_type(end_of_sequence_vocabulary_type)\n","            en_vocab = tuple(['Ġ', 'ġ', 'Ģ', 'K', 'o', 's', 'v', ' ', 'i', 't', 'a', 'k', 'n', 'g', 'h', 'r', 'd', 'l', 'p', 'c', 'e', 'f', 'u', 'm', '.', 'B', 'y', 'M', 'j', 'S', 'E', 'T', 'P', '-', '2', '1', '/', '0', '3', 'F', 'w', ',', 'b', \"'\", '[', 'R', ']', 'O', 'x', '\"', 'H', 'I', 'D', '9', 'A', '6', ':', 'q', 'V', ';', '7', 'z', '%', 'W', 'J', 'L', 'G', 'C', 'N', '5', '4', 'U', 'Z', '(', ')', '8', '?', 'Y', '$', 'Q', 'X'])\n","            kk_vocab = list([unknown_vocabulary_type, padding_vocabulary_type, end_of_sequence_vocabulary_type])\n","            en_encodings = list()\n","            kk_encodings = list()\n","            for entry in en_sentences_length_limited:\n","                encoding = list()\n","                for character in entry:\n","                    encoding.append(en_vocab.index(character))\n","                encoding.append(en_vocab.index(end_of_sequence_vocabulary_type))\n","                en_encodings.append(torch.tensor(encoding))\n","            for entry in kk_sentences_length_limited:\n","                encoding = list()\n","                for character in entry:\n","                    if character not in kk_vocab:\n","                        kk_vocab.append(character)\n","                    encoding.append(kk_vocab.index(character))\n","                encoding.append(kk_vocab.index(end_of_sequence_vocabulary_type))\n","                kk_encodings.append(torch.tensor(encoding))\n","            # fix vocabulary indices using tuple type\n","            dataset_holder.set_target_vocab(tuple(en_vocab))\n","            dataset_holder.set_target_encodings(en_encodings)\n","            dataset_holder.set_source_vocab(tuple(kk_vocab))\n","            dataset_holder.set_source_encodings(kk_encodings)\n","            dataset_holder = DatasetUtils.create_dataset_segments(dataset_holder)\n","            torch.save(dataset_holder,\n","                       self.datasets_directory + \"/\" +\n","                       self.parsed_dataset_directory + \"/\" +\n","                       \"SMTNewsCommentary_parsed-\" + str(int(time.time())))\n","        return dataset_holder\n","\n","\n","class Utils:\n","\n","    def __init__(self):\n","        pass\n","\n","    @staticmethod\n","    def load_python_object(object_path: str, object_attribute: str):\n","        path_segments = object_path.split('.')\n","        module = __import__(object_path)\n","        for segment in path_segments[1:]:\n","            module = getattr(module, segment)\n","        return getattr(module, object_attribute)\n","\n","\n","class DatasetUtils:\n","\n","    @staticmethod\n","    def shuffle_dataset(dataset_holder: DatasetHolder):\n","        new_source_encodings, new_target_encodings = (\n","            DatasetUtils.shuffle_lists(\n","                dataset_holder.get_source_encodings(),\n","                dataset_holder.get_target_encodings()\n","            )\n","        )\n","        dataset_holder.set_source_encodings(new_source_encodings)\n","        dataset_holder.set_target_encodings(new_target_encodings)\n","        return dataset_holder\n","\n","    @staticmethod\n","    def shuffle_training_dataset(dataset_holder: DatasetHolder):\n","        new_source_encodings, new_target_encodings = (\n","            DatasetUtils.shuffle_lists(\n","                dataset_holder.get_source_encodings_train(),\n","                dataset_holder.get_target_encodings_train()\n","            )\n","        )\n","        dataset_holder.set_source_encodings(new_source_encodings)\n","        dataset_holder.set_target_encodings(new_target_encodings)\n","        return dataset_holder\n","\n","    @staticmethod\n","    def shuffle_test_dataset(dataset_holder: DatasetHolder):\n","        new_source_encodings, new_target_encodings = (\n","            DatasetUtils.shuffle_lists(\n","                dataset_holder.get_source_encodings_test(),\n","                dataset_holder.get_target_encodings_test()\n","            )\n","        )\n","        dataset_holder.set_source_encodings(new_source_encodings)\n","        dataset_holder.set_target_encodings(new_target_encodings)\n","        return dataset_holder\n","\n","    @staticmethod\n","    def shuffle_lists(source_list, target_list):\n","        assert len(source_list) == len(target_list)\n","        list_element_shuffle_indices = list(range(0, len(source_list)))\n","        random.shuffle(list_element_shuffle_indices)\n","        new_source_list = list()\n","        new_target_list = list()\n","        for i in list_element_shuffle_indices:\n","            new_source_list.append(source_list[i])\n","            new_target_list.append(target_list[i])\n","        assert (len(new_source_list) == len(new_target_list)\n","                == len(source_list) == len(target_list))\n","        return new_source_list, new_target_list\n","\n","    @staticmethod\n","    def create_dataset_segments(dataset_holder: DatasetHolder):\n","        split_with_even_target_distribution = False\n","        iteration = 1\n","        best_split_target_encodings = None\n","        best_split_source_encodings = None\n","        best_split_deviation_from_desired = 1\n","        segments = 20\n","        split_size = len(dataset_holder.get_target_encodings()) // segments\n","        train_size = split_size * (segments - 1)\n","        while not split_with_even_target_distribution and iteration <= 20000:\n","            segment_attempt_start = time.time()\n","            dataset_holder = DatasetUtils.shuffle_dataset(dataset_holder)\n","            target_encodings = dataset_holder.get_target_encodings()\n","            source_encodings = dataset_holder.get_source_encodings()\n","            train_set_target_enc = target_encodings[0:train_size]\n","            test_set_target_enc = target_encodings[train_size:]\n","            numpy_encodings = list()\n","            for encoding in train_set_target_enc:\n","                numpy_encodings.append(encoding.flatten().numpy())\n","            train_set_target_enc_cts = np.bincount(\n","                np.concatenate([\n","                    np.concatenate(numpy_encodings),\n","                    np.arange(0, 170)\n","                ])\n","            )\n","            numpy_encodings = list()\n","            for encoding in test_set_target_enc:\n","                numpy_encodings.append(encoding.flatten().numpy())\n","            test_set_target_enc_cts = np.bincount(\n","                np.concatenate([\n","                    np.concatenate(numpy_encodings),\n","                    np.arange(0, 170)\n","                ])\n","            )\n","            # terms with probability ~ 1%\n","            total_5 = train_set_target_enc_cts[5] + test_set_target_enc_cts[5]\n","            total_40 = train_set_target_enc_cts[40] + test_set_target_enc_cts[40]\n","            total_42 = train_set_target_enc_cts[42] + test_set_target_enc_cts[42]\n","            # top 3 terms\n","            total_7 = train_set_target_enc_cts[7] + test_set_target_enc_cts[7]\n","            total_15 = train_set_target_enc_cts[15] + test_set_target_enc_cts[15]\n","            total_12 = train_set_target_enc_cts[12] + test_set_target_enc_cts[12]\n","            train_dist_goal = (segments - 1)/segments\n","            test_dist_goal = (1 / segments)\n","            deviation_from_desired = (\n","                    np.abs(((segments - 2)/segments) - (train_set_target_enc_cts[5] / total_5)) +\n","                    np.abs(train_dist_goal - (train_set_target_enc_cts[40] / total_40)) +\n","                    np.abs(train_dist_goal - (train_set_target_enc_cts[42] / total_42)) +\n","                    np.abs(train_dist_goal - (train_set_target_enc_cts[7] / total_7)) +\n","                    np.abs(train_dist_goal - (train_set_target_enc_cts[15] / total_15)) +\n","                    np.abs(train_dist_goal - (train_set_target_enc_cts[12] / total_12)) +\n","                    np.abs(test_dist_goal - (test_set_target_enc_cts[5] / total_5)) +\n","                    np.abs(test_dist_goal - (test_set_target_enc_cts[40] / total_40)) +\n","                    np.abs(test_dist_goal - (test_set_target_enc_cts[42] / total_42)) +\n","                    np.abs(test_dist_goal - (test_set_target_enc_cts[7] / total_7)) +\n","                    np.abs(test_dist_goal - (test_set_target_enc_cts[15] / total_15)) +\n","                    np.abs(test_dist_goal - (test_set_target_enc_cts[12] / total_12))\n","            )\n","            if deviation_from_desired <= 12 * 0.0001:\n","                split_with_even_target_distribution = True\n","                best_split_target_encodings = target_encodings\n","                best_split_source_encodings = source_encodings\n","                print(f\"Found dataset split within tolerance for deviation from uniform distribution over characters\")\n","            if deviation_from_desired < best_split_deviation_from_desired:\n","                best_split_target_encodings = target_encodings\n","                best_split_source_encodings = source_encodings\n","                best_split_deviation_from_desired = deviation_from_desired\n","            segment_attempt_end = time.time()\n","            print(f\"Completed data split attempt. \"\n","                  f\"iteration:{iteration} \"\n","                  f\"best_split_deviation_from_desired:{best_split_deviation_from_desired} \"\n","                  f\"time_to_complete_attempt:{segment_attempt_end-segment_attempt_start}\")\n","            iteration = iteration + 1\n","        best_split_source_encodings_train = best_split_source_encodings[0:train_size]\n","        best_split_target_encodings_train = best_split_target_encodings[0:train_size]\n","        assert len(best_split_source_encodings_train) == len(best_split_target_encodings_train)\n","        train_split_encoding_length_sum_and_encoding_index_pairs = list()\n","        for i in range(0, len(best_split_source_encodings_train)):\n","            train_split_encoding_length_sum_and_encoding_index_pairs.append(\n","                list([\n","                    best_split_source_encodings_train[i].shape[0] + best_split_target_encodings_train[i].shape[0],\n","                    np.abs(best_split_source_encodings_train[i].shape[0] - best_split_target_encodings_train[i].shape[0]),\n","                    i\n","                ])\n","            )\n","        train_split_encoding_length_sum_and_encoding_index_pairs = sorted(\n","            train_split_encoding_length_sum_and_encoding_index_pairs,\n","            key=lambda pair: (pair[0], pair[1])\n","        )\n","        train_source_encs_length_sorted = list()\n","        train_target_encs_length_sorted = list()\n","        for encoding_length_sum_and_encoding_index_pair in train_split_encoding_length_sum_and_encoding_index_pairs:\n","            train_source_encs_length_sorted.append(best_split_source_encodings_train[encoding_length_sum_and_encoding_index_pair[2]])\n","            train_target_encs_length_sorted.append(best_split_target_encodings_train[encoding_length_sum_and_encoding_index_pair[2]])\n","        best_split_source_encodings_test = best_split_source_encodings[train_size:]\n","        best_split_target_encodings_test = best_split_target_encodings[train_size:]\n","        assert len(best_split_source_encodings_test) == len(best_split_target_encodings_test)\n","        test_split_encoding_length_sum_and_encoding_index_pairs = list()\n","        for i in range(0, len(best_split_source_encodings_test)):\n","            test_split_encoding_length_sum_and_encoding_index_pairs.append(\n","                list([\n","                    best_split_source_encodings_test[i].shape[0] + best_split_target_encodings_test[i].shape[0],\n","                    np.abs(best_split_source_encodings_test[i].shape[0] - best_split_target_encodings_test[i].shape[0]),\n","                    i\n","                ])\n","            )\n","        test_split_encoding_length_sum_and_encoding_index_pairs = sorted(\n","            test_split_encoding_length_sum_and_encoding_index_pairs,\n","            key=lambda pair: (pair[0], pair[1])\n","        )\n","        test_source_encs_length_sorted = list()\n","        test_target_encs_length_sorted = list()\n","        for encoding_length_sum_and_encoding_index_pair in test_split_encoding_length_sum_and_encoding_index_pairs:\n","            test_source_encs_length_sorted.append(best_split_source_encodings_test[encoding_length_sum_and_encoding_index_pair[2]])\n","            test_target_encs_length_sorted.append(best_split_target_encodings_test[encoding_length_sum_and_encoding_index_pair[2]])\n","        dataset_holder.set_source_encodings(best_split_source_encodings)\n","        dataset_holder.set_target_encodings(best_split_target_encodings)\n","        dataset_holder.set_source_encodings_train(train_source_encs_length_sorted)\n","        dataset_holder.set_target_encodings_train(train_target_encs_length_sorted)\n","        dataset_holder.set_source_encodings_test(test_source_encs_length_sorted)\n","        dataset_holder.set_target_encodings_test(test_target_encs_length_sorted)\n","        return dataset_holder\n","\n","    # use a dedicated padding token to pad batches as in Xue 2021 - ByT5 - Sec 3.1\n","    @staticmethod\n","    def prepare_batches(\n","            source_encodings,\n","            target_encodings,\n","            source_vocab,\n","            target_vocab,\n","            batch_size_limit: int,\n","            element_difference_limit: int,\n","            padding_value):\n","        assert len(source_encodings) == len(target_encodings)\n","        total_elements = len(source_encodings)\n","        source_encodings_batches = list()\n","        target_encodings_batches = list()\n","        source_encodings_tensors = list()\n","        target_encodings_tensors = list()\n","        encodings_index = 0\n","        while encodings_index < total_elements - 1:\n","            batch_size = 0\n","            batch_end_reached = False\n","            min_source_enc_len = source_encodings[encodings_index+batch_size].shape[0]\n","            max_source_enc_len = source_encodings[encodings_index+batch_size].shape[0]\n","            min_target_enc_len = target_encodings[encodings_index+batch_size].shape[0]\n","            max_target_enc_len = target_encodings[encodings_index+batch_size].shape[0]\n","            while not batch_end_reached:\n","                if (max(abs(source_encodings[encodings_index+batch_size].shape[0] - min_source_enc_len),\n","                        abs(source_encodings[encodings_index+batch_size].shape[0] - max_source_enc_len)) > element_difference_limit\n","                        or max(abs(target_encodings[encodings_index+batch_size].shape[0] - min_target_enc_len),\n","                               abs(target_encodings[encodings_index+batch_size].shape[0] - max_target_enc_len)) > element_difference_limit):\n","                    batch_end_reached = True\n","                if batch_size == batch_size_limit - 1:\n","                    batch_end_reached = True\n","                if encodings_index + batch_size + 1 < total_elements:\n","                    batch_size = batch_size + 1\n","                else:\n","                    batch_end_reached = True\n","            max_src_len_for_batch = 0\n","            max_tgt_len_for_batch = 0\n","            for batch_index in range(0, batch_size):\n","                if len(source_encodings[encodings_index+batch_index]) > max_src_len_for_batch:\n","                    max_src_len_for_batch = len(source_encodings[encodings_index+batch_index])\n","                if len(target_encodings[encodings_index+batch_index]) > max_tgt_len_for_batch:\n","                    max_tgt_len_for_batch = len(target_encodings[encodings_index+batch_index])\n","            for batch_index in range(0, batch_size):\n","                source_encoding = source_encodings[encodings_index]\n","                target_encoding = target_encodings[encodings_index]\n","                source_encodings_tensors.append(\n","                    torch.nn.functional.pad(\n","                        source_encoding,\n","                        (0, max_src_len_for_batch - len(source_encoding)),\n","                        value=source_vocab.index(padding_value)\n","                    )\n","                )\n","                target_encodings_tensors.append(\n","                    torch.nn.functional.pad(\n","                        target_encoding,\n","                        (0, max_tgt_len_for_batch - len(target_encoding)),\n","                        value=target_vocab.index(padding_value)\n","                    )\n","                )\n","                encodings_index = encodings_index + 1\n","            if batch_size > 0:\n","                source_batch = torch.stack(source_encodings_tensors)\n","                target_batch = torch.stack(target_encodings_tensors)\n","                source_encodings_batches.append(source_batch)\n","                target_encodings_batches.append(target_batch)\n","            source_encodings_tensors = list()\n","            target_encodings_tensors = list()\n","        target_encodings_batches_with_index = list()\n","        for i in range(0, len(target_encodings_batches)):\n","            target_encodings_batches_with_index.append(list([target_encodings_batches[i], i]))\n","        assert len(target_encodings_batches_with_index) == len(target_encodings_batches)\n","        target_encodings_batches_with_index_sorted = sorted(\n","            target_encodings_batches_with_index,\n","            key=lambda batch_pair: (-batch_pair[0].shape[0], -batch_pair[0].shape[1])\n","        )\n","        source_encodings_batches_sorted = list()\n","        target_encodings_batches_sorted = list()\n","        for i in range(0, len(target_encodings_batches_with_index_sorted)):\n","            source_encodings_batches_sorted.append(\n","                source_encodings_batches[target_encodings_batches_with_index_sorted[i][1]]\n","            )\n","            target_encodings_batches_sorted.append(\n","                target_encodings_batches[target_encodings_batches_with_index_sorted[i][1]]\n","            )\n","        del source_encodings_tensors\n","        del target_encodings_tensors\n","        del source_encodings_batches\n","        del target_encodings_batches\n","        del target_encodings_batches_with_index_sorted\n","        return source_encodings_batches_sorted, target_encodings_batches_sorted\n","\n","    @staticmethod\n","    def prepare_training_batches(\n","            dataset_holder: DatasetHolder,\n","            batch_size_limit: int,\n","            element_difference_limit: int):\n","        source_encodings_batches, target_encodings_batches = DatasetUtils.prepare_batches(\n","            dataset_holder.get_source_encodings_train(),\n","            dataset_holder.get_target_encodings_train(),\n","            dataset_holder.get_source_vocab(),\n","            dataset_holder.get_target_vocab(),\n","            batch_size_limit,\n","            element_difference_limit,\n","            dataset_holder.get_padding_vocabulary_type()\n","        )\n","\n","        source_vocab_counts = {}\n","        for i in range(0, len(dataset_holder.get_source_vocab())):\n","            source_vocab_counts[i] = 0\n","        for source_encoding_batch in source_encodings_batches:\n","            for source_encoding in source_encoding_batch:\n","                for character in source_encoding:\n","                    source_vocab_counts[character.item()] = source_vocab_counts[character.item()] + 1\n","        target_vocab_counts = {}\n","        for i in range(0, len(dataset_holder.get_target_vocab())):\n","            target_vocab_counts[i] = 0\n","        for target_vocab_batch in target_encodings_batches:\n","            for target_encoding in target_vocab_batch:\n","                for character in target_encoding:\n","                    if character.item() not in target_vocab_counts:\n","                        target_vocab_counts[character.item()] = 0\n","                    target_vocab_counts[character.item()] = target_vocab_counts[character.item()] + 1\n","        dataset_holder.set_source_vocab_counts(source_vocab_counts)\n","        dataset_holder.set_target_vocab_counts(target_vocab_counts)\n","        return source_encodings_batches, target_encodings_batches\n","\n","    @staticmethod\n","    def decode_target_tensor(dataset_holder: DatasetHolder, tensor_to_decode):\n","        vocab = dataset_holder.get_target_vocab_numpy()\n","        decoded_tensor = np.take(vocab, tensor_to_decode.detach().to(device=\"cpu\").flatten().numpy())\n","        return \"\".join(decoded_tensor.tolist())\n","\n","    @staticmethod\n","    def decode_source_tensor(dataset_holder: DatasetHolder, tensor_to_decode):\n","        vocab = dataset_holder.get_source_vocab_numpy()\n","        decoded_tensor = np.take(vocab, tensor_to_decode.detach().to(device=\"cpu\").flatten().numpy())\n","        return \"\".join(decoded_tensor.tolist())\n","\n","\n","# class name matches file name\n","class transformer_vaswani2017(torch.nn.Transformer):\n","\n","    def __init__(self,\n","                 model_hyperparameters):\n","        super().__init__(\n","            d_model=model_hyperparameters['d_model'],\n","            nhead=model_hyperparameters['nhead'],\n","            num_encoder_layers=model_hyperparameters['num_encoder_layers'],\n","            num_decoder_layers=model_hyperparameters['num_decoder_layers'],\n","            dim_feedforward=model_hyperparameters['dim_feedforward'],\n","            dropout=model_hyperparameters['dropout'],\n","            activation=model_hyperparameters['activation'],\n","            custom_encoder=model_hyperparameters['custom_encoder'],\n","            custom_decoder=model_hyperparameters['custom_decoder'],\n","            layer_norm_eps=model_hyperparameters['layer_norm_eps'],\n","            batch_first=model_hyperparameters['batch_first'],\n","            norm_first=model_hyperparameters['norm_first'],\n","            bias=model_hyperparameters['bias'],\n","            device=model_hyperparameters['device'],\n","            dtype=model_hyperparameters['dtype']\n","        )\n","        self.model_hyperparameters = model_hyperparameters\n","        # add one for the end of sequence token\n","        self.max_src_seq_len = model_hyperparameters['max_src_seq_len'] + 1\n","        self.max_tgt_seq_len = model_hyperparameters['max_tgt_seq_len'] + 1\n","        self.src_embeddings = torch.nn.Embedding(\n","            model_hyperparameters['src_vocab_size'],\n","            model_hyperparameters['d_model']\n","        )\n","        self.tgt_embeddings = torch.nn.Embedding(\n","            model_hyperparameters['tgt_vocab_size'],\n","            model_hyperparameters['d_model']\n","        )\n","        self.src_pos_enc = torch.nn.Embedding(\n","            self.max_src_seq_len,\n","            model_hyperparameters['d_model']\n","        ).requires_grad_(False)\n","        self.tgt_pos_enc = torch.nn.Embedding(\n","            self.max_tgt_seq_len,\n","            model_hyperparameters['d_model']\n","        ).requires_grad_(False)\n","        self.linear_output_projection_1 = torch.nn.Linear(\n","            self.max_tgt_seq_len,\n","            1,\n","            bias=False\n","        )\n","        self.linear_output_projection_2 = torch.nn.Linear(\n","            model_hyperparameters['d_model'],\n","            model_hyperparameters['tgt_vocab_size'],\n","            bias=False\n","        )\n","        self.logsoftmax_output = torch.nn.LogSoftmax(dim=1)\n","        self.model_hyperparameters = model_hyperparameters\n","        self.tgt_mask_cache = {}\n","        for i in range(1, self.max_tgt_seq_len + 1):\n","            tgt_mask = self.generate_square_subsequent_mask(i)\n","            if is_remote_execution:\n","                self.tgt_mask_cache[i] = tgt_mask.to(device=\"cuda\")\n","            self.tgt_mask_cache[i] = tgt_mask\n","        self.indices_cache = {}\n","        for i in range(1, max([self.max_src_seq_len, self.max_tgt_seq_len]) + 1):\n","            indices = torch.tensor(np.arange(0, i), dtype=torch.long)\n","            if is_remote_execution:\n","                indices = indices.to(device=\"cuda\")\n","            self.indices_cache[i] = indices\n","\n","    def forward(self,\n","                src: torch.Tensor,\n","                tgt: torch.Tensor,\n","                src_mask: Optional[torch.Tensor] = None,\n","                tgt_mask: Optional[torch.Tensor] = None,\n","                memory_mask: Optional[torch.Tensor] = None,\n","                src_key_padding_mask: Optional[torch.Tensor] = None,\n","                tgt_key_padding_mask: Optional[torch.Tensor] = None,\n","                memory_key_padding_mask: Optional[torch.Tensor] = None,\n","                src_is_causal: Optional[bool] = None,\n","                tgt_is_causal: Optional[bool] = True,\n","                memory_is_causal: bool = False) -> torch.Tensor:\n","        src_embedding_pos_enc = self.src_embeddings(src) + self.src_pos_enc(self.indices_cache[src.shape[1]])\n","        tgt_embedding_pos_enc = self.tgt_embeddings(tgt) + self.tgt_pos_enc(self.indices_cache[tgt.shape[1]])\n","        tgt_mask = self.tgt_mask_cache[tgt.shape[1]]\n","        transformer_output = super().forward(src_embedding_pos_enc, tgt_embedding_pos_enc, src_mask,\n","                                             tgt_mask, memory_mask, src_key_padding_mask,\n","                                             tgt_key_padding_mask, memory_key_padding_mask,\n","                                             src_is_causal, tgt_is_causal, memory_is_causal)\n","        transformer_output = torch.swapaxes(transformer_output, -1, -2)\n","        transformer_output = torch.nn.functional.pad(\n","            transformer_output,\n","            (0, self.max_tgt_seq_len - transformer_output.shape[2]),\n","            value=0\n","        )\n","        output = self.logsoftmax_output(\n","            self.linear_output_projection_2(\n","                torch.squeeze(\n","                    self.linear_output_projection_1(\n","                        transformer_output\n","                    ),\n","                    dim=2\n","                )\n","            )\n","        )\n","        del src_embedding_pos_enc\n","        del tgt_embedding_pos_enc\n","        del transformer_output\n","        return output\n","\n","    def freeze_target_embeddings(self):\n","        del self.tgt_embeddings\n","        self.tgt_embeddings = torch.nn.Embedding(\n","            self.model_hyperparameters['tgt_vocab_size'],\n","            self.model_hyperparameters['d_model']\n","        ).requires_grad_(False)\n","        del self.linear_output_projection_1\n","        self.linear_output_projection_1 = torch.nn.Linear(\n","            self.max_tgt_seq_len,\n","            1,\n","            bias=False\n","        ).requires_grad_(False)\n","        del self.linear_output_projection_2\n","        self.linear_output_projection_2 = torch.nn.Linear(\n","            self.model_hyperparameters['d_model'],\n","            self.model_hyperparameters['tgt_vocab_size'],\n","            bias=False\n","        ).requires_grad_(False)\n","\n","    def set_source_embeddings_for_transfer_learning(self, source_embeddings_dim):\n","        del self.src_embeddings\n","        self.src_embeddings = torch.nn.Embedding(\n","            source_embeddings_dim,\n","            self.model_hyperparameters['d_model']\n","        )\n","\n","\n","class model_trainer_kocmi2018():\n","\n","    def __init__(self,\n","                 trainer_hyperparameters=None,\n","                 model_parameter_directory=None,\n","                 trainer_parameter_directory=None,\n","                 runner_hyperparameters_name=None,\n","                 latest_param_filename_tag=None):\n","        self.trainer_hyperparameters = trainer_hyperparameters\n","        self.optimizer_name = self.trainer_hyperparameters['optimizer_name']\n","        self.initial_lr = self.trainer_hyperparameters['initial_lr']\n","        self.exp_decay = self.trainer_hyperparameters['exp_decay']\n","        self.lr_scheduler_name = self.trainer_hyperparameters['lr_scheduler_name']\n","        self.epochs = self.trainer_hyperparameters['epochs']\n","        self.epoch_starting_index = self.trainer_hyperparameters['epoch_starting_index']\n","        self.batch_size_limit = self.trainer_hyperparameters['batch_size_limit']\n","        self.element_difference_limit = self.trainer_hyperparameters['element_difference_limit']\n","        self.batch_starting_index = self.trainer_hyperparameters['batch_starting_index']\n","        self.model_parameter_directory = model_parameter_directory\n","        self.trainer_parameter_directory = trainer_parameter_directory\n","        self.runner_hyperparameters_name = runner_hyperparameters_name\n","        self.latest_param_filename_tag = latest_param_filename_tag\n","        self.dataset_holder = None\n","        self.model = None\n","        self.source_encoding_batches = None\n","        self.target_encoding_batches = None\n","        self.optimizer = None\n","        self.lr_scheduler = None\n","        self.loss_fcn = None\n","\n","    def init_trainer(self):\n","        self.source_encoding_batches, self.target_encoding_batches = (\n","            DatasetUtils.prepare_training_batches(\n","                self.dataset_holder,\n","                self.batch_size_limit,\n","                self.element_difference_limit\n","            )\n","        )\n","        # get_target_vocab_counts requires that training batches have been prepared\n","        # this ensures that vocab counts include padding and eos tokens\n","        loss_weights = list()\n","        for vocab_term in self.dataset_holder.get_target_vocab():\n","            weight_for_term = 0\n","            if self.dataset_holder.get_target_vocab_counts()[self.dataset_holder.get_target_vocab().index(vocab_term)] != 0:\n","                weight_for_term = 1 / self.dataset_holder.get_target_vocab_counts()[\n","                    self.dataset_holder.get_target_vocab().index(vocab_term)\n","                ]\n","            loss_weights.append(\n","                weight_for_term\n","            )\n","        # set padding to have 0 weight\n","        loss_weights[\n","            self.dataset_holder.get_target_vocab().index(self.dataset_holder.get_padding_vocabulary_type())] = 0\n","        loss_weights = torch.tensor(loss_weights, dtype=torch.float)\n","        if is_remote_execution:\n","            torch.cuda.empty_cache()\n","            self.model.cuda()\n","            loss_weights = loss_weights.to(device=\"cuda\")\n","        self.loss_fcn = torch.nn.NLLLoss(weight=loss_weights)\n","        _optimizer_class_ = Utils.load_python_object('torch.optim', self.optimizer_name)\n","        self.optimizer = _optimizer_class_(self.model.parameters(), lr=self.initial_lr)\n","        _lr_scheduler_class_ = Utils.load_python_object('torch.optim.lr_scheduler', self.lr_scheduler_name)\n","        # constructor call assumes that the scheduler is the ExponentialLR scheduler\n","        self.lr_scheduler = _lr_scheduler_class_(self.optimizer, self.exp_decay)\n","        # scheduler_parameter_filepath = self.trainer_parameter_directory + \"/\" + self.runner_hyperparameters_name + \"-\" + self.latest_param_filename_tag + \"-scheduler.params\"\n","        # scheduler_parameters = torch.load(scheduler_parameter_filepath)\n","        # self.lr_scheduler.load_state_dict(scheduler_parameters)\n","        parameter_count = 0\n","        bytes_consumed = 0\n","        for parameter in self.model.parameters():\n","            if parameter.requires_grad:\n","                parameter_count = parameter_count + np.prod(parameter.data.shape)\n","                bytes_consumed = bytes_consumed + parameter.data.nbytes\n","        gb_consumed = bytes_consumed / 1024 / 1024 / 1024\n","        print(f\"Model trainer initialization complete.\"\n","              f\"Trainer will run on model with parameter count {parameter_count} \"\n","              f\"and parameter memory use {gb_consumed} GB\")\n","\n","    # pretraining is not used for monolingual english as described in Xue 2021 - ByT5 - Sec 3.1\n","    def run_trainer(self):\n","        assert self.epoch_starting_index < self.epochs\n","        for i in range(self.epoch_starting_index, self.epochs):\n","            while self.lr_scheduler.state_dict()['last_epoch'] > i:\n","                print(f\"Updating lr_scheduler: {self.lr_scheduler.state_dict()}\")\n","                self.lr_scheduler.step()\n","            epoch_start = time.time()\n","            print(f\"Beginning epoch {i+1} of {self.epochs} with scheduler {self.lr_scheduler.state_dict()}\")\n","            # if i > 0:\n","            #     self.source_encoding_batches, self.target_encoding_batches = DatasetUtils.shuffle_lists(\n","            #         self.source_encoding_batches, self.target_encoding_batches\n","            #     )\n","            source_batches = None\n","            target_batches = None\n","            if is_remote_execution:\n","                source_batches = list()\n","                target_batches = list()\n","                for batch in self.source_encoding_batches:\n","                    source_batches.append(batch.to(device=\"cuda\"))\n","                    del batch\n","                for batch in self.target_encoding_batches:\n","                    target_batches.append(batch.to(device=\"cuda\"))\n","                    del batch\n","                torch.cuda.empty_cache()\n","            else:\n","                source_batches = self.source_encoding_batches\n","                target_batches = self.target_encoding_batches\n","            assert len(source_batches) == len(target_batches)\n","            batch_ct = len(source_batches)\n","            batch_size = source_batches[0].shape[0]\n","            samples_passed = 0\n","            last_log = 0\n","            last_loss = 0\n","            note_step_prediction = False\n","            step_prediction_at_percentage_of_sample = 0\n","            total_batch_time = 0\n","            assert self.batch_starting_index < batch_ct\n","            for j in range(self.batch_starting_index, batch_ct):\n","                batch_start = time.time()\n","                batch_sequence_length = target_batches[j].shape[1]\n","                step_prediction_step_number = int(batch_sequence_length * step_prediction_at_percentage_of_sample)\n","                print(f\"Starting batch.\")\n","                print(f\"epoch:{i+1}/{self.epochs} batch:{j+1}/{batch_ct} batch_size:{target_batches[j].shape[0]}\")\n","                for k in range(1, batch_sequence_length-1):\n","                    target_batch_slices = torch.tensor_split(target_batches[j], [k], dim=1)\n","                    self.model.zero_grad()\n","                    output_logits = self.model.forward(\n","                        source_batches[j],\n","                        target_batch_slices[0]\n","                    )\n","                    next_word_indices = target_batch_slices[1][:, 0]\n","                    last_loss = self.loss_fcn(output_logits, next_word_indices)\n","                    last_loss.backward()\n","                    self.optimizer.step()\n","                    if note_step_prediction and k == step_prediction_step_number:\n","                        note_step_prediction = False\n","                        full_sequence = DatasetUtils.decode_target_tensor(self.dataset_holder, target_batches[j][0])\n","                        prefix_sequence = DatasetUtils.decode_target_tensor(\n","                            self.dataset_holder,\n","                            target_batch_slices[0][0]\n","                        )\n","                        next_token = DatasetUtils.decode_target_tensor(\n","                            self.dataset_holder,\n","                            next_word_indices[0]\n","                        )\n","                        predicted_token = DatasetUtils.decode_target_tensor(\n","                            self.dataset_holder,\n","                            torch.argmax(output_logits[0])\n","                        )\n","                        print(f\"Next token prediction. step:{k}/{batch_sequence_length} \"\n","                              f\"batch:{j+1}/{batch_ct} epoch:{i+1}/{self.epochs}\")\n","                        print(f\"full seq: {full_sequence}\")\n","                        print(f\"pref seq: {prefix_sequence}\")\n","                        print(f\"next tok: {next_token.rjust(k, ' ')}\")\n","                        print(f\"pred tok: {predicted_token.rjust(k, ' ')}\")\n","                        del full_sequence\n","                        del prefix_sequence\n","                        del next_token\n","                        del predicted_token\n","                    del target_batch_slices\n","                    del output_logits\n","                    del next_word_indices\n","                    last_loss = last_loss.detach()\n","                    gc.collect()\n","                    if is_remote_execution:\n","                        torch.cuda.empty_cache()\n","                batch_end = time.time()\n","                batch_time = batch_end - batch_start\n","                total_batch_time = total_batch_time + batch_time\n","                print(f\"Completed batch.\")\n","                print(f\"epoch:{i+1}/{self.epochs} batch:{j+1}/{batch_ct} batch_size:{target_batches[j].shape[0]} loss:{last_loss} \"\n","                      f\"time_for_batch_instance:{batch_time} total_batch_time:{total_batch_time} running_batch_average:{total_batch_time/(j+1)}\")\n","                samples_passed = samples_passed + batch_size\n","                if samples_passed - last_log > 100:\n","                    last_log = samples_passed\n","                    note_step_prediction = True\n","                    step_prediction_at_percentage_of_sample = random.random()\n","                    if is_remote_execution:\n","                        print(f\"Memory usage summary:\")\n","                        print(f\"{torch.cuda.memory_summary()}\")\n","                        torch.cuda.reset_max_memory_allocated()\n","                        torch.cuda.reset_max_memory_cached()\n","                        torch.cuda.reset_peak_memory_stats()\n","                    param_filename_tag = str(int(time.time()))\n","                    torch.save(\n","                        self.model.state_dict(),\n","                        self.model_parameter_directory + \"/\" + self.runner_hyperparameters_name + \"-\" + param_filename_tag + \"-model.params\"\n","                    )\n","                    torch.save(\n","                        self.lr_scheduler.state_dict(),\n","                        self.trainer_parameter_directory + \"/\" + self.runner_hyperparameters_name + \"-\" + param_filename_tag + \"-scheduler.params\"\n","                    )\n","                    torch.save(\n","                        f\"epoch:{i+1}/{self.epochs} batch:{j+1}/{batch_ct}\",\n","                        self.trainer_parameter_directory + \"/\" + self.runner_hyperparameters_name + \"-\" + param_filename_tag + \"-trainer.params\"\n","                    )\n","            del source_batches\n","            del target_batches\n","            gc.collect()\n","            if is_remote_execution:\n","                torch.cuda.empty_cache()\n","            self.lr_scheduler.step()\n","            epoch_end = time.time()\n","            print(f\"Completed epoch {i+1}/{self.epochs} in {(epoch_end - epoch_start) / 60 }m\")\n","            print(f\"epoch:{i+1}, batch:{j+1}/{batch_ct}, loss:{last_loss}\")\n","\n","    def get_dataset_holder(self):\n","        return self.dataset_holder\n","\n","    def set_dataset_holder(self, dataset_holder):\n","        self.dataset_holder = dataset_holder\n","\n","    def get_model(self):\n","        return self.model\n","\n","    def set_model(self, model):\n","        self.model = model\n","\n","\n","class Runner:\n","\n","    def __init__(self,\n","                 model_parameter_directory=root_filepath+\"resources/model_parameters\",\n","                 trainer_parameter_directory=root_filepath+\"resources/trainer_parameters\",\n","                 runner_hyperparameters_name=\"NewsCommentaryByT5Vaswani2017Kocmi2018_1\"):\n","        self.model_parameter_directory = model_parameter_directory\n","        self.trainer_parameter_directory = trainer_parameter_directory\n","        self.runner_hyperparameters_name = runner_hyperparameters_name\n","        self.runner_hyperparameters = NewsCommentaryByT5Vaswani2017Kocmi2018_1\n","        self.dataset_holder: DatasetHolder = None\n","        self.model = None\n","        self.trainer = None\n","        self.latest_param_filename_tag = ''\n","        if 'latest_param_filename_tag' in self.runner_hyperparameters:\n","            self.latest_param_filename_tag = self.runner_hyperparameters['latest_param_filename_tag']\n","        print(f\"Initialized runner {runner_hyperparameters_name} with parameters {self.runner_hyperparameters}\")\n","\n","    def load_dataset(self):\n","        dataset_transformer_name = self.runner_hyperparameters.get('dataset_transformer_name')\n","        dataset_hyperparameters = self.runner_hyperparameters.get('dataset_transformer_hyperparameters')\n","        dataset_transformer = dataset_transformer_newscommentary(dataset_hyperparameters=dataset_hyperparameters)\n","        self.dataset_holder = dataset_transformer.read_dataset()\n","\n","    def load_model(self):\n","        model_hyperparameters = self.runner_hyperparameters.get('model_hyperparameters')\n","        model_hyperparameters['src_vocab_size'] = 91\n","        model_hyperparameters['tgt_vocab_size'] = 81\n","        model_hyperparameters['max_src_seq_len'] = self.dataset_holder.get_max_src_seq_obs()\n","        model_hyperparameters['max_tgt_seq_len'] = 256\n","        model_parameter_filepath = self.model_parameter_directory + \"/\" + self.runner_hyperparameters_name + \"-\" + self.latest_param_filename_tag + \"-model.params\"\n","        self.model = transformer_vaswani2017(model_hyperparameters=model_hyperparameters)\n","        self.model.freeze_target_embeddings()\n","        model_parameters = torch.load(model_parameter_filepath)\n","        self.model.load_state_dict(model_parameters)\n","        self.model.set_source_embeddings_for_transfer_learning(len(self.dataset_holder.get_source_vocab()))\n","\n","    def load_trainer(self):\n","        trainer_hyperparameters = self.runner_hyperparameters.get('trainer_hyperparameters')\n","        self.trainer = model_trainer_kocmi2018(\n","            trainer_hyperparameters=trainer_hyperparameters,\n","            model_parameter_directory=self.model_parameter_directory,\n","            trainer_parameter_directory=self.trainer_parameter_directory,\n","            runner_hyperparameters_name=self.runner_hyperparameters_name,\n","            latest_param_filename_tag=self.latest_param_filename_tag\n","        )\n","\n","    def run_trainer(self):\n","        self.trainer.set_dataset_holder(self.dataset_holder)\n","        self.trainer.set_model(self.model)\n","        self.trainer.init_trainer()\n","        self.trainer.run_trainer()\n"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"1qcv-CZAnpo1","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ab25da96-7cab-4ebc-91ca-0b87a199b50c","executionInfo":{"status":"ok","timestamp":1715966142154,"user_tz":240,"elapsed":3380536,"user":{"displayName":"Matthew Johnson","userId":"09672185346885346735"}}},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Initialized runner NewsCommentaryByT5Vaswani2017Kocmi2018_1 with parameters {'dataset_transformer_name': 'dataset_transformer_newscommentary', 'model_name': 'transformer_vaswani2017', 'trainer_name': 'model_trainer_kocmi2018', 'latest_param_filename_tag': '1715937961', 'dataset_transformer_hyperparameters': {'sentence_length_min_percentile': 5, 'sentence_length_max_percentile': 95, 'parsed_dataset_filename': 'SMTNewsCommentary_parsed-1715949808'}, 'model_hyperparameters': {'d_model': 256, 'nhead': 8, 'num_encoder_layers': 9, 'num_decoder_layers': 3, 'dim_feedforward': 1796, 'dropout': 0.1, 'activation': <function relu at 0x7eb06c4c69e0>, 'custom_encoder': None, 'custom_decoder': None, 'layer_norm_eps': 1e-05, 'batch_first': True, 'norm_first': False, 'bias': True, 'device': None, 'dtype': None}, 'trainer_hyperparameters': {'optimizer_name': 'Adam', 'lr_scheduler_name': 'ExponentialLR', 'initial_lr': 0.0005, 'exp_decay': 0.5, 'epochs': 1, 'epoch_starting_index': 0, 'batch_size_limit': 250, 'element_difference_limit': 19, 'batch_starting_index': 0}}\n","Model trainer initialization complete.Trainer will run on model with parameter count 15060016 and parameter memory use 0.0561029314994812 GB\n","Beginning epoch 1 of 1 with scheduler {'gamma': 0.5, 'base_lrs': [0.0005], 'last_epoch': 0, 'verbose': False, '_step_count': 1, '_get_lr_called_within_step': False, '_last_lr': [0.0005]}\n","Starting batch.\n","epoch:1/1 batch:1/430 batch_size:196\n","Completed batch.\n","epoch:1/1 batch:1/430 batch_size:196 loss:6.291789531707764 time_for_batch_instance:18.982128858566284 total_batch_time:18.982128858566284 running_batch_average:18.982128858566284\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 280179 KiB |   4345 MiB |    926 GiB |    926 GiB |\n","|       from large pool | 196827 KiB |   4270 MiB |    920 GiB |    920 GiB |\n","|       from small pool |  83352 KiB |    110 MiB |      6 GiB |      5 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 280179 KiB |   4345 MiB |    926 GiB |    926 GiB |\n","|       from large pool | 196827 KiB |   4270 MiB |    920 GiB |    920 GiB |\n","|       from small pool |  83352 KiB |    110 MiB |      6 GiB |      5 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB |   4331 MiB |    924 GiB |    924 GiB |\n","|       from large pool | 189056 KiB |   4257 MiB |    918 GiB |    918 GiB |\n","|       from small pool |  83061 KiB |    109 MiB |      6 GiB |      5 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 641024 KiB |   4624 MiB | 214836 MiB | 214210 MiB |\n","|       from large pool | 552960 KiB |   4522 MiB | 213780 MiB | 213240 MiB |\n","|       from small pool |  88064 KiB |    114 MiB |   1056 MiB |    970 MiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 360844 KiB | 501876 KiB | 339697 MiB | 339344 MiB |\n","|       from large pool | 356133 KiB | 496124 KiB | 332656 MiB | 332308 MiB |\n","|       from small pool |   4711 KiB |  25111 KiB |   7041 MiB |   7036 MiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   82063    |   80259    |\n","|       from large pool |      98    |     248    |   46799    |   46701    |\n","|       from small pool |    1706    |    1850    |   35264    |   33558    |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   82063    |   80259    |\n","|       from large pool |      98    |     248    |   46799    |   46701    |\n","|       from small pool |    1706    |    1850    |   35264    |   33558    |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      64    |     151    |    4640    |    4576    |\n","|       from large pool |      21    |     100    |    4112    |    4091    |\n","|       from small pool |      43    |      57    |     528    |     485    |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      57    |      91    |   41442    |   41385    |\n","|       from large pool |      27    |      68    |   31202    |   31175    |\n","|       from small pool |      30    |      46    |   10240    |   10210    |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/cuda/memory.py:330: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/cuda/memory.py:356: FutureWarning: torch.cuda.reset_max_memory_cached now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      80    |      92    |   36136 K  |   36135 K  |\n","|       from large pool |      16    |      20    |   20411 K  |   20411 K  |\n","|       from small pool |      64    |      75    |   15724 K  |   15724 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:345/430 batch_size:2\n","Next token prediction. step:162/194 batch:345/430 epoch:1/1\n","full seq: Rather than using this month's National Congress of the Communist Party as a catalyst for reform, China kicks the can down the road, continuing on a path of excessive leverage and overcapacity.Ģ\n","pref seq: Rather than using this month's National Congress of the Communist Party as a catalyst for reform, China kicks the can down the road, continuing on a path of exces\n","next tok:                                                                                                                                                                  s\n","pred tok:                                                                                                                                                                   \n","Completed batch.\n","epoch:1/1 batch:345/430 batch_size:2 loss:5.613894939422607 time_for_batch_instance:34.04316258430481 total_batch_time:13374.983361244202 running_batch_average:38.76806771375131\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 277229 KiB | 355517 KiB | 266116 GiB | 266116 GiB |\n","|       from large pool | 193876 KiB | 240215 KiB | 255209 GiB | 255209 GiB |\n","|       from small pool |  83352 KiB | 121064 KiB |  10906 GiB |  10906 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 277229 KiB | 355517 KiB | 266116 GiB | 266116 GiB |\n","|       from large pool | 193876 KiB | 240215 KiB | 255209 GiB | 255209 GiB |\n","|       from small pool |  83352 KiB | 121064 KiB |  10906 GiB |  10906 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 349032 KiB | 262295 GiB | 262295 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 251392 GiB | 251392 GiB |\n","|       from small pool |  83061 KiB | 120755 KiB |  10903 GiB |  10903 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 382976 KiB | 407552 KiB |  42124 GiB |  42123 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 100352 KiB | 124928 KiB |    997 GiB |    996 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 105747 KiB | 168277 KiB | 168159 GiB | 168159 GiB |\n","|       from large pool |  88747 KiB | 135224 KiB | 156331 GiB | 156331 GiB |\n","|       from small pool |  16999 KiB |  40697 KiB |  11827 GiB |  11827 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   80587 K  |   80585 K  |\n","|       from large pool |      98    |     122    |   35112 K  |   35111 K  |\n","|       from small pool |    1706    |    1850    |   45475 K  |   45473 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   80587 K  |   80585 K  |\n","|       from large pool |      98    |     122    |   35112 K  |   35111 K  |\n","|       from small pool |    1706    |    1850    |   45475 K  |   45473 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      61    |      73    |    2077 K  |    2076 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      49    |      61    |     510 K  |     510 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      64    |      88    |   36226 K  |   36226 K  |\n","|       from large pool |      13    |      18    |   20433 K  |   20433 K  |\n","|       from small pool |      51    |      74    |   15792 K  |   15792 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:346/430 batch_size:2\n","Next token prediction. step:56/193 batch:346/430 epoch:1/1\n","full seq: Of course, as I note in my recent book on past, present, and future currencies, governments that issue large-denomination bills also risk aiding tax evasion and crime.Ģġġġġġġġġġġġġġġġġġġġġġġġġġ\n","pref seq: Of course, as I note in my recent book on past, present,\n","next tok:                                                         \n","pred tok:                                                        ġ\n","Completed batch.\n","epoch:1/1 batch:346/430 batch_size:2 loss:3.5170319080352783 time_for_batch_instance:33.91736149787903 total_batch_time:13408.90072274208 running_batch_average:38.75404833162451\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 277196 KiB | 364361 KiB | 266236 GiB | 266236 GiB |\n","|       from large pool | 193844 KiB | 243584 KiB | 255279 GiB | 255279 GiB |\n","|       from small pool |  83352 KiB | 124342 KiB |  10956 GiB |  10956 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 277196 KiB | 364361 KiB | 266236 GiB | 266236 GiB |\n","|       from large pool | 193844 KiB | 243584 KiB | 255279 GiB | 255279 GiB |\n","|       from small pool |  83352 KiB | 124342 KiB |  10956 GiB |  10956 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 357867 KiB | 262410 GiB | 262410 GiB |\n","|       from large pool | 189056 KiB | 237389 KiB | 251457 GiB | 251456 GiB |\n","|       from small pool |  83061 KiB | 124040 KiB |  10953 GiB |  10953 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 395264 KiB | 411648 KiB |  42126 GiB |  42126 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 112640 KiB | 129024 KiB |    999 GiB |    999 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 118067 KiB | 168283 KiB | 168284 GiB | 168284 GiB |\n","|       from large pool |  88780 KiB | 135224 KiB | 156401 GiB | 156401 GiB |\n","|       from small pool |  29287 KiB |  42412 KiB |  11883 GiB |  11883 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   80810 K  |   80808 K  |\n","|       from large pool |      98    |     122    |   35146 K  |   35145 K  |\n","|       from small pool |    1706    |    1850    |   45664 K  |   45662 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   80810 K  |   80808 K  |\n","|       from large pool |      98    |     122    |   35146 K  |   35145 K  |\n","|       from small pool |    1706    |    1850    |   45664 K  |   45662 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      67    |      75    |    2078 K  |    2078 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      55    |      63    |     511 K  |     511 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      86    |      98    |   36315 K  |   36315 K  |\n","|       from large pool |      15    |      20    |   20456 K  |   20456 K  |\n","|       from small pool |      71    |      81    |   15859 K  |   15859 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:347/430 batch_size:2\n","Next token prediction. step:127/192 batch:347/430 epoch:1/1\n","full seq: But a gradualist approach that includes the permanent withdrawal of large notes would have served the cause better, even if it did not generate the same \"shock and awe\" as the current policy.Ģ\n","pref seq: But a gradualist approach that includes the permanent withdrawal of large notes would have served the cause better, even if it \n","next tok:                                                                                                                               d\n","pred tok:                                                                                                                               .\n","Completed batch.\n","epoch:1/1 batch:347/430 batch_size:2 loss:4.197149276733398 time_for_batch_instance:33.98384094238281 total_batch_time:13442.884563684464 running_batch_average:38.74030133626646\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 278868 KiB | 341600 KiB | 266332 GiB | 266332 GiB |\n","|       from large pool | 195516 KiB | 242517 KiB | 255323 GiB | 255322 GiB |\n","|       from small pool |  83352 KiB | 122572 KiB |  11009 GiB |  11009 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 278868 KiB | 341600 KiB | 266332 GiB | 266332 GiB |\n","|       from large pool | 195516 KiB | 242517 KiB | 255323 GiB | 255322 GiB |\n","|       from small pool |  83352 KiB | 122572 KiB |  11009 GiB |  11009 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 330946 KiB | 262505 GiB | 262504 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 251498 GiB | 251498 GiB |\n","|       from small pool |  83061 KiB | 122272 KiB |  11006 GiB |  11006 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 385024 KiB | 409600 KiB |  42129 GiB |  42129 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 102400 KiB | 126976 KiB |   1002 GiB |   1002 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 106155 KiB | 168279 KiB | 168385 GiB | 168385 GiB |\n","|       from large pool |  87108 KiB | 135224 KiB | 156445 GiB | 156445 GiB |\n","|       from small pool |  19047 KiB |  42501 KiB |  11940 GiB |  11940 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   81031 K  |   81029 K  |\n","|       from large pool |      98    |     122    |   35167 K  |   35167 K  |\n","|       from small pool |    1706    |    1850    |   45863 K  |   45861 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   81031 K  |   81029 K  |\n","|       from large pool |      98    |     122    |   35167 K  |   35167 K  |\n","|       from small pool |    1706    |    1850    |   45863 K  |   45861 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      62    |      74    |    2079 K  |    2079 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      50    |      62    |     513 K  |     513 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      66    |      88    |   36397 K  |   36397 K  |\n","|       from large pool |      13    |      17    |   20468 K  |   20468 K  |\n","|       from small pool |      53    |      73    |   15928 K  |   15928 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:348/430 batch_size:2\n","Next token prediction. step:149/191 batch:348/430 epoch:1/1\n","full seq: But German Chancellor Angela Merkel has effectively thrown cold water on his proposals, suggesting, for example, risibly small amounts of money for investment in areas that urgently need it.Ģ\n","pref seq: But German Chancellor Angela Merkel has effectively thrown cold water on his proposals, suggesting, for example, risibly small amounts of money for i\n","next tok:                                                                                                                                                     n\n","pred tok:                                                                                                                                                      \n","Completed batch.\n","epoch:1/1 batch:348/430 batch_size:2 loss:5.462591171264648 time_for_batch_instance:33.70829391479492 total_batch_time:13476.592857599258 running_batch_average:38.72584154482546\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 277332 KiB | 350788 KiB | 266443 GiB | 266442 GiB |\n","|       from large pool | 193980 KiB | 244313 KiB | 255386 GiB | 255385 GiB |\n","|       from small pool |  83352 KiB | 119470 KiB |  11056 GiB |  11056 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 277332 KiB | 350788 KiB | 266443 GiB | 266442 GiB |\n","|       from large pool | 193980 KiB | 244313 KiB | 255386 GiB | 255385 GiB |\n","|       from small pool |  83352 KiB | 119470 KiB |  11056 GiB |  11056 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 344139 KiB | 262609 GiB | 262608 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 251555 GiB | 251555 GiB |\n","|       from small pool |  83061 KiB | 119181 KiB |  11053 GiB |  11053 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 385024 KiB | 407552 KiB |  42131 GiB |  42131 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 102400 KiB | 124928 KiB |   1004 GiB |   1004 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 107691 KiB | 168280 KiB | 168500 GiB | 168500 GiB |\n","|       from large pool |  88644 KiB | 135224 KiB | 156508 GiB | 156508 GiB |\n","|       from small pool |  19047 KiB |  38405 KiB |  11992 GiB |  11992 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   81251 K  |   81250 K  |\n","|       from large pool |      98    |     122    |   35199 K  |   35199 K  |\n","|       from small pool |    1706    |    1850    |   46052 K  |   46050 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   81251 K  |   81250 K  |\n","|       from large pool |      98    |     122    |   35199 K  |   35199 K  |\n","|       from small pool |    1706    |    1850    |   46052 K  |   46050 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      62    |      73    |    2080 K  |    2080 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      50    |      61    |     514 K  |     514 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      69    |      79    |   36483 K  |   36483 K  |\n","|       from large pool |      15    |      18    |   20489 K  |   20489 K  |\n","|       from small pool |      54    |      67    |   15994 K  |   15994 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:349/430 batch_size:2\n","Next token prediction. step:93/190 batch:349/430 epoch:1/1\n","full seq: Today the advanced countries that are the most exposed to the international economy are also those where safety nets and social insurance programs - welfare states - are the most extensive.Ģ\n","pref seq: Today the advanced countries that are the most exposed to the international economy are also \n","next tok:                                                                                             t\n","pred tok:                                                                                             Ģ\n","Completed batch.\n","epoch:1/1 batch:349/430 batch_size:2 loss:5.962311744689941 time_for_batch_instance:33.6129150390625 total_batch_time:13510.205772638321 running_batch_average:38.71119132561123\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 277249 KiB | 360366 KiB | 266558 GiB | 266558 GiB |\n","|       from large pool | 193897 KiB | 241185 KiB | 255453 GiB | 255453 GiB |\n","|       from small pool |  83352 KiB | 122962 KiB |  11105 GiB |  11104 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 277249 KiB | 360366 KiB | 266558 GiB | 266558 GiB |\n","|       from large pool | 193897 KiB | 241185 KiB | 255453 GiB | 255453 GiB |\n","|       from small pool |  83352 KiB | 122962 KiB |  11105 GiB |  11104 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 353466 KiB | 262719 GiB | 262719 GiB |\n","|       from large pool | 189056 KiB | 234588 KiB | 251618 GiB | 251617 GiB |\n","|       from small pool |  83061 KiB | 122657 KiB |  11101 GiB |  11101 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 391168 KiB | 409600 KiB |  42133 GiB |  42133 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 108544 KiB | 126976 KiB |   1006 GiB |   1006 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 113918 KiB | 167003 KiB | 168620 GiB | 168620 GiB |\n","|       from large pool |  88727 KiB | 135224 KiB | 156575 GiB | 156575 GiB |\n","|       from small pool |  25191 KiB |  40695 KiB |  12045 GiB |  12045 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   81471 K  |   81469 K  |\n","|       from large pool |      98    |     122    |   35233 K  |   35233 K  |\n","|       from small pool |    1706    |    1850    |   46237 K  |   46236 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   81471 K  |   81469 K  |\n","|       from large pool |      98    |     122    |   35233 K  |   35233 K  |\n","|       from small pool |    1706    |    1850    |   46237 K  |   46236 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      65    |      74    |    2081 K  |    2081 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      53    |      62    |     515 K  |     515 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      76    |      86    |   36570 K  |   36570 K  |\n","|       from large pool |      15    |      19    |   20510 K  |   20510 K  |\n","|       from small pool |      61    |      70    |   16060 K  |   16059 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:350/430 batch_size:2\n","Next token prediction. step:29/190 batch:350/430 epoch:1/1\n","full seq: During the first half of 2013, for example, Malaysia's government spent Ġ118.5 million more on ads than the next four advertisers combined.Ģġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġ\n","pref seq: During the first half of 2013\n","next tok:                             ,\n","pred tok:                             ġ\n","Completed batch.\n","epoch:1/1 batch:350/430 batch_size:2 loss:11.601104736328125 time_for_batch_instance:33.892821073532104 total_batch_time:13544.098593711853 running_batch_average:38.69742455346244\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 279553 KiB | 350217 KiB | 266668 GiB | 266667 GiB |\n","|       from large pool | 196201 KiB | 245137 KiB | 255516 GiB | 255516 GiB |\n","|       from small pool |  83352 KiB | 119125 KiB |  11151 GiB |  11151 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 279553 KiB | 350217 KiB | 266668 GiB | 266667 GiB |\n","|       from large pool | 196201 KiB | 245137 KiB | 255516 GiB | 255516 GiB |\n","|       from small pool |  83352 KiB | 119125 KiB |  11151 GiB |  11151 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 342989 KiB | 262822 GiB | 262822 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 251674 GiB | 251674 GiB |\n","|       from small pool |  83061 KiB | 118836 KiB |  11148 GiB |  11148 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 380928 KiB | 407552 KiB |  42136 GiB |  42136 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool |  98304 KiB | 124928 KiB |   1009 GiB |   1009 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 101374 KiB | 166133 KiB | 168735 GiB | 168735 GiB |\n","|       from large pool |  86423 KiB | 135224 KiB | 156638 GiB | 156638 GiB |\n","|       from small pool |  14951 KiB |  35608 KiB |  12096 GiB |  12096 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   81690 K  |   81688 K  |\n","|       from large pool |      98    |     122    |   35265 K  |   35264 K  |\n","|       from small pool |    1706    |    1850    |   46425 K  |   46423 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   81690 K  |   81688 K  |\n","|       from large pool |      98    |     122    |   35265 K  |   35264 K  |\n","|       from small pool |    1706    |    1850    |   46425 K  |   46423 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      60    |      73    |    2083 K  |    2083 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      48    |      61    |     516 K  |     516 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      69    |      81    |   36656 K  |   36656 K  |\n","|       from large pool |      13    |      19    |   20531 K  |   20531 K  |\n","|       from small pool |      56    |      65    |   16124 K  |   16124 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:351/430 batch_size:2\n","Next token prediction. step:106/190 batch:351/430 epoch:1/1\n","full seq: A world turned inside out, with new dynamism in the developing world far eclipsing lingering malaise in the advanced economies, is new - but hardly normal.Ģġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġ\n","pref seq: A world turned inside out, with new dynamism in the developing world far eclipsing lingering malaise in th\n","next tok:                                                                                                          e\n","pred tok:                                                                                                          e\n","Completed batch.\n","epoch:1/1 batch:351/430 batch_size:2 loss:4.912037372589111 time_for_batch_instance:33.55527925491333 total_batch_time:13577.653872966766 running_batch_average:38.682774566856885\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 277921 KiB | 364787 KiB | 266786 GiB | 266786 GiB |\n","|       from large pool | 194569 KiB | 243752 KiB | 255585 GiB | 255584 GiB |\n","|       from small pool |  83352 KiB | 124859 KiB |  11201 GiB |  11201 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 277921 KiB | 364787 KiB | 266786 GiB | 266786 GiB |\n","|       from large pool | 194569 KiB | 243752 KiB | 255585 GiB | 255584 GiB |\n","|       from small pool |  83352 KiB | 124859 KiB |  11201 GiB |  11201 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 358696 KiB | 262936 GiB | 262936 GiB |\n","|       from large pool | 189056 KiB | 237960 KiB | 251738 GiB | 251738 GiB |\n","|       from small pool |  83061 KiB | 124558 KiB |  11197 GiB |  11197 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 401408 KiB | 413696 KiB |  42138 GiB |  42138 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 118784 KiB | 131072 KiB |   1011 GiB |   1011 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 123486 KiB | 170327 KiB | 168859 GiB | 168859 GiB |\n","|       from large pool |  88055 KiB | 135224 KiB | 156707 GiB | 156707 GiB |\n","|       from small pool |  35431 KiB |  42445 KiB |  12152 GiB |  12152 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   81909 K  |   81907 K  |\n","|       from large pool |      98    |     122    |   35298 K  |   35298 K  |\n","|       from small pool |    1706    |    1850    |   46610 K  |   46609 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   81909 K  |   81907 K  |\n","|       from large pool |      98    |     122    |   35298 K  |   35298 K  |\n","|       from small pool |    1706    |    1850    |   46610 K  |   46609 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      70    |      76    |    2084 K  |    2084 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      58    |      64    |     517 K  |     517 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      82    |      87    |   36743 K  |   36743 K  |\n","|       from large pool |      14    |      19    |   20554 K  |   20554 K  |\n","|       from small pool |      68    |      73    |   16189 K  |   16189 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:352/430 batch_size:2\n","Next token prediction. step:52/190 batch:352/430 epoch:1/1\n","full seq: So long as foreigners are hungry for dollars, the US can spend whatever it needs to project power around the globe, simply by cranking up the printing press.Ģġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġ\n","pref seq: So long as foreigners are hungry for dollars, the US\n","next tok:                                                     \n","pred tok:                                                    ġ\n","Completed batch.\n","epoch:1/1 batch:352/430 batch_size:2 loss:4.437888145446777 time_for_batch_instance:33.48785710334778 total_batch_time:13611.141730070114 running_batch_average:38.66801627860828\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 277921 KiB | 364787 KiB | 266904 GiB | 266904 GiB |\n","|       from large pool | 194569 KiB | 243752 KiB | 255653 GiB | 255653 GiB |\n","|       from small pool |  83352 KiB | 124859 KiB |  11250 GiB |  11250 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 277921 KiB | 364787 KiB | 266904 GiB | 266904 GiB |\n","|       from large pool | 194569 KiB | 243752 KiB | 255653 GiB | 255653 GiB |\n","|       from small pool |  83352 KiB | 124859 KiB |  11250 GiB |  11250 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 358696 KiB | 263050 GiB | 263049 GiB |\n","|       from large pool | 189056 KiB | 237960 KiB | 251803 GiB | 251802 GiB |\n","|       from small pool |  83061 KiB | 124558 KiB |  11247 GiB |  11247 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 401408 KiB | 413696 KiB |  42140 GiB |  42140 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 118784 KiB | 131072 KiB |   1013 GiB |   1013 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 123486 KiB | 170327 KiB | 168983 GiB | 168983 GiB |\n","|       from large pool |  88055 KiB | 135224 KiB | 156775 GiB | 156775 GiB |\n","|       from small pool |  35431 KiB |  42445 KiB |  12207 GiB |  12207 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   82128 K  |   82126 K  |\n","|       from large pool |      98    |     122    |   35331 K  |   35331 K  |\n","|       from small pool |    1706    |    1850    |   46796 K  |   46794 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   82128 K  |   82126 K  |\n","|       from large pool |      98    |     122    |   35331 K  |   35331 K  |\n","|       from small pool |    1706    |    1850    |   46796 K  |   46794 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      70    |      76    |    2085 K  |    2085 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      58    |      64    |     518 K  |     518 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      82    |      87    |   36830 K  |   36830 K  |\n","|       from large pool |      14    |      19    |   20576 K  |   20576 K  |\n","|       from small pool |      68    |      73    |   16253 K  |   16253 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:353/430 batch_size:2\n","Next token prediction. step:25/188 batch:353/430 epoch:1/1\n","full seq: Many of the most worrisome examples of disinformation have been focused not on any particular election or candidate, but instead on exploiting societal divisions along, say, racial lines.Ģ\n","pref seq: Many of the most worrisom\n","next tok:                         e\n","pred tok:                         ġ\n","Completed batch.\n","epoch:1/1 batch:353/430 batch_size:2 loss:4.405200958251953 time_for_batch_instance:34.07562804222107 total_batch_time:13645.217358112335 running_batch_average:38.65500668020491\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 278743 KiB | 341600 KiB | 266996 GiB | 266996 GiB |\n","|       from large pool | 195391 KiB | 242517 KiB | 255695 GiB | 255695 GiB |\n","|       from small pool |  83352 KiB | 121666 KiB |  11301 GiB |  11301 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 278743 KiB | 341600 KiB | 266996 GiB | 266996 GiB |\n","|       from large pool | 195391 KiB | 242517 KiB | 255695 GiB | 255695 GiB |\n","|       from small pool |  83352 KiB | 121666 KiB |  11301 GiB |  11301 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 330946 KiB | 263141 GiB | 263140 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 251843 GiB | 251842 GiB |\n","|       from small pool |  83061 KiB | 121364 KiB |  11298 GiB |  11297 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 391168 KiB | 409600 KiB |  42142 GiB |  42141 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 108544 KiB | 126976 KiB |   1015 GiB |   1014 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 112424 KiB | 170326 KiB | 169080 GiB | 169080 GiB |\n","|       from large pool |  87233 KiB | 135224 KiB | 156817 GiB | 156817 GiB |\n","|       from small pool |  25191 KiB |  40719 KiB |  12263 GiB |  12263 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   82345 K  |   82343 K  |\n","|       from large pool |      98    |     122    |   35353 K  |   35353 K  |\n","|       from small pool |    1706    |    1850    |   46992 K  |   46990 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   82345 K  |   82343 K  |\n","|       from large pool |      98    |     122    |   35353 K  |   35353 K  |\n","|       from small pool |    1706    |    1850    |   46992 K  |   46990 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      65    |      74    |    2086 K  |    2086 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      53    |      62    |     519 K  |     519 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      68    |      84    |   36908 K  |   36908 K  |\n","|       from large pool |      13    |      17    |   20587 K  |   20587 K  |\n","|       from small pool |      55    |      69    |   16320 K  |   16320 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:354/430 batch_size:2\n","Next token prediction. step:8/188 batch:354/430 epoch:1/1\n","full seq: In the US, the only mainstream media organization that ran consistently skeptical articles about the case for war was the Knight Ridder group (which has since been acquired by McClatchy).Ģ\n","pref seq: In the U\n","next tok:        S\n","pred tok:        ġ\n","Completed batch.\n","epoch:1/1 batch:354/430 batch_size:2 loss:4.517773151397705 time_for_batch_instance:34.20534586906433 total_batch_time:13679.4227039814 running_batch_average:38.64243701689661\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 279768 KiB | 349219 KiB | 267105 GiB | 267104 GiB |\n","|       from large pool | 196416 KiB | 246333 KiB | 255757 GiB | 255757 GiB |\n","|       from small pool |  83352 KiB | 118780 KiB |  11347 GiB |  11347 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 279768 KiB | 349219 KiB | 267105 GiB | 267104 GiB |\n","|       from large pool | 196416 KiB | 246333 KiB | 255757 GiB | 255757 GiB |\n","|       from small pool |  83352 KiB | 118780 KiB |  11347 GiB |  11347 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 341640 KiB | 263242 GiB | 263241 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 251898 GiB | 251898 GiB |\n","|       from small pool |  83061 KiB | 118490 KiB |  11343 GiB |  11343 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 385024 KiB | 405504 KiB |  42144 GiB |  42143 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 102400 KiB | 122880 KiB |   1016 GiB |   1016 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 105255 KiB | 166712 KiB | 169192 GiB | 169192 GiB |\n","|       from large pool |  86208 KiB | 135224 KiB | 156879 GiB | 156879 GiB |\n","|       from small pool |  19047 KiB |  38672 KiB |  12313 GiB |  12313 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   82562 K  |   82560 K  |\n","|       from large pool |      98    |     122    |   35384 K  |   35384 K  |\n","|       from small pool |    1706    |    1850    |   47177 K  |   47175 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   82562 K  |   82560 K  |\n","|       from large pool |      98    |     122    |   35384 K  |   35384 K  |\n","|       from small pool |    1706    |    1850    |   47177 K  |   47175 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      62    |      72    |    2087 K  |    2087 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      50    |      60    |     520 K  |     520 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      73    |      85    |   36992 K  |   36992 K  |\n","|       from large pool |      15    |      19    |   20608 K  |   20608 K  |\n","|       from small pool |      58    |      69    |   16384 K  |   16384 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:355/430 batch_size:2\n","Next token prediction. step:73/188 batch:355/430 epoch:1/1\n","full seq: The common economic features, then and now, include low oil prices, a nonviable economic ideology, state ownership of crucial industries, and authoritarian rule.Ģġġġġġġġġġġġġġġġġġġġġġġġġġġ\n","pref seq: The common economic features, then and now, include low oil prices, a non\n","next tok:                                                                         v\n","pred tok:                                                                         N\n","Completed batch.\n","epoch:1/1 batch:355/430 batch_size:2 loss:7.738101005554199 time_for_batch_instance:33.385467290878296 total_batch_time:13712.808171272278 running_batch_average:38.627628651471206\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 277790 KiB | 359494 KiB | 267219 GiB | 267219 GiB |\n","|       from large pool | 194438 KiB | 240309 KiB | 255824 GiB | 255823 GiB |\n","|       from small pool |  83352 KiB | 123134 KiB |  11395 GiB |  11395 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 277790 KiB | 359494 KiB | 267219 GiB | 267219 GiB |\n","|       from large pool | 194438 KiB | 240309 KiB | 255824 GiB | 255823 GiB |\n","|       from small pool |  83352 KiB | 123134 KiB |  11395 GiB |  11395 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 353544 KiB | 263351 GiB | 263351 GiB |\n","|       from large pool | 189056 KiB | 234662 KiB | 251959 GiB | 251959 GiB |\n","|       from small pool |  83061 KiB | 122830 KiB |  11391 GiB |  11391 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 393216 KiB | 409600 KiB |  42145 GiB |  42145 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 110592 KiB | 126976 KiB |   1018 GiB |   1018 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 115425 KiB | 169842 KiB | 169312 GiB | 169311 GiB |\n","|       from large pool |  88186 KiB | 135224 KiB | 156946 GiB | 156946 GiB |\n","|       from small pool |  27239 KiB |  43483 KiB |  12365 GiB |  12365 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   82779 K  |   82777 K  |\n","|       from large pool |      98    |     122    |   35417 K  |   35417 K  |\n","|       from small pool |    1706    |    1850    |   47361 K  |   47359 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   82779 K  |   82777 K  |\n","|       from large pool |      98    |     122    |   35417 K  |   35417 K  |\n","|       from small pool |    1706    |    1850    |   47361 K  |   47359 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      66    |      74    |    2088 K  |    2087 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      54    |      62    |     521 K  |     521 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      77    |      90    |   37078 K  |   37078 K  |\n","|       from large pool |      16    |      19    |   20629 K  |   20629 K  |\n","|       from small pool |      61    |      72    |   16449 K  |   16449 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:356/430 batch_size:2\n","Next token prediction. step:127/187 batch:356/430 epoch:1/1\n","full seq: The same was true with Flynn, who lied time and again to the public, and to Vice President Michael Pence, about his communications with the Russian ambassador before he assumed his post.Ģ\n","pref seq: The same was true with Flynn, who lied time and again to the public, and to Vice President Michael Pence, about his communicati\n","next tok:                                                                                                                               o\n","pred tok:                                                                                                                               .\n","Completed batch.\n","epoch:1/1 batch:356/430 batch_size:2 loss:5.058393955230713 time_for_batch_instance:33.31514239311218 total_batch_time:13746.12331366539 running_batch_average:38.612705937262334\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 279734 KiB | 349026 KiB | 267326 GiB | 267326 GiB |\n","|       from large pool | 196382 KiB | 246333 KiB | 255885 GiB | 255885 GiB |\n","|       from small pool |  83352 KiB | 118780 KiB |  11440 GiB |  11440 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 279734 KiB | 349026 KiB | 267326 GiB | 267326 GiB |\n","|       from large pool | 196382 KiB | 246333 KiB | 255885 GiB | 255885 GiB |\n","|       from small pool |  83352 KiB | 118780 KiB |  11440 GiB |  11440 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 341442 KiB | 263452 GiB | 263451 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 252014 GiB | 252014 GiB |\n","|       from small pool |  83061 KiB | 118490 KiB |  11437 GiB |  11437 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 387072 KiB | 405504 KiB |  42147 GiB |  42147 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 104448 KiB | 122880 KiB |   1020 GiB |   1020 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 107337 KiB | 166712 KiB | 169424 GiB | 169423 GiB |\n","|       from large pool |  86242 KiB | 135224 KiB | 157007 GiB | 157007 GiB |\n","|       from small pool |  21095 KiB |  38672 KiB |  12416 GiB |  12416 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   82994 K  |   82992 K  |\n","|       from large pool |      98    |     122    |   35448 K  |   35448 K  |\n","|       from small pool |    1706    |    1850    |   47545 K  |   47544 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   82994 K  |   82992 K  |\n","|       from large pool |      98    |     122    |   35448 K  |   35448 K  |\n","|       from small pool |    1706    |    1850    |   47545 K  |   47544 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      63    |      72    |    2089 K  |    2088 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      51    |      60    |     522 K  |     522 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      72    |      85    |   37163 K  |   37162 K  |\n","|       from large pool |      15    |      19    |   20650 K  |   20650 K  |\n","|       from small pool |      57    |      69    |   16512 K  |   16512 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:357/430 batch_size:2\n","Next token prediction. step:71/187 batch:357/430 epoch:1/1\n","full seq: The Reagan tax plan used changes in deductions and other accounting rules to pay for major cuts in tax rates that lowered the top rate from 50% to 28%.Ģġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġ\n","pref seq: The Reagan tax plan used changes in deductions and other accounting rul\n","next tok:                                                                       e\n","pred tok:                                                                       ġ\n","Completed batch.\n","epoch:1/1 batch:357/430 batch_size:2 loss:4.976070404052734 time_for_batch_instance:33.20025706291199 total_batch_time:13779.323570728302 running_batch_average:38.597545016045665\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 276721 KiB | 361270 KiB | 267441 GiB | 267441 GiB |\n","|       from large pool | 193369 KiB | 241494 KiB | 255953 GiB | 255953 GiB |\n","|       from small pool |  83352 KiB | 123824 KiB |  11488 GiB |  11488 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 276721 KiB | 361270 KiB | 267441 GiB | 267441 GiB |\n","|       from large pool | 193369 KiB | 241494 KiB | 255953 GiB | 255953 GiB |\n","|       from small pool |  83352 KiB | 123824 KiB |  11488 GiB |  11488 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 355247 KiB | 263562 GiB | 263561 GiB |\n","|       from large pool | 189056 KiB | 235772 KiB | 252076 GiB | 252076 GiB |\n","|       from small pool |  83061 KiB | 123521 KiB |  11485 GiB |  11485 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 395264 KiB | 411648 KiB |  42150 GiB |  42149 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 112640 KiB | 129024 KiB |   1022 GiB |   1022 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 118542 KiB | 166235 KiB | 169544 GiB | 169544 GiB |\n","|       from large pool |  89255 KiB | 135224 KiB | 157075 GiB | 157075 GiB |\n","|       from small pool |  29287 KiB |  39593 KiB |  12469 GiB |  12469 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   83210 K  |   83208 K  |\n","|       from large pool |      98    |     122    |   35481 K  |   35481 K  |\n","|       from small pool |    1706    |    1850    |   47728 K  |   47727 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   83210 K  |   83208 K  |\n","|       from large pool |      98    |     122    |   35481 K  |   35481 K  |\n","|       from small pool |    1706    |    1850    |   47728 K  |   47727 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      67    |      75    |    2090 K  |    2090 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      55    |      63    |     523 K  |     523 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      83    |      92    |   37246 K  |   37246 K  |\n","|       from large pool |      18    |      20    |   20671 K  |   20671 K  |\n","|       from small pool |      65    |      76    |   16575 K  |   16574 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:358/430 batch_size:2\n","Next token prediction. step:1/186 batch:358/430 epoch:1/1\n","full seq: Right-wing populist movements have skillfully played on blue-collar voters' fears by convincing them that traditional labor parties will allow immigrants to flow in virtually unchecked.Ģ\n","pref seq: R\n","next tok: i\n","pred tok: ġ\n","Completed batch.\n","epoch:1/1 batch:358/430 batch_size:2 loss:5.39285135269165 time_for_batch_instance:32.80441951751709 total_batch_time:13812.12799024582 running_batch_average:38.5813631012453\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 276494 KiB | 347889 KiB | 267547 GiB | 267546 GiB |\n","|       from large pool | 193142 KiB | 242924 KiB | 256013 GiB | 256012 GiB |\n","|       from small pool |  83352 KiB | 118608 KiB |  11534 GiB |  11533 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 276494 KiB | 347889 KiB | 267547 GiB | 267546 GiB |\n","|       from large pool | 193142 KiB | 242924 KiB | 256013 GiB | 256012 GiB |\n","|       from small pool |  83352 KiB | 118608 KiB |  11534 GiB |  11533 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 340767 KiB | 263661 GiB | 263661 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 252131 GiB | 252131 GiB |\n","|       from small pool |  83061 KiB | 118317 KiB |  11530 GiB |  11530 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 389120 KiB | 405504 KiB |  42152 GiB |  42151 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 106496 KiB | 122880 KiB |   1024 GiB |   1024 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 112625 KiB | 166472 KiB | 169654 GiB | 169654 GiB |\n","|       from large pool |  89482 KiB | 135224 KiB | 157135 GiB | 157135 GiB |\n","|       from small pool |  23143 KiB |  38654 KiB |  12519 GiB |  12519 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   83424 K  |   83423 K  |\n","|       from large pool |      98    |     122    |   35512 K  |   35512 K  |\n","|       from small pool |    1706    |    1850    |   47912 K  |   47910 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   83424 K  |   83423 K  |\n","|       from large pool |      98    |     122    |   35512 K  |   35512 K  |\n","|       from small pool |    1706    |    1850    |   47912 K  |   47910 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      64    |      72    |    2091 K  |    2091 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      52    |      60    |     524 K  |     524 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      66    |      85    |   37330 K  |   37330 K  |\n","|       from large pool |      15    |      19    |   20691 K  |   20691 K  |\n","|       from small pool |      51    |      67    |   16638 K  |   16638 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:359/430 batch_size:2\n","Next token prediction. step:16/186 batch:359/430 epoch:1/1\n","full seq: With the expansion of passive investing set to continue, it is plausible that international institutional investors will have even less incentive to monitor governance in the long term.Ģ\n","pref seq: With the expansi\n","next tok:                o\n","pred tok:                ġ\n","Completed batch.\n","epoch:1/1 batch:359/430 batch_size:2 loss:5.5178542137146 time_for_batch_instance:32.94456195831299 total_batch_time:13845.072552204132 running_batch_average:38.56566170530399\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 278330 KiB | 349753 KiB | 267654 GiB | 267654 GiB |\n","|       from large pool | 194978 KiB | 245047 KiB | 256074 GiB | 256074 GiB |\n","|       from small pool |  83352 KiB | 119298 KiB |  11579 GiB |  11579 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 278330 KiB | 349753 KiB | 267654 GiB | 267654 GiB |\n","|       from large pool | 194978 KiB | 245047 KiB | 256074 GiB | 256074 GiB |\n","|       from small pool |  83352 KiB | 119298 KiB |  11579 GiB |  11579 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 342669 KiB | 263762 GiB | 263762 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 252186 GiB | 252186 GiB |\n","|       from small pool |  83061 KiB | 119009 KiB |  11576 GiB |  11576 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 382976 KiB | 407552 KiB |  42154 GiB |  42154 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 100352 KiB | 124928 KiB |   1027 GiB |   1027 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 104645 KiB | 164184 KiB | 169766 GiB | 169766 GiB |\n","|       from large pool |  87646 KiB | 135224 KiB | 157196 GiB | 157196 GiB |\n","|       from small pool |  16999 KiB |  35608 KiB |  12569 GiB |  12569 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   83639 K  |   83637 K  |\n","|       from large pool |      98    |     122    |   35543 K  |   35543 K  |\n","|       from small pool |    1706    |    1850    |   48095 K  |   48094 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   83639 K  |   83637 K  |\n","|       from large pool |      98    |     122    |   35543 K  |   35543 K  |\n","|       from small pool |    1706    |    1850    |   48095 K  |   48094 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      61    |      73    |    2092 K  |    2092 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      49    |      61    |     526 K  |     526 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      73    |      83    |   37414 K  |   37414 K  |\n","|       from large pool |      16    |      19    |   20712 K  |   20712 K  |\n","|       from small pool |      57    |      67    |   16702 K  |   16702 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:360/430 batch_size:2\n","Next token prediction. step:74/184 batch:360/430 epoch:1/1\n","full seq: To claim that China \"owes\" the US for its trade bilateral trade surplus would be like saying that your local grocery store owes you for the money you spent there during the last year.Ģ\n","pref seq: To claim that China \"owes\" the US for its trade bilateral trade surplus wo\n","next tok:                                                                          u\n","pred tok:                                                                          ġ\n","Completed batch.\n","epoch:1/1 batch:360/430 batch_size:2 loss:4.538687705993652 time_for_batch_instance:32.27276015281677 total_batch_time:13877.345312356949 running_batch_average:38.54818142321375\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 279242 KiB | 340571 KiB | 267743 GiB | 267742 GiB |\n","|       from large pool | 195890 KiB | 241487 KiB | 256114 GiB | 256114 GiB |\n","|       from small pool |  83352 KiB | 120534 KiB |  11628 GiB |  11628 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 279242 KiB | 340571 KiB | 267743 GiB | 267742 GiB |\n","|       from large pool | 195890 KiB | 241487 KiB | 256114 GiB | 256114 GiB |\n","|       from small pool |  83352 KiB | 120534 KiB |  11628 GiB |  11628 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 330946 KiB | 263849 GiB | 263849 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 252224 GiB | 252224 GiB |\n","|       from small pool |  83061 KiB | 120230 KiB |  11624 GiB |  11624 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 389120 KiB | 407552 KiB |  42156 GiB |  42156 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 106496 KiB | 124928 KiB |   1029 GiB |   1029 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 109877 KiB | 168973 KiB | 169859 GiB | 169859 GiB |\n","|       from large pool |  86734 KiB | 135224 KiB | 157236 GiB | 157236 GiB |\n","|       from small pool |  23143 KiB |  39357 KiB |  12622 GiB |  12622 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   83851 K  |   83849 K  |\n","|       from large pool |      98    |     122    |   35564 K  |   35564 K  |\n","|       from small pool |    1706    |    1850    |   48287 K  |   48285 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   83851 K  |   83849 K  |\n","|       from large pool |      98    |     122    |   35564 K  |   35564 K  |\n","|       from small pool |    1706    |    1850    |   48287 K  |   48285 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      64    |      73    |    2093 K  |    2093 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      52    |      61    |     527 K  |     526 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      69    |      81    |   37491 K  |   37491 K  |\n","|       from large pool |      12    |      17    |   20723 K  |   20723 K  |\n","|       from small pool |      57    |      69    |   16768 K  |   16768 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:361/430 batch_size:2\n","Next token prediction. step:44/183 batch:361/430 epoch:1/1\n","full seq: In several sectors, including energy and telecommunications, China requires foreign firms to share proprietary technology with their Chinese partners as a condition of market access.Ģ\n","pref seq: In several sectors, including energy and tel\n","next tok:                                            e\n","pred tok:                                            ġ\n","Completed batch.\n","epoch:1/1 batch:361/430 batch_size:2 loss:3.9270739555358887 time_for_batch_instance:31.94744324684143 total_batch_time:13909.29275560379 running_batch_average:38.529896829927395\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 278673 KiB | 341600 KiB | 267832 GiB | 267832 GiB |\n","|       from large pool | 195321 KiB | 242517 KiB | 256154 GiB | 256154 GiB |\n","|       from small pool |  83352 KiB | 121666 KiB |  11677 GiB |  11677 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 278673 KiB | 341600 KiB | 267832 GiB | 267832 GiB |\n","|       from large pool | 195321 KiB | 242517 KiB | 256154 GiB | 256154 GiB |\n","|       from small pool |  83352 KiB | 121666 KiB |  11677 GiB |  11677 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 330946 KiB | 263937 GiB | 263937 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 252263 GiB | 252263 GiB |\n","|       from small pool |  83061 KiB | 121364 KiB |  11674 GiB |  11674 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 389120 KiB | 409600 KiB |  42158 GiB |  42157 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 106496 KiB | 126976 KiB |   1031 GiB |   1030 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 110446 KiB | 168759 KiB | 169953 GiB | 169953 GiB |\n","|       from large pool |  87303 KiB | 135224 KiB | 157276 GiB | 157276 GiB |\n","|       from small pool |  23143 KiB |  40719 KiB |  12676 GiB |  12676 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   84062 K  |   84060 K  |\n","|       from large pool |      98    |     122    |   35584 K  |   35584 K  |\n","|       from small pool |    1706    |    1850    |   48477 K  |   48475 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   84062 K  |   84060 K  |\n","|       from large pool |      98    |     122    |   35584 K  |   35584 K  |\n","|       from small pool |    1706    |    1850    |   48477 K  |   48475 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      64    |      74    |    2094 K  |    2094 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      52    |      62    |     527 K  |     527 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      64    |      84    |   37567 K  |   37567 K  |\n","|       from large pool |      13    |      17    |   20734 K  |   20734 K  |\n","|       from small pool |      51    |      68    |   16833 K  |   16832 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:362/430 batch_size:2\n","Next token prediction. step:179/182 batch:362/430 epoch:1/1\n","full seq: The Japanese word for \"foreigner\" - gaijin - comprises the words for \"outside\" and \"person.\" The implication is that non-Japanese people can never truly understand Japanese culture.Ģ\n","pref seq: The Japanese word for \"foreigner\" - gaijin - comprises the words for \"outside\" and \"person.\" The implication is that non-Japanese people can never truly understand Japanese cultur\n","next tok:                                                                                                                                                                                   e\n","pred tok:                                                                                                                                                                                   t\n","Completed batch.\n","epoch:1/1 batch:362/430 batch_size:2 loss:5.1445159912109375 time_for_batch_instance:32.46818661689758 total_batch_time:13941.760942220688 running_batch_average:38.513151774090296\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 278268 KiB | 339804 KiB | 267917 GiB | 267917 GiB |\n","|       from large pool | 194915 KiB | 240721 KiB | 256193 GiB | 256192 GiB |\n","|       from small pool |  83352 KiB | 118722 KiB |  11724 GiB |  11724 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 278268 KiB | 339804 KiB | 267917 GiB | 267917 GiB |\n","|       from large pool | 194915 KiB | 240721 KiB | 256193 GiB | 256192 GiB |\n","|       from small pool |  83352 KiB | 118722 KiB |  11724 GiB |  11724 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 330946 KiB | 264021 GiB | 264021 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 252300 GiB | 252300 GiB |\n","|       from small pool |  83061 KiB | 118415 KiB |  11721 GiB |  11720 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 382976 KiB | 405504 KiB |  42160 GiB |  42160 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 100352 KiB | 122880 KiB |   1033 GiB |   1033 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 104708 KiB | 166229 KiB | 170042 GiB | 170042 GiB |\n","|       from large pool |  87708 KiB | 135224 KiB | 157315 GiB | 157315 GiB |\n","|       from small pool |  16999 KiB |  37399 KiB |  12727 GiB |  12727 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   84272 K  |   84270 K  |\n","|       from large pool |      98    |     122    |   35605 K  |   35605 K  |\n","|       from small pool |    1706    |    1850    |   48666 K  |   48665 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   84272 K  |   84270 K  |\n","|       from large pool |      98    |     122    |   35605 K  |   35605 K  |\n","|       from small pool |    1706    |    1850    |   48666 K  |   48665 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      61    |      72    |    2095 K  |    2095 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      49    |      60    |     529 K  |     528 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      67    |      78    |   37644 K  |   37644 K  |\n","|       from large pool |      11    |      17    |   20746 K  |   20746 K  |\n","|       from small pool |      56    |      66    |   16897 K  |   16897 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:363/430 batch_size:2\n","Next token prediction. step:165/181 batch:363/430 epoch:1/1\n","full seq: So, too, did the \"No\" campaign in Italy's upcoming constitutional referendum - upon which Italian Prime Minister Matteo Renzi has bet his political future.Ģġġġġġġġġġġġġġġġġġġġġġġġġġ\n","pref seq: So, too, did the \"No\" campaign in Italy's upcoming constitutional referendum - upon which Italian Prime Minister Matteo Renzi has bet his political future.Ģġġġġġġġġġ\n","next tok:                                                                                                                                                                     ġ\n","pred tok:                                                                                                                                                                     .\n","Completed batch.\n","epoch:1/1 batch:363/430 batch_size:2 loss:3.9414005279541016 time_for_batch_instance:34.203386545181274 total_batch_time:13975.96432876587 running_batch_average:38.5012791426057\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 277464 KiB | 356371 KiB | 268026 GiB | 268025 GiB |\n","|       from large pool | 194111 KiB | 240157 KiB | 256256 GiB | 256256 GiB |\n","|       from small pool |  83352 KiB | 121927 KiB |  11769 GiB |  11769 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 277464 KiB | 356371 KiB | 268026 GiB | 268025 GiB |\n","|       from large pool | 194111 KiB | 240157 KiB | 256256 GiB | 256256 GiB |\n","|       from small pool |  83352 KiB | 121927 KiB |  11769 GiB |  11769 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 348824 KiB | 264124 GiB | 264123 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 252358 GiB | 252358 GiB |\n","|       from small pool |  83061 KiB | 121620 KiB |  11766 GiB |  11765 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 380928 KiB | 407552 KiB |  42163 GiB |  42162 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool |  98304 KiB | 124928 KiB |   1036 GiB |   1035 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 103464 KiB | 167003 KiB | 170155 GiB | 170155 GiB |\n","|       from large pool |  88512 KiB | 135224 KiB | 157378 GiB | 157378 GiB |\n","|       from small pool |  14951 KiB |  38662 KiB |  12777 GiB |  12777 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   84481 K  |   84479 K  |\n","|       from large pool |      98    |     122    |   35637 K  |   35636 K  |\n","|       from small pool |    1706    |    1850    |   48844 K  |   48842 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   84481 K  |   84479 K  |\n","|       from large pool |      98    |     122    |   35637 K  |   35636 K  |\n","|       from small pool |    1706    |    1850    |   48844 K  |   48842 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      60    |      73    |    2096 K  |    2096 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      48    |      61    |     530 K  |     530 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      62    |      87    |   37725 K  |   37725 K  |\n","|       from large pool |      16    |      20    |   20766 K  |   20766 K  |\n","|       from small pool |      46    |      71    |   16959 K  |   16958 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:364/430 batch_size:2\n","Next token prediction. step:43/179 batch:364/430 epoch:1/1\n","full seq: As Trump launches his policies, however, the Fed is likely to tighten its monetary policy more than it had planned before the inauguration, not less, as the markets still expect.Ģ\n","pref seq: As Trump launches his policies, however, th\n","next tok:                                           e\n","pred tok:                                           ġ\n","Completed batch.\n","epoch:1/1 batch:364/430 batch_size:2 loss:3.6810011863708496 time_for_batch_instance:33.06256103515625 total_batch_time:14009.026889801025 running_batch_average:38.48633760934348\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 278547 KiB | 341600 KiB | 268113 GiB | 268113 GiB |\n","|       from large pool | 195195 KiB | 242517 KiB | 256295 GiB | 256295 GiB |\n","|       from small pool |  83352 KiB | 121440 KiB |  11817 GiB |  11817 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 278547 KiB | 341600 KiB | 268113 GiB | 268113 GiB |\n","|       from large pool | 195195 KiB | 242517 KiB | 256295 GiB | 256295 GiB |\n","|       from small pool |  83352 KiB | 121440 KiB |  11817 GiB |  11817 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 330946 KiB | 264209 GiB | 264209 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 252395 GiB | 252395 GiB |\n","|       from small pool |  83061 KiB | 121137 KiB |  11814 GiB |  11813 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 391168 KiB | 409600 KiB |  42165 GiB |  42164 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 108544 KiB | 126976 KiB |   1037 GiB |   1037 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 112620 KiB | 168759 KiB | 170247 GiB | 170247 GiB |\n","|       from large pool |  87429 KiB | 135224 KiB | 157417 GiB | 157417 GiB |\n","|       from small pool |  25191 KiB |  40719 KiB |  12829 GiB |  12829 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   84687 K  |   84685 K  |\n","|       from large pool |      98    |     122    |   35657 K  |   35657 K  |\n","|       from small pool |    1706    |    1850    |   49030 K  |   49028 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   84687 K  |   84685 K  |\n","|       from large pool |      98    |     122    |   35657 K  |   35657 K  |\n","|       from small pool |    1706    |    1850    |   49030 K  |   49028 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      65    |      74    |    2097 K  |    2097 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      53    |      62    |     531 K  |     531 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      68    |      82    |   37800 K  |   37799 K  |\n","|       from large pool |      13    |      17    |   20777 K  |   20777 K  |\n","|       from small pool |      55    |      69    |   17022 K  |   17022 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:365/430 batch_size:2\n","Next token prediction. step:91/179 batch:365/430 epoch:1/1\n","full seq: And yet he may now be tempted to appoint new members to the Fed Board who are even more dovish, and less independent, than Yellen, in order to boost credit to the private sector.Ģ\n","pref seq: And yet he may now be tempted to appoint new members to the Fed Board who are even more dov\n","next tok:                                                                                           i\n","pred tok:                                                                                           .\n","Completed batch.\n","epoch:1/1 batch:365/430 batch_size:2 loss:5.573685646057129 time_for_batch_instance:32.904865980148315 total_batch_time:14041.931755781174 running_batch_average:38.47104590624979\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 277301 KiB | 345634 KiB | 268213 GiB | 268213 GiB |\n","|       from large pool | 193949 KiB | 239946 KiB | 256353 GiB | 256352 GiB |\n","|       from small pool |  83352 KiB | 117918 KiB |  11860 GiB |  11860 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 277301 KiB | 345634 KiB | 268213 GiB | 268213 GiB |\n","|       from large pool | 193949 KiB | 239946 KiB | 256353 GiB | 256352 GiB |\n","|       from small pool |  83352 KiB | 117918 KiB |  11860 GiB |  11860 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 337473 KiB | 264304 GiB | 264303 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 252447 GiB | 252446 GiB |\n","|       from small pool |  83061 KiB | 117626 KiB |  11856 GiB |  11856 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 389120 KiB | 405504 KiB |  42166 GiB |  42166 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 106496 KiB | 122880 KiB |   1039 GiB |   1039 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 111818 KiB | 164416 KiB | 170351 GiB | 170351 GiB |\n","|       from large pool |  88675 KiB | 135224 KiB | 157475 GiB | 157474 GiB |\n","|       from small pool |  23143 KiB |  36614 KiB |  12876 GiB |  12876 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   84893 K  |   84891 K  |\n","|       from large pool |      98    |     122    |   35686 K  |   35686 K  |\n","|       from small pool |    1706    |    1850    |   49206 K  |   49205 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   84893 K  |   84891 K  |\n","|       from large pool |      98    |     122    |   35686 K  |   35686 K  |\n","|       from small pool |    1706    |    1850    |   49206 K  |   49205 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      64    |      72    |    2098 K  |    2098 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      52    |      60    |     532 K  |     532 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      72    |      83    |   37879 K  |   37879 K  |\n","|       from large pool |      13    |      19    |   20796 K  |   20796 K  |\n","|       from small pool |      59    |      68    |   17082 K  |   17082 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:366/430 batch_size:2\n","Next token prediction. step:130/179 batch:366/430 epoch:1/1\n","full seq: The bad news is that Trump is sticking to his \"buy American, hire American\" credo, and his protectionist gestures will hurt growth more than they save jobs.Ģġġġġġġġġġġġġġġġġġġġġġġ\n","pref seq: The bad news is that Trump is sticking to his \"buy American, hire American\" credo, and his protectionist gestures will hurt growth\n","next tok:                                                                                                                                   \n","pred tok:                                                                                                                                  t\n","Completed batch.\n","epoch:1/1 batch:366/430 batch_size:2 loss:3.2749361991882324 time_for_batch_instance:32.12778377532959 total_batch_time:14074.059539556503 running_batch_average:38.453714588952195\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 279172 KiB | 352971 KiB | 268319 GiB | 268319 GiB |\n","|       from large pool | 195819 KiB | 244313 KiB | 256415 GiB | 256415 GiB |\n","|       from small pool |  83352 KiB | 120892 KiB |  11904 GiB |  11904 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 279172 KiB | 352971 KiB | 268319 GiB | 268319 GiB |\n","|       from large pool | 195819 KiB | 244313 KiB | 256415 GiB | 256415 GiB |\n","|       from small pool |  83352 KiB | 120892 KiB |  11904 GiB |  11904 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 345574 KiB | 264403 GiB | 264403 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 252503 GiB | 252502 GiB |\n","|       from small pool |  83061 KiB | 120582 KiB |  11900 GiB |  11900 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 385024 KiB | 407552 KiB |  42169 GiB |  42169 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 102400 KiB | 124928 KiB |   1042 GiB |   1042 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 105852 KiB | 166472 KiB | 170462 GiB | 170462 GiB |\n","|       from large pool |  86804 KiB | 135224 KiB | 157537 GiB | 157537 GiB |\n","|       from small pool |  19047 KiB |  36636 KiB |  12924 GiB |  12924 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   85100 K  |   85098 K  |\n","|       from large pool |      98    |     122    |   35717 K  |   35717 K  |\n","|       from small pool |    1706    |    1850    |   49382 K  |   49380 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   85100 K  |   85098 K  |\n","|       from large pool |      98    |     122    |   35717 K  |   35717 K  |\n","|       from small pool |    1706    |    1850    |   49382 K  |   49380 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      62    |      73    |    2100 K  |    2100 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      50    |      61    |     533 K  |     533 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      65    |      77    |   37964 K  |   37964 K  |\n","|       from large pool |      11    |      17    |   20817 K  |   20817 K  |\n","|       from small pool |      54    |      65    |   17146 K  |   17146 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:367/430 batch_size:2\n","Next token prediction. step:11/178 batch:367/430 epoch:1/1\n","full seq: Most important, Merkel could finally tackle the important issues that have fallen by the wayside in recent years, to which the current coalition agreement pays only lip service.Ģ\n","pref seq: Most import\n","next tok:           a\n","pred tok:           Z\n","Completed batch.\n","epoch:1/1 batch:367/430 batch_size:2 loss:4.983635902404785 time_for_batch_instance:31.859371185302734 total_batch_time:14105.918910741806 running_batch_average:38.435746350795114\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 278338 KiB | 339804 KiB | 268402 GiB | 268402 GiB |\n","|       from large pool | 194986 KiB | 240721 KiB | 256452 GiB | 256452 GiB |\n","|       from small pool |  83352 KiB | 118495 KiB |  11949 GiB |  11949 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 278338 KiB | 339804 KiB | 268402 GiB | 268402 GiB |\n","|       from large pool | 194986 KiB | 240721 KiB | 256452 GiB | 256452 GiB |\n","|       from small pool |  83352 KiB | 118495 KiB |  11949 GiB |  11949 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 330946 KiB | 264484 GiB | 264484 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 252538 GiB | 252538 GiB |\n","|       from small pool |  83061 KiB | 118188 KiB |  11946 GiB |  11946 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 385024 KiB | 405504 KiB |  42171 GiB |  42171 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 102400 KiB | 122880 KiB |   1044 GiB |   1044 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 106685 KiB | 164534 KiB | 170548 GiB | 170548 GiB |\n","|       from large pool |  87638 KiB | 135224 KiB | 157574 GiB | 157574 GiB |\n","|       from small pool |  19047 KiB |  36628 KiB |  12974 GiB |  12974 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   85305 K  |   85303 K  |\n","|       from large pool |      98    |     122    |   35737 K  |   35737 K  |\n","|       from small pool |    1706    |    1850    |   49567 K  |   49565 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   85305 K  |   85303 K  |\n","|       from large pool |      98    |     122    |   35737 K  |   35737 K  |\n","|       from small pool |    1706    |    1850    |   49567 K  |   49565 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      62    |      72    |    2101 K  |    2101 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      50    |      60    |     534 K  |     534 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      60    |      77    |   38037 K  |   38037 K  |\n","|       from large pool |      11    |      16    |   20829 K  |   20829 K  |\n","|       from small pool |      49    |      66    |   17208 K  |   17208 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:368/430 batch_size:2\n","Next token prediction. step:92/178 batch:368/430 epoch:1/1\n","full seq: By putting the core issue of Palestinian rights front and center, the Palestinian leadership would be acknowledging a shift that is already occurring within Palestinian society.Ģ\n","pref seq: By putting the core issue of Palestinian rights front and center, the Palestinian leadership\n","next tok:                                                                                             \n","pred tok:                                                                                            .\n","Completed batch.\n","epoch:1/1 batch:368/430 batch_size:2 loss:5.356159210205078 time_for_batch_instance:32.56367826461792 total_batch_time:14138.482589006424 running_batch_average:38.4197896440392\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 276337 KiB | 341453 KiB | 268497 GiB | 268497 GiB |\n","|       from large pool | 192984 KiB | 240942 KiB | 256505 GiB | 256505 GiB |\n","|       from small pool |  83352 KiB | 117055 KiB |  11991 GiB |  11991 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 276337 KiB | 341453 KiB | 268497 GiB | 268497 GiB |\n","|       from large pool | 192984 KiB | 240942 KiB | 256505 GiB | 256505 GiB |\n","|       from small pool |  83352 KiB | 117055 KiB |  11991 GiB |  11991 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 334897 KiB | 264577 GiB | 264576 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 252588 GiB | 252588 GiB |\n","|       from small pool |  83061 KiB | 116761 KiB |  11988 GiB |  11988 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 393216 KiB | 403456 KiB |  42173 GiB |  42173 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 110592 KiB | 120832 KiB |   1046 GiB |   1046 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 116879 KiB | 168283 KiB | 170648 GiB | 170648 GiB |\n","|       from large pool |  89639 KiB | 135224 KiB | 157627 GiB | 157627 GiB |\n","|       from small pool |  27239 KiB |  38683 KiB |  13020 GiB |  13020 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   85510 K  |   85508 K  |\n","|       from large pool |      98    |     122    |   35767 K  |   35767 K  |\n","|       from small pool |    1706    |    1850    |   49743 K  |   49741 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   85510 K  |   85508 K  |\n","|       from large pool |      98    |     122    |   35767 K  |   35767 K  |\n","|       from small pool |    1706    |    1850    |   49743 K  |   49741 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      66    |      71    |    2102 K  |    2102 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      54    |      59    |     535 K  |     535 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      78    |      83    |   38116 K  |   38116 K  |\n","|       from large pool |      18    |      19    |   20848 K  |   20848 K  |\n","|       from small pool |      60    |      67    |   17268 K  |   17268 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:369/430 batch_size:2\n","Next token prediction. step:64/177 batch:369/430 epoch:1/1\n","full seq: Which billionaires will champion the SDGs for education, renewable energy, fresh water and sanitation, and sustainable agriculture?Ģġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġ\n","pref seq: Which billionaires will champion the SDGs for education, renewab\n","next tok:                                                                l\n","pred tok:                                                                ġ\n","Completed batch.\n","epoch:1/1 batch:369/430 batch_size:2 loss:5.358227729797363 time_for_batch_instance:31.657530784606934 total_batch_time:14170.14011979103 running_batch_average:38.40146373927109\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 276627 KiB | 340337 KiB | 268591 GiB | 268591 GiB |\n","|       from large pool | 193275 KiB | 241253 KiB | 256558 GiB | 256558 GiB |\n","|       from small pool |  83352 KiB | 116538 KiB |  12033 GiB |  12033 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 276627 KiB | 340337 KiB | 268591 GiB | 268591 GiB |\n","|       from large pool | 193275 KiB | 241253 KiB | 256558 GiB | 256558 GiB |\n","|       from small pool |  83352 KiB | 116538 KiB |  12033 GiB |  12033 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 333272 KiB | 264667 GiB | 264667 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 252637 GiB | 252637 GiB |\n","|       from small pool |  83061 KiB | 116243 KiB |  12029 GiB |  12029 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 393216 KiB | 403456 KiB |  42175 GiB |  42174 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 110592 KiB | 120832 KiB |   1047 GiB |   1047 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 116588 KiB | 166709 KiB | 170746 GiB | 170746 GiB |\n","|       from large pool |  89349 KiB | 135224 KiB | 157680 GiB | 157680 GiB |\n","|       from small pool |  27239 KiB |  38669 KiB |  13065 GiB |  13065 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   85714 K  |   85712 K  |\n","|       from large pool |      98    |     122    |   35796 K  |   35796 K  |\n","|       from small pool |    1706    |    1850    |   49917 K  |   49916 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   85714 K  |   85712 K  |\n","|       from large pool |      98    |     122    |   35796 K  |   35796 K  |\n","|       from small pool |    1706    |    1850    |   49917 K  |   49916 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      66    |      71    |    2103 K  |    2102 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      54    |      59    |     536 K  |     536 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      73    |      85    |   38195 K  |   38195 K  |\n","|       from large pool |      15    |      19    |   20866 K  |   20866 K  |\n","|       from small pool |      58    |      67    |   17328 K  |   17328 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:370/430 batch_size:2\n","Next token prediction. step:140/176 batch:370/430 epoch:1/1\n","full seq: To be sure, Putin's and ErdoĠan's crackdowns have been far more effective than Trump's tweets or PiS's stalled attempt at judicial reform this summer.Ģġġġġġġġġġġġġġġġġġġġġġġġġġ\n","pref seq: To be sure, Putin's and ErdoĠan's crackdowns have been far more effective than Trump's tweets or PiS's stalled attempt at judicial reform th\n","next tok:                                                                                                                                            i\n","pred tok:                                                                                                                                            e\n","Completed batch.\n","epoch:1/1 batch:370/430 batch_size:2 loss:3.8844172954559326 time_for_batch_instance:31.369228839874268 total_batch_time:14201.509348630905 running_batch_average:38.382457699002444\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 275916 KiB | 352353 KiB | 268695 GiB | 268695 GiB |\n","|       from large pool | 192564 KiB | 240170 KiB | 256618 GiB | 256618 GiB |\n","|       from small pool |  83352 KiB | 121237 KiB |  12076 GiB |  12076 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 275916 KiB | 352353 KiB | 268695 GiB | 268695 GiB |\n","|       from large pool | 192564 KiB | 240170 KiB | 256618 GiB | 256618 GiB |\n","|       from small pool |  83352 KiB | 121237 KiB |  12076 GiB |  12076 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 345928 KiB | 264765 GiB | 264765 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 252693 GiB | 252692 GiB |\n","|       from small pool |  83061 KiB | 120928 KiB |  12072 GiB |  12072 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 387072 KiB | 407552 KiB |  42177 GiB |  42176 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 104448 KiB | 124928 KiB |   1049 GiB |   1049 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 111155 KiB | 167263 KiB | 170854 GiB | 170854 GiB |\n","|       from large pool |  90060 KiB | 135224 KiB | 157740 GiB | 157740 GiB |\n","|       from small pool |  21095 KiB |  37634 KiB |  13113 GiB |  13113 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   85917 K  |   85915 K  |\n","|       from large pool |      98    |     122    |   35827 K  |   35827 K  |\n","|       from small pool |    1706    |    1850    |   50090 K  |   50088 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   85917 K  |   85915 K  |\n","|       from large pool |      98    |     122    |   35827 K  |   35827 K  |\n","|       from small pool |    1706    |    1850    |   50090 K  |   50088 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      63    |      73    |    2104 K  |    2103 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      51    |      61    |     537 K  |     537 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      62    |      80    |   38276 K  |   38276 K  |\n","|       from large pool |      14    |      17    |   20886 K  |   20886 K  |\n","|       from small pool |      48    |      65    |   17390 K  |   17390 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:371/430 batch_size:2\n","Next token prediction. step:149/175 batch:371/430 epoch:1/1\n","full seq: When projects are over budget, fall behind schedule, or fail to generate projected returns, investors pay the price.Ģġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġ\n","pref seq: When projects are over budget, fall behind schedule, or fail to generate projected returns, investors pay the price.Ģġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġ\n","next tok:                                                                                                                                                     ġ\n","pred tok:                                                                                                                                                     e\n","Completed batch.\n","epoch:1/1 batch:371/430 batch_size:2 loss:5.75766658782959 time_for_batch_instance:31.2134690284729 total_batch_time:14232.722817659378 running_batch_average:38.36313427940533\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 276202 KiB | 339234 KiB | 268783 GiB | 268783 GiB |\n","|       from large pool | 192849 KiB | 240150 KiB | 256658 GiB | 256658 GiB |\n","|       from small pool |  83352 KiB | 124176 KiB |  12125 GiB |  12125 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 276202 KiB | 339234 KiB | 268783 GiB | 268783 GiB |\n","|       from large pool | 192849 KiB | 240150 KiB | 256658 GiB | 256658 GiB |\n","|       from small pool |  83352 KiB | 124176 KiB |  12125 GiB |  12125 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 330946 KiB | 264853 GiB | 264852 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 252731 GiB | 252731 GiB |\n","|       from small pool |  83061 KiB | 123878 KiB |  12121 GiB |  12121 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 380928 KiB | 411648 KiB |  42180 GiB |  42179 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool |  98304 KiB | 129024 KiB |   1052 GiB |   1052 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 104726 KiB | 168277 KiB | 170946 GiB | 170946 GiB |\n","|       from large pool |  89774 KiB | 135224 KiB | 157780 GiB | 157780 GiB |\n","|       from small pool |  14951 KiB |  38671 KiB |  13166 GiB |  13166 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   86118 K  |   86117 K  |\n","|       from large pool |      98    |     122    |   35846 K  |   35846 K  |\n","|       from small pool |    1706    |    1850    |   50272 K  |   50270 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   86118 K  |   86117 K  |\n","|       from large pool |      98    |     122    |   35846 K  |   35846 K  |\n","|       from small pool |    1706    |    1850    |   50272 K  |   50270 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      60    |      75    |    2105 K  |    2105 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      48    |      63    |     539 K  |     538 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      68    |      84    |   38347 K  |   38347 K  |\n","|       from large pool |      18    |      20    |   20896 K  |   20896 K  |\n","|       from small pool |      50    |      69    |   17451 K  |   17451 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:372/430 batch_size:2\n","Next token prediction. step:82/175 batch:372/430 epoch:1/1\n","full seq: Second, the \"weightless economy\" - the economy of ideas, knowledge, and information - will account for a growing share of output, in developed and developing economies alike.Ģ\n","pref seq: Second, the \"weightless economy\" - the economy of ideas, knowledge, and informatio\n","next tok:                                                                                  n\n","pred tok:                                                                                  Z\n","Completed batch.\n","epoch:1/1 batch:372/430 batch_size:2 loss:6.01959228515625 time_for_batch_instance:30.978108882904053 total_batch_time:14263.700926542282 running_batch_average:38.34328206059753\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 276193 KiB | 340858 KiB | 268877 GiB | 268877 GiB |\n","|       from large pool | 192840 KiB | 240942 KiB | 256710 GiB | 256710 GiB |\n","|       from small pool |  83352 KiB | 117055 KiB |  12166 GiB |  12166 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 276193 KiB | 340858 KiB | 268877 GiB | 268877 GiB |\n","|       from large pool | 192840 KiB | 240942 KiB | 256710 GiB | 256710 GiB |\n","|       from small pool |  83352 KiB | 117055 KiB |  12166 GiB |  12166 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 334301 KiB | 264943 GiB | 264943 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 252780 GiB | 252780 GiB |\n","|       from small pool |  83061 KiB | 116761 KiB |  12163 GiB |  12162 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 391168 KiB | 403456 KiB |  42181 GiB |  42181 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 108544 KiB | 120832 KiB |   1054 GiB |   1054 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 114975 KiB | 168283 KiB | 171044 GiB | 171044 GiB |\n","|       from large pool |  89783 KiB | 135224 KiB | 157832 GiB | 157832 GiB |\n","|       from small pool |  25191 KiB |  38683 KiB |  13211 GiB |  13211 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   86320 K  |   86318 K  |\n","|       from large pool |      98    |     122    |   35875 K  |   35875 K  |\n","|       from small pool |    1706    |    1850    |   50444 K  |   50443 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   86320 K  |   86318 K  |\n","|       from large pool |      98    |     122    |   35875 K  |   35875 K  |\n","|       from small pool |    1706    |    1850    |   50444 K  |   50443 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      65    |      71    |    2106 K  |    2106 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      53    |      59    |     539 K  |     539 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      76    |      83    |   38424 K  |   38424 K  |\n","|       from large pool |      18    |      20    |   20914 K  |   20914 K  |\n","|       from small pool |      58    |      67    |   17510 K  |   17509 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:373/430 batch_size:2\n","Next token prediction. step:81/175 batch:373/430 epoch:1/1\n","full seq: It is this set of policy recommendations that the Hungarian government has deliberately distorted and labeled the \"Soros Plan.\"Ģġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġ\n","pref seq: It is this set of policy recommendations that the Hungarian government has delibe\n","next tok:                                                                                 r\n","pred tok:                                                                                 N\n","Completed batch.\n","epoch:1/1 batch:373/430 batch_size:2 loss:6.091032028198242 time_for_batch_instance:30.943310260772705 total_batch_time:14294.644236803055 running_batch_average:38.32344299411007\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 278833 KiB | 361543 KiB | 268985 GiB | 268984 GiB |\n","|       from large pool | 195481 KiB | 243182 KiB | 256773 GiB | 256772 GiB |\n","|       from small pool |  83352 KiB | 124859 KiB |  12212 GiB |  12212 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 278833 KiB | 361543 KiB | 268985 GiB | 268984 GiB |\n","|       from large pool | 195481 KiB | 243182 KiB | 256773 GiB | 256772 GiB |\n","|       from small pool |  83352 KiB | 124859 KiB |  12212 GiB |  12212 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 355713 KiB | 265047 GiB | 265047 GiB |\n","|       from large pool | 189056 KiB | 236217 KiB | 252838 GiB | 252838 GiB |\n","|       from small pool |  83061 KiB | 124558 KiB |  12208 GiB |  12208 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 395264 KiB | 411648 KiB |  42183 GiB |  42183 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 112640 KiB | 129024 KiB |   1056 GiB |   1056 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 116430 KiB | 170327 KiB | 171157 GiB | 171157 GiB |\n","|       from large pool |  87143 KiB | 135224 KiB | 157895 GiB | 157895 GiB |\n","|       from small pool |  29287 KiB |  42445 KiB |  13262 GiB |  13262 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   86522 K  |   86520 K  |\n","|       from large pool |      98    |     122    |   35905 K  |   35905 K  |\n","|       from small pool |    1706    |    1850    |   50616 K  |   50614 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   86522 K  |   86520 K  |\n","|       from large pool |      98    |     122    |   35905 K  |   35905 K  |\n","|       from small pool |    1706    |    1850    |   50616 K  |   50614 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      67    |      75    |    2107 K  |    2107 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      55    |      63    |     540 K  |     540 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      77    |      87    |   38504 K  |   38504 K  |\n","|       from large pool |      15    |      19    |   20935 K  |   20935 K  |\n","|       from small pool |      62    |      70    |   17569 K  |   17569 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:374/430 batch_size:2\n","Next token prediction. step:68/174 batch:374/430 epoch:1/1\n","full seq: Many emerging-market countries are dealing with populists of their own, or in the case of Poland, Hungary, and Turkey, with populists who have already turned into autocrats.Ģ\n","pref seq: Many emerging-market countries are dealing with populists of their o\n","next tok:                                                                    w\n","pred tok:                                                                    ġ\n","Completed batch.\n","epoch:1/1 batch:374/430 batch_size:2 loss:6.041921615600586 time_for_batch_instance:31.04789972305298 total_batch_time:14325.692136526108 running_batch_average:38.3039896698559\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 276285 KiB | 340449 KiB | 269078 GiB | 269077 GiB |\n","|       from large pool | 192932 KiB | 241039 KiB | 256824 GiB | 256824 GiB |\n","|       from small pool |  83352 KiB | 116883 KiB |  12253 GiB |  12252 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 276285 KiB | 340449 KiB | 269078 GiB | 269077 GiB |\n","|       from large pool | 192932 KiB | 241039 KiB | 256824 GiB | 256824 GiB |\n","|       from small pool |  83352 KiB | 116883 KiB |  12253 GiB |  12252 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 333627 KiB | 265136 GiB | 265136 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 252887 GiB | 252887 GiB |\n","|       from small pool |  83061 KiB | 116588 KiB |  12249 GiB |  12249 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 387072 KiB | 403456 KiB |  42184 GiB |  42184 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 104448 KiB | 120832 KiB |   1057 GiB |   1057 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 110787 KiB | 168276 KiB | 171254 GiB | 171254 GiB |\n","|       from large pool |  89691 KiB | 135224 KiB | 157947 GiB | 157946 GiB |\n","|       from small pool |  21095 KiB |  40430 KiB |  13307 GiB |  13307 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   86722 K  |   86720 K  |\n","|       from large pool |      98    |     122    |   35934 K  |   35934 K  |\n","|       from small pool |    1706    |    1850    |   50788 K  |   50786 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   86722 K  |   86720 K  |\n","|       from large pool |      98    |     122    |   35934 K  |   35934 K  |\n","|       from small pool |    1706    |    1850    |   50788 K  |   50786 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      63    |      71    |    2107 K  |    2107 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      51    |      59    |     541 K  |     541 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      75    |      83    |   38583 K  |   38583 K  |\n","|       from large pool |      18    |      19    |   20953 K  |   20953 K  |\n","|       from small pool |      57    |      68    |   17630 K  |   17630 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:375/430 batch_size:2\n","Next token prediction. step:144/174 batch:375/430 epoch:1/1\n","full seq: MGI found that, of 18 major destinations, none has achieved strong integration outcomes across the board, though some have done better than others.Ģġġġġġġġġġġġġġġġġġġġġġġġġġġ\n","pref seq: MGI found that, of 18 major destinations, none has achieved strong integration outcomes across the board, though some have done better than othe\n","next tok:                                                                                                                                                r\n","pred tok:                                                                                                                                                 \n","Completed batch.\n","epoch:1/1 batch:375/430 batch_size:2 loss:3.8210110664367676 time_for_batch_instance:32.21725344657898 total_batch_time:14357.909389972687 running_batch_average:38.287758373260495\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 278050 KiB | 352005 KiB | 269180 GiB | 269180 GiB |\n","|       from large pool | 194697 KiB | 244313 KiB | 256885 GiB | 256885 GiB |\n","|       from small pool |  83352 KiB | 120892 KiB |  12295 GiB |  12295 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 278050 KiB | 352005 KiB | 269180 GiB | 269180 GiB |\n","|       from large pool | 194697 KiB | 244313 KiB | 256885 GiB | 256885 GiB |\n","|       from small pool |  83352 KiB | 120892 KiB |  12295 GiB |  12295 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 344579 KiB | 265233 GiB | 265233 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 252941 GiB | 252941 GiB |\n","|       from small pool |  83061 KiB | 120582 KiB |  12291 GiB |  12291 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 382976 KiB | 407552 KiB |  42187 GiB |  42186 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 100352 KiB | 124928 KiB |   1059 GiB |   1059 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 104926 KiB | 166472 KiB | 171361 GiB | 171361 GiB |\n","|       from large pool |  87926 KiB | 135224 KiB | 158007 GiB | 158007 GiB |\n","|       from small pool |  16999 KiB |  36636 KiB |  13353 GiB |  13353 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   86923 K  |   86921 K  |\n","|       from large pool |      98    |     122    |   35964 K  |   35964 K  |\n","|       from small pool |    1706    |    1850    |   50958 K  |   50956 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   86923 K  |   86921 K  |\n","|       from large pool |      98    |     122    |   35964 K  |   35964 K  |\n","|       from small pool |    1706    |    1850    |   50958 K  |   50956 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      61    |      73    |    2109 K  |    2109 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      49    |      61    |     542 K  |     542 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      61    |      77    |   38666 K  |   38666 K  |\n","|       from large pool |      12    |      19    |   20973 K  |   20973 K  |\n","|       from small pool |      49    |      65    |   17692 K  |   17692 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:376/430 batch_size:2\n","Next token prediction. step:78/173 batch:376/430 epoch:1/1\n","full seq: And, third, manufacturing demand was not constrained by low domestic incomes: production could expand virtually without limit, through exports.Ģġġġġġġġġġġġġġġġġġġġġġġġġġġġġġ\n","pref seq: And, third, manufacturing demand was not constrained by low domestic incomes: \n","next tok:                                                                              p\n","pred tok:                                                                              Z\n","Completed batch.\n","epoch:1/1 batch:376/430 batch_size:2 loss:4.279299736022949 time_for_batch_instance:32.50434947013855 total_batch_time:14390.413739442825 running_batch_average:38.27237696660326\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 278016 KiB | 351812 KiB | 269283 GiB | 269282 GiB |\n","|       from large pool | 194663 KiB | 244313 KiB | 256945 GiB | 256945 GiB |\n","|       from small pool |  83352 KiB | 120892 KiB |  12337 GiB |  12337 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 278016 KiB | 351812 KiB | 269283 GiB | 269282 GiB |\n","|       from large pool | 194663 KiB | 244313 KiB | 256945 GiB | 256945 GiB |\n","|       from small pool |  83352 KiB | 120892 KiB |  12337 GiB |  12337 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 344381 KiB | 265329 GiB | 265328 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 252995 GiB | 252995 GiB |\n","|       from small pool |  83061 KiB | 120582 KiB |  12333 GiB |  12333 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 380928 KiB | 407552 KiB |  42189 GiB |  42189 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool |  98304 KiB | 124928 KiB |   1062 GiB |   1062 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 102912 KiB | 166472 KiB | 171467 GiB | 171467 GiB |\n","|       from large pool |  87960 KiB | 135224 KiB | 158067 GiB | 158067 GiB |\n","|       from small pool |  14951 KiB |  36636 KiB |  13400 GiB |  13400 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   87122 K  |   87120 K  |\n","|       from large pool |      98    |     122    |   35994 K  |   35994 K  |\n","|       from small pool |    1706    |    1850    |   51127 K  |   51125 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   87122 K  |   87120 K  |\n","|       from large pool |      98    |     122    |   35994 K  |   35994 K  |\n","|       from small pool |    1706    |    1850    |   51127 K  |   51125 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      60    |      73    |    2110 K  |    2110 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      48    |      61    |     543 K  |     543 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      58    |      77    |   38748 K  |   38748 K  |\n","|       from large pool |      12    |      17    |   20993 K  |   20993 K  |\n","|       from small pool |      46    |      65    |   17754 K  |   17754 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:377/430 batch_size:2\n","Next token prediction. step:18/173 batch:377/430 epoch:1/1\n","full seq: A 2016 survey of 1,000 liberal arts colleges found that only 18% required a US history or government course to earn a degree.Ģġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġ\n","pref seq: A 2016 survey of 1\n","next tok:                  ,\n","pred tok:                  ġ\n","Completed batch.\n","epoch:1/1 batch:377/430 batch_size:2 loss:5.407985687255859 time_for_batch_instance:32.06586575508118 total_batch_time:14422.479605197906 running_batch_average:38.255914072142986\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 278763 KiB | 361588 KiB | 269389 GiB | 269389 GiB |\n","|       from large pool | 195411 KiB | 243140 KiB | 257006 GiB | 257006 GiB |\n","|       from small pool |  83352 KiB | 125032 KiB |  12382 GiB |  12382 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 278763 KiB | 361588 KiB | 269389 GiB | 269389 GiB |\n","|       from large pool | 195411 KiB | 243140 KiB | 257006 GiB | 257006 GiB |\n","|       from small pool |  83352 KiB | 125032 KiB |  12382 GiB |  12382 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 355791 KiB | 265432 GiB | 265431 GiB |\n","|       from large pool | 189056 KiB | 236291 KiB | 253053 GiB | 253053 GiB |\n","|       from small pool |  83061 KiB | 124731 KiB |  12378 GiB |  12378 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 397312 KiB | 411648 KiB |  42191 GiB |  42191 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 114688 KiB | 129024 KiB |   1064 GiB |   1064 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 118548 KiB | 173539 KiB | 171579 GiB | 171579 GiB |\n","|       from large pool |  87213 KiB | 135224 KiB | 158128 GiB | 158128 GiB |\n","|       from small pool |  31335 KiB |  44526 KiB |  13450 GiB |  13450 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   87321 K  |   87320 K  |\n","|       from large pool |      98    |     122    |   36024 K  |   36024 K  |\n","|       from small pool |    1706    |    1850    |   51297 K  |   51295 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   87321 K  |   87320 K  |\n","|       from large pool |      98    |     122    |   36024 K  |   36024 K  |\n","|       from small pool |    1706    |    1850    |   51297 K  |   51295 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      68    |      75    |    2111 K  |    2111 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      56    |      63    |     544 K  |     544 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      74    |      87    |   38828 K  |   38827 K  |\n","|       from large pool |      15    |      19    |   21013 K  |   21013 K  |\n","|       from small pool |      59    |      72    |   17814 K  |   17814 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:378/430 batch_size:2\n","Next token prediction. step:22/172 batch:378/430 epoch:1/1\n","full seq: But this is nothing more than yet another temporary solution - or, to be less generous, the continuation of what has come to be known as the \"extend and pretend\" approach.Ģ\n","pref seq: But this is nothing mo\n","next tok:                      r\n","pred tok:                      ġ\n","Completed batch.\n","epoch:1/1 batch:378/430 batch_size:2 loss:3.7498934268951416 time_for_batch_instance:32.03257083892822 total_batch_time:14454.512176036835 running_batch_average:38.23945020115565\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 278394 KiB | 339804 KiB | 269469 GiB | 269469 GiB |\n","|       from large pool | 195042 KiB | 240721 KiB | 257042 GiB | 257042 GiB |\n","|       from small pool |  83352 KiB | 118948 KiB |  12426 GiB |  12426 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 278394 KiB | 339804 KiB | 269469 GiB | 269469 GiB |\n","|       from large pool | 195042 KiB | 240721 KiB | 257042 GiB | 257042 GiB |\n","|       from small pool |  83352 KiB | 118948 KiB |  12426 GiB |  12426 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 330946 KiB | 265510 GiB | 265510 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 253087 GiB | 253087 GiB |\n","|       from small pool |  83061 KiB | 118642 KiB |  12423 GiB |  12422 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 389120 KiB | 405504 KiB |  42193 GiB |  42193 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 106496 KiB | 122880 KiB |   1066 GiB |   1065 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 110725 KiB | 168232 KiB | 171663 GiB | 171663 GiB |\n","|       from large pool |  87582 KiB | 135224 KiB | 158164 GiB | 158164 GiB |\n","|       from small pool |  23143 KiB |  38619 KiB |  13498 GiB |  13498 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   87520 K  |   87518 K  |\n","|       from large pool |      98    |     122    |   36044 K  |   36043 K  |\n","|       from small pool |    1706    |    1850    |   51476 K  |   51474 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   87520 K  |   87518 K  |\n","|       from large pool |      98    |     122    |   36044 K  |   36043 K  |\n","|       from small pool |    1706    |    1850    |   51476 K  |   51474 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      64    |      72    |    2112 K  |    2112 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      52    |      60    |     545 K  |     545 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      74    |      78    |   38899 K  |   38899 K  |\n","|       from large pool |      11    |      16    |   21024 K  |   21024 K  |\n","|       from small pool |      63    |      66    |   17875 K  |   17875 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:379/430 batch_size:2\n","Next token prediction. step:157/171 batch:379/430 epoch:1/1\n","full seq: And the Chinese may be in a better position to respond to US attempts to inflict pain on them than the US is to respond to the pain that China might inflict on Americans.Ģ\n","pref seq: And the Chinese may be in a better position to respond to US attempts to inflict pain on them than the US is to respond to the pain that China might inflict \n","next tok:                                                                                                                                                             o\n","pred tok:                                                                                                                                                              \n","Completed batch.\n","epoch:1/1 batch:379/430 batch_size:2 loss:5.12553071975708 time_for_batch_instance:31.647868871688843 total_batch_time:14486.160044908524 running_batch_average:38.22205816598555\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 277937 KiB | 337495 KiB | 269544 GiB | 269544 GiB |\n","|       from large pool | 194585 KiB | 238412 KiB | 257076 GiB | 257076 GiB |\n","|       from small pool |  83352 KiB | 116128 KiB |  12468 GiB |  12468 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 277937 KiB | 337495 KiB | 269544 GiB | 269544 GiB |\n","|       from large pool | 194585 KiB | 238412 KiB | 257076 GiB | 257076 GiB |\n","|       from small pool |  83352 KiB | 116128 KiB |  12468 GiB |  12468 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 330946 KiB | 265585 GiB | 265585 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 253120 GiB | 253120 GiB |\n","|       from small pool |  83061 KiB | 115817 KiB |  12464 GiB |  12464 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 387072 KiB | 403456 KiB |  42195 GiB |  42194 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 104448 KiB | 120832 KiB |   1067 GiB |   1067 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 109134 KiB | 165681 KiB | 171742 GiB | 171742 GiB |\n","|       from large pool |  88039 KiB | 135224 KiB | 158198 GiB | 158198 GiB |\n","|       from small pool |  21095 KiB |  36334 KiB |  13543 GiB |  13543 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   87717 K  |   87715 K  |\n","|       from large pool |      98    |     122    |   36062 K  |   36062 K  |\n","|       from small pool |    1706    |    1850    |   51654 K  |   51652 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   87717 K  |   87715 K  |\n","|       from large pool |      98    |     122    |   36062 K  |   36062 K  |\n","|       from small pool |    1706    |    1850    |   51654 K  |   51652 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      63    |      71    |    2113 K  |    2113 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      51    |      59    |     546 K  |     546 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      58    |      75    |   38969 K  |   38969 K  |\n","|       from large pool |      11    |      17    |   21034 K  |   21034 K  |\n","|       from small pool |      47    |      63    |   17934 K  |   17934 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:380/430 batch_size:2\n","Next token prediction. step:151/171 batch:380/430 epoch:1/1\n","full seq: With a clear SDG plan, the World Bank would find partners to help it fulfill its core, historic, and vital mission.Ģġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġ\n","pref seq: With a clear SDG plan, the World Bank would find partners to help it fulfill its core, historic, and vital mission.Ģġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġ\n","next tok:                                                                                                                                                       ġ\n","pred tok:                                                                                                                                                        \n","Completed batch.\n","epoch:1/1 batch:380/430 batch_size:2 loss:5.937673568725586 time_for_batch_instance:31.39470648765564 total_batch_time:14517.55475139618 running_batch_average:38.20409145104258\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 277072 KiB | 339519 KiB | 269634 GiB | 269633 GiB |\n","|       from large pool | 193720 KiB | 240436 KiB | 257125 GiB | 257125 GiB |\n","|       from small pool |  83352 KiB | 115745 KiB |  12508 GiB |  12508 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 277072 KiB | 339519 KiB | 269634 GiB | 269633 GiB |\n","|       from large pool | 193720 KiB | 240436 KiB | 257125 GiB | 257125 GiB |\n","|       from small pool |  83352 KiB | 115745 KiB |  12508 GiB |  12508 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 330946 KiB | 265671 GiB | 265671 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 253167 GiB | 253167 GiB |\n","|       from small pool |  83061 KiB | 115449 KiB |  12504 GiB |  12504 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 387072 KiB | 401408 KiB |  42196 GiB |  42196 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 104448 KiB | 118784 KiB |   1069 GiB |   1069 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 109999 KiB | 166218 KiB | 171835 GiB | 171835 GiB |\n","|       from large pool |  88904 KiB | 135224 KiB | 158248 GiB | 158247 GiB |\n","|       from small pool |  21095 KiB |  34603 KiB |  13587 GiB |  13587 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   87914 K  |   87912 K  |\n","|       from large pool |      98    |     122    |   36091 K  |   36091 K  |\n","|       from small pool |    1706    |    1850    |   51822 K  |   51821 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   87914 K  |   87912 K  |\n","|       from large pool |      98    |     122    |   36091 K  |   36091 K  |\n","|       from small pool |    1706    |    1850    |   51822 K  |   51821 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      63    |      70    |    2114 K  |    2114 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      51    |      58    |     547 K  |     547 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      73    |      85    |   39044 K  |   39044 K  |\n","|       from large pool |      15    |      19    |   21053 K  |   21053 K  |\n","|       from small pool |      58    |      69    |   17991 K  |   17991 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:381/430 batch_size:2\n","Next token prediction. step:54/171 batch:381/430 epoch:1/1\n","full seq: In 1930, for example, America's Smoot-Hawley Tariff Act singled out Swiss watches, Japanese silk products, and other nationally iconic imports.Ģġġġġġġġġġġġġġġġġġġġġġġġġġġġ\n","pref seq: In 1930, for example, America's Smoot-Hawley Tariff Ac\n","next tok:                                                      t\n","pred tok:                                                      [\n","Completed batch.\n","epoch:1/1 batch:381/430 batch_size:2 loss:4.011384963989258 time_for_batch_instance:31.27410650253296 total_batch_time:14548.828857898712 running_batch_average:38.18590251416985\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 277782 KiB | 348519 KiB | 269733 GiB | 269733 GiB |\n","|       from large pool | 194429 KiB | 244313 KiB | 257184 GiB | 257184 GiB |\n","|       from small pool |  83352 KiB | 119754 KiB |  12549 GiB |  12549 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 277782 KiB | 348519 KiB | 269733 GiB | 269733 GiB |\n","|       from large pool | 194429 KiB | 244313 KiB | 257184 GiB | 257184 GiB |\n","|       from small pool |  83352 KiB | 119754 KiB |  12549 GiB |  12549 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 341130 KiB | 265764 GiB | 265764 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 253219 GiB | 253219 GiB |\n","|       from small pool |  83061 KiB | 119443 KiB |  12545 GiB |  12545 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 393216 KiB | 407552 KiB |  42198 GiB |  42197 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 110592 KiB | 124928 KiB |   1071 GiB |   1070 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 115434 KiB | 165991 KiB | 171938 GiB | 171938 GiB |\n","|       from large pool |  88194 KiB | 135224 KiB | 158306 GiB | 158306 GiB |\n","|       from small pool |  27239 KiB |  36628 KiB |  13632 GiB |  13632 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   88111 K  |   88109 K  |\n","|       from large pool |      98    |     122    |   36120 K  |   36120 K  |\n","|       from small pool |    1706    |    1850    |   51990 K  |   51988 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   88111 K  |   88109 K  |\n","|       from large pool |      98    |     122    |   36120 K  |   36120 K  |\n","|       from small pool |    1706    |    1850    |   51990 K  |   51988 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      66    |      73    |    2114 K  |    2114 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      54    |      61    |     548 K  |     548 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      68    |      77    |   39123 K  |   39123 K  |\n","|       from large pool |      14    |      17    |   21073 K  |   21073 K  |\n","|       from small pool |      54    |      63    |   18050 K  |   18050 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:382/430 batch_size:2\n","Next token prediction. step:29/171 batch:382/430 epoch:1/1\n","full seq: If this happens again under Trump, fiscal deficits will push up interest rates and the dollar even further, and hurt the economy in the long term.Ģġġġġġġġġġġġġġġġġġġġġġġġġ\n","pref seq: If this happens again under T\n","next tok:                             r\n","pred tok:                             ġ\n","Completed batch.\n","epoch:1/1 batch:382/430 batch_size:2 loss:3.8097105026245117 time_for_batch_instance:31.22473907470703 total_batch_time:14580.05359697342 running_batch_average:38.167679573228845\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 277782 KiB | 348519 KiB | 269832 GiB | 269832 GiB |\n","|       from large pool | 194429 KiB | 244313 KiB | 257242 GiB | 257242 GiB |\n","|       from small pool |  83352 KiB | 119754 KiB |  12590 GiB |  12589 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 277782 KiB | 348519 KiB | 269832 GiB | 269832 GiB |\n","|       from large pool | 194429 KiB | 244313 KiB | 257242 GiB | 257242 GiB |\n","|       from small pool |  83352 KiB | 119754 KiB |  12590 GiB |  12589 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 341130 KiB | 265857 GiB | 265857 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 253271 GiB | 253271 GiB |\n","|       from small pool |  83061 KiB | 119443 KiB |  12586 GiB |  12586 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 393216 KiB | 407552 KiB |  42199 GiB |  42199 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 110592 KiB | 124928 KiB |   1072 GiB |   1072 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 115434 KiB | 168277 KiB | 172041 GiB | 172041 GiB |\n","|       from large pool |  88194 KiB | 135224 KiB | 158364 GiB | 158364 GiB |\n","|       from small pool |  27239 KiB |  36645 KiB |  13677 GiB |  13677 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   88308 K  |   88306 K  |\n","|       from large pool |      98    |     122    |   36150 K  |   36150 K  |\n","|       from small pool |    1706    |    1850    |   52157 K  |   52156 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   88308 K  |   88306 K  |\n","|       from large pool |      98    |     122    |   36150 K  |   36150 K  |\n","|       from small pool |    1706    |    1850    |   52157 K  |   52156 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      66    |      73    |    2115 K  |    2115 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      54    |      61    |     549 K  |     549 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      68    |      76    |   39202 K  |   39202 K  |\n","|       from large pool |      14    |      17    |   21093 K  |   21093 K  |\n","|       from small pool |      54    |      63    |   18108 K  |   18108 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:383/430 batch_size:2\n","Next token prediction. step:79/168 batch:383/430 epoch:1/1\n","full seq: If an unscrupulous interviewer is looking for a particular answer or claim, they have the power to edit, manipulate, or even rewrite their subject's words to that end.Ģ\n","pref seq: If an unscrupulous interviewer is looking for a particular answer or claim, the\n","next tok:                                                                               y\n","pred tok:                                                                               N\n","Completed batch.\n","epoch:1/1 batch:383/430 batch_size:2 loss:3.988284111022949 time_for_batch_instance:30.85287046432495 total_batch_time:14610.906467437744 running_batch_average:38.14858085492884\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 279551 KiB | 340065 KiB | 269911 GiB | 269911 GiB |\n","|       from large pool | 196199 KiB | 240982 KiB | 257277 GiB | 257277 GiB |\n","|       from small pool |  83352 KiB | 119218 KiB |  12633 GiB |  12633 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 279551 KiB | 340065 KiB | 269911 GiB | 269911 GiB |\n","|       from large pool | 196199 KiB | 240982 KiB | 257277 GiB | 257277 GiB |\n","|       from small pool |  83352 KiB | 119218 KiB |  12633 GiB |  12633 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 330946 KiB | 265935 GiB | 265934 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 253305 GiB | 253305 GiB |\n","|       from small pool |  83061 KiB | 118912 KiB |  12629 GiB |  12629 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 387072 KiB | 407552 KiB |  42201 GiB |  42200 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 104448 KiB | 124928 KiB |   1074 GiB |   1073 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 107520 KiB | 168277 KiB | 172124 GiB | 172124 GiB |\n","|       from large pool |  86425 KiB | 135224 KiB | 158399 GiB | 158399 GiB |\n","|       from small pool |  21095 KiB |  38671 KiB |  13724 GiB |  13724 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   88501 K  |   88499 K  |\n","|       from large pool |      98    |     122    |   36168 K  |   36168 K  |\n","|       from small pool |    1706    |    1850    |   52332 K  |   52330 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   88501 K  |   88499 K  |\n","|       from large pool |      98    |     122    |   36168 K  |   36168 K  |\n","|       from small pool |    1706    |    1850    |   52332 K  |   52330 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      63    |      73    |    2116 K  |    2116 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      51    |      61    |     549 K  |     549 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      71    |      83    |   39269 K  |   39269 K  |\n","|       from large pool |      11    |      17    |   21104 K  |   21104 K  |\n","|       from small pool |      60    |      71    |   18165 K  |   18165 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:384/430 batch_size:2\n","Next token prediction. step:164/168 batch:384/430 epoch:1/1\n","full seq: In India, a 2005 amendment created a unique mechanism to restore balance and fairness to patenting standards, thereby safeguarding access.Ģġġġġġġġġġġġġġġġġġġġġġġġġġġġġġ\n","pref seq: In India, a 2005 amendment created a unique mechanism to restore balance and fairness to patenting standards, thereby safeguarding access.Ģġġġġġġġġġġġġġġġġġġġġġġġġġ\n","next tok:                                                                                                                                                                    ġ\n","pred tok:                                                                                                                                                                     \n","Completed batch.\n","epoch:1/1 batch:384/430 batch_size:2 loss:3.7338032722473145 time_for_batch_instance:30.57346796989441 total_batch_time:14641.479935407639 running_batch_average:38.128853998457394\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 277554 KiB | 348750 KiB | 270008 GiB | 270008 GiB |\n","|       from large pool | 194201 KiB | 243203 KiB | 257334 GiB | 257334 GiB |\n","|       from small pool |  83352 KiB | 119964 KiB |  12674 GiB |  12673 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 277554 KiB | 348750 KiB | 270008 GiB | 270008 GiB |\n","|       from large pool | 194201 KiB | 243203 KiB | 257334 GiB | 257334 GiB |\n","|       from small pool |  83352 KiB | 119964 KiB |  12674 GiB |  12673 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 341960 KiB | 266027 GiB | 266026 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 253356 GiB | 253356 GiB |\n","|       from small pool |  83061 KiB | 119653 KiB |  12670 GiB |  12670 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 385024 KiB | 407552 KiB |  42203 GiB |  42203 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 102400 KiB | 124928 KiB |   1076 GiB |   1076 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 107470 KiB | 166229 KiB | 172225 GiB | 172225 GiB |\n","|       from large pool |  88422 KiB | 135224 KiB | 158456 GiB | 158456 GiB |\n","|       from small pool |  19047 KiB |  37656 KiB |  13768 GiB |  13768 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   88695 K  |   88693 K  |\n","|       from large pool |      98    |     122    |   36198 K  |   36197 K  |\n","|       from small pool |    1706    |    1850    |   52497 K  |   52495 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   88695 K  |   88693 K  |\n","|       from large pool |      98    |     122    |   36198 K  |   36197 K  |\n","|       from small pool |    1706    |    1850    |   52497 K  |   52495 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      62    |      73    |    2117 K  |    2117 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      50    |      61    |     551 K  |     551 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      64    |      79    |   39347 K  |   39347 K  |\n","|       from large pool |      14    |      17    |   21123 K  |   21123 K  |\n","|       from small pool |      50    |      65    |   18223 K  |   18223 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:385/430 batch_size:2\n","Next token prediction. step:92/168 batch:385/430 epoch:1/1\n","full seq: Populist movements allege that it does not benefit the average citizen very much, if at all. Instead, they tout protectionism and unilateralism.Ģġġġġġġġġġġġġġġġġġġġġġġġ\n","pref seq: Populist movements allege that it does not benefit the average citizen very much, if at all.\n","next tok:                                                                                             \n","pred tok:                                                                                            .\n","Completed batch.\n","epoch:1/1 batch:385/430 batch_size:2 loss:4.064996242523193 time_for_batch_instance:30.163288831710815 total_batch_time:14671.64322423935 running_batch_average:38.1081642188035\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 277866 KiB | 346219 KiB | 270104 GiB | 270104 GiB |\n","|       from large pool | 194513 KiB | 244313 KiB | 257389 GiB | 257389 GiB |\n","|       from small pool |  83352 KiB | 119060 KiB |  12715 GiB |  12714 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 277866 KiB | 346219 KiB | 270104 GiB | 270104 GiB |\n","|       from large pool | 194513 KiB | 244313 KiB | 257389 GiB | 257389 GiB |\n","|       from small pool |  83352 KiB | 119060 KiB |  12715 GiB |  12714 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 339565 KiB | 266117 GiB | 266117 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 253406 GiB | 253405 GiB |\n","|       from small pool |  83061 KiB | 118771 KiB |  12711 GiB |  12711 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 387072 KiB | 405504 KiB |  42205 GiB |  42205 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 104448 KiB | 122880 KiB |   1078 GiB |   1078 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 109206 KiB | 168280 KiB | 172325 GiB | 172325 GiB |\n","|       from large pool |  88110 KiB | 135224 KiB | 158511 GiB | 158511 GiB |\n","|       from small pool |  21095 KiB |  38405 KiB |  13813 GiB |  13813 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   88888 K  |   88886 K  |\n","|       from large pool |      98    |     122    |   36225 K  |   36225 K  |\n","|       from small pool |    1706    |    1850    |   52662 K  |   52661 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   88888 K  |   88886 K  |\n","|       from large pool |      98    |     122    |   36225 K  |   36225 K  |\n","|       from small pool |    1706    |    1850    |   52662 K  |   52661 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      63    |      72    |    2118 K  |    2118 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      51    |      60    |     552 K  |     552 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      65    |      79    |   39422 K  |   39422 K  |\n","|       from large pool |      14    |      17    |   21141 K  |   21141 K  |\n","|       from small pool |      51    |      67    |   18280 K  |   18280 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:386/430 batch_size:2\n","Next token prediction. step:85/167 batch:386/430 epoch:1/1\n","full seq: Under the proposal, possession of more than five grams of \"yaba\" - a methamphetamine-based drug targeted by the government's crackdown - could be punishable by death.Ģ\n","pref seq: Under the proposal, possession of more than five grams of \"yaba\" - a methamphetamine-\n","next tok:                                                                                     b\n","pred tok:                                                                                     ;\n","Completed batch.\n","epoch:1/1 batch:386/430 batch_size:2 loss:4.32002067565918 time_for_batch_instance:30.482314586639404 total_batch_time:14702.125538825989 running_batch_average:38.088408131673546\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 278871 KiB | 339804 KiB | 270180 GiB | 270180 GiB |\n","|       from large pool | 195519 KiB | 240721 KiB | 257423 GiB | 257423 GiB |\n","|       from small pool |  83352 KiB | 117530 KiB |  12757 GiB |  12757 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 278871 KiB | 339804 KiB | 270180 GiB | 270180 GiB |\n","|       from large pool | 195519 KiB | 240721 KiB | 257423 GiB | 257423 GiB |\n","|       from small pool |  83352 KiB | 117530 KiB |  12757 GiB |  12757 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 330946 KiB | 266192 GiB | 266192 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 253438 GiB | 253438 GiB |\n","|       from small pool |  83061 KiB | 117221 KiB |  12753 GiB |  12753 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 391168 KiB | 405504 KiB |  42206 GiB |  42206 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 108544 KiB | 122880 KiB |   1079 GiB |   1079 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 112296 KiB | 168280 KiB | 172404 GiB | 172404 GiB |\n","|       from large pool |  87105 KiB | 135224 KiB | 158545 GiB | 158545 GiB |\n","|       from small pool |  25191 KiB |  38605 KiB |  13859 GiB |  13859 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   89080 K  |   89079 K  |\n","|       from large pool |      98    |     122    |   36244 K  |   36244 K  |\n","|       from small pool |    1706    |    1850    |   52836 K  |   52835 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   89080 K  |   89079 K  |\n","|       from large pool |      98    |     122    |   36244 K  |   36244 K  |\n","|       from small pool |    1706    |    1850    |   52836 K  |   52835 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      65    |      72    |    2119 K  |    2119 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      53    |      60    |     552 K  |     552 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      68    |      76    |   39490 K  |   39490 K  |\n","|       from large pool |      10    |      17    |   21152 K  |   21152 K  |\n","|       from small pool |      58    |      64    |   18337 K  |   18337 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:387/430 batch_size:2\n","Next token prediction. step:97/167 batch:387/430 epoch:1/1\n","full seq: As such, the US has contributed more to ongoing climate change than any other country. And US per capita emissions are higher than in any other large country, by far.Ģ\n","pref seq: As such, the US has contributed more to ongoing climate change than any other country. And US per\n","next tok:                                                                                                  \n","pred tok:                                                                                                 .\n","Completed batch.\n","epoch:1/1 batch:387/430 batch_size:2 loss:5.476871967315674 time_for_batch_instance:30.72421884536743 total_batch_time:14732.849757671356 running_batch_average:38.06937921878903\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 275647 KiB | 339234 KiB | 270264 GiB | 270264 GiB |\n","|       from large pool | 192295 KiB | 240150 KiB | 257460 GiB | 257460 GiB |\n","|       from small pool |  83352 KiB | 123663 KiB |  12803 GiB |  12803 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 275647 KiB | 339234 KiB | 270264 GiB | 270264 GiB |\n","|       from large pool | 192295 KiB | 240150 KiB | 257460 GiB | 257460 GiB |\n","|       from small pool |  83352 KiB | 123663 KiB |  12803 GiB |  12803 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 330946 KiB | 266274 GiB | 266274 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 253475 GiB | 253474 GiB |\n","|       from small pool |  83061 KiB | 123365 KiB |  12799 GiB |  12799 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 382976 KiB | 409600 KiB |  42209 GiB |  42209 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 100352 KiB | 126976 KiB |   1082 GiB |   1082 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 107328 KiB | 168277 KiB | 172492 GiB | 172492 GiB |\n","|       from large pool |  90329 KiB | 135224 KiB | 158582 GiB | 158582 GiB |\n","|       from small pool |  16999 KiB |  38671 KiB |  13909 GiB |  13909 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   89273 K  |   89271 K  |\n","|       from large pool |      98    |     122    |   36262 K  |   36262 K  |\n","|       from small pool |    1706    |    1850    |   53010 K  |   53008 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   89273 K  |   89271 K  |\n","|       from large pool |      98    |     122    |   36262 K  |   36262 K  |\n","|       from small pool |    1706    |    1850    |   53010 K  |   53008 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      61    |      74    |    2120 K  |    2120 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      49    |      62    |     554 K  |     554 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      75    |      84    |   39557 K  |   39557 K  |\n","|       from large pool |      18    |      20    |   21161 K  |   21161 K  |\n","|       from small pool |      57    |      69    |   18396 K  |   18396 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:388/430 batch_size:2\n","Next token prediction. step:30/167 batch:388/430 epoch:1/1\n","full seq: Finally, the government that Suu Kyi leads must repeal or amend all discriminatory laws and end official anti-Rohingya discrimination.Ģġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġ\n","pref seq: Finally, the government that S\n","next tok:                              u\n","pred tok:                              ġ\n","Completed batch.\n","epoch:1/1 batch:388/430 batch_size:2 loss:4.2412004470825195 time_for_batch_instance:30.98088788986206 total_batch_time:14763.830645561218 running_batch_average:38.05110991124025\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 277540 KiB | 348552 KiB | 270361 GiB | 270361 GiB |\n","|       from large pool | 194187 KiB | 243203 KiB | 257517 GiB | 257517 GiB |\n","|       from small pool |  83352 KiB | 119862 KiB |  12843 GiB |  12843 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 277540 KiB | 348552 KiB | 270361 GiB | 270361 GiB |\n","|       from large pool | 194187 KiB | 243203 KiB | 257517 GiB | 257517 GiB |\n","|       from small pool |  83352 KiB | 119862 KiB |  12843 GiB |  12843 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 341761 KiB | 266366 GiB | 266366 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 253526 GiB | 253526 GiB |\n","|       from small pool |  83061 KiB | 119551 KiB |  12840 GiB |  12839 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 382976 KiB | 405504 KiB |  42211 GiB |  42211 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 100352 KiB | 122880 KiB |   1084 GiB |   1084 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 105436 KiB | 166229 KiB | 172593 GiB | 172593 GiB |\n","|       from large pool |  88436 KiB | 135224 KiB | 158639 GiB | 158639 GiB |\n","|       from small pool |  16999 KiB |  37656 KiB |  13954 GiB |  13954 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   89465 K  |   89463 K  |\n","|       from large pool |      98    |     122    |   36291 K  |   36291 K  |\n","|       from small pool |    1706    |    1850    |   53174 K  |   53172 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   89465 K  |   89463 K  |\n","|       from large pool |      98    |     122    |   36291 K  |   36291 K  |\n","|       from small pool |    1706    |    1850    |   53174 K  |   53172 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      61    |      72    |    2121 K  |    2121 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      49    |      60    |     555 K  |     555 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      66    |      79    |   39635 K  |   39634 K  |\n","|       from large pool |      14    |      20    |   21181 K  |   21181 K  |\n","|       from small pool |      52    |      65    |   18453 K  |   18453 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:389/430 batch_size:2\n","Next token prediction. step:86/167 batch:389/430 epoch:1/1\n","full seq: EEA membership would not amount to British \"cherry picking\" of EU benefits, which other countries have understandably refused to accept.Ģġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġ\n","pref seq: EEA membership would not amount to British \"cherry picking\" of EU benefits, which othe\n","next tok:                                                                                      r\n","pred tok:                                                                                      ġ\n","Completed batch.\n","epoch:1/1 batch:389/430 batch_size:2 loss:4.332856178283691 time_for_batch_instance:29.869158029556274 total_batch_time:14793.699803590775 running_batch_average:38.03007661591459\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 277602 KiB | 348231 KiB | 270458 GiB | 270457 GiB |\n","|       from large pool | 194249 KiB | 243245 KiB | 257574 GiB | 257573 GiB |\n","|       from small pool |  83352 KiB | 119689 KiB |  12883 GiB |  12883 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 277602 KiB | 348231 KiB | 270458 GiB | 270457 GiB |\n","|       from large pool | 194249 KiB | 243245 KiB | 257574 GiB | 257573 GiB |\n","|       from small pool |  83352 KiB | 119689 KiB |  12883 GiB |  12883 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 341286 KiB | 266457 GiB | 266457 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 253577 GiB | 253577 GiB |\n","|       from small pool |  83061 KiB | 119378 KiB |  12880 GiB |  12880 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 385024 KiB | 405504 KiB |  42214 GiB |  42213 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 102400 KiB | 122880 KiB |   1087 GiB |   1086 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 107422 KiB | 166230 KiB | 172694 GiB | 172694 GiB |\n","|       from large pool |  88374 KiB | 135224 KiB | 158696 GiB | 158696 GiB |\n","|       from small pool |  19047 KiB |  37374 KiB |  13998 GiB |  13998 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   89657 K  |   89656 K  |\n","|       from large pool |      98    |     122    |   36320 K  |   36320 K  |\n","|       from small pool |    1706    |    1850    |   53337 K  |   53335 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   89657 K  |   89656 K  |\n","|       from large pool |      98    |     122    |   36320 K  |   36320 K  |\n","|       from small pool |    1706    |    1850    |   53337 K  |   53335 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      62    |      72    |    2123 K  |    2123 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      50    |      60    |     556 K  |     556 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      62    |      75    |   39712 K  |   39712 K  |\n","|       from large pool |      14    |      17    |   21200 K  |   21200 K  |\n","|       from small pool |      48    |      61    |   18511 K  |   18511 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:390/430 batch_size:2\n","Next token prediction. step:84/166 batch:390/430 epoch:1/1\n","full seq: Most likely, a growing sense of insecurity is pushing the elderly into the populists' arms.Ģġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġ\n","pref seq: Most likely, a growing sense of insecurity is pushing the elderly into the populists\n","next tok:                                                                                    '\n","pred tok:                                                                                    N\n","Completed batch.\n","epoch:1/1 batch:390/430 batch_size:2 loss:4.704745292663574 time_for_batch_instance:29.85528039932251 total_batch_time:14823.555083990097 running_batch_average:38.009115599974606\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 278377 KiB | 365641 KiB | 270563 GiB | 270563 GiB |\n","|       from large pool | 195024 KiB | 241421 KiB | 257635 GiB | 257634 GiB |\n","|       from small pool |  83352 KiB | 127022 KiB |  12928 GiB |  12928 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 278377 KiB | 365641 KiB | 270563 GiB | 270563 GiB |\n","|       from large pool | 195024 KiB | 241421 KiB | 257635 GiB | 257634 GiB |\n","|       from small pool |  83352 KiB | 127022 KiB |  12928 GiB |  12928 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 361548 KiB | 266559 GiB | 266559 GiB |\n","|       from large pool | 189056 KiB | 237124 KiB | 253635 GiB | 253635 GiB |\n","|       from small pool |  83061 KiB | 126726 KiB |  12924 GiB |  12924 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 387072 KiB | 413696 KiB |  42216 GiB |  42216 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 104448 KiB | 131072 KiB |   1089 GiB |   1089 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 108695 KiB | 166711 KiB | 172803 GiB | 172803 GiB |\n","|       from large pool |  87599 KiB | 135224 KiB | 158757 GiB | 158757 GiB |\n","|       from small pool |  21095 KiB |  38671 KiB |  14046 GiB |  14046 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   89849 K  |   89847 K  |\n","|       from large pool |      98    |     122    |   36349 K  |   36349 K  |\n","|       from small pool |    1706    |    1850    |   53499 K  |   53498 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   89849 K  |   89847 K  |\n","|       from large pool |      98    |     122    |   36349 K  |   36349 K  |\n","|       from small pool |    1706    |    1850    |   53499 K  |   53498 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      63    |      76    |    2124 K  |    2124 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      51    |      64    |     557 K  |     557 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      67    |      88    |   39788 K  |   39788 K  |\n","|       from large pool |      16    |      20    |   21218 K  |   21218 K  |\n","|       from small pool |      51    |      69    |   18570 K  |   18569 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:391/430 batch_size:2\n","Next token prediction. step:30/165 batch:391/430 epoch:1/1\n","full seq: Is it possible for oil companies to temper their excitement during periods of rising prices, and not to fall into a malaise when prices are low for lengthy periods?Ģ\n","pref seq: Is it possible for oil compani\n","next tok:                              e\n","pred tok:                              ġ\n","Completed batch.\n","epoch:1/1 batch:391/430 batch_size:2 loss:7.953080177307129 time_for_batch_instance:29.05567455291748 total_batch_time:14852.610758543015 running_batch_average:37.9862167737673\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 279995 KiB | 339804 KiB | 270639 GiB | 270639 GiB |\n","|       from large pool | 196642 KiB | 240721 KiB | 257669 GiB | 257668 GiB |\n","|       from small pool |  83352 KiB | 117778 KiB |  12970 GiB |  12970 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 279995 KiB | 339804 KiB | 270639 GiB | 270639 GiB |\n","|       from large pool | 196642 KiB | 240721 KiB | 257669 GiB | 257668 GiB |\n","|       from small pool |  83352 KiB | 117778 KiB |  12970 GiB |  12970 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 330946 KiB | 266634 GiB | 266634 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 253668 GiB | 253667 GiB |\n","|       from small pool |  83061 KiB | 117470 KiB |  12966 GiB |  12966 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 385024 KiB | 405504 KiB |  42218 GiB |  42218 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 102400 KiB | 122880 KiB |   1091 GiB |   1091 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 105029 KiB | 164534 KiB | 172883 GiB | 172882 GiB |\n","|       from large pool |  85981 KiB | 135224 KiB | 158791 GiB | 158791 GiB |\n","|       from small pool |  19047 KiB |  36628 KiB |  14091 GiB |  14091 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   90039 K  |   90037 K  |\n","|       from large pool |      98    |     122    |   36367 K  |   36367 K  |\n","|       from small pool |    1706    |    1850    |   53671 K  |   53670 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   90039 K  |   90037 K  |\n","|       from large pool |      98    |     122    |   36367 K  |   36367 K  |\n","|       from small pool |    1706    |    1850    |   53671 K  |   53670 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      62    |      72    |    2125 K  |    2125 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      50    |      60    |     558 K  |     558 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      63    |      77    |   39856 K  |   39856 K  |\n","|       from large pool |       9    |      16    |   21228 K  |   21228 K  |\n","|       from small pool |      54    |      66    |   18627 K  |   18627 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:392/430 batch_size:2\n","Next token prediction. step:74/164 batch:392/430 epoch:1/1\n","full seq: In many cases, banks chose to relend funds rather than take losses onto their books or force politically connected firms into bankruptcy.Ģġġġġġġġġġġġġġġġġġġġġġġġġġġ\n","pref seq: In many cases, banks chose to relend funds rather than take losses onto th\n","next tok:                                                                          e\n","pred tok:                                                                          N\n","Completed batch.\n","epoch:1/1 batch:392/430 batch_size:2 loss:3.818986415863037 time_for_batch_instance:28.738178253173828 total_batch_time:14881.348936796188 running_batch_average:37.962624838765784\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 281029 KiB | 344404 KiB | 270732 GiB | 270731 GiB |\n","|       from large pool | 197676 KiB | 245227 KiB | 257722 GiB | 257722 GiB |\n","|       from small pool |  83352 KiB | 118133 KiB |  13009 GiB |  13009 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 281029 KiB | 344404 KiB | 270732 GiB | 270731 GiB |\n","|       from large pool | 197676 KiB | 245227 KiB | 257722 GiB | 257722 GiB |\n","|       from small pool |  83352 KiB | 118133 KiB |  13009 GiB |  13009 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 337343 KiB | 266721 GiB | 266721 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 253715 GiB | 253715 GiB |\n","|       from small pool |  83061 KiB | 117842 KiB |  13006 GiB |  13005 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 380928 KiB | 405504 KiB |  42220 GiB |  42220 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool |  98304 KiB | 122880 KiB |   1093 GiB |   1093 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |  99899 KiB | 164958 KiB | 172979 GiB | 172979 GiB |\n","|       from large pool |  84947 KiB | 135224 KiB | 158844 GiB | 158844 GiB |\n","|       from small pool |  14951 KiB |  36625 KiB |  14135 GiB |  14135 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   90228 K  |   90226 K  |\n","|       from large pool |      98    |     122    |   36394 K  |   36394 K  |\n","|       from small pool |    1706    |    1850    |   53833 K  |   53831 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   90228 K  |   90226 K  |\n","|       from large pool |      98    |     122    |   36394 K  |   36394 K  |\n","|       from small pool |    1706    |    1850    |   53833 K  |   53831 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      60    |      72    |    2126 K  |    2126 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      48    |      60    |     559 K  |     559 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      63    |      80    |   39928 K  |   39928 K  |\n","|       from large pool |      15    |      19    |   21245 K  |   21245 K  |\n","|       from small pool |      48    |      63    |   18682 K  |   18682 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:393/430 batch_size:2\n","Next token prediction. step:1/164 batch:393/430 epoch:1/1\n","full seq: Yet they have made only limited investments in infrastructure equity, focusing such investment, instead, on small- and medium-size enterprises in emerging markets.Ģ\n","pref seq: Y\n","next tok: e\n","pred tok: ġ\n","Completed batch.\n","epoch:1/1 batch:393/430 batch_size:2 loss:5.15381383895874 time_for_batch_instance:28.90647554397583 total_batch_time:14910.255412340164 running_batch_average:37.93958120188337\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 277972 KiB | 372040 KiB | 270839 GiB | 270838 GiB |\n","|       from large pool | 194619 KiB | 245329 KiB | 257783 GiB | 257783 GiB |\n","|       from small pool |  83352 KiB | 129060 KiB |  13055 GiB |  13055 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 277972 KiB | 372040 KiB | 270839 GiB | 270838 GiB |\n","|       from large pool | 194619 KiB | 245329 KiB | 257783 GiB | 257783 GiB |\n","|       from small pool |  83352 KiB | 129060 KiB |  13055 GiB |  13055 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 367331 KiB | 266826 GiB | 266826 GiB |\n","|       from large pool | 189056 KiB | 240913 KiB | 253774 GiB | 253774 GiB |\n","|       from small pool |  83061 KiB | 128768 KiB |  13051 GiB |  13051 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 385024 KiB | 413696 KiB |  42223 GiB |  42223 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 102400 KiB | 131072 KiB |   1096 GiB |   1096 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 107052 KiB | 170331 KiB | 173090 GiB | 173090 GiB |\n","|       from large pool |  88004 KiB | 135224 KiB | 158906 GiB | 158905 GiB |\n","|       from small pool |  19047 KiB |  41495 KiB |  14184 GiB |  14184 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   90416 K  |   90415 K  |\n","|       from large pool |      98    |     122    |   36422 K  |   36422 K  |\n","|       from small pool |    1706    |    1850    |   53994 K  |   53992 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   90416 K  |   90415 K  |\n","|       from large pool |      98    |     122    |   36422 K  |   36422 K  |\n","|       from small pool |    1706    |    1850    |   53994 K  |   53992 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      62    |      76    |    2127 K  |    2127 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      50    |      64    |     561 K  |     561 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      71    |      81    |   40007 K  |   40007 K  |\n","|       from large pool |      17    |      21    |   21263 K  |   21263 K  |\n","|       from small pool |      54    |      64    |   18744 K  |   18744 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:394/430 batch_size:2\n","Next token prediction. step:132/163 batch:394/430 epoch:1/1\n","full seq: Government agencies need to be close enough to private enterprises to elicit the requisite information about the technological and market realities on the ground.Ģ\n","pref seq: Government agencies need to be close enough to private enterprises to elicit the requisite information about the technological and m\n","next tok:                                                                                                                                    a\n","pred tok:                                                                                                                                    e\n","Completed batch.\n","epoch:1/1 batch:394/430 batch_size:2 loss:3.4941201210021973 time_for_batch_instance:28.994986295700073 total_batch_time:14939.250398635864 running_batch_average:37.91687918435498\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 279798 KiB | 339804 KiB | 270913 GiB | 270912 GiB |\n","|       from large pool | 196446 KiB | 240721 KiB | 257817 GiB | 257816 GiB |\n","|       from small pool |  83352 KiB | 117120 KiB |  13096 GiB |  13096 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 279798 KiB | 339804 KiB | 270913 GiB | 270912 GiB |\n","|       from large pool | 196446 KiB | 240721 KiB | 257817 GiB | 257816 GiB |\n","|       from small pool |  83352 KiB | 117120 KiB |  13096 GiB |  13096 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 330946 KiB | 266899 GiB | 266899 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 253806 GiB | 253806 GiB |\n","|       from small pool |  83061 KiB | 116811 KiB |  13092 GiB |  13092 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 395264 KiB | 405504 KiB |  42224 GiB |  42224 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 112640 KiB | 122880 KiB |   1097 GiB |   1097 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 115465 KiB | 168280 KiB | 173168 GiB | 173168 GiB |\n","|       from large pool |  86178 KiB | 135224 KiB | 158939 GiB | 158938 GiB |\n","|       from small pool |  29287 KiB |  38605 KiB |  14229 GiB |  14229 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   90604 K  |   90602 K  |\n","|       from large pool |      98    |     122    |   36440 K  |   36440 K  |\n","|       from small pool |    1706    |    1850    |   54163 K  |   54162 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   90604 K  |   90602 K  |\n","|       from large pool |      98    |     122    |   36440 K  |   36440 K  |\n","|       from small pool |    1706    |    1850    |   54163 K  |   54162 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      67    |      72    |    2128 K  |    2128 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      55    |      60    |     561 K  |     561 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      61    |      76    |   40074 K  |   40074 K  |\n","|       from large pool |       9    |      17    |   21274 K  |   21274 K  |\n","|       from small pool |      52    |      64    |   18800 K  |   18800 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:395/430 batch_size:2\n","Next token prediction. step:140/162 batch:395/430 epoch:1/1\n","full seq: First, by bringing forward the British election, May has effectively extended the deadline for Britain's withdrawal from the European Union from 2019 until 2022.Ģ\n","pref seq: First, by bringing forward the British election, May has effectively extended the deadline for Britain's withdrawal from the European Union \n","next tok:                                                                                                                                            f\n","pred tok:                                                                                                                                             \n","Completed batch.\n","epoch:1/1 batch:395/430 batch_size:2 loss:4.474493503570557 time_for_batch_instance:28.615317583084106 total_batch_time:14967.865716218948 running_batch_average:37.89333092713658\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 281767 KiB | 342246 KiB | 270994 GiB | 270993 GiB |\n","|       from large pool | 198415 KiB | 243162 KiB | 257853 GiB | 257853 GiB |\n","|       from small pool |  83352 KiB | 122459 KiB |  13140 GiB |  13140 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 281767 KiB | 342246 KiB | 270994 GiB | 270993 GiB |\n","|       from large pool | 198415 KiB | 243162 KiB | 257853 GiB | 257853 GiB |\n","|       from small pool |  83352 KiB | 122459 KiB |  13140 GiB |  13140 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 330946 KiB | 266978 GiB | 266978 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 253841 GiB | 253841 GiB |\n","|       from small pool |  83061 KiB | 122159 KiB |  13136 GiB |  13136 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 380928 KiB | 409600 KiB |  42227 GiB |  42227 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool |  98304 KiB | 126976 KiB |   1100 GiB |   1100 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |  99160 KiB | 167794 KiB | 173252 GiB | 173252 GiB |\n","|       from large pool |  84209 KiB | 135224 KiB | 158975 GiB | 158975 GiB |\n","|       from small pool |  14951 KiB |  37655 KiB |  14277 GiB |  14277 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   90791 K  |   90789 K  |\n","|       from large pool |      98    |     122    |   36458 K  |   36458 K  |\n","|       from small pool |    1706    |    1850    |   54332 K  |   54330 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   90791 K  |   90789 K  |\n","|       from large pool |      98    |     122    |   36458 K  |   36458 K  |\n","|       from small pool |    1706    |    1850    |   54332 K  |   54330 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      60    |      74    |    2129 K  |    2129 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      48    |      62    |     563 K  |     563 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      62    |      82    |   40139 K  |   40139 K  |\n","|       from large pool |      12    |      18    |   21283 K  |   21283 K  |\n","|       from small pool |      50    |      69    |   18856 K  |   18856 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:396/430 batch_size:2\n","Next token prediction. step:58/162 batch:396/430 epoch:1/1\n","full seq: It is not surprising that equity investors have responded to the surge in animal spirits by attempting to run ahead of a possible uptick in economic performance.Ģ\n","pref seq: It is not surprising that equity investors have responded \n","next tok:                                                          t\n","pred tok:                                                          ġ\n","Completed batch.\n","epoch:1/1 batch:396/430 batch_size:2 loss:4.0561442375183105 time_for_batch_instance:28.797146320343018 total_batch_time:14996.662862539291 running_batch_average:37.87036076398811\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 279214 KiB | 338744 KiB | 271067 GiB | 271066 GiB |\n","|       from large pool | 195862 KiB | 239661 KiB | 257886 GiB | 257885 GiB |\n","|       from small pool |  83352 KiB | 116552 KiB |  13181 GiB |  13180 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 279214 KiB | 338744 KiB | 271067 GiB | 271066 GiB |\n","|       from large pool | 195862 KiB | 239661 KiB | 257886 GiB | 257885 GiB |\n","|       from small pool |  83352 KiB | 116552 KiB |  13181 GiB |  13180 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 330946 KiB | 267050 GiB | 267049 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 253873 GiB | 253872 GiB |\n","|       from small pool |  83061 KiB | 116242 KiB |  13177 GiB |  13177 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 382976 KiB | 403456 KiB |  42229 GiB |  42228 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 100352 KiB | 120832 KiB |   1101 GiB |   1101 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 103761 KiB | 165747 KiB | 173329 GiB | 173329 GiB |\n","|       from large pool |  86762 KiB | 135224 KiB | 159008 GiB | 159008 GiB |\n","|       from small pool |  16999 KiB |  34573 KiB |  14321 GiB |  14321 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   90977 K  |   90975 K  |\n","|       from large pool |      98    |     122    |   36476 K  |   36476 K  |\n","|       from small pool |    1706    |    1850    |   54501 K  |   54499 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   90977 K  |   90975 K  |\n","|       from large pool |      98    |     122    |   36476 K  |   36476 K  |\n","|       from small pool |    1706    |    1850    |   54501 K  |   54499 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      61    |      71    |    2130 K  |    2130 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      49    |      59    |     564 K  |     564 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      59    |      77    |   40205 K  |   40205 K  |\n","|       from large pool |      10    |      16    |   21293 K  |   21293 K  |\n","|       from small pool |      49    |      66    |   18911 K  |   18911 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:397/430 batch_size:2\n","Next token prediction. step:119/160 batch:397/430 epoch:1/1\n","full seq: Indeed, come 2021, the UK will still be hurtling toward a \"cliff edge\": a full break from Europe, with no alternative arrangement in place to cushion the blow.Ģ\n","pref seq: Indeed, come 2021, the UK will still be hurtling toward a \"cliff edge\": a full break from Europe, with no alternative a\n","next tok:                                                                                                                       r\n","pred tok:                                                                                                                       .\n","Completed batch.\n","epoch:1/1 batch:397/430 batch_size:2 loss:4.2485032081604 time_for_batch_instance:28.616114377975464 total_batch_time:15025.278976917267 running_batch_average:37.84705031969085\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 277916 KiB | 337418 KiB | 271138 GiB | 271137 GiB |\n","|       from large pool | 194564 KiB | 238335 KiB | 257917 GiB | 257917 GiB |\n","|       from small pool |  83352 KiB | 115441 KiB |  13220 GiB |  13220 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 277916 KiB | 337418 KiB | 271138 GiB | 271137 GiB |\n","|       from large pool | 194564 KiB | 238335 KiB | 257917 GiB | 257917 GiB |\n","|       from small pool |  83352 KiB | 115441 KiB |  13220 GiB |  13220 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 330946 KiB | 267120 GiB | 267119 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 253903 GiB | 253903 GiB |\n","|       from small pool |  83061 KiB | 115129 KiB |  13216 GiB |  13216 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 378880 KiB | 403456 KiB |  42230 GiB |  42230 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool |  96256 KiB | 120832 KiB |   1103 GiB |   1103 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 100963 KiB | 170325 KiB | 173403 GiB | 173403 GiB |\n","|       from large pool |  88060 KiB | 135224 KiB | 159039 GiB | 159039 GiB |\n","|       from small pool |  12903 KiB |  38693 KiB |  14363 GiB |  14363 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   91161 K  |   91159 K  |\n","|       from large pool |      98    |     122    |   36494 K  |   36494 K  |\n","|       from small pool |    1706    |    1850    |   54667 K  |   54665 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   91161 K  |   91159 K  |\n","|       from large pool |      98    |     122    |   36494 K  |   36494 K  |\n","|       from small pool |    1706    |    1850    |   54667 K  |   54665 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      59    |      71    |    2131 K  |    2131 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      47    |      59    |     565 K  |     564 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      63    |      76    |   40269 K  |   40269 K  |\n","|       from large pool |      11    |      17    |   21303 K  |   21303 K  |\n","|       from small pool |      52    |      64    |   18966 K  |   18966 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:398/430 batch_size:2\n","Next token prediction. step:86/160 batch:398/430 epoch:1/1\n","full seq: The crash of 1907 preceded World War I; and the 1929 crash, the 1931 European banking crisis, and the Great Depression preceded WWII.Ģġġġġġġġġġġġġġġġġġġġġġġġġġġ\n","pref seq: The crash of 1907 preceded World War I; and the 1929 crash, the 1931 European banking \n","next tok:                                                                                      c\n","pred tok:                                                                                      3\n","Completed batch.\n","epoch:1/1 batch:398/430 batch_size:2 loss:4.216714859008789 time_for_batch_instance:28.710849046707153 total_batch_time:15053.989825963974 running_batch_average:37.824095040110485\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 277029 KiB | 342060 KiB | 271226 GiB | 271226 GiB |\n","|       from large pool | 193677 KiB | 239974 KiB | 257968 GiB | 257968 GiB |\n","|       from small pool |  83352 KiB | 116848 KiB |  13258 GiB |  13258 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 277029 KiB | 342060 KiB | 271226 GiB | 271226 GiB |\n","|       from large pool | 193677 KiB | 239974 KiB | 257968 GiB | 257968 GiB |\n","|       from small pool |  83352 KiB | 116848 KiB |  13258 GiB |  13258 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 334158 KiB | 267203 GiB | 267203 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 253949 GiB | 253948 GiB |\n","|       from small pool |  83061 KiB | 116555 KiB |  13254 GiB |  13254 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 382976 KiB | 405504 KiB |  42232 GiB |  42231 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 100352 KiB | 122880 KiB |   1104 GiB |   1104 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 105946 KiB | 164187 KiB | 173495 GiB | 173495 GiB |\n","|       from large pool |  88947 KiB | 135224 KiB | 159090 GiB | 159090 GiB |\n","|       from small pool |  16999 KiB |  36606 KiB |  14405 GiB |  14405 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   91345 K  |   91344 K  |\n","|       from large pool |      98    |     122    |   36520 K  |   36520 K  |\n","|       from small pool |    1706    |    1850    |   54825 K  |   54823 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   91345 K  |   91344 K  |\n","|       from large pool |      98    |     122    |   36520 K  |   36520 K  |\n","|       from small pool |    1706    |    1850    |   54825 K  |   54823 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      61    |      72    |    2132 K  |    2132 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      49    |      60    |     565 K  |     565 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      65    |      85    |   40342 K  |   40342 K  |\n","|       from large pool |      15    |      19    |   21320 K  |   21320 K  |\n","|       from small pool |      50    |      68    |   19021 K  |   19021 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:399/430 batch_size:2\n","Next token prediction. step:52/159 batch:399/430 epoch:1/1\n","full seq: For a country with a balanced current account, a deficit can arise if its investment rate rises, its saving rate falls, or some combination of the two occurs.Ģ\n","pref seq: For a country with a balanced current account, a def\n","next tok:                                                    i\n","pred tok:                                                    ġ\n","Completed batch.\n","epoch:1/1 batch:399/430 batch_size:2 loss:5.376102924346924 time_for_batch_instance:28.73291563987732 total_batch_time:15082.722741603851 running_batch_average:37.80131012933296\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 278419 KiB | 339234 KiB | 271306 GiB | 271305 GiB |\n","|       from large pool | 195067 KiB | 240150 KiB | 258004 GiB | 258003 GiB |\n","|       from small pool |  83352 KiB | 122831 KiB |  13302 GiB |  13302 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 278419 KiB | 339234 KiB | 271306 GiB | 271305 GiB |\n","|       from large pool | 195067 KiB | 240150 KiB | 258004 GiB | 258003 GiB |\n","|       from small pool |  83352 KiB | 122831 KiB |  13302 GiB |  13302 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 330946 KiB | 267281 GiB | 267281 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 253983 GiB | 253983 GiB |\n","|       from small pool |  83061 KiB | 122531 KiB |  13298 GiB |  13298 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 380928 KiB | 409600 KiB |  42234 GiB |  42234 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool |  98304 KiB | 126976 KiB |   1107 GiB |   1107 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 102508 KiB | 168277 KiB | 173579 GiB | 173578 GiB |\n","|       from large pool |  87557 KiB | 135224 KiB | 159126 GiB | 159125 GiB |\n","|       from small pool |  14951 KiB |  38671 KiB |  14452 GiB |  14452 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   91528 K  |   91527 K  |\n","|       from large pool |      98    |     122    |   36537 K  |   36537 K  |\n","|       from small pool |    1706    |    1850    |   54991 K  |   54989 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   91528 K  |   91527 K  |\n","|       from large pool |      98    |     122    |   36537 K  |   36537 K  |\n","|       from small pool |    1706    |    1850    |   54991 K  |   54989 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      60    |      74    |    2133 K  |    2133 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      48    |      62    |     567 K  |     566 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      68    |      84    |   40406 K  |   40406 K  |\n","|       from large pool |      15    |      20    |   21329 K  |   21329 K  |\n","|       from small pool |      53    |      69    |   19076 K  |   19076 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:400/430 batch_size:2\n","Next token prediction. step:130/158 batch:400/430 epoch:1/1\n","full seq: These figures will likely trouble Google, Facebook, and other tech giants whose businesses are no less reliant on trust than traditional media organizations.Ģ\n","pref seq: These figures will likely trouble Google, Facebook, and other tech giants whose businesses are no less reliant on trust than tradi\n","next tok:                                                                                                                                  t\n","pred tok:                                                                                                                                   \n","Completed batch.\n","epoch:1/1 batch:400/430 batch_size:2 loss:5.4641947746276855 time_for_batch_instance:27.8526554107666 total_batch_time:15110.575397014618 running_batch_average:37.77643849253654\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 277134 KiB | 337465 KiB | 271368 GiB | 271368 GiB |\n","|       from large pool | 193782 KiB | 238381 KiB | 258032 GiB | 258032 GiB |\n","|       from small pool |  83352 KiB | 109079 KiB |  13336 GiB |  13336 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 277134 KiB | 337465 KiB | 271368 GiB | 271368 GiB |\n","|       from large pool | 193782 KiB | 238381 KiB | 258032 GiB | 258032 GiB |\n","|       from small pool |  83352 KiB | 109079 KiB |  13336 GiB |  13336 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 330946 KiB | 267342 GiB | 267342 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 254010 GiB | 254010 GiB |\n","|       from small pool |  83061 KiB | 108781 KiB |  13332 GiB |  13332 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 382976 KiB | 395264 KiB |  42235 GiB |  42235 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 100352 KiB | 112640 KiB |   1108 GiB |   1108 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 105841 KiB | 163943 KiB | 173644 GiB | 173644 GiB |\n","|       from large pool |  88842 KiB | 135224 KiB | 159154 GiB | 159154 GiB |\n","|       from small pool |  16999 KiB |  32518 KiB |  14489 GiB |  14489 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   91710 K  |   91708 K  |\n","|       from large pool |      98    |     122    |   36555 K  |   36555 K  |\n","|       from small pool |    1706    |    1850    |   55155 K  |   55153 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   91710 K  |   91708 K  |\n","|       from large pool |      98    |     122    |   36555 K  |   36555 K  |\n","|       from small pool |    1706    |    1850    |   55155 K  |   55153 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      61    |      67    |    2134 K  |    2134 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      49    |      55    |     567 K  |     567 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      66    |      74    |   40476 K  |   40476 K  |\n","|       from large pool |      15    |      20    |   21338 K  |   21338 K  |\n","|       from small pool |      51    |      59    |   19137 K  |   19137 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:401/430 batch_size:2\n","Next token prediction. step:107/155 batch:401/430 epoch:1/1\n","full seq: Hardline Israelis repeatedly sought to convince the US to attack Iran's nuclear facilities, or at least allow Israel to do so.Ģġġġġġġġġġġġġġġġġġġġġġġġġġġġġ\n","pref seq: Hardline Israelis repeatedly sought to convince the US to attack Iran's nuclear facilities, or at least all\n","next tok:                                                                                                           o\n","pred tok:                                                                                                           .\n","Completed batch.\n","epoch:1/1 batch:401/430 batch_size:2 loss:4.440857887268066 time_for_batch_instance:27.116827726364136 total_batch_time:15137.692224740982 running_batch_average:37.74985592204734\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 277077 KiB | 339596 KiB | 271453 GiB | 271453 GiB |\n","|       from large pool | 193725 KiB | 239932 KiB | 258080 GiB | 258080 GiB |\n","|       from small pool |  83352 KiB | 115991 KiB |  13372 GiB |  13372 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 277077 KiB | 339596 KiB | 271453 GiB | 271453 GiB |\n","|       from large pool | 193725 KiB | 239932 KiB | 258080 GiB | 258080 GiB |\n","|       from small pool |  83352 KiB | 115991 KiB |  13372 GiB |  13372 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 332213 KiB | 267422 GiB | 267422 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 254054 GiB | 254053 GiB |\n","|       from small pool |  83061 KiB | 115696 KiB |  13368 GiB |  13368 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 387072 KiB | 403456 KiB |  42237 GiB |  42236 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 104448 KiB | 120832 KiB |   1110 GiB |   1109 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 109994 KiB | 164424 KiB | 173732 GiB | 173732 GiB |\n","|       from large pool |  88899 KiB | 135224 KiB | 159202 GiB | 159202 GiB |\n","|       from small pool |  21095 KiB |  35586 KiB |  14529 GiB |  14529 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   91889 K  |   91887 K  |\n","|       from large pool |      98    |     122    |   36580 K  |   36580 K  |\n","|       from small pool |    1706    |    1850    |   55308 K  |   55306 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   91889 K  |   91887 K  |\n","|       from large pool |      98    |     122    |   36580 K  |   36580 K  |\n","|       from small pool |    1706    |    1850    |   55308 K  |   55306 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      63    |      71    |    2134 K  |    2134 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      51    |      59    |     568 K  |     568 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      77    |      83    |   40543 K  |   40543 K  |\n","|       from large pool |      14    |      19    |   21355 K  |   21355 K  |\n","|       from small pool |      63    |      68    |   19188 K  |   19188 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:402/430 batch_size:2\n","Next token prediction. step:109/154 batch:402/430 epoch:1/1\n","full seq: As power dynamics shift, victims overcome the belief that they must suffer in silence, and come to trust that enough people will actually listen to them.Ģ\n","pref seq: As power dynamics shift, victims overcome the belief that they must suffer in silence, and come to trust that\n","next tok:                                                                                                              \n","pred tok:                                                                                                             .\n","Completed batch.\n","epoch:1/1 batch:402/430 batch_size:2 loss:4.115777492523193 time_for_batch_instance:26.717710971832275 total_batch_time:15164.409935712814 running_batch_average:37.72241277540501\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 277076 KiB | 336690 KiB | 271519 GiB | 271519 GiB |\n","|       from large pool | 193724 KiB | 237607 KiB | 258110 GiB | 258110 GiB |\n","|       from small pool |  83352 KiB | 113694 KiB |  13409 GiB |  13409 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 277076 KiB | 336690 KiB | 271519 GiB | 271519 GiB |\n","|       from large pool | 193724 KiB | 237607 KiB | 258110 GiB | 258110 GiB |\n","|       from small pool |  83352 KiB | 113694 KiB |  13409 GiB |  13409 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 330946 KiB | 267488 GiB | 267488 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 254082 GiB | 254082 GiB |\n","|       from small pool |  83061 KiB | 113379 KiB |  13405 GiB |  13405 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 380928 KiB | 401408 KiB |  42238 GiB |  42238 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool |  98304 KiB | 118784 KiB |   1111 GiB |   1111 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 103851 KiB | 164182 KiB | 173801 GiB | 173801 GiB |\n","|       from large pool |  88900 KiB | 135224 KiB | 159232 GiB | 159232 GiB |\n","|       from small pool |  14951 KiB |  33560 KiB |  14569 GiB |  14569 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   92066 K  |   92064 K  |\n","|       from large pool |      98    |     122    |   36597 K  |   36597 K  |\n","|       from small pool |    1706    |    1850    |   55468 K  |   55466 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   92066 K  |   92064 K  |\n","|       from large pool |      98    |     122    |   36597 K  |   36597 K  |\n","|       from small pool |    1706    |    1850    |   55468 K  |   55466 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      60    |      70    |    2135 K  |    2135 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      48    |      58    |     569 K  |     568 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      58    |      77    |   40610 K  |   40610 K  |\n","|       from large pool |      11    |      17    |   21364 K  |   21364 K  |\n","|       from small pool |      47    |      63    |   19245 K  |   19245 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:403/430 batch_size:2\n","Next token prediction. step:48/154 batch:403/430 epoch:1/1\n","full seq: According to the Center for International Media Assistance, the donations included \"generous\" support to the \"reliably pro-government\" newspaper Pobjeda.Ģ\n","pref seq: According to the Center for International Media \n","next tok:                                                A\n","pred tok:                                                N\n","Completed batch.\n","epoch:1/1 batch:403/430 batch_size:2 loss:3.336080551147461 time_for_batch_instance:26.703664541244507 total_batch_time:15191.113600254059 running_batch_average:37.695070968372356\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 277244 KiB | 336914 KiB | 271586 GiB | 271586 GiB |\n","|       from large pool | 193892 KiB | 237831 KiB | 258140 GiB | 258139 GiB |\n","|       from small pool |  83352 KiB | 114147 KiB |  13446 GiB |  13446 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 277244 KiB | 336914 KiB | 271586 GiB | 271586 GiB |\n","|       from large pool | 193892 KiB | 237831 KiB | 258140 GiB | 258139 GiB |\n","|       from small pool |  83352 KiB | 114147 KiB |  13446 GiB |  13446 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 330946 KiB | 267554 GiB | 267554 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 254111 GiB | 254111 GiB |\n","|       from small pool |  83061 KiB | 113833 KiB |  13442 GiB |  13442 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 389120 KiB | 401408 KiB |  42239 GiB |  42239 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 106496 KiB | 118784 KiB |   1112 GiB |   1112 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 111875 KiB | 168039 KiB | 173871 GiB | 173871 GiB |\n","|       from large pool |  88732 KiB | 135224 KiB | 159262 GiB | 159262 GiB |\n","|       from small pool |  23143 KiB |  36331 KiB |  14609 GiB |  14609 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   92243 K  |   92241 K  |\n","|       from large pool |      98    |     122    |   36614 K  |   36614 K  |\n","|       from small pool |    1706    |    1850    |   55628 K  |   55627 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   92243 K  |   92241 K  |\n","|       from large pool |      98    |     122    |   36614 K  |   36614 K  |\n","|       from small pool |    1706    |    1850    |   55628 K  |   55627 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      64    |      70    |    2136 K  |    2136 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      52    |      58    |     569 K  |     569 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      64    |      77    |   40671 K  |   40671 K  |\n","|       from large pool |      11    |      17    |   21374 K  |   21374 K  |\n","|       from small pool |      53    |      65    |   19297 K  |   19297 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:404/430 batch_size:2\n","Next token prediction. step:21/154 batch:404/430 epoch:1/1\n","full seq: For these and many other reasons, it is a moral imperative that the world work together to achieve the vision set by our religious and political leaders.Ģ\n","pref seq: For these and many ot\n","next tok:                     h\n","pred tok:                     N\n","Completed batch.\n","epoch:1/1 batch:404/430 batch_size:2 loss:3.7999675273895264 time_for_batch_instance:26.75869345664978 total_batch_time:15217.872293710709 running_batch_average:37.66800072700671\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 277496 KiB | 337250 KiB | 271654 GiB | 271654 GiB |\n","|       from large pool | 194144 KiB | 238167 KiB | 258170 GiB | 258170 GiB |\n","|       from small pool |  83352 KiB | 114826 KiB |  13484 GiB |  13483 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 277496 KiB | 337250 KiB | 271654 GiB | 271654 GiB |\n","|       from large pool | 194144 KiB | 238167 KiB | 258170 GiB | 258170 GiB |\n","|       from small pool |  83352 KiB | 114826 KiB |  13484 GiB |  13483 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 330946 KiB | 267621 GiB | 267621 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 254141 GiB | 254141 GiB |\n","|       from small pool |  83061 KiB | 114513 KiB |  13480 GiB |  13480 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 385024 KiB | 403456 KiB |  42241 GiB |  42240 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 102400 KiB | 120832 KiB |   1113 GiB |   1113 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 107527 KiB | 170325 KiB | 173942 GiB | 173942 GiB |\n","|       from large pool |  88480 KiB | 135224 KiB | 159292 GiB | 159292 GiB |\n","|       from small pool |  19047 KiB |  38693 KiB |  14650 GiB |  14650 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   92420 K  |   92418 K  |\n","|       from large pool |      98    |     122    |   36631 K  |   36631 K  |\n","|       from small pool |    1706    |    1850    |   55789 K  |   55787 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   92420 K  |   92418 K  |\n","|       from large pool |      98    |     122    |   36631 K  |   36631 K  |\n","|       from small pool |    1706    |    1850    |   55789 K  |   55787 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      62    |      71    |    2136 K  |    2136 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      50    |      59    |     570 K  |     570 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      68    |      76    |   40734 K  |   40734 K  |\n","|       from large pool |      11    |      17    |   21383 K  |   21383 K  |\n","|       from small pool |      57    |      64    |   19350 K  |   19350 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:405/430 batch_size:2\n","Next token prediction. step:33/151 batch:405/430 epoch:1/1\n","full seq: He concluded his admonition by declaring that, \"The enemy is on the right\" - a statement that ended up only fanning the flames of tribalism even more.Ģ\n","pref seq: He concluded his admonition by de\n","next tok:                                 c\n","pred tok:                                 ġ\n","Completed batch.\n","epoch:1/1 batch:405/430 batch_size:2 loss:4.8956427574157715 time_for_batch_instance:26.52442717552185 total_batch_time:15244.39672088623 running_batch_average:37.640485730583286\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 276883 KiB | 337059 KiB | 271714 GiB | 271714 GiB |\n","|       from large pool | 193531 KiB | 237975 KiB | 258197 GiB | 258197 GiB |\n","|       from small pool |  83352 KiB | 108815 KiB |  13516 GiB |  13516 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 276883 KiB | 337059 KiB | 271714 GiB | 271714 GiB |\n","|       from large pool | 193531 KiB | 237975 KiB | 258197 GiB | 258197 GiB |\n","|       from small pool |  83352 KiB | 108815 KiB |  13516 GiB |  13516 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 330946 KiB | 267680 GiB | 267679 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 254167 GiB | 254167 GiB |\n","|       from small pool |  83061 KiB | 108516 KiB |  13512 GiB |  13512 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 380928 KiB | 395264 KiB |  42242 GiB |  42242 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool |  98304 KiB | 112640 KiB |   1115 GiB |   1115 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 104044 KiB | 164184 KiB | 174005 GiB | 174004 GiB |\n","|       from large pool |  89093 KiB | 135224 KiB | 159319 GiB | 159319 GiB |\n","|       from small pool |  14951 KiB |  32552 KiB |  14685 GiB |  14685 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   92594 K  |   92592 K  |\n","|       from large pool |      98    |     122    |   36648 K  |   36647 K  |\n","|       from small pool |    1706    |    1850    |   55946 K  |   55944 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   92594 K  |   92592 K  |\n","|       from large pool |      98    |     122    |   36648 K  |   36647 K  |\n","|       from small pool |    1706    |    1850    |   55946 K  |   55944 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      60    |      67    |    2137 K  |    2137 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      48    |      55    |     571 K  |     570 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      60    |      75    |   40801 K  |   40801 K  |\n","|       from large pool |      15    |      18    |   21392 K  |   21392 K  |\n","|       from small pool |      45    |      60    |   19409 K  |   19409 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:406/430 batch_size:2\n","Next token prediction. step:85/151 batch:406/430 epoch:1/1\n","full seq: But what the pre-euro romanticists overlook is that euro membership has given Italy low inflation, and thus lower interest rates.Ģġġġġġġġġġġġġġġġġġġġġġ\n","pref seq: But what the pre-euro romanticists overlook is that euro membership has given Italy l\n","next tok:                                                                                     o\n","pred tok:                                                                                     Z\n","Completed batch.\n","epoch:1/1 batch:406/430 batch_size:2 loss:3.6224141120910645 time_for_batch_instance:26.168458461761475 total_batch_time:15270.565179347992 running_batch_average:37.61222950578323\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 278482 KiB | 339519 KiB | 271791 GiB | 271791 GiB |\n","|       from large pool | 195129 KiB | 240436 KiB | 258240 GiB | 258240 GiB |\n","|       from small pool |  83352 KiB | 113683 KiB |  13551 GiB |  13550 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 278482 KiB | 339519 KiB | 271791 GiB | 271791 GiB |\n","|       from large pool | 195129 KiB | 240436 KiB | 258240 GiB | 258240 GiB |\n","|       from small pool |  83352 KiB | 113683 KiB |  13551 GiB |  13550 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 330946 KiB | 267755 GiB | 267754 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 254208 GiB | 254207 GiB |\n","|       from small pool |  83061 KiB | 113384 KiB |  13547 GiB |  13546 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 385024 KiB | 399360 KiB |  42243 GiB |  42243 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 102400 KiB | 116736 KiB |   1116 GiB |   1116 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 106542 KiB | 164165 KiB | 174085 GiB | 174085 GiB |\n","|       from large pool |  87494 KiB | 135224 KiB | 159363 GiB | 159362 GiB |\n","|       from small pool |  19047 KiB |  34580 KiB |  14722 GiB |  14722 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   92768 K  |   92766 K  |\n","|       from large pool |      98    |     122    |   36672 K  |   36672 K  |\n","|       from small pool |    1706    |    1850    |   56095 K  |   56093 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   92768 K  |   92766 K  |\n","|       from large pool |      98    |     122    |   36672 K  |   36672 K  |\n","|       from small pool |    1706    |    1850    |   56095 K  |   56093 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      62    |      69    |    2138 K  |    2138 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      50    |      57    |     571 K  |     571 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      66    |      82    |   40868 K  |   40868 K  |\n","|       from large pool |      13    |      19    |   21408 K  |   21408 K  |\n","|       from small pool |      53    |      66    |   19460 K  |   19460 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:407/430 batch_size:2\n","Next token prediction. step:10/146 batch:407/430 epoch:1/1\n","full seq: Not even Brexit has halted immigration from Italy, contrary to the prevailing trends in Western Europe.Ģġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġ\n","pref seq: Not even B\n","next tok:          r\n","pred tok:          ġ\n","Completed batch.\n","epoch:1/1 batch:407/430 batch_size:2 loss:4.594784736633301 time_for_batch_instance:25.6464204788208 total_batch_time:15296.211599826813 running_batch_average:37.582829483603966\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 276018 KiB | 339710 KiB | 271872 GiB | 271871 GiB |\n","|       from large pool | 192665 KiB | 239100 KiB | 258286 GiB | 258286 GiB |\n","|       from small pool |  83352 KiB | 115758 KiB |  13585 GiB |  13585 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 276018 KiB | 339710 KiB | 271872 GiB | 271871 GiB |\n","|       from large pool | 192665 KiB | 239100 KiB | 258286 GiB | 258286 GiB |\n","|       from small pool |  83352 KiB | 115758 KiB |  13585 GiB |  13585 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 332325 KiB | 267830 GiB | 267830 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 254249 GiB | 254249 GiB |\n","|       from small pool |  83061 KiB | 115463 KiB |  13581 GiB |  13581 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 387072 KiB | 403456 KiB |  42245 GiB |  42244 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 104448 KiB | 120832 KiB |   1118 GiB |   1117 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 111054 KiB | 164955 KiB | 174169 GiB | 174169 GiB |\n","|       from large pool |  89958 KiB | 135224 KiB | 159408 GiB | 159408 GiB |\n","|       from small pool |  21095 KiB |  36628 KiB |  14760 GiB |  14760 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   92935 K  |   92934 K  |\n","|       from large pool |      98    |     122    |   36696 K  |   36696 K  |\n","|       from small pool |    1706    |    1850    |   56239 K  |   56237 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   92935 K  |   92934 K  |\n","|       from large pool |      98    |     122    |   36696 K  |   36696 K  |\n","|       from small pool |    1706    |    1850    |   56239 K  |   56237 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      63    |      71    |    2138 K  |    2138 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      51    |      59    |     572 K  |     572 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      69    |      85    |   40932 K  |   40932 K  |\n","|       from large pool |      13    |      19    |   21424 K  |   21424 K  |\n","|       from small pool |      56    |      69    |   19508 K  |   19508 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:408/430 batch_size:2\n","Next token prediction. step:101/143 batch:408/430 epoch:1/1\n","full seq: In 2018, the Trump administration - and companies like Uber and 21st Century Fox - will ignore it at their peril.Ģġġġġġġġġġġġġġġġġġġġġġġġġġġġġġ\n","pref seq: In 2018, the Trump administration - and companies like Uber and 21st Century Fox - will ignore it at \n","next tok:                                                                                                     t\n","pred tok:                                                                                                      \n","Completed batch.\n","epoch:1/1 batch:408/430 batch_size:2 loss:4.048933982849121 time_for_batch_instance:24.799118041992188 total_batch_time:15321.010717868805 running_batch_average:37.55149685752158\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 277919 KiB | 338956 KiB | 271945 GiB | 271944 GiB |\n","|       from large pool | 194567 KiB | 239872 KiB | 258327 GiB | 258327 GiB |\n","|       from small pool |  83352 KiB | 112863 KiB |  13617 GiB |  13617 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 277919 KiB | 338956 KiB | 271945 GiB | 271944 GiB |\n","|       from large pool | 194567 KiB | 239872 KiB | 258327 GiB | 258327 GiB |\n","|       from small pool |  83352 KiB | 112863 KiB |  13617 GiB |  13617 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 330946 KiB | 267901 GiB | 267900 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 254287 GiB | 254287 GiB |\n","|       from small pool |  83061 KiB | 112562 KiB |  13613 GiB |  13613 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 387072 KiB | 397312 KiB |  42246 GiB |  42246 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 104448 KiB | 114688 KiB |   1119 GiB |   1119 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 109152 KiB | 163701 KiB | 174245 GiB | 174245 GiB |\n","|       from large pool |  88057 KiB | 135224 KiB | 159449 GiB | 159449 GiB |\n","|       from small pool |  21095 KiB |  32532 KiB |  14795 GiB |  14795 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   93100 K  |   93098 K  |\n","|       from large pool |      98    |     122    |   36719 K  |   36719 K  |\n","|       from small pool |    1706    |    1850    |   56380 K  |   56378 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   93100 K  |   93098 K  |\n","|       from large pool |      98    |     122    |   36719 K  |   36719 K  |\n","|       from small pool |    1706    |    1850    |   56380 K  |   56378 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      63    |      68    |    2139 K  |    2139 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      51    |      56    |     573 K  |     573 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      73    |      82    |   40996 K  |   40996 K  |\n","|       from large pool |      13    |      19    |   21439 K  |   21439 K  |\n","|       from small pool |      60    |      66    |   19557 K  |   19557 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:409/430 batch_size:2\n","Next token prediction. step:8/142 batch:409/430 epoch:1/1\n","full seq: Myanmar's military has engaged in a sustained campaign of ethnic cleansing, with the primary goal of expelling the Rohingya from the country.Ģ\n","pref seq: Myanmar'\n","next tok:        s\n","pred tok:        ġ\n","Completed batch.\n","epoch:1/1 batch:409/430 batch_size:2 loss:4.091887474060059 time_for_batch_instance:24.76545476913452 total_batch_time:15345.77617263794 running_batch_average:37.52023514092406\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 278990 KiB | 338549 KiB | 272010 GiB | 272009 GiB |\n","|       from large pool | 195637 KiB | 239465 KiB | 258356 GiB | 258356 GiB |\n","|       from small pool |  83352 KiB | 116314 KiB |  13653 GiB |  13653 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 278990 KiB | 338549 KiB | 272010 GiB | 272009 GiB |\n","|       from large pool | 195637 KiB | 239465 KiB | 258356 GiB | 258356 GiB |\n","|       from small pool |  83352 KiB | 116314 KiB |  13653 GiB |  13653 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 330946 KiB | 267965 GiB | 267964 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 254315 GiB | 254315 GiB |\n","|       from small pool |  83061 KiB | 116004 KiB |  13649 GiB |  13649 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 395264 KiB | 401408 KiB |  42247 GiB |  42246 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 112640 KiB | 118784 KiB |   1119 GiB |   1119 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 116274 KiB | 170328 KiB | 174313 GiB | 174313 GiB |\n","|       from large pool |  86986 KiB | 135224 KiB | 159478 GiB | 159478 GiB |\n","|       from small pool |  29287 KiB |  41729 KiB |  14834 GiB |  14834 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   93263 K  |   93261 K  |\n","|       from large pool |      98    |     122    |   36735 K  |   36735 K  |\n","|       from small pool |    1706    |    1850    |   56528 K  |   56526 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   93263 K  |   93261 K  |\n","|       from large pool |      98    |     122    |   36735 K  |   36735 K  |\n","|       from small pool |    1706    |    1850    |   56528 K  |   56526 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      67    |      70    |    2139 K  |    2139 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      55    |      58    |     573 K  |     573 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      70    |      82    |   41057 K  |   41057 K  |\n","|       from large pool |      10    |      16    |   21448 K  |   21448 K  |\n","|       from small pool |      60    |      70    |   19609 K  |   19609 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:410/430 batch_size:2\n","Next token prediction. step:82/137 batch:410/430 epoch:1/1\n","full seq: During the campaign, Trump promised to get tough on executives who outsource American jobs.Ģġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġ\n","pref seq: During the campaign, Trump promised to get tough on executives who outsource Ameri\n","next tok:                                                                                  c\n","pred tok:                                                                                  K\n","Completed batch.\n","epoch:1/1 batch:410/430 batch_size:2 loss:3.829145908355713 time_for_batch_instance:23.530629873275757 total_batch_time:15369.306802511215 running_batch_average:37.48611415246638\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 276282 KiB | 335355 KiB | 272068 GiB | 272068 GiB |\n","|       from large pool | 192930 KiB | 236272 KiB | 258382 GiB | 258382 GiB |\n","|       from small pool |  83352 KiB | 112178 KiB |  13685 GiB |  13685 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 276282 KiB | 335355 KiB | 272068 GiB | 272068 GiB |\n","|       from large pool | 192930 KiB | 236272 KiB | 258382 GiB | 258382 GiB |\n","|       from small pool |  83352 KiB | 112178 KiB |  13685 GiB |  13685 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 330946 KiB | 268022 GiB | 268022 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 254340 GiB | 254340 GiB |\n","|       from small pool |  83061 KiB | 111861 KiB |  13681 GiB |  13681 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 387072 KiB | 399360 KiB |  42248 GiB |  42247 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 104448 KiB | 116736 KiB |   1120 GiB |   1120 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 110789 KiB | 170209 KiB | 174374 GiB | 174374 GiB |\n","|       from large pool |  89694 KiB | 135224 KiB | 159504 GiB | 159504 GiB |\n","|       from small pool |  21095 KiB |  38696 KiB |  14869 GiB |  14869 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   93420 K  |   93419 K  |\n","|       from large pool |      98    |     122    |   36750 K  |   36750 K  |\n","|       from small pool |    1706    |    1850    |   56670 K  |   56668 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   93420 K  |   93419 K  |\n","|       from large pool |      98    |     122    |   36750 K  |   36750 K  |\n","|       from small pool |    1706    |    1850    |   56670 K  |   56668 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      63    |      69    |    2140 K  |    2140 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      51    |      57    |     573 K  |     573 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      68    |      74    |   41114 K  |   41114 K  |\n","|       from large pool |      10    |      17    |   21456 K  |   21456 K  |\n","|       from small pool |      58    |      62    |   19658 K  |   19658 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:411/430 batch_size:2\n","Next token prediction. step:75/137 batch:411/430 epoch:1/1\n","full seq: Yet, because equity investors are the last to be repaid in case of project failure, they carry the most risk.Ģġġġġġġġġġġġġġġġġġġġġġġġġġġġ\n","pref seq: Yet, because equity investors are the last to be repaid in case of project \n","next tok:                                                                           f\n","pred tok:                                                                           K\n","Completed batch.\n","epoch:1/1 batch:411/430 batch_size:2 loss:3.355694055557251 time_for_batch_instance:23.649219036102295 total_batch_time:15392.956021547318 running_batch_average:37.45244774099104\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 279185 KiB | 339179 KiB | 272134 GiB | 272134 GiB |\n","|       from large pool | 195832 KiB | 240095 KiB | 258412 GiB | 258412 GiB |\n","|       from small pool |  83352 KiB | 118746 KiB |  13722 GiB |  13721 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 279185 KiB | 339179 KiB | 272134 GiB | 272134 GiB |\n","|       from large pool | 195832 KiB | 240095 KiB | 258412 GiB | 258412 GiB |\n","|       from small pool |  83352 KiB | 118746 KiB |  13722 GiB |  13721 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 330946 KiB | 268087 GiB | 268086 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 254369 GiB | 254368 GiB |\n","|       from small pool |  83061 KiB | 118440 KiB |  13718 GiB |  13718 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 380928 KiB | 405504 KiB |  42249 GiB |  42249 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool |  98304 KiB | 122880 KiB |   1122 GiB |   1122 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 101743 KiB | 166709 KiB | 174443 GiB | 174443 GiB |\n","|       from large pool |  86791 KiB | 135224 KiB | 159534 GiB | 159534 GiB |\n","|       from small pool |  14951 KiB |  38669 KiB |  14908 GiB |  14908 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   93578 K  |   93576 K  |\n","|       from large pool |      98    |     122    |   36765 K  |   36764 K  |\n","|       from small pool |    1706    |    1850    |   56813 K  |   56811 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   93578 K  |   93576 K  |\n","|       from large pool |      98    |     122    |   36765 K  |   36764 K  |\n","|       from small pool |    1706    |    1850    |   56813 K  |   56811 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      60    |      72    |    2141 K  |    2141 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      48    |      60    |     574 K  |     574 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      58    |      80    |   41172 K  |   41172 K  |\n","|       from large pool |      12    |      17    |   21464 K  |   21464 K  |\n","|       from small pool |      46    |      68    |   19707 K  |   19707 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:412/430 batch_size:2\n","Next token prediction. step:117/133 batch:412/430 epoch:1/1\n","full seq: It's true whether you are liberal or conservative, populist or mainstream, a Keynesian or a supply-sider.Ģġġġġġġġġġġġġġġġġġġġġġġġġġġġ\n","pref seq: It's true whether you are liberal or conservative, populist or mainstream, a Keynesian or a supply-sider.Ģġġġġġġġġġġġ\n","next tok:                                                                                                                     ġ\n","pred tok:                                                                                                                     .\n","Completed batch.\n","epoch:1/1 batch:412/430 batch_size:2 loss:3.230679988861084 time_for_batch_instance:23.356680870056152 total_batch_time:15416.312702417374 running_batch_average:37.418234714605276\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 278793 KiB | 338787 KiB | 272197 GiB | 272197 GiB |\n","|       from large pool | 195440 KiB | 239703 KiB | 258440 GiB | 258440 GiB |\n","|       from small pool |  83352 KiB | 118336 KiB |  13757 GiB |  13757 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 278793 KiB | 338787 KiB | 272197 GiB | 272197 GiB |\n","|       from large pool | 195440 KiB | 239703 KiB | 258440 GiB | 258440 GiB |\n","|       from small pool |  83352 KiB | 118336 KiB |  13757 GiB |  13757 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 330946 KiB | 268149 GiB | 268149 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 254396 GiB | 254396 GiB |\n","|       from small pool |  83061 KiB | 118030 KiB |  13753 GiB |  13753 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 385024 KiB | 405504 KiB |  42251 GiB |  42250 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 102400 KiB | 122880 KiB |   1123 GiB |   1123 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 106231 KiB | 166709 KiB | 174509 GiB | 174509 GiB |\n","|       from large pool |  87183 KiB | 135224 KiB | 159562 GiB | 159562 GiB |\n","|       from small pool |  19047 KiB |  38669 KiB |  14946 GiB |  14946 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   93730 K  |   93729 K  |\n","|       from large pool |      98    |     122    |   36779 K  |   36779 K  |\n","|       from small pool |    1706    |    1850    |   56951 K  |   56949 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   93730 K  |   93729 K  |\n","|       from large pool |      98    |     122    |   36779 K  |   36779 K  |\n","|       from small pool |    1706    |    1850    |   56951 K  |   56949 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      62    |      72    |    2142 K  |    2141 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      50    |      60    |     575 K  |     575 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      67    |      80    |   41227 K  |   41227 K  |\n","|       from large pool |      12    |      17    |   21472 K  |   21472 K  |\n","|       from small pool |      55    |      68    |   19755 K  |   19755 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:413/430 batch_size:2\n","Next token prediction. step:73/130 batch:413/430 epoch:1/1\n","full seq: He realized that an extremist would raise interest rates - any real-estate developer's worst nightmare.Ģġġġġġġġġġġġġġġġġġġġġġġġġġġ\n","pref seq: He realized that an extremist would raise interest rates - any real-estat\n","next tok:                                                                         e\n","pred tok:                                                                         K\n","Completed batch.\n","epoch:1/1 batch:413/430 batch_size:2 loss:3.1806933879852295 time_for_batch_instance:23.41116213798523 total_batch_time:15439.723864555359 running_batch_average:37.38431928463767\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 278105 KiB | 338422 KiB | 272258 GiB | 272258 GiB |\n","|       from large pool | 194753 KiB | 239339 KiB | 258468 GiB | 258467 GiB |\n","|       from small pool |  83352 KiB | 117412 KiB |  13790 GiB |  13790 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 278105 KiB | 338422 KiB | 272258 GiB | 272258 GiB |\n","|       from large pool | 194753 KiB | 239339 KiB | 258468 GiB | 258467 GiB |\n","|       from small pool |  83352 KiB | 117412 KiB |  13790 GiB |  13790 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 330946 KiB | 268209 GiB | 268209 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 254422 GiB | 254422 GiB |\n","|       from small pool |  83061 KiB | 117103 KiB |  13786 GiB |  13786 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 387072 KiB | 403456 KiB |  42252 GiB |  42251 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 104448 KiB | 120832 KiB |   1125 GiB |   1124 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 108966 KiB | 168759 KiB | 174573 GiB | 174573 GiB |\n","|       from large pool |  87871 KiB | 135224 KiB | 159590 GiB | 159590 GiB |\n","|       from small pool |  21095 KiB |  40719 KiB |  14983 GiB |  14983 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   93880 K  |   93878 K  |\n","|       from large pool |      98    |     122    |   36793 K  |   36793 K  |\n","|       from small pool |    1706    |    1850    |   57086 K  |   57084 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   93880 K  |   93878 K  |\n","|       from large pool |      98    |     122    |   36793 K  |   36793 K  |\n","|       from small pool |    1706    |    1850    |   57086 K  |   57084 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      63    |      71    |    2142 K  |    2142 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      51    |      59    |     576 K  |     575 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      59    |      82    |   41282 K  |   41282 K  |\n","|       from large pool |      10    |      17    |   21479 K  |   21479 K  |\n","|       from small pool |      49    |      69    |   19802 K  |   19802 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:414/430 batch_size:2\n","Next token prediction. step:65/126 batch:414/430 epoch:1/1\n","full seq: Since 2007, almost 1.5 million Italians have left the country, joining four million other expats.Ģġġġġġġġġġġġġġġġġġġġġġġġġġġġġ\n","pref seq: Since 2007, almost 1.5 million Italians have left the country, jo\n","next tok:                                                                 i\n","pred tok:                                                                 K\n","Completed batch.\n","epoch:1/1 batch:414/430 batch_size:2 loss:2.9277074337005615 time_for_batch_instance:22.433536767959595 total_batch_time:15462.157401323318 running_batch_average:37.34820628338966\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 278807 KiB | 338366 KiB | 272316 GiB | 272316 GiB |\n","|       from large pool | 195455 KiB | 239283 KiB | 258494 GiB | 258493 GiB |\n","|       from small pool |  83352 KiB | 116506 KiB |  13822 GiB |  13822 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 278807 KiB | 338366 KiB | 272316 GiB | 272316 GiB |\n","|       from large pool | 195455 KiB | 239283 KiB | 258494 GiB | 258493 GiB |\n","|       from small pool |  83352 KiB | 116506 KiB |  13822 GiB |  13822 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 330946 KiB | 268266 GiB | 268266 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 254447 GiB | 254447 GiB |\n","|       from small pool |  83061 KiB | 116196 KiB |  13818 GiB |  13818 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 385024 KiB | 401408 KiB |  42253 GiB |  42252 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 102400 KiB | 118784 KiB |   1126 GiB |   1125 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 106216 KiB | 166926 KiB | 174634 GiB | 174634 GiB |\n","|       from large pool |  87169 KiB | 135224 KiB | 159616 GiB | 159615 GiB |\n","|       from small pool |  19047 KiB |  38673 KiB |  15018 GiB |  15018 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   94024 K  |   94022 K  |\n","|       from large pool |      98    |     122    |   36807 K  |   36807 K  |\n","|       from small pool |    1706    |    1850    |   57217 K  |   57215 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   94024 K  |   94022 K  |\n","|       from large pool |      98    |     122    |   36807 K  |   36807 K  |\n","|       from small pool |    1706    |    1850    |   57217 K  |   57215 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      62    |      70    |    2143 K  |    2143 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      50    |      58    |     576 K  |     576 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      67    |      81    |   41334 K  |   41334 K  |\n","|       from large pool |      10    |      15    |   21487 K  |   21487 K  |\n","|       from small pool |      57    |      69    |   19847 K  |   19847 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:415/430 batch_size:2\n","Next token prediction. step:32/123 batch:415/430 epoch:1/1\n","full seq: Germany's answer is to put the burden on the weak countries already suffering from high unemployment and low growth rates.Ģ\n","pref seq: Germany's answer is to put the b\n","next tok:                                u\n","pred tok:                                K\n","Completed batch.\n","epoch:1/1 batch:415/430 batch_size:2 loss:2.6215384006500244 time_for_batch_instance:21.725425481796265 total_batch_time:15483.882826805115 running_batch_average:37.31056102844606\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 277824 KiB | 340210 KiB | 272360 GiB | 272359 GiB |\n","|       from large pool | 194472 KiB | 241127 KiB | 258513 GiB | 258513 GiB |\n","|       from small pool |  83352 KiB | 101951 KiB |  13846 GiB |  13846 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 277824 KiB | 340210 KiB | 272360 GiB | 272359 GiB |\n","|       from large pool | 194472 KiB | 241127 KiB | 258513 GiB | 258513 GiB |\n","|       from small pool |  83352 KiB | 101951 KiB |  13846 GiB |  13846 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 330946 KiB | 268308 GiB | 268308 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 254466 GiB | 254466 GiB |\n","|       from small pool |  83061 KiB | 101640 KiB |  13842 GiB |  13842 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 380928 KiB | 393216 KiB |  42254 GiB |  42254 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool |  98304 KiB | 110592 KiB |   1127 GiB |   1127 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 103103 KiB | 161654 KiB | 174679 GiB | 174679 GiB |\n","|       from large pool |  88152 KiB | 135224 KiB | 159635 GiB | 159635 GiB |\n","|       from small pool |  14951 KiB |  29487 KiB |  15043 GiB |  15043 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   94165 K  |   94163 K  |\n","|       from large pool |      98    |     122    |   36820 K  |   36820 K  |\n","|       from small pool |    1706    |    1850    |   57345 K  |   57343 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   94165 K  |   94163 K  |\n","|       from large pool |      98    |     122    |   36820 K  |   36820 K  |\n","|       from small pool |    1706    |    1850    |   57345 K  |   57343 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      60    |      66    |    2143 K  |    2143 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      48    |      54    |     577 K  |     577 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      65    |      71    |   41386 K  |   41386 K  |\n","|       from large pool |      13    |      16    |   21493 K  |   21493 K  |\n","|       from small pool |      52    |      60    |   19892 K  |   19892 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:416/430 batch_size:2\n","Next token prediction. step:80/123 batch:416/430 epoch:1/1\n","full seq: And is it credible to place the blame overwhelmingly on the US, as Gorbachev and certainly the Kremlin are inclined to do?Ģ\n","pref seq: And is it credible to place the blame overwhelmingly on the US, as Gorbachev and\n","next tok:                                                                                 \n","pred tok:                                                                                K\n","Completed batch.\n","epoch:1/1 batch:416/430 batch_size:2 loss:4.380953788757324 time_for_batch_instance:21.650335550308228 total_batch_time:15505.533162355423 running_batch_average:37.272916255662075\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 279220 KiB | 339592 KiB | 272406 GiB | 272405 GiB |\n","|       from large pool | 195867 KiB | 240508 KiB | 258535 GiB | 258534 GiB |\n","|       from small pool |  83352 KiB | 104687 KiB |  13870 GiB |  13870 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 279220 KiB | 339592 KiB | 272406 GiB | 272405 GiB |\n","|       from large pool | 195867 KiB | 240508 KiB | 258535 GiB | 258534 GiB |\n","|       from small pool |  83352 KiB | 104687 KiB |  13870 GiB |  13870 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 330946 KiB | 268353 GiB | 268352 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 254486 GiB | 254485 GiB |\n","|       from small pool |  83061 KiB | 104381 KiB |  13866 GiB |  13866 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 380928 KiB | 393216 KiB |  42255 GiB |  42255 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool |  98304 KiB | 110592 KiB |   1128 GiB |   1128 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 101708 KiB | 162907 KiB | 174727 GiB | 174727 GiB |\n","|       from large pool |  86756 KiB | 135224 KiB | 159657 GiB | 159657 GiB |\n","|       from small pool |  14951 KiB |  31275 KiB |  15070 GiB |  15070 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   94306 K  |   94304 K  |\n","|       from large pool |      98    |     122    |   36833 K  |   36833 K  |\n","|       from small pool |    1706    |    1850    |   57473 K  |   57471 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   94306 K  |   94304 K  |\n","|       from large pool |      98    |     122    |   36833 K  |   36833 K  |\n","|       from small pool |    1706    |    1850    |   57473 K  |   57471 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      60    |      66    |    2144 K  |    2144 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      48    |      54    |     577 K  |     577 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      60    |      72    |   41438 K  |   41438 K  |\n","|       from large pool |      13    |      16    |   21500 K  |   21500 K  |\n","|       from small pool |      47    |      60    |   19937 K  |   19937 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:417/430 batch_size:2\n","Next token prediction. step:37/121 batch:417/430 epoch:1/1\n","full seq: We need the World Bank's voice and strenuous efforts to mobilize grant financing for the SDGs.Ģġġġġġġġġġġġġġġġġġġġġġġġġġġ\n","pref seq: We need the World Bank's voice and st\n","next tok:                                     r\n","pred tok:                                     K\n","Completed batch.\n","epoch:1/1 batch:417/430 batch_size:2 loss:2.6591556072235107 time_for_batch_instance:21.77524161338806 total_batch_time:15527.308403968811 running_batch_average:37.23575156827053\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 278751 KiB | 338310 KiB | 272460 GiB | 272460 GiB |\n","|       from large pool | 195399 KiB | 239227 KiB | 258559 GiB | 258559 GiB |\n","|       from small pool |  83352 KiB | 115600 KiB |  13901 GiB |  13901 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 278751 KiB | 338310 KiB | 272460 GiB | 272460 GiB |\n","|       from large pool | 195399 KiB | 239227 KiB | 258559 GiB | 258559 GiB |\n","|       from small pool |  83352 KiB | 115600 KiB |  13901 GiB |  13901 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 330946 KiB | 268406 GiB | 268406 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 254509 GiB | 254509 GiB |\n","|       from small pool |  83061 KiB | 115288 KiB |  13897 GiB |  13897 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 389120 KiB | 401408 KiB |  42256 GiB |  42256 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 106496 KiB | 118784 KiB |   1129 GiB |   1128 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 110368 KiB | 165996 KiB | 174784 GiB | 174784 GiB |\n","|       from large pool |  87225 KiB | 135224 KiB | 159681 GiB | 159681 GiB |\n","|       from small pool |  23143 KiB |  38671 KiB |  15103 GiB |  15103 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   94445 K  |   94443 K  |\n","|       from large pool |      98    |     122    |   36846 K  |   36846 K  |\n","|       from small pool |    1706    |    1850    |   57598 K  |   57597 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   94445 K  |   94443 K  |\n","|       from large pool |      98    |     122    |   36846 K  |   36846 K  |\n","|       from small pool |    1706    |    1850    |   57598 K  |   57597 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      64    |      70    |    2144 K  |    2144 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      52    |      58    |     578 K  |     578 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      75    |      83    |   41485 K  |   41485 K  |\n","|       from large pool |      10    |      15    |   21508 K  |   21508 K  |\n","|       from small pool |      65    |      71    |   19977 K  |   19977 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:418/430 batch_size:2\n","Next token prediction. step:99/120 batch:418/430 epoch:1/1\n","full seq: Our relationship is deepened in the most personal way possible, through the intertwining of so many individuals' lives.Ģ\n","pref seq: Our relationship is deepened in the most personal way possible, through the intertwining of so many\n","next tok:                                                                                                    \n","pred tok:                                                                                                   .\n","Completed batch.\n","epoch:1/1 batch:418/430 batch_size:2 loss:2.4738430976867676 time_for_batch_instance:21.869843006134033 total_batch_time:15549.178246974945 running_batch_average:37.19899102147116\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 278581 KiB | 339830 KiB | 272504 GiB | 272504 GiB |\n","|       from large pool | 195229 KiB | 240747 KiB | 258579 GiB | 258579 GiB |\n","|       from small pool |  83352 KiB | 103536 KiB |  13924 GiB |  13924 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 278581 KiB | 339830 KiB | 272504 GiB | 272504 GiB |\n","|       from large pool | 195229 KiB | 240747 KiB | 258579 GiB | 258579 GiB |\n","|       from small pool |  83352 KiB | 103536 KiB |  13924 GiB |  13924 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 330946 KiB | 268449 GiB | 268448 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 254528 GiB | 254528 GiB |\n","|       from small pool |  83061 KiB | 103228 KiB |  13920 GiB |  13920 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 380928 KiB | 393216 KiB |  42257 GiB |  42257 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool |  98304 KiB | 110592 KiB |   1130 GiB |   1130 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 102346 KiB | 162136 KiB | 174830 GiB | 174830 GiB |\n","|       from large pool |  87395 KiB | 135224 KiB | 159701 GiB | 159701 GiB |\n","|       from small pool |  14951 KiB |  30504 KiB |  15128 GiB |  15128 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   94582 K  |   94581 K  |\n","|       from large pool |      98    |     122    |   36859 K  |   36859 K  |\n","|       from small pool |    1706    |    1850    |   57723 K  |   57721 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   94582 K  |   94581 K  |\n","|       from large pool |      98    |     122    |   36859 K  |   36859 K  |\n","|       from small pool |    1706    |    1850    |   57723 K  |   57721 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      60    |      66    |    2145 K  |    2145 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      48    |      54    |     578 K  |     578 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      60    |      78    |   41537 K  |   41537 K  |\n","|       from large pool |      14    |      16    |   21515 K  |   21515 K  |\n","|       from small pool |      46    |      66    |   20022 K  |   20022 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:419/430 batch_size:2\n","Next token prediction. step:66/119 batch:419/430 epoch:1/1\n","full seq: Juncker's vision rejects a multi-speed Europe, in favor of uniform steps by all EU members.Ģġġġġġġġġġġġġġġġġġġġġġġġġġġġ\n","pref seq: Juncker's vision rejects a multi-speed Europe, in favor of uniform\n","next tok:                                                                   \n","pred tok:                                                                  K\n","Completed batch.\n","epoch:1/1 batch:419/430 batch_size:2 loss:2.3814706802368164 time_for_batch_instance:21.410446166992188 total_batch_time:15570.588693141937 running_batch_average:37.161309530171685\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 277157 KiB | 336870 KiB | 272557 GiB | 272557 GiB |\n","|       from large pool | 193805 KiB | 237787 KiB | 258603 GiB | 258603 GiB |\n","|       from small pool |  83352 KiB | 114921 KiB |  13953 GiB |  13953 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 277157 KiB | 336870 KiB | 272557 GiB | 272557 GiB |\n","|       from large pool | 193805 KiB | 237787 KiB | 258603 GiB | 258603 GiB |\n","|       from small pool |  83352 KiB | 114921 KiB |  13953 GiB |  13953 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 330946 KiB | 268501 GiB | 268500 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 254551 GiB | 254550 GiB |\n","|       from small pool |  83061 KiB | 114608 KiB |  13949 GiB |  13949 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 385024 KiB | 399360 KiB |  42258 GiB |  42258 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 102400 KiB | 116736 KiB |   1131 GiB |   1131 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 107866 KiB | 168232 KiB | 174886 GiB | 174885 GiB |\n","|       from large pool |  88819 KiB | 135224 KiB | 159725 GiB | 159725 GiB |\n","|       from small pool |  19047 KiB |  38405 KiB |  15160 GiB |  15160 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   94719 K  |   94717 K  |\n","|       from large pool |      98    |     122    |   36872 K  |   36872 K  |\n","|       from small pool |    1706    |    1850    |   57847 K  |   57845 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   94719 K  |   94717 K  |\n","|       from large pool |      98    |     122    |   36872 K  |   36872 K  |\n","|       from small pool |    1706    |    1850    |   57847 K  |   57845 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      62    |      69    |    2145 K  |    2145 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      50    |      57    |     579 K  |     579 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      60    |      77    |   41586 K  |   41586 K  |\n","|       from large pool |      11    |      16    |   21522 K  |   21522 K  |\n","|       from small pool |      49    |      66    |   20064 K  |   20064 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:420/430 batch_size:2\n","Next token prediction. step:111/118 batch:420/430 epoch:1/1\n","full seq: And, given the combination of complex agendas and high expectations, those leaders may fail.Ģġġġġġġġġġġġġġġġġġġġġġġġġġ\n","pref seq: And, given the combination of complex agendas and high expectations, those leaders may fail.Ģġġġġġġġġġġġġġġġġġġ\n","next tok:                                                                                                               ġ\n","pred tok:                                                                                                               .\n","Completed batch.\n","epoch:1/1 batch:420/430 batch_size:2 loss:2.2728919982910156 time_for_batch_instance:21.362956285476685 total_batch_time:15591.951649427414 running_batch_average:37.1236944033986\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 277143 KiB | 336870 KiB | 272609 GiB | 272609 GiB |\n","|       from large pool | 193791 KiB | 237787 KiB | 258626 GiB | 258626 GiB |\n","|       from small pool |  83352 KiB | 114921 KiB |  13983 GiB |  13982 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 277143 KiB | 336870 KiB | 272609 GiB | 272609 GiB |\n","|       from large pool | 193791 KiB | 237787 KiB | 258626 GiB | 258626 GiB |\n","|       from small pool |  83352 KiB | 114921 KiB |  13983 GiB |  13982 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 330946 KiB | 268552 GiB | 268552 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 254573 GiB | 254573 GiB |\n","|       from small pool |  83061 KiB | 114608 KiB |  13978 GiB |  13978 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 385024 KiB | 399360 KiB |  42259 GiB |  42259 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 102400 KiB | 116736 KiB |   1132 GiB |   1132 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 107880 KiB | 168232 KiB | 174941 GiB | 174940 GiB |\n","|       from large pool |  88833 KiB | 135224 KiB | 159748 GiB | 159748 GiB |\n","|       from small pool |  19047 KiB |  38405 KiB |  15192 GiB |  15192 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   94854 K  |   94852 K  |\n","|       from large pool |      98    |     122    |   36884 K  |   36884 K  |\n","|       from small pool |    1706    |    1850    |   57969 K  |   57968 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   94854 K  |   94852 K  |\n","|       from large pool |      98    |     122    |   36884 K  |   36884 K  |\n","|       from small pool |    1706    |    1850    |   57969 K  |   57968 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      62    |      69    |    2146 K  |    2146 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      50    |      57    |     579 K  |     579 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      64    |      77    |   41635 K  |   41635 K  |\n","|       from large pool |      11    |      15    |   21529 K  |   21529 K  |\n","|       from small pool |      53    |      66    |   20106 K  |   20106 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:421/430 batch_size:2\n","Next token prediction. step:104/113 batch:421/430 epoch:1/1\n","full seq: The statutory tax rate on corporate profits is now 35%, the highest in the OECD.Ģġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġ\n","pref seq: The statutory tax rate on corporate profits is now 35%, the highest in the OECD.Ģġġġġġġġġġġġġġġġġġġġġġġġ\n","next tok:                                                                                                        ġ\n","pred tok:                                                                                                        .\n","Completed batch.\n","epoch:1/1 batch:421/430 batch_size:2 loss:2.5533440113067627 time_for_batch_instance:20.399818420410156 total_batch_time:15612.351467847824 running_batch_average:37.083970232417634\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 277811 KiB | 336870 KiB | 272659 GiB | 272659 GiB |\n","|       from large pool | 194458 KiB | 237787 KiB | 258649 GiB | 258648 GiB |\n","|       from small pool |  83352 KiB | 114921 KiB |  14010 GiB |  14010 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 277811 KiB | 336870 KiB | 272659 GiB | 272659 GiB |\n","|       from large pool | 194458 KiB | 237787 KiB | 258649 GiB | 258648 GiB |\n","|       from small pool |  83352 KiB | 114921 KiB |  14010 GiB |  14010 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 330946 KiB | 268601 GiB | 268601 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 254595 GiB | 254595 GiB |\n","|       from small pool |  83061 KiB | 114608 KiB |  14006 GiB |  14006 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 389120 KiB | 399360 KiB |  42260 GiB |  42260 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 106496 KiB | 116736 KiB |   1133 GiB |   1132 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 111309 KiB | 168232 KiB | 174993 GiB | 174993 GiB |\n","|       from large pool |  88165 KiB | 135224 KiB | 159771 GiB | 159771 GiB |\n","|       from small pool |  23143 KiB |  38405 KiB |  15222 GiB |  15222 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   94983 K  |   94982 K  |\n","|       from large pool |      98    |     122    |   36896 K  |   36896 K  |\n","|       from small pool |    1706    |    1850    |   58087 K  |   58085 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   94983 K  |   94982 K  |\n","|       from large pool |      98    |     122    |   36896 K  |   36896 K  |\n","|       from small pool |    1706    |    1850    |   58087 K  |   58085 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      64    |      69    |    2146 K  |    2146 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      52    |      57    |     580 K  |     580 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      63    |      77    |   41682 K  |   41682 K  |\n","|       from large pool |      10    |      15    |   21536 K  |   21536 K  |\n","|       from small pool |      53    |      66    |   20146 K  |   20146 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:422/430 batch_size:2\n","Next token prediction. step:54/112 batch:422/430 epoch:1/1\n","full seq: Other advanced economies have also experienced sustained declines in their respective slices of the global pie.Ģ\n","pref seq: Other advanced economies have also experienced sustain\n","next tok:                                                      e\n","pred tok:                                                      ;\n","Completed batch.\n","epoch:1/1 batch:422/430 batch_size:2 loss:2.400310754776001 time_for_batch_instance:19.94028377532959 total_batch_time:15632.291751623154 running_batch_average:37.04334538299325\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 277669 KiB | 340231 KiB | 272698 GiB | 272698 GiB |\n","|       from large pool | 194317 KiB | 241148 KiB | 258667 GiB | 258666 GiB |\n","|       from small pool |  83352 KiB | 102404 KiB |  14031 GiB |  14031 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 277669 KiB | 340231 KiB | 272698 GiB | 272698 GiB |\n","|       from large pool | 194317 KiB | 241148 KiB | 258667 GiB | 258666 GiB |\n","|       from small pool |  83352 KiB | 102404 KiB |  14031 GiB |  14031 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 330946 KiB | 268640 GiB | 268639 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 254612 GiB | 254612 GiB |\n","|       from small pool |  83061 KiB | 102094 KiB |  14027 GiB |  14027 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 380928 KiB | 393216 KiB |  42261 GiB |  42261 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool |  98304 KiB | 110592 KiB |   1134 GiB |   1134 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 103258 KiB | 161654 KiB | 175034 GiB | 175034 GiB |\n","|       from large pool |  88307 KiB | 135224 KiB | 159789 GiB | 159788 GiB |\n","|       from small pool |  14951 KiB |  29486 KiB |  15245 GiB |  15245 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   95112 K  |   95110 K  |\n","|       from large pool |      98    |     122    |   36908 K  |   36908 K  |\n","|       from small pool |    1706    |    1850    |   58203 K  |   58201 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   95112 K  |   95110 K  |\n","|       from large pool |      98    |     122    |   36908 K  |   36908 K  |\n","|       from small pool |    1706    |    1850    |   58203 K  |   58201 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      60    |      66    |    2147 K  |    2147 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      48    |      54    |     580 K  |     580 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      62    |      70    |   41728 K  |   41728 K  |\n","|       from large pool |      14    |      16    |   21542 K  |   21542 K  |\n","|       from small pool |      48    |      57    |   20186 K  |   20186 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:423/430 batch_size:2\n","Next token prediction. step:68/111 batch:423/430 epoch:1/1\n","full seq: And back-loaded stimulus has its own problems, unless it is managed extremely carefully.Ģġġġġġġġġġġġġġġġġġġġġġġ\n","pref seq: And back-loaded stimulus has its own problems, unless it is managed \n","next tok:                                                                    e\n","pred tok:                                                                    ;\n","Completed batch.\n","epoch:1/1 batch:423/430 batch_size:2 loss:2.3169028759002686 time_for_batch_instance:19.36778473854065 total_batch_time:15651.659536361694 running_batch_average:37.0015591876163\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 276380 KiB | 335454 KiB | 272745 GiB | 272745 GiB |\n","|       from large pool | 193027 KiB | 236370 KiB | 258687 GiB | 258687 GiB |\n","|       from small pool |  83352 KiB | 111976 KiB |  14057 GiB |  14057 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 276380 KiB | 335454 KiB | 272745 GiB | 272745 GiB |\n","|       from large pool | 193027 KiB | 236370 KiB | 258687 GiB | 258687 GiB |\n","|       from small pool |  83352 KiB | 111976 KiB |  14057 GiB |  14057 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 330946 KiB | 268686 GiB | 268685 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 254632 GiB | 254632 GiB |\n","|       from small pool |  83061 KiB | 111659 KiB |  14053 GiB |  14053 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 385024 KiB | 397312 KiB |  42262 GiB |  42261 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 102400 KiB | 114688 KiB |   1134 GiB |   1134 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 108644 KiB | 163701 KiB | 175082 GiB | 175082 GiB |\n","|       from large pool |  89596 KiB | 135224 KiB | 159809 GiB | 159809 GiB |\n","|       from small pool |  19047 KiB |  33560 KiB |  15272 GiB |  15272 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   95239 K  |   95237 K  |\n","|       from large pool |      98    |     122    |   36920 K  |   36920 K  |\n","|       from small pool |    1706    |    1850    |   58318 K  |   58316 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   95239 K  |   95237 K  |\n","|       from large pool |      98    |     122    |   36920 K  |   36920 K  |\n","|       from small pool |    1706    |    1850    |   58318 K  |   58316 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      62    |      68    |    2147 K  |    2147 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      50    |      56    |     580 K  |     580 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      61    |      77    |   41772 K  |   41772 K  |\n","|       from large pool |      11    |      16    |   21548 K  |   21548 K  |\n","|       from small pool |      50    |      65    |   20224 K  |   20224 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:424/430 batch_size:2\n","Next token prediction. step:101/105 batch:424/430 epoch:1/1\n","full seq: At best, China's government acted prematurely when it insisted that the renminbi be included in the SDR.Ģ\n","pref seq: At best, China's government acted prematurely when it insisted that the renminbi be included in the S\n","next tok:                                                                                                     D\n","pred tok:                                                                                                     .\n","Completed batch.\n","epoch:1/1 batch:424/430 batch_size:2 loss:3.0965991020202637 time_for_batch_instance:18.3719961643219 total_batch_time:15670.031532526016 running_batch_average:36.957621538976454\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 277979 KiB | 338519 KiB | 272781 GiB | 272780 GiB |\n","|       from large pool | 194626 KiB | 239436 KiB | 258704 GiB | 258703 GiB |\n","|       from small pool |  83352 KiB | 101498 KiB |  14077 GiB |  14077 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 277979 KiB | 338519 KiB | 272781 GiB | 272780 GiB |\n","|       from large pool | 194626 KiB | 239436 KiB | 258704 GiB | 258703 GiB |\n","|       from small pool |  83352 KiB | 101498 KiB |  14077 GiB |  14077 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 330946 KiB | 268720 GiB | 268720 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 254647 GiB | 254647 GiB |\n","|       from small pool |  83061 KiB | 101187 KiB |  14073 GiB |  14073 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 380928 KiB | 393216 KiB |  42263 GiB |  42262 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool |  98304 KiB | 110592 KiB |   1135 GiB |   1135 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 102949 KiB | 161652 KiB | 175119 GiB | 175119 GiB |\n","|       from large pool |  87997 KiB | 135224 KiB | 159826 GiB | 159826 GiB |\n","|       from small pool |  14951 KiB |  29230 KiB |  15293 GiB |  15293 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   95359 K  |   95357 K  |\n","|       from large pool |      98    |     122    |   36931 K  |   36931 K  |\n","|       from small pool |    1706    |    1850    |   58427 K  |   58425 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   95359 K  |   95357 K  |\n","|       from large pool |      98    |     122    |   36931 K  |   36931 K  |\n","|       from small pool |    1706    |    1850    |   58427 K  |   58425 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      60    |      66    |    2148 K  |    2148 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      48    |      54    |     581 K  |     581 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      61    |      65    |   41819 K  |   41819 K  |\n","|       from large pool |      12    |      15    |   21554 K  |   21554 K  |\n","|       from small pool |      49    |      54    |   20265 K  |   20265 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:425/430 batch_size:2\n","Next token prediction. step:75/105 batch:425/430 epoch:1/1\n","full seq: In newsrooms from Serbia to South Africa, taxpayer-generated funding is growing.Ģġġġġġġġġġġġġġġġġġġġġġġġġ\n","pref seq: In newsrooms from Serbia to South Africa, taxpayer-generated funding is gro\n","next tok:                                                                           w\n","pred tok:                                                                           ;\n","Completed batch.\n","epoch:1/1 batch:425/430 batch_size:2 loss:2.988610029220581 time_for_batch_instance:18.224013805389404 total_batch_time:15688.255546331406 running_batch_average:36.91354246195625\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 276408 KiB | 335257 KiB | 272824 GiB | 272824 GiB |\n","|       from large pool | 193055 KiB | 236174 KiB | 258723 GiB | 258723 GiB |\n","|       from small pool |  83352 KiB | 111523 KiB |  14101 GiB |  14101 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 276408 KiB | 335257 KiB | 272824 GiB | 272824 GiB |\n","|       from large pool | 193055 KiB | 236174 KiB | 258723 GiB | 258723 GiB |\n","|       from small pool |  83352 KiB | 111523 KiB |  14101 GiB |  14101 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 330946 KiB | 268763 GiB | 268763 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 254666 GiB | 254666 GiB |\n","|       from small pool |  83061 KiB | 111205 KiB |  14097 GiB |  14097 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 387072 KiB | 397312 KiB |  42263 GiB |  42263 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 104448 KiB | 114688 KiB |   1136 GiB |   1136 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 110664 KiB | 164182 KiB | 175165 GiB | 175165 GiB |\n","|       from large pool |  89568 KiB | 135224 KiB | 159845 GiB | 159845 GiB |\n","|       from small pool |  21095 KiB |  33560 KiB |  15319 GiB |  15319 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   95479 K  |   95477 K  |\n","|       from large pool |      98    |     122    |   36942 K  |   36942 K  |\n","|       from small pool |    1706    |    1850    |   58536 K  |   58534 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   95479 K  |   95477 K  |\n","|       from large pool |      98    |     122    |   36942 K  |   36942 K  |\n","|       from small pool |    1706    |    1850    |   58536 K  |   58534 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      63    |      68    |    2148 K  |    2148 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      51    |      56    |     581 K  |     581 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      70    |      77    |   41864 K  |   41864 K  |\n","|       from large pool |      11    |      16    |   21560 K  |   21560 K  |\n","|       from small pool |      59    |      63    |   20304 K  |   20304 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:426/430 batch_size:2\n","Next token prediction. step:29/103 batch:426/430 epoch:1/1\n","full seq: Moscow had 20 daily newspapers, with views ranging from liberal to Stalinist.Ģġġġġġġġġġġġġġġġġġġġġġġġġġ\n","pref seq: Moscow had 20 daily newspaper\n","next tok:                             s\n","pred tok:                             ;\n","Completed batch.\n","epoch:1/1 batch:426/430 batch_size:2 loss:3.2413387298583984 time_for_batch_instance:17.970571279525757 total_batch_time:15706.226117610931 running_batch_average:36.86907539345289\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 275374 KiB | 335220 KiB | 272866 GiB | 272866 GiB |\n","|       from large pool | 192022 KiB | 236136 KiB | 258742 GiB | 258742 GiB |\n","|       from small pool |  83352 KiB | 111029 KiB |  14124 GiB |  14124 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 275374 KiB | 335220 KiB | 272866 GiB | 272866 GiB |\n","|       from large pool | 192022 KiB | 236136 KiB | 258742 GiB | 258742 GiB |\n","|       from small pool |  83352 KiB | 111029 KiB |  14124 GiB |  14124 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 330946 KiB | 268804 GiB | 268804 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 254684 GiB | 254684 GiB |\n","|       from small pool |  83061 KiB | 110733 KiB |  14120 GiB |  14120 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 389120 KiB | 395264 KiB |  42264 GiB |  42264 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 106496 KiB | 112640 KiB |   1137 GiB |   1137 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 113745 KiB | 163700 KiB | 175209 GiB | 175209 GiB |\n","|       from large pool |  90602 KiB | 135224 KiB | 159864 GiB | 159864 GiB |\n","|       from small pool |  23143 KiB |  32540 KiB |  15344 GiB |  15344 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   95596 K  |   95595 K  |\n","|       from large pool |      98    |     122    |   36953 K  |   36953 K  |\n","|       from small pool |    1706    |    1850    |   58643 K  |   58641 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   95596 K  |   95595 K  |\n","|       from large pool |      98    |     122    |   36953 K  |   36953 K  |\n","|       from small pool |    1706    |    1850    |   58643 K  |   58641 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      64    |      67    |    2148 K  |    2148 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      52    |      55    |     582 K  |     582 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      79    |      82    |   41910 K  |   41910 K  |\n","|       from large pool |      19    |      19    |   21565 K  |   21565 K  |\n","|       from small pool |      60    |      64    |   20344 K  |   20344 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:427/430 batch_size:2\n","Next token prediction. step:87/98 batch:427/430 epoch:1/1\n","full seq: This can be summed up in \"three Ps\": People, Prosperity, and Peace.Ģġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġ\n","pref seq: This can be summed up in \"three Ps\": People, Prosperity, and Peace.Ģġġġġġġġġġġġġġġġġġġġ\n","next tok:                                                                                       ġ\n","pred tok:                                                                                       ġ\n","Completed batch.\n","epoch:1/1 batch:427/430 batch_size:2 loss:4.057686805725098 time_for_batch_instance:16.893204927444458 total_batch_time:15723.119322538376 running_batch_average:36.82229349540603\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 275374 KiB | 335220 KiB | 272906 GiB | 272906 GiB |\n","|       from large pool | 192022 KiB | 236136 KiB | 258760 GiB | 258759 GiB |\n","|       from small pool |  83352 KiB | 111029 KiB |  14146 GiB |  14146 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 275374 KiB | 335220 KiB | 272906 GiB | 272906 GiB |\n","|       from large pool | 192022 KiB | 236136 KiB | 258760 GiB | 258759 GiB |\n","|       from small pool |  83352 KiB | 111029 KiB |  14146 GiB |  14146 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 330946 KiB | 268844 GiB | 268843 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 254701 GiB | 254701 GiB |\n","|       from small pool |  83061 KiB | 110733 KiB |  14142 GiB |  14142 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 387072 KiB | 395264 KiB |  42265 GiB |  42264 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 104448 KiB | 112640 KiB |   1137 GiB |   1137 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 111697 KiB | 163167 KiB | 175250 GiB | 175250 GiB |\n","|       from large pool |  90602 KiB | 135224 KiB | 159882 GiB | 159882 GiB |\n","|       from small pool |  21095 KiB |  32540 KiB |  15368 GiB |  15368 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   95708 K  |   95707 K  |\n","|       from large pool |      98    |     122    |   36963 K  |   36963 K  |\n","|       from small pool |    1706    |    1850    |   58745 K  |   58743 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   95708 K  |   95707 K  |\n","|       from large pool |      98    |     122    |   36963 K  |   36963 K  |\n","|       from small pool |    1706    |    1850    |   58745 K  |   58743 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      63    |      67    |    2149 K  |    2149 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      51    |      55    |     582 K  |     582 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      76    |      83    |   41953 K  |   41953 K  |\n","|       from large pool |      19    |      19    |   21570 K  |   21570 K  |\n","|       from small pool |      57    |      65    |   20382 K  |   20382 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:428/430 batch_size:2\n","Next token prediction. step:56/97 batch:428/430 epoch:1/1\n","full seq: The depth of OONI data supports much-needed accountability and oversight.Ģġġġġġġġġġġġġġġġġġġġġġġġ\n","pref seq: The depth of OONI data supports much-needed accountabili\n","next tok:                                                        t\n","pred tok:                                                        d\n","Completed batch.\n","epoch:1/1 batch:428/430 batch_size:2 loss:4.008888244628906 time_for_batch_instance:16.864955186843872 total_batch_time:15739.98427772522 running_batch_average:36.77566420029257\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 279009 KiB | 337844 KiB | 272944 GiB | 272943 GiB |\n","|       from large pool | 195657 KiB | 238761 KiB | 258776 GiB | 258776 GiB |\n","|       from small pool |  83352 KiB | 109217 KiB |  14167 GiB |  14167 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 279009 KiB | 337844 KiB | 272944 GiB | 272943 GiB |\n","|       from large pool | 195657 KiB | 238761 KiB | 258776 GiB | 258776 GiB |\n","|       from small pool |  83352 KiB | 109217 KiB |  14167 GiB |  14167 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 330946 KiB | 268881 GiB | 268881 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 254718 GiB | 254718 GiB |\n","|       from small pool |  83061 KiB | 108918 KiB |  14163 GiB |  14163 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 387072 KiB | 395264 KiB |  42265 GiB |  42265 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 104448 KiB | 112640 KiB |   1138 GiB |   1138 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 108062 KiB | 163700 KiB | 175290 GiB | 175289 GiB |\n","|       from large pool |  86967 KiB | 135224 KiB | 159899 GiB | 159898 GiB |\n","|       from small pool |  21095 KiB |  32539 KiB |  15391 GiB |  15391 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   95819 K  |   95817 K  |\n","|       from large pool |      98    |     122    |   36973 K  |   36973 K  |\n","|       from small pool |    1706    |    1850    |   58845 K  |   58844 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   95819 K  |   95817 K  |\n","|       from large pool |      98    |     122    |   36973 K  |   36973 K  |\n","|       from small pool |    1706    |    1850    |   58845 K  |   58844 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      63    |      67    |    2149 K  |    2149 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      51    |      55    |     582 K  |     582 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      74    |      77    |   41994 K  |   41994 K  |\n","|       from large pool |      14    |      19    |   21576 K  |   21576 K  |\n","|       from small pool |      60    |      62    |   20418 K  |   20418 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:429/430 batch_size:2\n","Next token prediction. step:1/96 batch:429/430 epoch:1/1\n","full seq: Many expected the vote to produce severe economic volatility.Ģġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġġ\n","pref seq: M\n","next tok: a\n","pred tok: t\n","Completed batch.\n","epoch:1/1 batch:429/430 batch_size:2 loss:4.155074596405029 time_for_batch_instance:16.530895471572876 total_batch_time:15756.515173196793 running_batch_average:36.72847359719532\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 275374 KiB | 335220 KiB | 272983 GiB | 272982 GiB |\n","|       from large pool | 192022 KiB | 236136 KiB | 258794 GiB | 258794 GiB |\n","|       from small pool |  83352 KiB | 111029 KiB |  14188 GiB |  14188 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 275374 KiB | 335220 KiB | 272983 GiB | 272982 GiB |\n","|       from large pool | 192022 KiB | 236136 KiB | 258794 GiB | 258794 GiB |\n","|       from small pool |  83352 KiB | 111029 KiB |  14188 GiB |  14188 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 330946 KiB | 268919 GiB | 268919 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 254735 GiB | 254734 GiB |\n","|       from small pool |  83061 KiB | 110733 KiB |  14184 GiB |  14184 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 387072 KiB | 395264 KiB |  42266 GiB |  42265 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 104448 KiB | 112640 KiB |   1138 GiB |   1138 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 111697 KiB | 163167 KiB | 175330 GiB | 175330 GiB |\n","|       from large pool |  90602 KiB | 135224 KiB | 159916 GiB | 159916 GiB |\n","|       from small pool |  21095 KiB |  32540 KiB |  15414 GiB |  15414 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   95929 K  |   95927 K  |\n","|       from large pool |      98    |     122    |   36983 K  |   36983 K  |\n","|       from small pool |    1706    |    1850    |   58945 K  |   58943 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   95929 K  |   95927 K  |\n","|       from large pool |      98    |     122    |   36983 K  |   36983 K  |\n","|       from small pool |    1706    |    1850    |   58945 K  |   58943 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      63    |      67    |    2149 K  |    2149 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      51    |      55    |     583 K  |     583 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      74    |      83    |   42037 K  |   42037 K  |\n","|       from large pool |      19    |      19    |   21580 K  |   21580 K  |\n","|       from small pool |      55    |      65    |   20456 K  |   20456 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:1/1 batch:430/430 batch_size:2\n","Next token prediction. step:30/95 batch:430/430 epoch:1/1\n","full seq: I write on global economics, and my work takes me to far-flung places.Ģġġġġġġġġġġġġġġġġġġġġġġġġ\n","pref seq: I write on global economics, a\n","next tok:                              n\n","pred tok:                               \n","Completed batch.\n","epoch:1/1 batch:430/430 batch_size:2 loss:4.205839157104492 time_for_batch_instance:17.554721117019653 total_batch_time:15774.069894313812 running_batch_average:36.6838834751484\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 277513 KiB | 336715 KiB | 273019 GiB | 273019 GiB |\n","|       from large pool | 194161 KiB | 237632 KiB | 258810 GiB | 258810 GiB |\n","|       from small pool |  83352 KiB | 108764 KiB |  14208 GiB |  14208 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 277513 KiB | 336715 KiB | 273019 GiB | 273019 GiB |\n","|       from large pool | 194161 KiB | 237632 KiB | 258810 GiB | 258810 GiB |\n","|       from small pool |  83352 KiB | 108764 KiB |  14208 GiB |  14208 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 272117 KiB | 330946 KiB | 268955 GiB | 268955 GiB |\n","|       from large pool | 189056 KiB | 232160 KiB | 254751 GiB | 254750 GiB |\n","|       from small pool |  83061 KiB | 108464 KiB |  14204 GiB |  14204 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   | 385024 KiB | 395264 KiB |  42266 GiB |  42266 GiB |\n","|       from large pool | 282624 KiB | 282624 KiB |  41127 GiB |  41127 GiB |\n","|       from small pool | 102400 KiB | 112640 KiB |   1139 GiB |   1139 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 107510 KiB | 160862 KiB | 175368 GiB | 175368 GiB |\n","|       from large pool |  88463 KiB | 135224 KiB | 159932 GiB | 159932 GiB |\n","|       from small pool |  19047 KiB |  32261 KiB |  15436 GiB |  15436 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |    1804    |    1972    |   96037 K  |   96035 K  |\n","|       from large pool |      98    |     122    |   36993 K  |   36993 K  |\n","|       from small pool |    1706    |    1850    |   59043 K  |   59042 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |    1804    |    1972    |   96037 K  |   96035 K  |\n","|       from large pool |      98    |     122    |   36993 K  |   36993 K  |\n","|       from small pool |    1706    |    1850    |   59043 K  |   59042 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      62    |      67    |    2150 K  |    2149 K  |\n","|       from large pool |      12    |      12    |    1566 K  |    1566 K  |\n","|       from small pool |      50    |      55    |     583 K  |     583 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      65    |      75    |   42077 K  |   42077 K  |\n","|       from large pool |      14    |      19    |   21586 K  |   21586 K  |\n","|       from small pool |      51    |      60    |   20491 K  |   20491 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Completed epoch 1/1 in 264.2190821170807m\n","epoch:1, batch:430/430, loss:4.205839157104492\n"]}],"source":["runner = Runner(runner_hyperparameters_name=\"NewsCommentaryByT5Vaswani2017Kocmi2018_1\")\n","\n","runner.load_dataset()\n","runner.load_model()\n","runner.load_trainer()\n","runner.run_trainer()"]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[],"gpuType":"L4","authorship_tag":"ABX9TyOruI+vyC8iuuJ54xqWuGRN"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}