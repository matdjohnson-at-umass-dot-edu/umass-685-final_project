{"cells":[{"cell_type":"markdown","metadata":{"id":"XxChZLAKliXg"},"source":["Content taken from GitHub repository hosting the code:\n","\n","https://github.com/matthewjohnson42/umass-cs685-finalproject\n","\n","Substantial modifications made to adapt to Colab training environment."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30477,"status":"ok","timestamp":1715723009709,"user":{"displayName":"Matthew Johnson","userId":"09672185346885346735"},"user_tz":240},"id":"U0NG9bOzleFZ","outputId":"56e54f0b-f5d0-4a64-9a22-4a5bef94097a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]},{"data":{"text/plain":["device(type='cuda')"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["from google.colab import drive\n","\n","import torch\n","import numpy as np\n","\n","import random\n","from typing import Optional\n","import time\n","import os\n","import gc\n","\n","\n","drive.mount('/content/drive', force_remount=True)\n","root_filepath = '/content/drive/MyDrive/CS685-NLP-GroupProject/Code/singleNotebookFromPythonFilesStructure/'\n","is_remote_execution = True\n","\n","torch.device(\"cuda\")"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1715723009710,"user":{"displayName":"Matthew Johnson","userId":"09672185346885346735"},"user_tz":240},"id":"sllajv_0n2Vu"},"outputs":[],"source":["SETimesByT5Vaswani2017Kocmi2018_0 = {\n","    'dataset_transformer_name': 'dataset_transformer_setimesbyt5',\n","    'model_name': 'transformer_vaswani2017',\n","    'trainer_name': 'model_trainer_kocmi2018',\n","    'latest_param_filename_tag': '1715672129',\n","    # corresponds to dictionary 'get' calls in the dataset_loader constructor\n","    'dataset_transformer_hyperparameters': {\n","        'sentence_length_min_percentile': 5,\n","        'sentence_length_max_percentile': 95,\n","        'parsed_dataset_filename': 'setimes_parsed-1715586293'\n","    },\n","    # corresponds to dictionary 'get' calls in the model constructor\n","    'model_hyperparameters': {\n","        'd_model': 256,\n","        'nhead': 8,\n","        # number of encoders is 3 times that of decoders, following Xue 2021 - ByT5 - Sec 3.1\n","        'num_encoder_layers': 9,\n","        'num_decoder_layers': 3,\n","        'dim_feedforward': 2048,\n","        'dropout': 0.1,\n","        'activation': torch.nn.functional.relu,\n","        'custom_encoder': None,\n","        'custom_decoder': None,\n","        'layer_norm_eps': 1e-5,\n","        'batch_first': True,\n","        'norm_first': False,\n","        'bias': True,\n","        'device': None,\n","        'dtype': None\n","    },\n","    # corresponds to dictionary 'get' calls in the trainer constructor\n","    'trainer_hyperparameters': {\n","        # optimization and lr schedule following Kocmi 2018 - Trivial TL - Sec 3\n","        'optimizer_name': 'Adam',\n","        'lr_scheduler_name': 'ExponentialLR',\n","        'initial_lr': 0.001,\n","        'exp_decay': 0.5,\n","        'epochs': 10,\n","        'epoch_starting_index': 0,\n","        'batch_size_limit': 175,\n","        'element_difference_limit': 19,\n","        'batch_starting_index': 765\n","    }\n","}\n","\n","SETimesByT5Vaswani2017Kocmi2018_1 = {\n","    'dataset_transformer_name': 'dataset_transformer_setimesbyt5',\n","    'model_name': 'transformer_vaswani2017',\n","    'trainer_name': 'model_trainer_kocmi2018',\n","    'latest_param_filename_tag': '1715672186',\n","    # corresponds to dictionary 'get' calls in the dataset_loader constructor\n","    'dataset_transformer_hyperparameters': {\n","        'sentence_length_min_percentile': 5,\n","        'sentence_length_max_percentile': 95,\n","        'parsed_dataset_filename': 'setimes_parsed-1715586974'\n","    },\n","    # corresponds to dictionary 'get' calls in the model constructor\n","    'model_hyperparameters': {\n","        'd_model': 256,\n","        'nhead': 8,\n","        # number of encoders is 3 times that of decoders, following Xue 2021 - ByT5 - Sec 3.1\n","        'num_encoder_layers': 9,\n","        'num_decoder_layers': 3,\n","        'dim_feedforward': 1796,\n","        'dropout': 0.1,\n","        'activation': torch.nn.functional.relu,\n","        'custom_encoder': None,\n","        'custom_decoder': None,\n","        'layer_norm_eps': 1e-5,\n","        'batch_first': True,\n","        'norm_first': False,\n","        'bias': True,\n","        'device': None,\n","        'dtype': None\n","    },\n","    # corresponds to dictionary 'get' calls in the trainer constructor\n","    'trainer_hyperparameters': {\n","        # optimization and lr schedule following Kocmi 2018 - Trivial TL - Sec 3\n","        'optimizer_name': 'Adam',\n","        'lr_scheduler_name': 'ExponentialLR',\n","        'initial_lr': 0.001,\n","        'exp_decay': 0.5,\n","        'epochs': 10,\n","        'epoch_starting_index': 1,\n","        'batch_size_limit': 250,\n","        'element_difference_limit': 19,\n","        'batch_starting_index': 0\n","    }\n","}\n","\n","SETimesByT5Vaswani2017Kocmi2018_2 = {\n","    'dataset_transformer_name': 'dataset_transformer_setimesbyt5',\n","    'model_name': 'transformer_vaswani2017',\n","    'trainer_name': 'model_trainer_kocmi2018',\n","    'latest_param_filename_tag': '1715672061',\n","    # corresponds to dictionary 'get' calls in the dataset_loader constructor\n","    'dataset_transformer_hyperparameters': {\n","        'sentence_length_min_percentile': 5,\n","        'sentence_length_max_percentile': 95,\n","        'parsed_dataset_filename': 'setimes_parsed-1715586361'\n","    },\n","    # corresponds to dictionary 'get' calls in the model constructor\n","    'model_hyperparameters': {\n","        'd_model': 128,\n","        'nhead': 8,\n","        # number of encoders is 3 times that of decoders, following Xue 2021 - ByT5 - Sec 3.1\n","        'num_encoder_layers': 9,\n","        'num_decoder_layers': 3,\n","        'dim_feedforward': 1024,\n","        'dropout': 0.1,\n","        'activation': torch.nn.functional.relu,\n","        'custom_encoder': None,\n","        'custom_decoder': None,\n","        'layer_norm_eps': 1e-5,\n","        'batch_first': True,\n","        'norm_first': False,\n","        'bias': True,\n","        'device': None,\n","        'dtype': None\n","    },\n","    # corresponds to dictionary 'get' calls in the trainer constructor\n","    'trainer_hyperparameters': {\n","        # optimization and lr schedule following Kocmi 2018 - Trivial TL - Sec 3\n","        'optimizer_name': 'Adam',\n","        'lr_scheduler_name': 'ExponentialLR',\n","        'initial_lr': 0.001,\n","        'exp_decay': 0.5,\n","        'epochs': 10,\n","        'epoch_starting_index': 1,\n","        'batch_size_limit': 400,\n","        'element_difference_limit': 19,\n","        'batch_starting_index': 0\n","    }\n","}\n","\n","loss_weights_0 = torch.tensor([0, 0, 0.244293498, 0.354252208, 0.119055746, 0.129490827, 0.234447, 0.331966255, 0.062493498, 0.200436672, 0.128134531, 0.115730135, 0.114789455, 0.111928721, 0.120232896, 0.172708905, 0.091552235, 0.18382728, 0.167772254, 0.221570123, 0.26933557, 0.207267199, 0.161156936, 0.163208063, 0.206129376, 0.1923278, 0.246448966, 0.309805116, 0.312319847, 0.341492611, 0.287077958, 0.317765776, 0.282694925, 0.328107375, 0.305618951, 0.342956521, 0.33013427, 0.36810305, 0.29995848, 0.39787945, 0.36195021, 0.231575726, 0.238716465, 0.228047462, 0.589442629, 0.428540415, 0.349514641, 0.428583838, 0.372321337, 0.35910363, 0.314836573, 0.359830778, 0.329628544, 0.358553271, 0.38731315, 0.301171514, 0.414866271, 0.454463773, 0.410552656, 0.418645272, 0.489374491, 0.60674051, 0.415410876, 0.387694004, 0.469862412, 0.387466491, 0.404244134, 0.410692024, 0.3650963, 0.328332631, 0.362047807, 0.390990331, 0.407611852, 0.353090879, 0.519082435, 0.465516001, 0.382984849, 0.382904558, 0.417591599, 0.47406963, 0.513595183, 0.561900207, 0.600687916, 0.552947486, 0.672534847, 0.775971182, 0.728910416, 0.783069437, 0.726598021, 0.870987145, 0.761128877, 0.716818395, 0.708372474, 0.70507743, 0.731312344, 0.718124592, 0.931839821, 0.675783865, 0.863679642, 0.79786095, 0.870987145, 0.888835536, 0.845831251, 0.845831251, 0.870987145, 0.831986963, 0.817320914, 0.888835536, 0.82798286, 0.931839821, 0.900147142, 0.91399143, 0.91399143, 0.956995715, 0.931839821, 1, 0.900147142, 0.870987145, 0.870987145, 1, 0.900147142, 0.888835536, 0.956995715, 0.824221583, 1, 1, 0.956995715, 1, 0.931839821, 0.931839821, 0.956995715, 0.956995715, 0.956995715, 0.888835536, 0.931839821, 1, 0.900147142, 0.91399143, 0.956995715, 0.956995715, 0.956995715, 1, 1, 1, 0.900147142, 0.931839821, 0.900147142, 0.931839821, 0.956995715, 0.91399143, 1, 0.956995715, 1, 1, 1, 1, 1, 0.956995715, 1, 1, 1, 1, 1, 1, 1, 0.931839821, 1, 0.956995715, 1, 1, 0.956995715])\n","loss_weights_1 = torch.tensor([0, 0, 0.283786926, 0.387999164, 0.165094134, 0.174983875, 0.274455009, 0.366877881, 0.111487844, 0.242222071, 0.173698459, 0.16194232, 0.1610508, 0.158339569, 0.166209765, 0.215943364, 0.139027964, 0.226480689, 0.211264704, 0.262251081, 0.307520293, 0.248695632, 0.204995104, 0.206939038, 0.247617272, 0.23453697, 0.285829749, 0.345874889, 0.3482582, 0.375906387, 0.324335459, 0.353419523, 0.320181484, 0.363220667, 0.341907494, 0.377293793, 0.365141636, 0.401126157, 0.336542841, 0.429346435, 0.395294867, 0.271733788, 0.27850135, 0.268389913, 0.610898469, 0.458405049, 0.383509184, 0.458446203, 0.405123996, 0.39259705, 0.350643401, 0.393286196, 0.36466234, 0.392075452, 0.419332333, 0.337692481, 0.44544552, 0.482973645, 0.441357336, 0.449027029, 0.51605992, 0.627292358, 0.445961663, 0.419693282, 0.497567547, 0.419477659, 0.435378499, 0.44148942, 0.398276541, 0.363434152, 0.395387363, 0.422817343, 0.438570219, 0.386898527, 0.544215318, 0.493448281, 0.415230229, 0.415154135, 0.448028421, 0.501554895, 0.539014832, 0.584795422, 0.621556075, 0.576310573, 0.689648265, 0.78767899, 0.743077631, 0.794406288, 0.740886083, 0.877729392, 0.773612348, 0.731617543, 0.723613008, 0.720490164, 0.745354034, 0.732855478, 0.93540189, 0.692727489, 0.870803781, 0.808424792, 0.877729392, 0.894645021, 0.853888152, 0.853888152, 0.877729392, 0.84076737, 0.826867773, 0.894645021, 0.836972522, 0.93540189, 0.90536548, 0.918486261, 0.918486261, 0.959243131, 0.93540189, 1, 0.90536548, 0.877729392, 0.877729392, 1, 0.90536548, 0.894645021, 0.959243131, 0.833407811, 1, 1, 0.959243131, 1, 0.93540189, 0.93540189, 0.959243131, 0.959243131, 0.959243131, 0.894645021, 0.93540189, 1, 0.90536548, 0.918486261, 0.959243131, 0.959243131, 0.959243131, 1, 1, 1, 0.90536548, 0.93540189, 0.90536548, 0.93540189, 0.959243131, 0.918486261, 1, 0.959243131, 1, 1, 1, 1, 1, 0.959243131, 1, 1, 1, 1, 1, 1, 1, 0.93540189, 1, 0.959243131, 1, 1, 0.959243131])\n","\n","english_char_mappings = {\n","    ord(\" \"): ord(\" \"),\n","    ord(\"e\"): ord(\"e\"),\n","    ord(\"t\"): ord(\"t\"),\n","    ord(\"a\"): ord(\"a\"),\n","    ord(\"i\"): ord(\"i\"),\n","    ord(\"o\"): ord(\"o\"),\n","    ord(\"n\"): ord(\"n\"),\n","    ord(\"r\"): ord(\"r\"),\n","    ord(\"s\"): ord(\"s\"),\n","    ord(\"h\"): ord(\"h\"),\n","    ord(\"l\"): ord(\"l\"),\n","    ord(\"d\"): ord(\"d\"),\n","    ord(\"c\"): ord(\"c\"),\n","    ord(\"u\"): ord(\"u\"),\n","    ord(\"m\"): ord(\"m\"),\n","    ord(\"p\"): ord(\"p\"),\n","    ord(\"f\"): ord(\"f\"),\n","    ord(\"g\"): ord(\"g\"),\n","    ord(\"y\"): ord(\"y\"),\n","    ord(\"b\"): ord(\"b\"),\n","    ord(\"w\"): ord(\"w\"),\n","    ord(\"v\"): ord(\"v\"),\n","    ord(\",\"): ord(\",\"),\n","    ord(\".\"): ord(\".\"),\n","    ord(\"k\"): ord(\"k\"),\n","    ord(\"T\"): ord(\"T\"),\n","    ord(\"S\"): ord(\"S\"),\n","    ord(\"0\"): ord(\"0\"),\n","    ord(\"A\"): ord(\"A\"),\n","    ord(\"-\"): ord(\"-\"),\n","    ord(\"B\"): ord(\"B\"),\n","    ord(\"M\"): ord(\"M\"),\n","    ord(\"\\\"\"): ord(\"\\\"\"),\n","    ord(\"E\"): ord(\"E\"),\n","    ord(\"P\"): ord(\"P\"),\n","    ord(\"C\"): ord(\"C\"),\n","    ord(\"I\"): ord(\"I\"),\n","    ord(\"1\"): ord(\"1\"),\n","    ord(\"'\"): ord(\"'\"),\n","    ord(\"j\"): ord(\"j\"),\n","    ord(\"2\"): ord(\"2\"),\n","    ord(\"R\"): ord(\"R\"),\n","    ord(\"U\"): ord(\"U\"),\n","    ord(\"K\"): ord(\"K\"),\n","    ord(\"D\"): ord(\"D\"),\n","    ord(\"x\"): ord(\"x\"),\n","    ord(\"H\"): ord(\"H\"),\n","    ord(\"F\"): ord(\"F\"),\n","    ord(\"N\"): ord(\"N\"),\n","    ord(\"G\"): ord(\"G\"),\n","    ord(\"/\"): ord(\"/\"),\n","    ord(\"O\"): ord(\"O\"),\n","    ord(\")\"): ord(\")\"),\n","    ord(\"(\"): ord(\"(\"),\n","    ord(\"9\"): ord(\"9\"),\n","    ord(\"W\"): ord(\"W\"),\n","    ord(\"z\"): ord(\"z\"),\n","    ord(\"5\"): ord(\"5\"),\n","    ord(\"3\"): ord(\"3\"),\n","    ord(\"J\"): ord(\"J\"),\n","    ord(\"4\"): ord(\"4\"),\n","    ord(\"q\"): ord(\"q\"),\n","    ord(\"L\"): ord(\"L\"),\n","    ord(\"6\"): ord(\"6\"),\n","    ord(\"7\"): ord(\"7\"),\n","    ord(\"8\"): ord(\"8\"),\n","    ord(\"V\"): ord(\"V\"),\n","    ord(\"[\"): ord(\"[\"),\n","    ord(\"]\"): ord(\"]\"),\n","    ord(\":\"): ord(\":\"),\n","    ord(\"Z\"): ord(\"Z\"),\n","    ord(\"%\"): ord(\"%\"),\n","    ord(\"Y\"): ord(\"Y\"),\n","    ord(\";\"): ord(\";\"),\n","    ord(\"–\"): ord(\"-\"),\n","    ord(\"?\"): ord(\"?\"),\n","    ord(\"X\"): ord(\"X\"),\n","    ord(\"$\"): ord(\"$\"),\n","    ord(\"’\"): ord(\"'\"),\n","    ord(\"Q\"): ord(\"Q\"),\n","    ord(\"…\"): ord(\"\\u0120\"),\n","    ord(\"!\"): ord(\"\\u0120\"),\n","    ord(\"\u0026\"): ord(\"\\u0120\"),\n","    ord(\"ć\"): ord(\"\\u0120\"),\n","    ord(\"”\"): ord(\"\\\"\"),\n","    ord(\"é\"): ord(\"\\u0120\"),\n","    ord(\"“\"): ord(\"\\\"\"),\n","    ord(\"ı\"): ord(\"\\u0120\"),\n","    ord(\"ü\"): ord(\"\\u0120\"),\n","    ord(\"+\"): ord(\"\\u0120\"),\n","    ord(\"ç\"): ord(\"\\u0120\"),\n","    ord(\"ˈ\"): ord(\"'\"),\n","    ord(\"ö\"): ord(\"\\u0120\"),\n","    ord(\"ë\"): ord(\"\\u0120\"),\n","    ord(\"Ç\"): ord(\"\\u0120\"),\n","    ord(\"ğ\"): ord(\"\\u0120\"),\n","    ord(\"č\"): ord(\"\\u0120\"),\n","    ord(\"š\"): ord(\"\\u0120\"),\n","    ord(\"‘\"): ord(\"'\"),\n","    ord(\"ž\"): ord(\"\\u0120\"),\n","    ord(\"*\"): ord(\"\\u0120\"),\n","    ord(\"ş\"): ord(\"\\u0120\"),\n","    ord(\"б\"): ord(\"\\u0120\"),\n","    ord(\"Š\"): ord(\"\\u0120\"),\n","    ord(\"İ\"): ord(\"\\u0120\"),\n","    ord(\"à\"): ord(\"\\u0120\"),\n","    ord(\"г\"): ord(\"\\u0120\"),\n","    ord(\"ï\"): ord(\"\\u0120\"),\n","    ord(\"Ü\"): ord(\"\\u0120\"),\n","    ord(\"—\"): ord(\"-\"),\n","    ord(\"€\"): ord(\"\\u0120\"),\n","    ord(\"Ö\"): ord(\"\\u0120\"),\n","    ord(\"đ\"): ord(\"\\u0120\"),\n","    ord(\"\\\\\"): ord(\"\\u0120\"),\n","    ord(\"Ι\"): ord(\"\\u0120\"),\n","    ord(\"Α\"): ord(\"A\"),\n","    ord(\"`\"): ord(\"'\"),\n","    ord(\"_\"): ord(\"\\u0120\"),\n","    ord(\"=\"): ord(\"\\u0120\"),\n","    ord(\"@\"): ord(\"\\u0120\"),\n","    ord(\"А\"): ord(\"A\"),\n","    ord(\"ó\"): ord(\"\\u0120\"),\n","    ord(\"í\"): ord(\"\\u0120\"),\n","    ord(\"â\"): ord(\"\\u0120\"),\n","    ord(\"\\x80\"): ord(\"\\u0120\"),\n","    ord(\"Ž\"): ord(\"\\u0120\"),\n","    ord(\"Κ\"): ord(\"K\"),\n","    ord(\"Ο\"): ord(\"O\"),\n","    ord(\"р\"): ord(\"p\"),\n","    ord(\"Ş\"): ord(\"\\u0120\"),\n","    ord(\"á\"): ord(\"\\u0120\"),\n","    ord(\"у\"): ord(\"y\"),\n","    ord(\"\\x93\"): ord(\"\\u0120\"),\n","    ord(\"°\"): ord(\"\\u0120\"),\n","    ord(\"\u003c\"): ord(\"\\u0120\"),\n","    ord(\"½\"): ord(\"\\u0120\"),\n","    ord(\"Т\"): ord(\"T\"),\n","    ord(\"ø\"): ord(\"\\u0120\"),\n","    ord(\"Ε\"): ord(\"E\"),\n","    ord(\"#\"): ord(\"\\u0120\"),\n","    ord(\"ý\"): ord(\"\\u0120\"),\n","    ord(\"л\"): ord(\"\\u0120\"),\n","    ord(\"я\"): ord(\"\\u0120\"),\n","    ord(\"�\"): ord(\"\\u0120\"),\n","    ord(\"º\"): ord(\"\\u0120\"),\n","    ord(\"ä\"): ord(\"\\u0120\"),\n","    ord(\"е\"): ord(\"e\"),\n","    ord(\"о\"): ord(\"o\"),\n","    ord(\"Đ\"): ord(\"\\u0120\"),\n","    ord(\"è\"): ord(\"\\u0120\"),\n","    ord(\"¾\"): ord(\"\\u0120\"),\n","    ord(\"\\x96\"): ord(\"\\u0120\"),\n","    ord(\"æ\"): ord(\"\\u0120\"),\n","    ord(\"\u003e\"): ord(\"\\u0120\"),\n","    ord(\"¦\"): ord(\"\\u0120\"),\n","    ord(\"μ\"): ord(\"\\u0120\"),\n","    ord(\"Č\"): ord(\"\\u0120\"),\n","    ord(\"ñ\"): ord(\"\\u0120\"),\n","    ord(\"х\"): ord(\"x\"),\n","    ord(\"М\"): ord(\"M\"),\n","    ord(\"É\"): ord(\"\\u0120\"),\n","    ord(\"±\"): ord(\"\\u0120\"),\n","    ord(\"£\"): ord(\"\\u0120\"),\n","    ord(\"{\"): ord(\"\\u0120\"),\n","    ord(\"}\"): ord(\"\\u0120\"),\n","    ord(\"ъ\"): ord(\"\\u0120\"),\n","    ord(\"а\"): ord(\"\\u0120\"),\n","    ord(\"и\"): ord(\"\\u0120\")\n","}\n","\n","turkish_char_mappings = {\n","    ord(\" \"): ord(\" \"),\n","    ord(\"a\"): ord(\"a\"),\n","    ord(\"e\"): ord(\"e\"),\n","    ord(\"i\"): ord(\"i\"),\n","    ord(\"n\"): ord(\"n\"),\n","    ord(\"r\"): ord(\"r\"),\n","    ord(\"l\"): ord(\"l\"),\n","    ord(\"ı\"): ord(\"ı\"),\n","    ord(\"k\"): ord(\"k\"),\n","    ord(\"d\"): ord(\"d\"),\n","    ord(\"t\"): ord(\"t\"),\n","    ord(\"s\"): ord(\"s\"),\n","    ord(\"u\"): ord(\"u\"),\n","    ord(\"m\"): ord(\"m\"),\n","    ord(\"y\"): ord(\"y\"),\n","    ord(\"o\"): ord(\"o\"),\n","    ord(\"ü\"): ord(\"ü\"),\n","    ord(\"b\"): ord(\"b\"),\n","    ord(\"ş\"): ord(\"ş\"),\n","    ord(\"v\"): ord(\"v\"),\n","    ord(\"g\"): ord(\"g\"),\n","    ord(\"z\"): ord(\"z\"),\n","    ord(\"ç\"): ord(\"ç\"),\n","    ord(\"ğ\"): ord(\"ğ\"),\n","    ord(\".\"): ord(\".\"),\n","    ord(\",\"): ord(\",\"),\n","    ord(\"c\"): ord(\"c\"),\n","    ord(\"h\"): ord(\"h\"),\n","    ord(\"p\"): ord(\"p\"),\n","    ord(\"ö\"): ord(\"ö\"),\n","    ord(\"'\"): ord(\"'\"),\n","    ord(\"B\"): ord(\"B\"),\n","    ord(\"A\"): ord(\"A\"),\n","    ord(\"f\"): ord(\"f\"),\n","    ord(\"S\"): ord(\"S\"),\n","    ord(\"K\"): ord(\"K\"),\n","    ord(\"0\"): ord(\"0\"),\n","    ord(\"\\\"\"): ord(\"\\\"\"),\n","    ord(\"T\"): ord(\"T\"),\n","    ord(\"M\"): ord(\"M\"),\n","    ord(\"1\"): ord(\"1\"),\n","    ord(\"P\"): ord(\"P\"),\n","    ord(\"D\"): ord(\"D\"),\n","    ord(\"H\"): ord(\"H\"),\n","    ord(\"2\"): ord(\"2\"),\n","    ord(\"E\"): ord(\"E\"),\n","    ord(\"R\"): ord(\"R\"),\n","    ord(\"-\"): ord(\"-\"),\n","    ord(\"G\"): ord(\"G\"),\n","    ord(\"j\"): ord(\"j\"),\n","    ord(\"Y\"): ord(\"Y\"),\n","    ord(\"C\"): ord(\"C\"),\n","    ord(\"İ\"): ord(\"İ\"),\n","    ord(\"O\"): ord(\"O\"),\n","    ord(\"/\"): ord(\"/\"),\n","    ord(\"F\"): ord(\"F\"),\n","    ord(\"N\"): ord(\"N\"),\n","    ord(\"9\"): ord(\"9\"),\n","    ord(\"5\"): ord(\"5\"),\n","    ord(\"3\"): ord(\"3\"),\n","    ord(\"I\"): ord(\"I\"),\n","    ord(\"4\"): ord(\"4\"),\n","    ord(\"L\"): ord(\"L\"),\n","    ord(\"6\"): ord(\"6\"),\n","    ord(\")\"): ord(\")\"),\n","    ord(\"(\"): ord(\"(\"),\n","    ord(\"7\"): ord(\"7\"),\n","    ord(\"8\"): ord(\"8\"),\n","    ord(\"U\"): ord(\"U\"),\n","    ord(\"V\"): ord(\"V\"),\n","    ord(\":\"): ord(\":\"),\n","    ord(\"[\"): ord(\"[\"),\n","    ord(\"]\"): ord(\"]\"),\n","    ord(\"’\"): ord(\"'\"),\n","    ord(\"Z\"): ord(\"Z\"),\n","    ord(\"Ç\"): ord(\"Ç\"),\n","    ord(\"J\"): ord(\"J\"),\n","    ord(\"Ü\"): ord(\"Ü\"),\n","    ord(\"Ş\"): ord(\"Ş\"),\n","    ord(\"Ö\"): ord(\"Ö\"),\n","    ord(\"%\"): ord(\"%\"),\n","    ord(\";\"): ord(\";\"),\n","    ord(\"w\"): ord(\"w\"),\n","    ord(\"W\"): ord(\"W\"),\n","    ord(\"â\"): ord(\"â\"),\n","    ord(\"–\"): ord(\"-\"),\n","    ord(\"?\"): ord(\"?\"),\n","    ord(\"x\"): ord(\"x\"),\n","    ord(\"“\"): ord(\"\\\"\"),\n","    ord(\"”\"): ord(\"\\\"\"),\n","    ord(\"X\"): ord(\"X\"),\n","    ord(\"q\"): ord(\"q\"),\n","    ord(\"î\"): ord(\"\\u0120\"),\n","    ord(\"\u0026\"): ord(\"\\u0120\"),\n","    ord(\"!\"): ord(\"\\u0120\"),\n","    ord(\"ð\"): ord(\"\\u0120\"),\n","    ord(\"Q\"): ord(\"\\u0120\"),\n","    ord(\"+\"): ord(\"\\u0120\"),\n","    ord(\"þ\"): ord(\"\\u0120\"),\n","    ord(\"‘\"): ord(\"'\"),\n","    ord(\"é\"): ord(\"\\u0120\"),\n","    ord(\"º\"): ord(\"\\u0120\"),\n","    ord(\"ë\"): ord(\"\\u0120\"),\n","    ord(\"…\"): ord(\"\\u0120\"),\n","    ord(\"б\"): ord(\"\\u0120\"),\n","    ord(\"*\"): ord(\"\\u0120\"),\n","    ord(\"=\"): ord(\"\\u0120\"),\n","    ord(\"`\"): ord(\"'\"),\n","    ord(\"ć\"): ord(\"\\u0120\"),\n","    ord(\"û\"): ord(\"\\u0120\"),\n","    ord(\"Ý\"): ord(\"\\u0120\"),\n","    ord(\"г\"): ord(\"\\u0120\"),\n","    ord(\"—\"): ord(\"\\u0120\"),\n","    ord(\"\\\\\"): ord(\"\\u0120\"),\n","    ord(\"°\"): ord(\"\\u0120\"),\n","    ord(\"@\"): ord(\"\\u0120\"),\n","    ord(\"č\"): ord(\"\\u0120\"),\n","    ord(\"ó\"): ord(\"\\u0120\"),\n","    ord(\"š\"): ord(\"\\u0120\"),\n","    ord(\"р\"): ord(\"\\u0120\"),\n","    ord(\"_\"): ord(\"\\u0120\"),\n","    ord(\"{\"): ord(\"\\u0120\"),\n","    ord(\"#\"): ord(\"\\u0120\"),\n","    ord(\"^\"): ord(\"\\u0120\"),\n","    ord(\"\u003e\"): ord(\"\\u0120\"),\n","    ord(\"$\"): ord(\"\\u0120\"),\n","    ord(\"đ\"): ord(\"\\u0120\"),\n","    ord(\"í\"): ord(\"\\u0120\"),\n","    ord(\"ø\"): ord(\"\\u0120\"),\n","    ord(\"Š\"): ord(\"\\u0120\"),\n","    ord(\"ž\"): ord(\"\\u0120\"),\n","    ord(\"Þ\"): ord(\"\\u0120\"),\n","    ord(\"л\"): ord(\"\\u0120\"),\n","    ord(\"я\"): ord(\"\\u0120\"),\n","    ord(\"}\"): ord(\"\\u0120\"),\n","    ord(\"±\"): ord(\"\\u0120\"),\n","    ord(\"½\"): ord(\"\\u0120\"),\n","    ord(\"¾\"): ord(\"\\u0120\"),\n","    ord(\"ª\"): ord(\"\\u0120\"),\n","    ord(\"á\"): ord(\"\\u0120\"),\n","    ord(\"É\"): ord(\"\\u0120\"),\n","    ord(\"è\"): ord(\"\\u0120\"),\n","    ord(\"Ğ\"): ord(\"\\u0120\"),\n","    ord(\"ï\"): ord(\"\\u0120\"),\n","    ord(\"ñ\"): ord(\"\\u0120\"),\n","    ord(\"ý\"): ord(\"\\u0120\"),\n","    ord(\"Ž\"): ord(\"\\u0120\"),\n","    ord(\"μ\"): ord(\"\\u0120\"),\n","    ord(\"а\"): ord(\"\\u0120\"),\n","    ord(\"и\"): ord(\"\\u0120\"),\n","    ord(\"у\"): ord(\"\\u0120\"),\n","    ord(\"х\"): ord(\"\\u0120\"),\n","    ord(\"ъ\"): ord(\"\\u0120\"),\n","}\n"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1715723009710,"user":{"displayName":"Matthew Johnson","userId":"09672185346885346735"},"user_tz":240},"id":"RJAevV6XnuW1"},"outputs":[],"source":["class DatasetHolder:\n","\n","    def __init__(self):\n","        self.unknown_vocabulary_type = None\n","        self.padding_vocabulary_type = None\n","        self.end_of_sequence_type = None\n","        self.target_vocab = None\n","        self.target_vocab_array = None\n","        self.target_vocab_counts = None\n","        self.source_vocab = None\n","        self.source_vocab_array = None\n","        self.source_vocab_counts = None\n","        self.target_encodings = None\n","        self.target_encodings_train = None\n","        self.target_encodings_test = None\n","        self.source_encodings = None\n","        self.source_encodings_train = None\n","        self.source_encodings_test = None\n","        self.max_src_seq_obs = 0\n","        self.max_tgt_seq_obs = 0\n","\n","    def get_unknown_vocabulary_type(self):\n","        return self.unknown_vocabulary_type\n","\n","    def set_unknown_vocabulary_type(self, unknown_vocabulary_type):\n","        self.unknown_vocabulary_type = unknown_vocabulary_type\n","\n","    def get_padding_vocabulary_type(self):\n","        return self.padding_vocabulary_type\n","\n","    def set_padding_vocabulary_type(self, padding_vocabulary_type):\n","        self.padding_vocabulary_type = padding_vocabulary_type\n","\n","    def get_end_of_sequence_vocabulary_type(self):\n","        return self.end_of_sequence_type\n","\n","    def set_end_of_sequence_vocabulary_type(self, end_of_sequence_type):\n","        self.end_of_sequence_type = end_of_sequence_type\n","\n","    def get_target_vocab(self):\n","        return self.target_vocab\n","\n","    def set_target_vocab(self, target_vocab):\n","        self.target_vocab = target_vocab\n","\n","    def get_target_vocab_numpy(self):\n","        if self.target_vocab_array is None:\n","            self.target_vocab_array = np.array(self.target_vocab)\n","        return self.target_vocab_array\n","\n","    def get_target_vocab_counts(self):\n","        return self.target_vocab_counts\n","\n","    def set_target_vocab_counts(self, target_vocab_counts):\n","        self.target_vocab_counts = target_vocab_counts\n","\n","    def get_source_vocab(self):\n","        return self.source_vocab\n","\n","    def set_source_vocab(self, source_vocab):\n","        self.source_vocab = source_vocab\n","\n","    def get_source_vocab_numpy(self):\n","        if self.source_vocab_array is None:\n","            self.source_vocab_array = np.array(self.source_vocab)\n","        return self.source_vocab_array\n","\n","    def get_source_vocab_counts(self):\n","        return self.source_vocab_counts\n","\n","    def set_source_vocab_counts(self, source_vocab_counts):\n","        self.source_vocab_counts = source_vocab_counts\n","\n","    def get_target_encodings(self):\n","        return self.target_encodings\n","\n","    def set_target_encodings(self, target_encodings):\n","        del self.target_encodings\n","        self.target_encodings = target_encodings\n","        if is_remote_execution:\n","            torch.cuda.empty_cache()\n","\n","    def get_source_encodings(self):\n","        return self.source_encodings\n","\n","    def set_source_encodings(self, source_encodings):\n","        del self.source_encodings\n","        self.source_encodings = source_encodings\n","        if is_remote_execution:\n","            torch.cuda.empty_cache()\n","\n","    def get_target_encodings_train(self):\n","        return self.target_encodings_train\n","\n","    def set_target_encodings_train(self, target_encodings_train):\n","        del self.target_encodings_train\n","        self.target_encodings_train = target_encodings_train\n","        if is_remote_execution:\n","            torch.cuda.empty_cache()\n","\n","    def get_source_encodings_train(self):\n","        return self.source_encodings_train\n","\n","    def set_source_encodings_train(self, source_encodings_train):\n","        del self.source_encodings_train\n","        self.source_encodings_train = source_encodings_train\n","        if is_remote_execution:\n","            torch.cuda.empty_cache()\n","\n","    def get_target_encodings_test(self):\n","        return self.target_encodings_test\n","\n","    def set_target_encodings_test(self, target_encodings_test):\n","        del self.target_encodings_test\n","        self.target_encodings_test = target_encodings_test\n","        if is_remote_execution:\n","            torch.cuda.empty_cache()\n","\n","    def get_source_encodings_test(self):\n","        return self.source_encodings_test\n","\n","    def set_source_encodings_test(self, source_encodings_test):\n","        del self.source_encodings_test\n","        self.source_encodings_test = source_encodings_test\n","        if is_remote_execution:\n","            torch.cuda.empty_cache()\n","\n","    def get_max_src_seq_obs(self):\n","        return self.max_src_seq_obs\n","\n","    def set_max_src_seq_obs(self, max_src_seq_obs):\n","        self.max_src_seq_obs = max_src_seq_obs\n","\n","    def get_max_tgt_seq_obs(self):\n","        return self.max_tgt_seq_obs\n","\n","    def set_max_tgt_seq_obs(self, max_tgt_seq_obs):\n","        self.max_tgt_seq_obs = max_tgt_seq_obs\n","\n","\n","# class name matches file name\n","class dataset_transformer_setimesbyt5():\n","\n","    def __init__(self,\n","                 datasets_directory=root_filepath+\"resources\",\n","                 raw_dataset_directory=\"raw_datasets/setimes\",\n","                 parsed_dataset_directory=\"parsed_datasets/setimes\",\n","                 ids_filename='SETIMES.en-tr.ids',\n","                 en_filename='SETIMES.en-tr.en',\n","                 tr_filename='SETIMES.en-tr.tr',\n","                 dataset_hyperparameters=None):\n","        self.datasets_directory = datasets_directory\n","        self.raw_dataset_directory = raw_dataset_directory\n","        self.parsed_dataset_directory = parsed_dataset_directory\n","        self.ids_filename = ids_filename\n","        self.en_filename = en_filename\n","        self.tr_filename = tr_filename\n","        self.parsed_dataset_filename = None\n","        if 'parsed_dataset_filename' in dataset_hyperparameters:\n","            self.parsed_dataset_filename = dataset_hyperparameters['parsed_dataset_filename']\n","        self.sentence_length_min_percentile = None\n","        if 'sentence_length_min_percentile' in dataset_hyperparameters:\n","            self.sentence_length_min_percentile = dataset_hyperparameters['sentence_length_min_percentile']\n","        self.sentence_length_max_percentile = None\n","        if 'sentence_length_max_percentile' in dataset_hyperparameters:\n","            self.sentence_length_max_percentile = dataset_hyperparameters['sentence_length_max_percentile']\n","\n","\n","    def read_dataset(self):\n","        dataset_holder = None\n","        if self.parsed_dataset_filename is not None:\n","            dataset_holder = torch.load(self.datasets_directory + \"/\"\n","                                        + self.parsed_dataset_directory + \"/\"\n","                                        + self.parsed_dataset_filename)\n","        else:\n","            target_sentences = list()\n","            source_sentences = list()\n","            index_file = open(self.datasets_directory + \"/\" + self.raw_dataset_directory + \"/\" + self.ids_filename)\n","            en_file = open(self.datasets_directory + \"/\" + self.raw_dataset_directory + \"/\" + self.en_filename)\n","            tr_file = open(self.datasets_directory + \"/\" + self.raw_dataset_directory + \"/\" + self.tr_filename)\n","            indices = list()\n","            en_sentences = list()\n","            tr_sentences = list()\n","            line_number = 1\n","            for line in index_file:\n","                line_segments = line.strip().split()\n","                if len(line_segments) != 4:\n","                    print(\"Line segmentation error on line \" + str(line_number))\n","                    print(\"Content: \" + line)\n","                    continue\n","                if line_segments[0].startswith(\"en\") and line_segments[1].startswith(\"tr\"):\n","                    indices.append((int(line_segments[2]), int(line_segments[3])))\n","                elif line_segments[0].startswith(\"tr\") and line_segments[1].startswith(\"en\"):\n","                    indices.append((int(line_segments[3]), int(line_segments[2])))\n","                else:\n","                    print(\"Index parsing error on line \" + str(line_number))\n","                    print(\"Content: \" + line)\n","                    continue\n","                line_number = line_number + 1\n","            for line in en_file:\n","                en_sentences.append(line.strip())\n","            for line in tr_file:\n","                tr_sentences.append(line.strip())\n","            for index in indices:\n","                target_sentences.append(en_sentences[index[0] - 1])\n","                source_sentences.append(tr_sentences[index[1] - 1])\n","            target_sentence_lengths = list()\n","            for sentence in target_sentences:\n","                target_sentence_lengths.append(len(sentence))\n","            source_sentence_lengths = list()\n","            for sentence in source_sentences:\n","                source_sentence_lengths.append(len(sentence))\n","            target_sentences_length_limited = list()\n","            source_sentences_length_limited = list()\n","            target_min_len = int(np.percentile(sorted(target_sentence_lengths), self.sentence_length_min_percentile))\n","            target_max_len = int(np.percentile(sorted(target_sentence_lengths), self.sentence_length_max_percentile))\n","            source_min_len = int(np.percentile(sorted(source_sentence_lengths), self.sentence_length_min_percentile))\n","            source_max_len = int(np.percentile(sorted(source_sentence_lengths), self.sentence_length_max_percentile))\n","            max_src_seq_obs = 0\n","            max_tgt_seq_obs = 0\n","            for i in range(0, len(target_sentences)):\n","                if (len(target_sentences[i]) \u003e target_min_len and len(target_sentences[i]) \u003c= target_max_len\n","                        and len(source_sentences[i]) \u003e source_min_len and len(source_sentences[i]) \u003c= source_max_len):\n","                    if len(source_sentences[i]) \u003e max_src_seq_obs:\n","                        max_src_seq_obs = len(source_sentences[i])\n","                    if len(target_sentences[i]) \u003e max_tgt_seq_obs:\n","                        max_tgt_seq_obs = len(target_sentences[i])\n","                    target_sentences_length_limited.append(target_sentences[i].translate(english_char_mappings))\n","                    source_sentences_length_limited.append(source_sentences[i].translate(turkish_char_mappings))\n","            dataset_holder = DatasetHolder()\n","            dataset_holder.set_max_src_seq_obs(max_src_seq_obs)\n","            dataset_holder.set_max_tgt_seq_obs(max_tgt_seq_obs)\n","            # encode to Pytorch tensors as raw UTF-8 character vocabulary\n","            # method replicated from Xue 2021 - ByT5 - Introduction, sec 3.1\n","            unknown_vocabulary_type = \"\\u0120\".encode('utf-8').decode('utf-8')\n","            padding_vocabulary_type = \"\\u0121\".encode('utf-8').decode('utf-8')\n","            end_of_sequence_vocabulary_type = \"\\u0122\".encode('utf-8').decode('utf-8')\n","            dataset_holder.set_unknown_vocabulary_type(unknown_vocabulary_type)\n","            dataset_holder.set_padding_vocabulary_type(padding_vocabulary_type)\n","            dataset_holder.set_end_of_sequence_vocabulary_type(end_of_sequence_vocabulary_type)\n","            target_vocab = list([unknown_vocabulary_type, padding_vocabulary_type, end_of_sequence_vocabulary_type])\n","            source_vocab = list([unknown_vocabulary_type, padding_vocabulary_type, end_of_sequence_vocabulary_type])\n","            target_encodings = list()\n","            source_encodings = list()\n","            for entry in target_sentences_length_limited:\n","                encoding = list()\n","                for character in entry:\n","                    if character not in target_vocab:\n","                        target_vocab.append(character)\n","                    encoding.append(target_vocab.index(character))\n","                encoding.append(target_vocab.index(end_of_sequence_vocabulary_type))\n","                target_encodings.append(torch.tensor(encoding))\n","            for entry in source_sentences_length_limited:\n","                encoding = list()\n","                for character in entry:\n","                    if character not in source_vocab:\n","                        source_vocab.append(character)\n","                    encoding.append(source_vocab.index(character))\n","                encoding.append(target_vocab.index(end_of_sequence_vocabulary_type))\n","                source_encodings.append(torch.tensor(encoding))\n","            # fix vocabulary indices using tuple type\n","            dataset_holder.set_target_vocab(tuple(target_vocab))\n","            dataset_holder.set_target_encodings(target_encodings)\n","            dataset_holder.set_source_vocab(tuple(source_vocab))\n","            dataset_holder.set_source_encodings(source_encodings)\n","            dataset_holder = DatasetUtils.create_dataset_segments(dataset_holder)\n","            torch.save(dataset_holder,\n","                       self.datasets_directory + \"/\" +\n","                       self.parsed_dataset_directory + \"/\" +\n","                       \"setimes_parsed-\" + str(int(time.time())))\n","        return dataset_holder\n","\n","\n","class Utils:\n","\n","    def __init__(self):\n","        pass\n","\n","    @staticmethod\n","    def load_python_object(object_path: str, object_attribute: str):\n","        path_segments = object_path.split('.')\n","        module = __import__(object_path)\n","        for segment in path_segments[1:]:\n","            module = getattr(module, segment)\n","        return getattr(module, object_attribute)\n","\n","\n","class DatasetUtils:\n","\n","    @staticmethod\n","    def shuffle_dataset(dataset_holder: DatasetHolder):\n","        new_source_encodings, new_target_encodings = (\n","            DatasetUtils.shuffle_lists(\n","                dataset_holder.get_source_encodings(),\n","                dataset_holder.get_target_encodings()\n","            )\n","        )\n","        dataset_holder.set_source_encodings(new_source_encodings)\n","        dataset_holder.set_target_encodings(new_target_encodings)\n","        return dataset_holder\n","\n","    @staticmethod\n","    def shuffle_training_dataset(dataset_holder: DatasetHolder):\n","        new_source_encodings, new_target_encodings = (\n","            DatasetUtils.shuffle_lists(\n","                dataset_holder.get_source_encodings_train(),\n","                dataset_holder.get_target_encodings_train()\n","            )\n","        )\n","        dataset_holder.set_source_encodings(new_source_encodings)\n","        dataset_holder.set_target_encodings(new_target_encodings)\n","        return dataset_holder\n","\n","    @staticmethod\n","    def shuffle_test_dataset(dataset_holder: DatasetHolder):\n","        new_source_encodings, new_target_encodings = (\n","            DatasetUtils.shuffle_lists(\n","                dataset_holder.get_source_encodings_test(),\n","                dataset_holder.get_target_encodings_test()\n","            )\n","        )\n","        dataset_holder.set_source_encodings(new_source_encodings)\n","        dataset_holder.set_target_encodings(new_target_encodings)\n","        return dataset_holder\n","\n","    @staticmethod\n","    def shuffle_lists(source_list, target_list):\n","        assert len(source_list) == len(target_list)\n","        list_element_shuffle_indices = list(range(0, len(source_list)))\n","        random.shuffle(list_element_shuffle_indices)\n","        new_source_list = list()\n","        new_target_list = list()\n","        for i in list_element_shuffle_indices:\n","            new_source_list.append(source_list[i])\n","            new_target_list.append(target_list[i])\n","        assert (len(new_source_list) == len(new_target_list)\n","                == len(source_list) == len(target_list))\n","        return new_source_list, new_target_list\n","\n","    @staticmethod\n","    def create_dataset_segments(dataset_holder: DatasetHolder):\n","        split_with_even_target_distribution = False\n","        iteration = 1\n","        best_split_target_encodings = None\n","        best_split_source_encodings = None\n","        best_split_deviation_from_desired = 1\n","        segments = 20\n","        split_size = len(dataset_holder.get_target_encodings()) // segments\n","        train_size = split_size * (segments - 1)\n","        while not split_with_even_target_distribution and iteration \u003c= 100:\n","            segment_attempt_start = time.time()\n","            dataset_holder = DatasetUtils.shuffle_dataset(dataset_holder)\n","            target_encodings = dataset_holder.get_target_encodings()\n","            source_encodings = dataset_holder.get_source_encodings()\n","            train_set_target_enc = target_encodings[0:train_size]\n","            test_set_target_enc = target_encodings[train_size:]\n","            numpy_encodings = list()\n","            for encoding in train_set_target_enc:\n","                numpy_encodings.append(encoding.flatten().numpy())\n","            train_set_target_enc_cts = np.bincount(\n","                np.concatenate([\n","                    np.concatenate(numpy_encodings),\n","                    np.arange(0, 170)\n","                ])\n","            )\n","            numpy_encodings = list()\n","            for encoding in test_set_target_enc:\n","                numpy_encodings.append(encoding.flatten().numpy())\n","            test_set_target_enc_cts = np.bincount(\n","                np.concatenate([\n","                    np.concatenate(numpy_encodings),\n","                    np.arange(0, 170)\n","                ])\n","            )\n","            # terms with probability ~ 1%\n","            total_5 = train_set_target_enc_cts[5] + test_set_target_enc_cts[5]\n","            total_40 = train_set_target_enc_cts[40] + test_set_target_enc_cts[40]\n","            total_42 = train_set_target_enc_cts[42] + test_set_target_enc_cts[42]\n","            # top 3 terms\n","            total_7 = train_set_target_enc_cts[7] + test_set_target_enc_cts[7]\n","            total_15 = train_set_target_enc_cts[15] + test_set_target_enc_cts[15]\n","            total_12 = train_set_target_enc_cts[12] + test_set_target_enc_cts[12]\n","            train_dist_goal = (segments - 1)/segments\n","            test_dist_goal = (1 / segments)\n","            deviation_from_desired = (\n","                    np.abs(((segments - 2)/segments) - (train_set_target_enc_cts[5] / total_5)) +\n","                    np.abs(train_dist_goal - (train_set_target_enc_cts[40] / total_40)) +\n","                    np.abs(train_dist_goal - (train_set_target_enc_cts[42] / total_42)) +\n","                    np.abs(train_dist_goal - (train_set_target_enc_cts[7] / total_7)) +\n","                    np.abs(train_dist_goal - (train_set_target_enc_cts[15] / total_15)) +\n","                    np.abs(train_dist_goal - (train_set_target_enc_cts[12] / total_12)) +\n","                    np.abs(test_dist_goal - (test_set_target_enc_cts[5] / total_5)) +\n","                    np.abs(test_dist_goal - (test_set_target_enc_cts[40] / total_40)) +\n","                    np.abs(test_dist_goal - (test_set_target_enc_cts[42] / total_42)) +\n","                    np.abs(test_dist_goal - (test_set_target_enc_cts[7] / total_7)) +\n","                    np.abs(test_dist_goal - (test_set_target_enc_cts[15] / total_15)) +\n","                    np.abs(test_dist_goal - (test_set_target_enc_cts[12] / total_12))\n","            )\n","            if deviation_from_desired \u003c= 12 * 0.0001:\n","                split_with_even_target_distribution = True\n","                best_split_target_encodings = target_encodings\n","                best_split_source_encodings = source_encodings\n","                print(f\"Found dataset split within tolerance for deviation from uniform distribution over characters\")\n","            if deviation_from_desired \u003c best_split_deviation_from_desired:\n","                best_split_target_encodings = target_encodings\n","                best_split_source_encodings = source_encodings\n","                best_split_deviation_from_desired = deviation_from_desired\n","            segment_attempt_end = time.time()\n","            print(f\"Completed data split attempt. \"\n","                  f\"iteration:{iteration} \"\n","                  f\"best_split_deviation_from_desired:{best_split_deviation_from_desired} \"\n","                  f\"time_to_complete_attempt:{segment_attempt_end-segment_attempt_start}\")\n","            iteration = iteration + 1\n","        best_split_source_encodings_train = best_split_source_encodings[0:train_size]\n","        best_split_target_encodings_train = best_split_target_encodings[0:train_size]\n","        assert len(best_split_source_encodings_train) == len(best_split_target_encodings_train)\n","        train_split_encoding_length_sum_and_encoding_index_pairs = list()\n","        for i in range(0, len(best_split_source_encodings_train)):\n","            train_split_encoding_length_sum_and_encoding_index_pairs.append(\n","                list([\n","                    best_split_source_encodings_train[i].shape[0] + best_split_target_encodings_train[i].shape[0],\n","                    np.abs(best_split_source_encodings_train[i].shape[0] - best_split_target_encodings_train[i].shape[0]),\n","                    i\n","                ])\n","            )\n","        train_split_encoding_length_sum_and_encoding_index_pairs = sorted(\n","            train_split_encoding_length_sum_and_encoding_index_pairs,\n","            key=lambda pair: (pair[0], pair[1])\n","        )\n","        train_source_encs_length_sorted = list()\n","        train_target_encs_length_sorted = list()\n","        for encoding_length_sum_and_encoding_index_pair in train_split_encoding_length_sum_and_encoding_index_pairs:\n","            train_source_encs_length_sorted.append(best_split_source_encodings_train[encoding_length_sum_and_encoding_index_pair[2]])\n","            train_target_encs_length_sorted.append(best_split_target_encodings_train[encoding_length_sum_and_encoding_index_pair[2]])\n","        best_split_source_encodings_test = best_split_source_encodings[train_size:]\n","        best_split_target_encodings_test = best_split_target_encodings[train_size:]\n","        assert len(best_split_source_encodings_test) == len(best_split_target_encodings_test)\n","        test_split_encoding_length_sum_and_encoding_index_pairs = list()\n","        for i in range(0, len(best_split_source_encodings_test)):\n","            test_split_encoding_length_sum_and_encoding_index_pairs.append(\n","                list([\n","                    best_split_source_encodings_test[i].shape[0] + best_split_target_encodings_test[i].shape[0],\n","                    np.abs(best_split_source_encodings_test[i].shape[0] - best_split_target_encodings_test[i].shape[0]),\n","                    i\n","                ])\n","            )\n","        test_split_encoding_length_sum_and_encoding_index_pairs = sorted(\n","            test_split_encoding_length_sum_and_encoding_index_pairs,\n","            key=lambda pair: (pair[0], pair[1])\n","        )\n","        test_source_encs_length_sorted = list()\n","        test_target_encs_length_sorted = list()\n","        for encoding_length_sum_and_encoding_index_pair in test_split_encoding_length_sum_and_encoding_index_pairs:\n","            test_source_encs_length_sorted.append(best_split_source_encodings_test[encoding_length_sum_and_encoding_index_pair[2]])\n","            test_target_encs_length_sorted.append(best_split_target_encodings_test[encoding_length_sum_and_encoding_index_pair[2]])\n","        dataset_holder.set_source_encodings(best_split_source_encodings)\n","        dataset_holder.set_target_encodings(best_split_target_encodings)\n","        dataset_holder.set_source_encodings_train(train_source_encs_length_sorted)\n","        dataset_holder.set_target_encodings_train(train_target_encs_length_sorted)\n","        dataset_holder.set_source_encodings_test(test_source_encs_length_sorted)\n","        dataset_holder.set_target_encodings_test(test_target_encs_length_sorted)\n","        return dataset_holder\n","\n","    # use a dedicated padding token to pad batches as in Xue 2021 - ByT5 - Sec 3.1\n","    @staticmethod\n","    def prepare_batches(\n","            source_encodings,\n","            target_encodings,\n","            source_vocab,\n","            target_vocab,\n","            batch_size_limit: int,\n","            element_difference_limit: int,\n","            padding_value):\n","        assert len(source_encodings) == len(target_encodings)\n","        total_elements = len(source_encodings)\n","        source_encodings_batches = list()\n","        target_encodings_batches = list()\n","        source_encodings_tensors = list()\n","        target_encodings_tensors = list()\n","        encodings_index = 0\n","        while encodings_index \u003c total_elements - 1:\n","            batch_size = 0\n","            batch_end_reached = False\n","            min_source_enc_len = source_encodings[encodings_index+batch_size].shape[0]\n","            max_source_enc_len = source_encodings[encodings_index+batch_size].shape[0]\n","            min_target_enc_len = target_encodings[encodings_index+batch_size].shape[0]\n","            max_target_enc_len = target_encodings[encodings_index+batch_size].shape[0]\n","            while not batch_end_reached:\n","                if (max(abs(source_encodings[encodings_index+batch_size].shape[0] - min_source_enc_len),\n","                        abs(source_encodings[encodings_index+batch_size].shape[0] - max_source_enc_len)) \u003e element_difference_limit\n","                        or max(abs(target_encodings[encodings_index+batch_size].shape[0] - min_target_enc_len),\n","                               abs(target_encodings[encodings_index+batch_size].shape[0] - max_target_enc_len)) \u003e element_difference_limit):\n","                    batch_end_reached = True\n","                if batch_size == batch_size_limit - 1:\n","                    batch_end_reached = True\n","                if encodings_index + batch_size + 1 \u003c total_elements:\n","                    batch_size = batch_size + 1\n","                else:\n","                    batch_end_reached = True\n","            max_src_len_for_batch = 0\n","            max_tgt_len_for_batch = 0\n","            for batch_index in range(0, batch_size):\n","                if len(source_encodings[encodings_index+batch_index]) \u003e max_src_len_for_batch:\n","                    max_src_len_for_batch = len(source_encodings[encodings_index+batch_index])\n","                if len(target_encodings[encodings_index+batch_index]) \u003e max_tgt_len_for_batch:\n","                    max_tgt_len_for_batch = len(target_encodings[encodings_index+batch_index])\n","            for batch_index in range(0, batch_size):\n","                source_encoding = source_encodings[encodings_index]\n","                target_encoding = target_encodings[encodings_index]\n","                source_encodings_tensors.append(\n","                    torch.nn.functional.pad(\n","                        source_encoding,\n","                        (0, max_src_len_for_batch - len(source_encoding)),\n","                        value=source_vocab.index(padding_value)\n","                    )\n","                )\n","                target_encodings_tensors.append(\n","                    torch.nn.functional.pad(\n","                        target_encoding,\n","                        (0, max_tgt_len_for_batch - len(target_encoding)),\n","                        value=target_vocab.index(padding_value)\n","                    )\n","                )\n","                encodings_index = encodings_index + 1\n","            if batch_size \u003e 0:\n","                source_batch = torch.stack(source_encodings_tensors)\n","                target_batch = torch.stack(target_encodings_tensors)\n","                source_encodings_batches.append(source_batch)\n","                target_encodings_batches.append(target_batch)\n","            source_encodings_tensors = list()\n","            target_encodings_tensors = list()\n","        target_encodings_batches_with_index = list()\n","        for i in range(0, len(target_encodings_batches)):\n","            target_encodings_batches_with_index.append(list([target_encodings_batches[i], i]))\n","        assert len(target_encodings_batches_with_index) == len(target_encodings_batches)\n","        target_encodings_batches_with_index_sorted = sorted(\n","            target_encodings_batches_with_index,\n","            key=lambda batch_pair: (-batch_pair[0].shape[0], -batch_pair[0].shape[1])\n","        )\n","        source_encodings_batches_sorted = list()\n","        target_encodings_batches_sorted = list()\n","        for i in range(0, len(target_encodings_batches_with_index_sorted)):\n","            source_encodings_batches_sorted.append(\n","                source_encodings_batches[target_encodings_batches_with_index_sorted[i][1]]\n","            )\n","            target_encodings_batches_sorted.append(\n","                target_encodings_batches[target_encodings_batches_with_index_sorted[i][1]]\n","            )\n","        del source_encodings_tensors\n","        del target_encodings_tensors\n","        del source_encodings_batches\n","        del target_encodings_batches\n","        del target_encodings_batches_with_index_sorted\n","        return source_encodings_batches_sorted, target_encodings_batches_sorted\n","\n","    @staticmethod\n","    def prepare_training_batches(\n","            dataset_holder: DatasetHolder,\n","            batch_size_limit: int,\n","            element_difference_limit: int):\n","        source_encodings_batches, target_encodings_batches = DatasetUtils.prepare_batches(\n","            dataset_holder.get_source_encodings_train(),\n","            dataset_holder.get_target_encodings_train(),\n","            dataset_holder.get_source_vocab(),\n","            dataset_holder.get_target_vocab(),\n","            batch_size_limit,\n","            element_difference_limit,\n","            dataset_holder.get_padding_vocabulary_type()\n","        )\n","\n","        source_vocab_counts = {}\n","        for source_encoding_batch in source_encodings_batches:\n","            for source_encoding in source_encoding_batch:\n","                for character in source_encoding:\n","                    if character.item() not in source_vocab_counts:\n","                        source_vocab_counts[character.item()] = 0\n","                    source_vocab_counts[character.item()] = source_vocab_counts[character.item()] + 1\n","        target_vocab_counts = {}\n","        for target_vocab_batch in target_encodings_batches:\n","            for target_encoding in target_vocab_batch:\n","                for character in target_encoding:\n","                    if character.item() not in target_vocab_counts:\n","                        target_vocab_counts[character.item()] = 0\n","                    target_vocab_counts[character.item()] = target_vocab_counts[character.item()] + 1\n","        dataset_holder.set_source_vocab_counts(source_vocab_counts)\n","        dataset_holder.set_target_vocab_counts(target_vocab_counts)\n","        return source_encodings_batches, target_encodings_batches\n","\n","    @staticmethod\n","    def decode_target_tensor(dataset_holder: DatasetHolder, tensor_to_decode):\n","        vocab = dataset_holder.get_target_vocab_numpy()\n","        decoded_tensor = np.take(vocab, tensor_to_decode.detach().to(device=\"cpu\").flatten().numpy())\n","        return \"\".join(decoded_tensor.tolist())\n","\n","    @staticmethod\n","    def decode_source_tensor(dataset_holder: DatasetHolder, tensor_to_decode):\n","        vocab = dataset_holder.get_source_vocab_numpy()\n","        decoded_tensor = np.take(vocab, tensor_to_decode.detach().to(device=\"cpu\").flatten().numpy())\n","        return \"\".join(decoded_tensor.tolist())\n","\n","\n","# class name matches file name\n","class transformer_vaswani2017(torch.nn.Transformer):\n","\n","    def __init__(self,\n","                 model_hyperparameters):\n","        super().__init__(\n","            d_model=model_hyperparameters['d_model'],\n","            nhead=model_hyperparameters['nhead'],\n","            num_encoder_layers=model_hyperparameters['num_encoder_layers'],\n","            num_decoder_layers=model_hyperparameters['num_decoder_layers'],\n","            dim_feedforward=model_hyperparameters['dim_feedforward'],\n","            dropout=model_hyperparameters['dropout'],\n","            activation=model_hyperparameters['activation'],\n","            custom_encoder=model_hyperparameters['custom_encoder'],\n","            custom_decoder=model_hyperparameters['custom_decoder'],\n","            layer_norm_eps=model_hyperparameters['layer_norm_eps'],\n","            batch_first=model_hyperparameters['batch_first'],\n","            norm_first=model_hyperparameters['norm_first'],\n","            bias=model_hyperparameters['bias'],\n","            device=model_hyperparameters['device'],\n","            dtype=model_hyperparameters['dtype']\n","        )\n","        # add one for the end of sequence token\n","        self.max_src_seq_len = model_hyperparameters['max_src_seq_len'] + 1\n","        self.max_tgt_seq_len = model_hyperparameters['max_tgt_seq_len'] + 1\n","        self.src_embeddings = torch.nn.Embedding(\n","            model_hyperparameters['src_vocab_size'],\n","            model_hyperparameters['d_model']\n","        )\n","        self.tgt_embeddings = torch.nn.Embedding(\n","            model_hyperparameters['tgt_vocab_size'],\n","            model_hyperparameters['d_model']\n","        )\n","        self.src_pos_enc = torch.nn.Embedding(\n","            self.max_src_seq_len,\n","            model_hyperparameters['d_model']\n","        ).requires_grad_(False)\n","        self.tgt_pos_enc = torch.nn.Embedding(\n","            self.max_tgt_seq_len,\n","            model_hyperparameters['d_model']\n","        ).requires_grad_(False)\n","        self.linear_output_projection_1 = torch.nn.Linear(\n","            self.max_tgt_seq_len,\n","            1,\n","            bias=False\n","        )\n","        self.linear_output_projection_2 = torch.nn.Linear(\n","            model_hyperparameters['d_model'],\n","            model_hyperparameters['tgt_vocab_size'],\n","            bias=False\n","        )\n","        self.logsoftmax_output = torch.nn.LogSoftmax(dim=1)\n","        self.model_hyperparameters = model_hyperparameters\n","        self.tgt_mask_cache = {}\n","        for i in range(1, self.max_tgt_seq_len + 1):\n","            tgt_mask = self.generate_square_subsequent_mask(i)\n","            if is_remote_execution:\n","                self.tgt_mask_cache[i] = tgt_mask.to(device=\"cuda\")\n","            self.tgt_mask_cache[i] = tgt_mask\n","        self.indices_cache = {}\n","        for i in range(1, max([self.max_src_seq_len, self.max_tgt_seq_len]) + 1):\n","            indices = torch.tensor(np.arange(0, i), dtype=torch.long)\n","            if is_remote_execution:\n","                indices = indices.to(device=\"cuda\")\n","            self.indices_cache[i] = indices\n","\n","    def forward(self,\n","                src: torch.Tensor,\n","                tgt: torch.Tensor,\n","                src_mask: Optional[torch.Tensor] = None,\n","                tgt_mask: Optional[torch.Tensor] = None,\n","                memory_mask: Optional[torch.Tensor] = None,\n","                src_key_padding_mask: Optional[torch.Tensor] = None,\n","                tgt_key_padding_mask: Optional[torch.Tensor] = None,\n","                memory_key_padding_mask: Optional[torch.Tensor] = None,\n","                src_is_causal: Optional[bool] = None,\n","                tgt_is_causal: Optional[bool] = True,\n","                memory_is_causal: bool = False) -\u003e torch.Tensor:\n","        src_embedding_pos_enc = self.src_embeddings(src) + self.src_pos_enc(self.indices_cache[src.shape[1]])\n","        tgt_embedding_pos_enc = self.tgt_embeddings(tgt) + self.tgt_pos_enc(self.indices_cache[tgt.shape[1]])\n","        tgt_mask = self.tgt_mask_cache[tgt.shape[1]]\n","        transformer_output = super().forward(src_embedding_pos_enc, tgt_embedding_pos_enc, src_mask,\n","                                             tgt_mask, memory_mask, src_key_padding_mask,\n","                                             tgt_key_padding_mask, memory_key_padding_mask,\n","                                             src_is_causal, tgt_is_causal, memory_is_causal)\n","        transformer_output = torch.swapaxes(transformer_output, -1, -2)\n","        transformer_output = torch.nn.functional.pad(\n","            transformer_output,\n","            (0, self.max_tgt_seq_len - transformer_output.shape[2]),\n","            value=0\n","        )\n","        output = self.logsoftmax_output(\n","            self.linear_output_projection_2(\n","                torch.squeeze(\n","                    self.linear_output_projection_1(\n","                        transformer_output\n","                    ),\n","                    dim=2\n","                )\n","            )\n","        )\n","        del src_embedding_pos_enc\n","        del tgt_embedding_pos_enc\n","        del transformer_output\n","        return output\n","\n","\n","class model_trainer_kocmi2018():\n","\n","    def __init__(self,\n","                 trainer_hyperparameters=None,\n","                 model_parameter_directory=None,\n","                 trainer_parameter_directory=None,\n","                 runner_hyperparameters_name=None,\n","                 latest_param_filename_tag=None):\n","        self.trainer_hyperparameters = trainer_hyperparameters\n","        self.optimizer_name = self.trainer_hyperparameters['optimizer_name']\n","        self.initial_lr = self.trainer_hyperparameters['initial_lr']\n","        self.exp_decay = self.trainer_hyperparameters['exp_decay']\n","        self.lr_scheduler_name = self.trainer_hyperparameters['lr_scheduler_name']\n","        self.epochs = self.trainer_hyperparameters['epochs']\n","        self.epoch_starting_index = self.trainer_hyperparameters['epoch_starting_index']\n","        self.batch_size_limit = self.trainer_hyperparameters['batch_size_limit']\n","        self.element_difference_limit = self.trainer_hyperparameters['element_difference_limit']\n","        self.batch_starting_index = self.trainer_hyperparameters['batch_starting_index']\n","        self.model_parameter_directory = model_parameter_directory\n","        self.trainer_parameter_directory = trainer_parameter_directory\n","        self.runner_hyperparameters_name = runner_hyperparameters_name\n","        self.latest_param_filename_tag = latest_param_filename_tag\n","        self.dataset_holder = None\n","        self.model = None\n","        self.source_encoding_batches = None\n","        self.target_encoding_batches = None\n","        self.optimizer = None\n","        self.lr_scheduler = None\n","        self.loss_fcn = None\n","\n","    def init_trainer(self):\n","        self.source_encoding_batches, self.target_encoding_batches = (\n","            DatasetUtils.prepare_training_batches(\n","                self.dataset_holder,\n","                self.batch_size_limit,\n","                self.element_difference_limit\n","            )\n","        )\n","        # get_target_vocab_counts requires that training batches have been prepared\n","        # this ensures that vocab counts include padding and eos tokens\n","        loss_weights = list()\n","        for vocab_term in self.dataset_holder.get_target_vocab():\n","            loss_weights.append(\n","                1 / self.dataset_holder.get_target_vocab_counts()[\n","                    self.dataset_holder.get_target_vocab().index(vocab_term)\n","                ]\n","            )\n","        # set padding to have 0 weight\n","        loss_weights[\n","            self.dataset_holder.get_target_vocab().index(self.dataset_holder.get_padding_vocabulary_type())] = 0\n","        loss_weights = torch.tensor(loss_weights, dtype=torch.float)\n","        if is_remote_execution:\n","            torch.cuda.empty_cache()\n","            self.model.cuda()\n","            loss_weights = loss_weights.to(device=\"cuda\")\n","        self.loss_fcn = torch.nn.NLLLoss(weight=loss_weights)\n","        _optimizer_class_ = Utils.load_python_object('torch.optim', self.optimizer_name)\n","        self.optimizer = _optimizer_class_(self.model.parameters(), lr=self.initial_lr)\n","        _lr_scheduler_class_ = Utils.load_python_object('torch.optim.lr_scheduler', self.lr_scheduler_name)\n","        # constructor call assumes that the scheduler is the ExponentialLR scheduler\n","        self.lr_scheduler = _lr_scheduler_class_(self.optimizer, self.exp_decay)\n","        scheduler_parameter_filepath = self.trainer_parameter_directory + \"/\" + self.runner_hyperparameters_name + \"-\" + self.latest_param_filename_tag + \"-scheduler.params\"\n","        if os.path.exists(scheduler_parameter_filepath):\n","            scheduler_parameters = torch.load(scheduler_parameter_filepath)\n","            self.lr_scheduler.load_state_dict(scheduler_parameters)\n","        parameter_count = 0\n","        bytes_consumed = 0\n","        for parameter in self.model.parameters():\n","            if parameter.requires_grad:\n","                parameter_count = parameter_count + np.prod(parameter.data.shape)\n","                bytes_consumed = bytes_consumed + parameter.data.nbytes\n","        gb_consumed = bytes_consumed / 1024 / 1024 / 1024\n","        print(f\"Model trainer initialization complete.\"\n","              f\"Trainer will run on model with parameter count {parameter_count} \"\n","              f\"and parameter memory use {gb_consumed} GB\")\n","\n","    # pretraining is not used for monolingual english as described in Xue 2021 - ByT5 - Sec 3.1\n","    def run_trainer(self):\n","        assert self.epoch_starting_index \u003c self.epochs\n","        for i in range(self.epoch_starting_index, self.epochs):\n","            while self.lr_scheduler.state_dict()['last_epoch'] \u003e i:\n","                print(f\"Updating lr_scheduler: {self.lr_scheduler.state_dict()}\")\n","                self.lr_scheduler.step()\n","            epoch_start = time.time()\n","            print(f\"Beginning epoch {i+1} of {self.epochs} with scheduler {self.lr_scheduler.state_dict()}\")\n","            # if i \u003e 0:\n","            #     self.source_encoding_batches, self.target_encoding_batches = DatasetUtils.shuffle_lists(\n","            #         self.source_encoding_batches, self.target_encoding_batches\n","            #     )\n","            source_batches = None\n","            target_batches = None\n","            if is_remote_execution:\n","                source_batches = list()\n","                target_batches = list()\n","                for batch in self.source_encoding_batches:\n","                    source_batches.append(batch.to(device=\"cuda\"))\n","                    del batch\n","                for batch in self.target_encoding_batches:\n","                    target_batches.append(batch.to(device=\"cuda\"))\n","                    del batch\n","                torch.cuda.empty_cache()\n","            else:\n","                source_batches = self.source_encoding_batches\n","                target_batches = self.target_encoding_batches\n","            assert len(source_batches) == len(target_batches)\n","            batch_ct = len(source_batches)\n","            batch_size = source_batches[0].shape[0]\n","            samples_passed = 0\n","            last_log = 0\n","            last_loss = 0\n","            note_step_prediction = False\n","            step_prediction_at_percentage_of_sample = 0\n","            total_batch_time = 0\n","            assert self.batch_starting_index \u003c batch_ct\n","            for j in range(self.batch_starting_index, batch_ct):\n","                batch_start = time.time()\n","                batch_sequence_length = target_batches[j].shape[1]\n","                step_prediction_step_number = int(batch_sequence_length * step_prediction_at_percentage_of_sample)\n","                print(f\"Starting batch.\")\n","                print(f\"epoch:{i+1}/{self.epochs} batch:{j+1}/{batch_ct} batch_size:{target_batches[j].shape[0]}\")\n","                for k in range(1, batch_sequence_length-1):\n","                    target_batch_slices = torch.tensor_split(target_batches[j], [k], dim=1)\n","                    self.model.zero_grad()\n","                    output_logits = self.model.forward(\n","                        source_batches[j],\n","                        target_batch_slices[0]\n","                    )\n","                    next_word_indices = target_batch_slices[1][:, 0]\n","                    last_loss = self.loss_fcn(output_logits, next_word_indices)\n","                    last_loss.backward()\n","                    self.optimizer.step()\n","                    if note_step_prediction and k == step_prediction_step_number:\n","                        note_step_prediction = False\n","                        full_sequence = DatasetUtils.decode_target_tensor(self.dataset_holder, target_batches[j][0])\n","                        prefix_sequence = DatasetUtils.decode_target_tensor(\n","                            self.dataset_holder,\n","                            target_batch_slices[0][0]\n","                        )\n","                        next_token = DatasetUtils.decode_target_tensor(\n","                            self.dataset_holder,\n","                            next_word_indices[0]\n","                        )\n","                        predicted_token = DatasetUtils.decode_target_tensor(\n","                            self.dataset_holder,\n","                            torch.argmax(output_logits[0])\n","                        )\n","                        print(f\"Next token prediction. step:{k}/{batch_sequence_length} \"\n","                              f\"batch:{j+1}/{batch_ct} epoch:{i+1}/{self.epochs}\")\n","                        print(f\"full seq: {full_sequence}\")\n","                        print(f\"pref seq: {prefix_sequence}\")\n","                        print(f\"next tok: {next_token.rjust(k, ' ')}\")\n","                        print(f\"pred tok: {predicted_token.rjust(k, ' ')}\")\n","                        del full_sequence\n","                        del prefix_sequence\n","                        del next_token\n","                        del predicted_token\n","                    del target_batch_slices\n","                    del output_logits\n","                    del next_word_indices\n","                    last_loss = last_loss.detach()\n","                    gc.collect()\n","                    if is_remote_execution:\n","                        torch.cuda.empty_cache()\n","                batch_end = time.time()\n","                batch_time = batch_end - batch_start\n","                total_batch_time = total_batch_time + batch_time\n","                print(f\"Completed batch.\")\n","                print(f\"epoch:{i+1}/{self.epochs} batch:{j+1}/{batch_ct} batch_size:{target_batches[j].shape[0]} loss:{last_loss} \"\n","                      f\"time_for_batch_instance:{batch_time} total_batch_time:{total_batch_time} running_batch_average:{total_batch_time/(j+1)}\")\n","                samples_passed = samples_passed + batch_size\n","                if samples_passed - last_log \u003e 100:\n","                    last_log = samples_passed\n","                    note_step_prediction = True\n","                    step_prediction_at_percentage_of_sample = random.random()\n","                    if is_remote_execution:\n","                        print(f\"Memory usage summary:\")\n","                        print(f\"{torch.cuda.memory_summary()}\")\n","                        torch.cuda.reset_max_memory_allocated()\n","                        torch.cuda.reset_max_memory_cached()\n","                        torch.cuda.reset_peak_memory_stats()\n","                    param_filename_tag = str(int(time.time()))\n","                    torch.save(\n","                        self.model.state_dict(),\n","                        self.model_parameter_directory + \"/\" + self.runner_hyperparameters_name + \"-\" + param_filename_tag + \"-model.params\"\n","                    )\n","                    torch.save(\n","                        self.lr_scheduler.state_dict(),\n","                        self.trainer_parameter_directory + \"/\" + self.runner_hyperparameters_name + \"-\" + param_filename_tag + \"-scheduler.params\"\n","                    )\n","                    torch.save(\n","                        f\"epoch:{i+1}/{self.epochs} batch:{j+1}/{batch_ct}\",\n","                        self.trainer_parameter_directory + \"/\" + self.runner_hyperparameters_name + \"-\" + param_filename_tag + \"-trainer.params\"\n","                    )\n","            del source_batches\n","            del target_batches\n","            gc.collect()\n","            if is_remote_execution:\n","                torch.cuda.empty_cache()\n","            self.lr_scheduler.step()\n","            epoch_end = time.time()\n","            print(f\"Completed epoch {i+1}/{self.epochs} in {(epoch_end - epoch_start) / 60 }m\")\n","            print(f\"epoch:{i+1}, batch:{j+1}/{batch_ct}, loss:{last_loss}\")\n","\n","    def get_dataset_holder(self):\n","        return self.dataset_holder\n","\n","    def set_dataset_holder(self, dataset_holder):\n","        self.dataset_holder = dataset_holder\n","\n","    def get_model(self):\n","        return self.model\n","\n","    def set_model(self, model):\n","        self.model = model\n","\n","\n","class Runner:\n","\n","    def __init__(self,\n","                 model_parameter_directory=root_filepath+\"resources/model_parameters\",\n","                 trainer_parameter_directory=root_filepath+\"resources/trainer_parameters\",\n","                 runner_hyperparameters_name=\"SETimesByT5Vaswani2017Kocmi2018_1\"):\n","        self.model_parameter_directory = model_parameter_directory\n","        self.trainer_parameter_directory = trainer_parameter_directory\n","        self.runner_hyperparameters_name = runner_hyperparameters_name\n","        self.runner_hyperparameters = SETimesByT5Vaswani2017Kocmi2018_1\n","        self.dataset_holder: DatasetHolder = None\n","        self.model = None\n","        self.trainer = None\n","        self.latest_param_filename_tag = None\n","        if 'latest_param_filename_tag' in self.runner_hyperparameters:\n","            self.latest_param_filename_tag = self.runner_hyperparameters['latest_param_filename_tag']\n","        print(f\"Initialized runner {runner_hyperparameters_name} with parameters {self.runner_hyperparameters}\")\n","\n","    def load_dataset(self):\n","        dataset_transformer_name = self.runner_hyperparameters.get('dataset_transformer_name')\n","        dataset_hyperparameters = self.runner_hyperparameters.get('dataset_transformer_hyperparameters')\n","        dataset_transformer = dataset_transformer_setimesbyt5(dataset_hyperparameters=dataset_hyperparameters)\n","        self.dataset_holder = dataset_transformer.read_dataset()\n","\n","    def load_model(self):\n","        model_hyperparameters = self.runner_hyperparameters.get('model_hyperparameters')\n","        model_hyperparameters['src_vocab_size'] = len(self.dataset_holder.get_source_vocab())\n","        model_hyperparameters['tgt_vocab_size'] = len(self.dataset_holder.get_target_vocab())\n","        model_hyperparameters['max_src_seq_len'] = self.dataset_holder.get_max_src_seq_obs()\n","        model_hyperparameters['max_tgt_seq_len'] = self.dataset_holder.get_max_tgt_seq_obs()\n","        model_parameter_filepath = self.model_parameter_directory + \"/\" + self.runner_hyperparameters_name + \"-\" + self.latest_param_filename_tag + \"-model.params\"\n","        self.model = transformer_vaswani2017(model_hyperparameters=model_hyperparameters)\n","        if os.path.exists(model_parameter_filepath):\n","            model_parameters = torch.load(model_parameter_filepath)\n","            self.model.load_state_dict(model_parameters)\n","\n","    def load_trainer(self):\n","        trainer_hyperparameters = self.runner_hyperparameters.get('trainer_hyperparameters')\n","        self.trainer = model_trainer_kocmi2018(\n","            trainer_hyperparameters=trainer_hyperparameters,\n","            model_parameter_directory=self.model_parameter_directory,\n","            trainer_parameter_directory=self.trainer_parameter_directory,\n","            runner_hyperparameters_name=self.runner_hyperparameters_name,\n","            latest_param_filename_tag=self.latest_param_filename_tag\n","        )\n","\n","    def run_trainer(self):\n","        self.trainer.set_dataset_holder(self.dataset_holder)\n","        self.trainer.set_model(self.model)\n","        self.trainer.init_trainer()\n","        self.trainer.run_trainer()\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"1qcv-CZAnpo1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Initialized runner SETimesByT5Vaswani2017Kocmi2018_1 with parameters {'dataset_transformer_name': 'dataset_transformer_setimesbyt5', 'model_name': 'transformer_vaswani2017', 'trainer_name': 'model_trainer_kocmi2018', 'latest_param_filename_tag': '1715672186', 'dataset_transformer_hyperparameters': {'sentence_length_min_percentile': 5, 'sentence_length_max_percentile': 95, 'parsed_dataset_filename': 'setimes_parsed-1715586974'}, 'model_hyperparameters': {'d_model': 256, 'nhead': 8, 'num_encoder_layers': 9, 'num_decoder_layers': 3, 'dim_feedforward': 1796, 'dropout': 0.1, 'activation': \u003cfunction relu at 0x7fcc0cb1e9e0\u003e, 'custom_encoder': None, 'custom_decoder': None, 'layer_norm_eps': 1e-05, 'batch_first': True, 'norm_first': False, 'bias': True, 'device': None, 'dtype': None}, 'trainer_hyperparameters': {'optimizer_name': 'Adam', 'lr_scheduler_name': 'ExponentialLR', 'initial_lr': 0.001, 'exp_decay': 0.5, 'epochs': 10, 'epoch_starting_index': 1, 'batch_size_limit': 250, 'element_difference_limit': 19, 'batch_starting_index': 0}}\n","Model trainer initialization complete.Trainer will run on model with parameter count 15086641 and parameter memory use 0.05620211735367775 GB\n","Beginning epoch 2 of 10 with scheduler {'gamma': 0.5, 'base_lrs': [0.001], 'last_epoch': 0, 'verbose': False, '_step_count': 1, '_get_lr_called_within_step': False, '_last_lr': [0.001]}\n","Starting batch.\n","epoch:2/10 batch:1/7698 batch_size:250\n","Completed batch.\n","epoch:2/10 batch:1/7698 batch_size:250 loss:4.167308330535889 time_for_batch_instance:296.93020272254944 total_batch_time:296.93020272254944 running_batch_average:296.93020272254944\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 656000 KiB |  22430 MiB |  19068 GiB |  19067 GiB |\n","|       from large pool | 198550 KiB |  21985 MiB |  19043 GiB |  19043 GiB |\n","|       from small pool | 457450 KiB |    480 MiB |     24 GiB |     24 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 656000 KiB |  22430 MiB |  19068 GiB |  19067 GiB |\n","|       from large pool | 198550 KiB |  21985 MiB |  19043 GiB |  19043 GiB |\n","|       from small pool | 457450 KiB |    480 MiB |     24 GiB |     24 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  22397 MiB |  19017 GiB |  19016 GiB |\n","|       from large pool | 189056 KiB |  21956 MiB |  18992 GiB |  18992 GiB |\n","|       from small pool | 453671 KiB |    477 MiB |     24 GiB |     24 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2416 MiB |  23474 MiB |   4514 GiB |   4512 GiB |\n","|       from large pool |   1966 MiB |  23010 MiB |   4511 GiB |   4509 GiB |\n","|       from small pool |    450 MiB |    484 MiB |      3 GiB |      3 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1775 MiB |   3158 MiB |   6178 GiB |   6176 GiB |\n","|       from large pool |   1772 MiB |   3155 MiB |   6150 GiB |   6148 GiB |\n","|       from small pool |      3 MiB |     22 MiB |     27 GiB |     27 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |  351825    |  335476    |\n","|       from large pool |      98    |     263    |  205473    |  205375    |\n","|       from small pool |   16251    |   16398    |  146352    |  130101    |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |  351825    |  335476    |\n","|       from large pool |      98    |     263    |  205473    |  205375    |\n","|       from small pool |   16251    |   16398    |  146352    |  130101    |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     240    |     334    |   20384    |   20144    |\n","|       from large pool |      15    |     102    |   18414    |   18399    |\n","|       from small pool |     225    |     242    |    1970    |    1745    |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      63    |     142    |  135193    |  135130    |\n","|       from large pool |      12    |      56    |   82339    |   82327    |\n","|       from small pool |      51    |     106    |   52854    |   52803    |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:2/7698 batch_size:250\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/cuda/memory.py:330: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/cuda/memory.py:356: FutureWarning: torch.cuda.reset_max_memory_cached now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Next token prediction. step:211/257 batch:2/7698 epoch:2/10\n","full seq: With ethnic tensions running high and the situation in BiH deteriorating, a move in that direction \"would put at risk the country's relative stability and the progress achieved so far\", the prominent Brussels-based advocacy group warned in a report.Ģġġġġġġġ\n","pref seq: With ethnic tensions running high and the situation in BiH deteriorating, a move in that direction \"would put at risk the country's relative stability and the progress achieved so far\", the prominent Brussels-ba\n","next tok:                                                                                                                                                                                                                   s\n","pred tok:                                                                                                                                                                                                                   )\n","Completed batch.\n","epoch:2/10 batch:2/7698 batch_size:250 loss:2.243262529373169 time_for_batch_instance:295.9378798007965 total_batch_time:592.868082523346 running_batch_average:296.434041261673\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 656000 KiB |  22430 MiB |  38135 GiB |  38134 GiB |\n","|       from large pool | 198550 KiB |  21985 MiB |  38086 GiB |  38086 GiB |\n","|       from small pool | 457450 KiB |    480 MiB |     48 GiB |     48 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 656000 KiB |  22430 MiB |  38135 GiB |  38134 GiB |\n","|       from large pool | 198550 KiB |  21985 MiB |  38086 GiB |  38086 GiB |\n","|       from small pool | 457450 KiB |    480 MiB |     48 GiB |     48 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  22397 MiB |  38033 GiB |  38032 GiB |\n","|       from large pool | 189056 KiB |  21956 MiB |  37984 GiB |  37984 GiB |\n","|       from small pool | 453671 KiB |    477 MiB |     48 GiB |     48 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2416 MiB |  23474 MiB |   9001 GiB |   8999 GiB |\n","|       from large pool |   1966 MiB |  23010 MiB |   8994 GiB |   8992 GiB |\n","|       from small pool |    450 MiB |    484 MiB |      7 GiB |      6 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1775 MiB |   3158 MiB |  12431 GiB |  12429 GiB |\n","|       from large pool |   1772 MiB |   3155 MiB |  12376 GiB |  12374 GiB |\n","|       from small pool |      3 MiB |     22 MiB |     54 GiB |     54 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |  687044    |  670695    |\n","|       from large pool |      98    |     263    |  410848    |  410750    |\n","|       from small pool |   16251    |   16398    |  276196    |  259945    |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |  687044    |  670695    |\n","|       from large pool |      98    |     263    |  410848    |  410750    |\n","|       from small pool |   16251    |   16398    |  276196    |  259945    |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     240    |     334    |   40242    |   40002    |\n","|       from large pool |      15    |     102    |   36535    |   36520    |\n","|       from small pool |     225    |     242    |    3707    |    3482    |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      63    |     142    |  269801    |  269738    |\n","|       from large pool |      12    |      56    |  164532    |  164520    |\n","|       from small pool |      51    |     106    |  105269    |  105218    |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:3/7698 batch_size:250\n","Next token prediction. step:242/257 batch:3/7698 epoch:2/10\n","full seq: The country's defence system already has a unit for special operations, Djukanovic noted, and the future army will be founded in co-ordination with the principles prescribed by Euro-Atlantic integration, taking into account its structural needs.Ģġġġġġġġġġġġ\n","pref seq: The country's defence system already has a unit for special operations, Djukanovic noted, and the future army will be founded in co-ordination with the principles prescribed by Euro-Atlantic integration, taking into account its structural nee\n","next tok:                                                                                                                                                                                                                                                  d\n","pred tok:                                                                                                                                                                                                                                                  Ģ\n","Completed batch.\n","epoch:2/10 batch:3/7698 batch_size:250 loss:1.9688199758529663 time_for_batch_instance:295.92853474617004 total_batch_time:888.796617269516 running_batch_average:296.2655390898387\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 656000 KiB |  22430 MiB |  57203 GiB |  57202 GiB |\n","|       from large pool | 198550 KiB |  21985 MiB |  57130 GiB |  57129 GiB |\n","|       from small pool | 457450 KiB |    480 MiB |     73 GiB |     72 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 656000 KiB |  22430 MiB |  57203 GiB |  57202 GiB |\n","|       from large pool | 198550 KiB |  21985 MiB |  57130 GiB |  57129 GiB |\n","|       from small pool | 457450 KiB |    480 MiB |     73 GiB |     72 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  22397 MiB |  57049 GiB |  57049 GiB |\n","|       from large pool | 189056 KiB |  21956 MiB |  56976 GiB |  56976 GiB |\n","|       from small pool | 453671 KiB |    477 MiB |     72 GiB |     72 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2416 MiB |  23474 MiB |  13470 GiB |  13468 GiB |\n","|       from large pool |   1966 MiB |  23010 MiB |  13459 GiB |  13457 GiB |\n","|       from small pool |    450 MiB |    484 MiB |     10 GiB |     10 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1775 MiB |   3158 MiB |  18656 GiB |  18655 GiB |\n","|       from large pool |   1772 MiB |   3155 MiB |  18574 GiB |  18573 GiB |\n","|       from small pool |      3 MiB |     22 MiB |     82 GiB |     82 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |    1022 K  |    1005 K  |\n","|       from large pool |      98    |     263    |     616 K  |     616 K  |\n","|       from small pool |   16251    |   16398    |     406 K  |     389 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |    1022 K  |    1005 K  |\n","|       from large pool |      98    |     263    |     616 K  |     616 K  |\n","|       from small pool |   16251    |   16398    |     406 K  |     389 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     240    |     334    |   60029    |   59789    |\n","|       from large pool |      15    |     102    |   54584    |   54569    |\n","|       from small pool |     225    |     242    |    5445    |    5220    |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      63    |     142    |  404184    |  404121    |\n","|       from large pool |      12    |      56    |  246497    |  246485    |\n","|       from small pool |      51    |     106    |  157687    |  157636    |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:4/7698 batch_size:250\n","Next token prediction. step:72/257 batch:4/7698 epoch:2/10\n","full seq: President Alfred Moisiu, meanwhile, is emphasising the positive, pointing to enhanced regional co-operation, Albania's contribution to the fight against international terrorism, the opening of the SAA negotiations, and the beatification of Mother Teresa.Ģġġ\n","pref seq: President Alfred Moisiu, meanwhile, is emphasising the positive, pointin\n","next tok:                                                                        g\n","pred tok:                                                                        ,\n","Completed batch.\n","epoch:2/10 batch:4/7698 batch_size:250 loss:1.353549838066101 time_for_batch_instance:295.929172039032 total_batch_time:1184.725789308548 running_batch_average:296.181447327137\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 656000 KiB |  22430 MiB |  76270 GiB |  76270 GiB |\n","|       from large pool | 198550 KiB |  21985 MiB |  76173 GiB |  76173 GiB |\n","|       from small pool | 457450 KiB |    480 MiB |     97 GiB |     96 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 656000 KiB |  22430 MiB |  76270 GiB |  76270 GiB |\n","|       from large pool | 198550 KiB |  21985 MiB |  76173 GiB |  76173 GiB |\n","|       from small pool | 457450 KiB |    480 MiB |     97 GiB |     96 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  22397 MiB |  76066 GiB |  76065 GiB |\n","|       from large pool | 189056 KiB |  21956 MiB |  75969 GiB |  75968 GiB |\n","|       from small pool | 453671 KiB |    477 MiB |     97 GiB |     96 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2416 MiB |  23474 MiB |  17960 GiB |  17957 GiB |\n","|       from large pool |   1966 MiB |  23010 MiB |  17946 GiB |  17944 GiB |\n","|       from small pool |    450 MiB |    484 MiB |     14 GiB |     13 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1775 MiB |   3158 MiB |  24894 GiB |  24892 GiB |\n","|       from large pool |   1772 MiB |   3155 MiB |  24785 GiB |  24783 GiB |\n","|       from small pool |      3 MiB |     22 MiB |    109 GiB |    109 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |    1357 K  |    1341 K  |\n","|       from large pool |      98    |     263    |     821 K  |     821 K  |\n","|       from small pool |   16251    |   16398    |     535 K  |     519 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |    1357 K  |    1341 K  |\n","|       from large pool |      98    |     263    |     821 K  |     821 K  |\n","|       from small pool |   16251    |   16398    |     535 K  |     519 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     240    |     334    |   79904    |   79664    |\n","|       from large pool |      15    |     102    |   72722    |   72707    |\n","|       from small pool |     225    |     242    |    7182    |    6957    |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      63    |     142    |  538598    |  538535    |\n","|       from large pool |      12    |      56    |  328518    |  328506    |\n","|       from small pool |      51    |     106    |  210080    |  210029    |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:5/7698 batch_size:250\n","Next token prediction. step:190/257 batch:5/7698 epoch:2/10\n","full seq: Meanwhile, the World Bank adopted a new four-year strategy for co-operation with Turkey that envisions $4.45 billion in funding to boost competitiveness and employment, promote gender equality and public services and further deepen stable development.Ģġġġġġ\n","pref seq: Meanwhile, the World Bank adopted a new four-year strategy for co-operation with Turkey that envisions $4.45 billion in funding to boost competitiveness and employment, promote gender equali\n","next tok:                                                                                                                                                                                              t\n","pred tok:                                                                                                                                                                                              ,\n","Completed batch.\n","epoch:2/10 batch:5/7698 batch_size:250 loss:1.7901521921157837 time_for_batch_instance:295.8253321647644 total_batch_time:1480.5511214733124 running_batch_average:296.1102242946625\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 656000 KiB |  22430 MiB |  95338 GiB |  95337 GiB |\n","|       from large pool | 198550 KiB |  21985 MiB |  95217 GiB |  95216 GiB |\n","|       from small pool | 457450 KiB |    480 MiB |    121 GiB |    121 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 656000 KiB |  22430 MiB |  95338 GiB |  95337 GiB |\n","|       from large pool | 198550 KiB |  21985 MiB |  95217 GiB |  95216 GiB |\n","|       from small pool | 457450 KiB |    480 MiB |    121 GiB |    121 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  22397 MiB |  95082 GiB |  95082 GiB |\n","|       from large pool | 189056 KiB |  21956 MiB |  94961 GiB |  94961 GiB |\n","|       from small pool | 453671 KiB |    477 MiB |    121 GiB |    120 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2416 MiB |  23474 MiB |  22428 GiB |  22426 GiB |\n","|       from large pool |   1966 MiB |  23010 MiB |  22411 GiB |  22409 GiB |\n","|       from small pool |    450 MiB |    484 MiB |     17 GiB |     16 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1775 MiB |   3158 MiB |  31104 GiB |  31102 GiB |\n","|       from large pool |   1772 MiB |   3155 MiB |  30968 GiB |  30966 GiB |\n","|       from small pool |      3 MiB |     22 MiB |    136 GiB |    136 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |    1692 K  |    1676 K  |\n","|       from large pool |      98    |     263    |    1026 K  |    1026 K  |\n","|       from small pool |   16251    |   16398    |     665 K  |     649 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |    1692 K  |    1676 K  |\n","|       from large pool |      98    |     263    |    1026 K  |    1026 K  |\n","|       from small pool |   16251    |   16398    |     665 K  |     649 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     240    |     334    |   99691    |   99451    |\n","|       from large pool |      15    |     102    |   90771    |   90756    |\n","|       from small pool |     225    |     242    |    8920    |    8695    |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      63    |     142    |  672776    |  672713    |\n","|       from large pool |      12    |      56    |  410278    |  410266    |\n","|       from small pool |      51    |     106    |  262498    |  262447    |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:6/7698 batch_size:250\n","Next token prediction. step:185/223 batch:6/7698 epoch:2/10\n","full seq: According to Bulgarian media reports, the minister was accompanied by Delyan Dakov, who will serve as Sofia's special representative in Libya's rebel capital and will maintain regular contacts with the NTC.Ģġġġġġġġġġġġġġġġġ\n","pref seq: According to Bulgarian media reports, the minister was accompanied by Delyan Dakov, who will serve as Sofia's special representative in Libya's rebel capital and will maintain regular c\n","next tok:                                                                                                                                                                                         o\n","pred tok:                                                                                                                                                                                         -\n","Completed batch.\n","epoch:2/10 batch:6/7698 batch_size:250 loss:0.6997292041778564 time_for_batch_instance:248.52051997184753 total_batch_time:1729.07164144516 running_batch_average:288.17860690752667\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 657091 KiB |  19155 MiB | 109465 GiB | 109465 GiB |\n","|       from large pool | 199641 KiB |  18712 MiB | 109323 GiB | 109323 GiB |\n","|       from small pool | 457450 KiB |    479 MiB |    142 GiB |    141 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 657091 KiB |  19155 MiB | 109465 GiB | 109465 GiB |\n","|       from large pool | 199641 KiB |  18712 MiB | 109323 GiB | 109323 GiB |\n","|       from small pool | 457450 KiB |    479 MiB |    142 GiB |    141 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  19130 MiB | 109195 GiB | 109194 GiB |\n","|       from large pool | 189056 KiB |  18691 MiB | 109052 GiB | 109052 GiB |\n","|       from small pool | 453671 KiB |    475 MiB |    142 GiB |    141 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2576 MiB |  20026 MiB |  25689 GiB |  25686 GiB |\n","|       from large pool |   2126 MiB |  19562 MiB |  25668 GiB |  25666 GiB |\n","|       from small pool |    450 MiB |    482 MiB |     20 GiB |     20 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1934 MiB |   3549 MiB |  35502 GiB |  35500 GiB |\n","|       from large pool |   1931 MiB |   3544 MiB |  35343 GiB |  35341 GiB |\n","|       from small pool |      3 MiB |     18 MiB |    159 GiB |    159 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |    1983 K  |    1966 K  |\n","|       from large pool |      98    |     263    |    1204 K  |    1204 K  |\n","|       from small pool |   16251    |   16398    |     778 K  |     762 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |    1983 K  |    1966 K  |\n","|       from large pool |      98    |     263    |    1204 K  |    1204 K  |\n","|       from small pool |   16251    |   16398    |     778 K  |     762 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     245    |     333    |  117203    |  116958    |\n","|       from large pool |      20    |     101    |  106643    |  106623    |\n","|       from small pool |     225    |     241    |   10560    |   10335    |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      67    |     155    |     829 K  |     829 K  |\n","|       from large pool |      16    |      68    |     521 K  |     521 K  |\n","|       from small pool |      51    |     103    |     308 K  |     307 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:7/7698 batch_size:250\n","Next token prediction. step:150/222 batch:7/7698 epoch:2/10\n","full seq: The Islamic Community of Kosovo has issued a statement distancing itself from the protests by Bashkohu and other groups, announcing instead that it is working with the mayor to find a possible location.Ģġġġġġġġġġġġġġġġġġġġ\n","pref seq: The Islamic Community of Kosovo has issued a statement distancing itself from the protests by Bashkohu and other groups, announcing instead that it is\n","next tok:                                                                                                                                                       \n","pred tok:                                                                                                                                                      ,\n","Completed batch.\n","epoch:2/10 batch:7/7698 batch_size:250 loss:2.0104687213897705 time_for_batch_instance:239.73696279525757 total_batch_time:1968.8086042404175 running_batch_average:281.25837203434537\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 653777 KiB |  18946 MiB | 123371 GiB | 123370 GiB |\n","|       from large pool | 196327 KiB |  18503 MiB | 123208 GiB | 123207 GiB |\n","|       from small pool | 457450 KiB |    479 MiB |    162 GiB |    162 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 653777 KiB |  18946 MiB | 123371 GiB | 123370 GiB |\n","|       from large pool | 196327 KiB |  18503 MiB | 123208 GiB | 123207 GiB |\n","|       from small pool | 457450 KiB |    479 MiB |    162 GiB |    162 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  18929 MiB | 123092 GiB | 123092 GiB |\n","|       from large pool | 189056 KiB |  18490 MiB | 122929 GiB | 122929 GiB |\n","|       from small pool | 453671 KiB |    475 MiB |    162 GiB |    162 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   9594 MiB |  19826 MiB |  27374 GiB |  27365 GiB |\n","|       from large pool |   9142 MiB |  19358 MiB |  27350 GiB |  27341 GiB |\n","|       from small pool |    452 MiB |    482 MiB |     23 GiB |     23 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   8955 MiB |   9323 MiB |  43941 GiB |  43932 GiB |\n","|       from large pool |   8950 MiB |   9318 MiB |  43758 GiB |  43750 GiB |\n","|       from small pool |      5 MiB |     16 MiB |    182 GiB |    182 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |    2272 K  |    2255 K  |\n","|       from large pool |      98    |     263    |    1380 K  |    1380 K  |\n","|       from small pool |   16251    |   16398    |     891 K  |     875 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |    2272 K  |    2255 K  |\n","|       from large pool |      98    |     263    |    1380 K  |    1380 K  |\n","|       from small pool |   16251    |   16398    |     891 K  |     875 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     260    |     326    |  128868    |  128608    |\n","|       from large pool |      34    |      92    |  116594    |  116560    |\n","|       from small pool |     226    |     241    |   12274    |   12048    |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      91    |     156    |    1003 K  |    1003 K  |\n","|       from large pool |      30    |      69    |     651 K  |     651 K  |\n","|       from small pool |      61    |     103    |     351 K  |     351 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:8/7698 batch_size:250\n","Next token prediction. step:202/215 batch:8/7698 epoch:2/10\n","full seq: The National Bank of Macedonia managed to slow credit growth and contain the loss of reserves by tightening the bank liquidity and reserve requirements and by raising its policy rate from 7% to 9%.Ģġġġġġġġġġġġġġġġġġ\n","pref seq: The National Bank of Macedonia managed to slow credit growth and contain the loss of reserves by tightening the bank liquidity and reserve requirements and by raising its policy rate from 7% to 9%.Ģġġġġ\n","next tok:                                                                                                                                                                                                          ġ\n","pred tok:                                                                                                                                                                                                          Ģ\n","Completed batch.\n","epoch:2/10 batch:8/7698 batch_size:250 loss:0.8640038967132568 time_for_batch_instance:237.59442234039307 total_batch_time:2206.4030265808105 running_batch_average:275.8003783226013\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 659162 KiB |  18366 MiB | 136448 GiB | 136447 GiB |\n","|       from large pool | 201712 KiB |  17924 MiB | 136265 GiB | 136265 GiB |\n","|       from small pool | 457450 KiB |    479 MiB |    182 GiB |    182 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 659162 KiB |  18366 MiB | 136448 GiB | 136447 GiB |\n","|       from large pool | 201712 KiB |  17924 MiB | 136265 GiB | 136265 GiB |\n","|       from small pool | 457450 KiB |    479 MiB |    182 GiB |    182 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  18350 MiB | 136152 GiB | 136152 GiB |\n","|       from large pool | 189056 KiB |  17911 MiB | 135969 GiB | 135969 GiB |\n","|       from small pool | 453671 KiB |    475 MiB |    182 GiB |    182 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   4924 MiB |  19240 MiB |  29877 GiB |  29872 GiB |\n","|       from large pool |   4474 MiB |  18774 MiB |  29850 GiB |  29846 GiB |\n","|       from small pool |    450 MiB |    482 MiB |     27 GiB |     26 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   4280 MiB |   8956 MiB |  48414 GiB |  48409 GiB |\n","|       from large pool |   4277 MiB |   8950 MiB |  48209 GiB |  48205 GiB |\n","|       from small pool |      3 MiB |     17 MiB |    204 GiB |    204 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |    2552 K  |    2535 K  |\n","|       from large pool |      98    |     263    |    1551 K  |    1551 K  |\n","|       from small pool |   16251    |   16398    |    1000 K  |     984 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |    2552 K  |    2535 K  |\n","|       from large pool |      98    |     263    |    1551 K  |    1551 K  |\n","|       from small pool |   16251    |   16398    |    1000 K  |     984 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     250    |     335    |  143981    |  143731    |\n","|       from large pool |      25    |     102    |  130093    |  130068    |\n","|       from small pool |     225    |     241    |   13888    |   13663    |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      77    |     159    |    1159 K  |    1159 K  |\n","|       from large pool |      20    |      72    |     763 K  |     762 K  |\n","|       from small pool |      57    |     103    |     396 K  |     396 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:9/7698 batch_size:250\n","Next token prediction. step:85/215 batch:9/7698 epoch:2/10\n","full seq: \"We have full knowledge of what is going on in our barracks and there is no way that a Hague suspect could be currently located in a Serbia-Montenegro military complex,\" Davinic was quoted as saying.Ģġġġġġġġġġġġġġġġ\n","pref seq: \"We have full knowledge of what is going on in our barracks and there is no way that \n","next tok:                                                                                     a\n","pred tok:                                                                                     P\n","Completed batch.\n","epoch:2/10 batch:9/7698 batch_size:250 loss:1.352391004562378 time_for_batch_instance:237.5349473953247 total_batch_time:2443.9379739761353 running_batch_average:271.54866377512616\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 658262 KiB |  18368 MiB | 149526 GiB | 149525 GiB |\n","|       from large pool | 200812 KiB |  17926 MiB | 149323 GiB | 149322 GiB |\n","|       from small pool | 457450 KiB |    479 MiB |    202 GiB |    202 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 658262 KiB |  18368 MiB | 149526 GiB | 149525 GiB |\n","|       from large pool | 200812 KiB |  17926 MiB | 149323 GiB | 149322 GiB |\n","|       from small pool | 457450 KiB |    479 MiB |    202 GiB |    202 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  18350 MiB | 149212 GiB | 149212 GiB |\n","|       from large pool | 189056 KiB |  17911 MiB | 149009 GiB | 149009 GiB |\n","|       from small pool | 453671 KiB |    475 MiB |    202 GiB |    202 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   4854 MiB |  19238 MiB |  32374 GiB |  32370 GiB |\n","|       from large pool |   4404 MiB |  18772 MiB |  32344 GiB |  32340 GiB |\n","|       from small pool |    450 MiB |    482 MiB |     30 GiB |     29 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   4211 MiB |   5003 MiB |  52798 GiB |  52793 GiB |\n","|       from large pool |   4207 MiB |   4997 MiB |  52571 GiB |  52567 GiB |\n","|       from small pool |      3 MiB |     17 MiB |    226 GiB |    226 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |    2832 K  |    2815 K  |\n","|       from large pool |      98    |     263    |    1722 K  |    1722 K  |\n","|       from small pool |   16251    |   16398    |    1109 K  |    1093 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |    2832 K  |    2815 K  |\n","|       from large pool |      98    |     263    |    1722 K  |    1722 K  |\n","|       from small pool |   16251    |   16398    |    1109 K  |    1093 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     249    |     332    |  159184    |  158935    |\n","|       from large pool |      24    |      99    |  143682    |  143658    |\n","|       from small pool |     225    |     241    |   15502    |   15277    |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      76    |     161    |    1312 K  |    1312 K  |\n","|       from large pool |      19    |      74    |     871 K  |     871 K  |\n","|       from small pool |      57    |     102    |     440 K  |     440 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:10/7698 batch_size:250\n","Next token prediction. step:149/215 batch:10/7698 epoch:2/10\n","full seq: The 2005 inflation rate in Montenegro, which was predicted to be the lowest in the region, was reported by the Montenegrin Statistics Bureau last month to be 1.8 per cent -- even lower than expected.Ģġġġġġġġġġġġġġġġ\n","pref seq: The 2005 inflation rate in Montenegro, which was predicted to be the lowest in the region, was reported by the Montenegrin Statistics Bureau last mon\n","next tok:                                                                                                                                                     t\n","pred tok:                                                                                                                                                     ,\n","Completed batch.\n","epoch:2/10 batch:10/7698 batch_size:250 loss:0.673570990562439 time_for_batch_instance:237.43373918533325 total_batch_time:2681.3717131614685 running_batch_average:268.13717131614686\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 658262 KiB |  18368 MiB | 162603 GiB | 162603 GiB |\n","|       from large pool | 200812 KiB |  17926 MiB | 162380 GiB | 162380 GiB |\n","|       from small pool | 457450 KiB |    479 MiB |    222 GiB |    222 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 658262 KiB |  18368 MiB | 162603 GiB | 162603 GiB |\n","|       from large pool | 200812 KiB |  17926 MiB | 162380 GiB | 162380 GiB |\n","|       from small pool | 457450 KiB |    479 MiB |    222 GiB |    222 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  18350 MiB | 162272 GiB | 162272 GiB |\n","|       from large pool | 189056 KiB |  17911 MiB | 162049 GiB | 162049 GiB |\n","|       from small pool | 453671 KiB |    475 MiB |    222 GiB |    222 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   4854 MiB |  19238 MiB |  34870 GiB |  34865 GiB |\n","|       from large pool |   4404 MiB |  18772 MiB |  34837 GiB |  34832 GiB |\n","|       from small pool |    450 MiB |    482 MiB |     33 GiB |     32 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   4211 MiB |   5038 MiB |  57184 GiB |  57180 GiB |\n","|       from large pool |   4207 MiB |   5034 MiB |  56935 GiB |  56931 GiB |\n","|       from small pool |      3 MiB |     17 MiB |    249 GiB |    249 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |    3112 K  |    3095 K  |\n","|       from large pool |      98    |     263    |    1893 K  |    1893 K  |\n","|       from small pool |   16251    |   16398    |    1218 K  |    1202 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |    3112 K  |    3095 K  |\n","|       from large pool |      98    |     263    |    1893 K  |    1893 K  |\n","|       from small pool |   16251    |   16398    |    1218 K  |    1202 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     249    |     331    |  174384    |  174135    |\n","|       from large pool |      24    |      98    |  157268    |  157244    |\n","|       from small pool |     225    |     241    |   17116    |   16891    |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      76    |     158    |    1465 K  |    1465 K  |\n","|       from large pool |      19    |      71    |     980 K  |     980 K  |\n","|       from small pool |      57    |     102    |     484 K  |     484 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:11/7698 batch_size:250\n","Next token prediction. step:183/214 batch:11/7698 epoch:2/10\n","full seq: Delegation members said they were very impressed by their catapult launch in the C-2 carrier onboard deliver propeller aircraft that took them back to the US Naval Air Station Sigonella at Sicily.Ģġġġġġġġġġġġġġġġġġ\n","pref seq: Delegation members said they were very impressed by their catapult launch in the C-2 carrier onboard deliver propeller aircraft that took them back to the US Naval Air Station Sigonel\n","next tok:                                                                                                                                                                                       l\n","pred tok:                                                                                                                                                                                       Y\n","Completed batch.\n","epoch:2/10 batch:11/7698 batch_size:250 loss:1.1687991619110107 time_for_batch_instance:235.35934329032898 total_batch_time:2916.7310564517975 running_batch_average:265.15736876834524\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 651698 KiB |  18292 MiB | 175552 GiB | 175552 GiB |\n","|       from large pool | 194248 KiB |  17849 MiB | 175309 GiB | 175309 GiB |\n","|       from small pool | 457450 KiB |    479 MiB |    242 GiB |    242 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 651698 KiB |  18292 MiB | 175552 GiB | 175552 GiB |\n","|       from large pool | 194248 KiB |  17849 MiB | 175309 GiB | 175309 GiB |\n","|       from small pool | 457450 KiB |    479 MiB |    242 GiB |    242 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  18267 MiB | 175214 GiB | 175214 GiB |\n","|       from large pool | 189056 KiB |  17828 MiB | 174972 GiB | 174971 GiB |\n","|       from small pool | 453671 KiB |    475 MiB |    242 GiB |    242 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2156 MiB |  19158 MiB |  37818 GiB |  37816 GiB |\n","|       from large pool |   1706 MiB |  18692 MiB |  37782 GiB |  37780 GiB |\n","|       from small pool |    450 MiB |    482 MiB |     36 GiB |     36 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1519 MiB |   5220 MiB |  61475 GiB |  61474 GiB |\n","|       from large pool |   1516 MiB |   5212 MiB |  61204 GiB |  61203 GiB |\n","|       from small pool |      3 MiB |     19 MiB |    271 GiB |    271 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |    3390 K  |    3374 K  |\n","|       from large pool |      98    |     263    |    2063 K  |    2063 K  |\n","|       from small pool |   16251    |   16398    |    1327 K  |    1311 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |    3390 K  |    3374 K  |\n","|       from large pool |      98    |     263    |    2063 K  |    2063 K  |\n","|       from small pool |   16251    |   16398    |    1327 K  |    1311 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     255    |     345    |  191065    |  190810    |\n","|       from large pool |      30    |     112    |  172345    |  172315    |\n","|       from small pool |     225    |     241    |   18720    |   18495    |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      79    |     181    |    1636 K  |    1636 K  |\n","|       from large pool |      24    |      94    |    1107 K  |    1107 K  |\n","|       from small pool |      55    |     102    |     528 K  |     528 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:12/7698 batch_size:250\n","Next token prediction. step:35/214 batch:12/7698 epoch:2/10\n","full seq: We also have established mostly a professor exchange programme with the law faculties of the state universities in Zagreb, Ljubljana, Maribor, Belgrade, Nish, Sofia, as well as in France and the US.Ģġġġġġġġġġġġġġġġ\n","pref seq: We also have established mostly a p\n","next tok:                                   r\n","pred tok:                                   V\n","Completed batch.\n","epoch:2/10 batch:12/7698 batch_size:250 loss:3.8425049781799316 time_for_batch_instance:234.9095332622528 total_batch_time:3151.6405897140503 running_batch_average:262.6367158095042\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 654059 KiB |  18417 MiB | 188603 GiB | 188602 GiB |\n","|       from large pool | 196609 KiB |  17975 MiB | 188340 GiB | 188340 GiB |\n","|       from small pool | 457450 KiB |    479 MiB |    262 GiB |    262 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 654059 KiB |  18417 MiB | 188603 GiB | 188602 GiB |\n","|       from large pool | 196609 KiB |  17975 MiB | 188340 GiB | 188340 GiB |\n","|       from small pool | 457450 KiB |    479 MiB |    262 GiB |    262 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  18383 MiB | 188250 GiB | 188250 GiB |\n","|       from large pool | 189056 KiB |  17944 MiB | 187988 GiB | 187988 GiB |\n","|       from small pool | 453671 KiB |    475 MiB |    262 GiB |    262 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2796 MiB |  19210 MiB |  40637 GiB |  40634 GiB |\n","|       from large pool |   2346 MiB |  18744 MiB |  40597 GiB |  40595 GiB |\n","|       from small pool |    450 MiB |    482 MiB |     39 GiB |     39 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   2157 MiB |   3208 MiB |  66803 GiB |  66801 GiB |\n","|       from large pool |   2153 MiB |   3203 MiB |  66510 GiB |  66507 GiB |\n","|       from small pool |      3 MiB |     17 MiB |    293 GiB |    293 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |    3669 K  |    3653 K  |\n","|       from large pool |      98    |     263    |    2233 K  |    2233 K  |\n","|       from small pool |   16251    |   16398    |    1436 K  |    1419 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |    3669 K  |    3653 K  |\n","|       from large pool |      98    |     263    |    2233 K  |    2233 K  |\n","|       from small pool |   16251    |   16398    |    1436 K  |    1419 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     247    |     337    |  207365    |  207118    |\n","|       from large pool |      22    |     104    |  187033    |  187011    |\n","|       from small pool |     225    |     241    |   20332    |   20107    |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      72    |     140    |    1783 K  |    1783 K  |\n","|       from large pool |      16    |      56    |    1211 K  |    1211 K  |\n","|       from small pool |      56    |     102    |     572 K  |     572 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:13/7698 batch_size:250\n","Next token prediction. step:36/214 batch:13/7698 epoch:2/10\n","full seq: Cyprus and Greece are the happiest countries in Southeast Europe, according to the first-ever World Happiness Report, published by the Earth Institute of Columbia University in New York on April 2nd.Ģġġġġġġġġġġġġġġ\n","pref seq: Cyprus and Greece are the happiest c\n","next tok:                                    o\n","pred tok:                                    z\n","Completed batch.\n","epoch:2/10 batch:13/7698 batch_size:250 loss:2.1526389122009277 time_for_batch_instance:235.57401943206787 total_batch_time:3387.214609146118 running_batch_average:260.5549699343168\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 658990 KiB |  18355 MiB | 201609 GiB | 201609 GiB |\n","|       from large pool | 201540 KiB |  17913 MiB | 201327 GiB | 201327 GiB |\n","|       from small pool | 457450 KiB |    479 MiB |    282 GiB |    282 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 658990 KiB |  18355 MiB | 201609 GiB | 201609 GiB |\n","|       from large pool | 201540 KiB |  17913 MiB | 201327 GiB | 201327 GiB |\n","|       from small pool | 457450 KiB |    479 MiB |    282 GiB |    282 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  18325 MiB | 201240 GiB | 201239 GiB |\n","|       from large pool | 189056 KiB |  17886 MiB | 200957 GiB | 200957 GiB |\n","|       from small pool | 453671 KiB |    475 MiB |    282 GiB |    282 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   4820 MiB |  19182 MiB |  43113 GiB |  43108 GiB |\n","|       from large pool |   4370 MiB |  18716 MiB |  43070 GiB |  43066 GiB |\n","|       from small pool |    450 MiB |    482 MiB |     42 GiB |     42 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   4176 MiB |   5125 MiB |  71178 GiB |  71174 GiB |\n","|       from large pool |   4173 MiB |   5121 MiB |  70862 GiB |  70858 GiB |\n","|       from small pool |      3 MiB |     17 MiB |    315 GiB |    315 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |    3948 K  |    3931 K  |\n","|       from large pool |      98    |     263    |    2403 K  |    2403 K  |\n","|       from small pool |   16251    |   16398    |    1544 K  |    1528 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |    3948 K  |    3931 K  |\n","|       from large pool |      98    |     263    |    2403 K  |    2403 K  |\n","|       from small pool |   16251    |   16398    |    1544 K  |    1528 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     248    |     332    |  222458    |  222210    |\n","|       from large pool |      23    |      99    |  200519    |  200496    |\n","|       from small pool |     225    |     241    |   21939    |   21714    |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      75    |     161    |    1935 K  |    1935 K  |\n","|       from large pool |      18    |      74    |    1319 K  |    1319 K  |\n","|       from small pool |      57    |     102    |     616 K  |     616 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:14/7698 batch_size:250\n","Next token prediction. step:159/212 batch:14/7698 epoch:2/10\n","full seq: Macedonian Prime Minister Nikola Gruevski (left) sent Greek counterpart Costas Karamanlis a letter last week, urging him to correct \"historical mistakes of the past\". [SETimes photo illustration]Ģġġġġġġġġġġġġġġġġ\n","pref seq: Macedonian Prime Minister Nikola Gruevski (left) sent Greek counterpart Costas Karamanlis a letter last week, urging him to correct \"historical mistakes of the\n","next tok:                                                                                                                                                                \n","pred tok:                                                                                                                                                               c\n","Completed batch.\n","epoch:2/10 batch:14/7698 batch_size:250 loss:1.1012572050094604 time_for_batch_instance:232.46394872665405 total_batch_time:3619.678557872772 running_batch_average:258.54846841948375\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 655111 KiB |  18152 MiB | 214351 GiB | 214350 GiB |\n","|       from large pool | 197661 KiB |  17709 MiB | 214048 GiB | 214048 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    302 GiB |    301 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 655111 KiB |  18152 MiB | 214351 GiB | 214350 GiB |\n","|       from large pool | 197661 KiB |  17709 MiB | 214048 GiB | 214048 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    302 GiB |    301 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  18101 MiB | 213948 GiB | 213947 GiB |\n","|       from large pool | 189056 KiB |  17663 MiB | 213646 GiB | 213646 GiB |\n","|       from small pool | 453671 KiB |    475 MiB |    302 GiB |    301 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2412 MiB |  18932 MiB |  45984 GiB |  45982 GiB |\n","|       from large pool |   1962 MiB |  18468 MiB |  45939 GiB |  45937 GiB |\n","|       from small pool |    450 MiB |    482 MiB |     45 GiB |     45 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1772 MiB |   4187 MiB |  75199 GiB |  75197 GiB |\n","|       from large pool |   1768 MiB |   4179 MiB |  74862 GiB |  74860 GiB |\n","|       from small pool |      3 MiB |     17 MiB |    337 GiB |    337 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |    4224 K  |    4207 K  |\n","|       from large pool |      98    |     263    |    2571 K  |    2571 K  |\n","|       from small pool |   16251    |   16398    |    1652 K  |    1636 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |    4224 K  |    4207 K  |\n","|       from large pool |      98    |     263    |    2571 K  |    2571 K  |\n","|       from small pool |   16251    |   16398    |    1652 K  |    1636 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     241    |     337    |  239001    |  238760    |\n","|       from large pool |      16    |     104    |  215492    |  215476    |\n","|       from small pool |     225    |     241    |   23509    |   23284    |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      65    |     141    |    2046 K  |    2046 K  |\n","|       from large pool |      13    |      54    |    1385 K  |    1385 K  |\n","|       from small pool |      52    |     102    |     660 K  |     660 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:15/7698 batch_size:250\n","Next token prediction. step:88/212 batch:15/7698 epoch:2/10\n","full seq: Nicknamed \"Vulpea\" (the Fox), he led the General Directorate of Information and Internal Protection (DGIPI), one of the seven Romanian secret services, between 1998 and 2007, under three presidents.Ģġġġġġġġġġġġġġ\n","pref seq: Nicknamed \"Vulpea\" (the Fox), he led the General Directorate of Information and Internal\n","next tok:                                                                                         \n","pred tok:                                                                                        P\n","Completed batch.\n","epoch:2/10 batch:15/7698 batch_size:250 loss:0.9607763886451721 time_for_batch_instance:232.72552824020386 total_batch_time:3852.404086112976 running_batch_average:256.8269390741984\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 654647 KiB |  18151 MiB | 227092 GiB | 227091 GiB |\n","|       from large pool | 197197 KiB |  17709 MiB | 226770 GiB | 226770 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    322 GiB |    321 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 654647 KiB |  18151 MiB | 227092 GiB | 227091 GiB |\n","|       from large pool | 197197 KiB |  17709 MiB | 226770 GiB | 226770 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    322 GiB |    321 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  18101 MiB | 226657 GiB | 226656 GiB |\n","|       from large pool | 189056 KiB |  17663 MiB | 226335 GiB | 226335 GiB |\n","|       from small pool | 453671 KiB |    475 MiB |    321 GiB |    321 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2480 MiB |  18930 MiB |  48861 GiB |  48858 GiB |\n","|       from large pool |   2030 MiB |  18466 MiB |  48812 GiB |  48810 GiB |\n","|       from small pool |    450 MiB |    482 MiB |     48 GiB |     48 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1840 MiB |   3932 MiB |  79157 GiB |  79155 GiB |\n","|       from large pool |   1837 MiB |   3927 MiB |  78798 GiB |  78796 GiB |\n","|       from small pool |      3 MiB |     17 MiB |    359 GiB |    359 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |    4500 K  |    4483 K  |\n","|       from large pool |      98    |     263    |    2739 K  |    2739 K  |\n","|       from small pool |   16251    |   16398    |    1760 K  |    1743 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |    4500 K  |    4483 K  |\n","|       from large pool |      98    |     263    |    2739 K  |    2739 K  |\n","|       from small pool |   16251    |   16398    |    1760 K  |    1743 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     241    |     335    |  255413    |  255172    |\n","|       from large pool |      16    |     103    |  230334    |  230318    |\n","|       from small pool |     225    |     241    |   25079    |   24854    |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      66    |     139    |    2155 K  |    2155 K  |\n","|       from large pool |      14    |      53    |    1451 K  |    1451 K  |\n","|       from small pool |      52    |     102    |     703 K  |     703 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:16/7698 batch_size:250\n","Next token prediction. step:120/210 batch:16/7698 epoch:2/10\n","full seq: Nine days later, the Serbian authorities handed him over to The Hague tribunal to answer charges of genocide and war crimes, stemming from the 1992-1995 conflict in Bosnia and Herzegovina (BiH).Ģġġġġġġġġġġġġġġġ\n","pref seq: Nine days later, the Serbian authorities handed him over to The Hague tribunal to answer charges of genocide and war cri\n","next tok:                                                                                                                        m\n","pred tok:                                                                                                                        ,\n","Completed batch.\n","epoch:2/10 batch:16/7698 batch_size:250 loss:0.8485494256019592 time_for_batch_instance:230.70621371269226 total_batch_time:4083.1102998256683 running_batch_average:255.19439373910427\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 657805 KiB |  17968 MiB | 239602 GiB | 239602 GiB |\n","|       from large pool | 200355 KiB |  17526 MiB | 239261 GiB | 239261 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    341 GiB |    341 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 657805 KiB |  17968 MiB | 239602 GiB | 239602 GiB |\n","|       from large pool | 200355 KiB |  17526 MiB | 239261 GiB | 239261 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    341 GiB |    341 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  17936 MiB | 239133 GiB | 239133 GiB |\n","|       from large pool | 189056 KiB |  17497 MiB | 238792 GiB | 238792 GiB |\n","|       from small pool | 453671 KiB |    475 MiB |    341 GiB |    340 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2190 MiB |  18790 MiB |  51726 GiB |  51724 GiB |\n","|       from large pool |   1740 MiB |  18324 MiB |  51674 GiB |  51673 GiB |\n","|       from small pool |    450 MiB |    482 MiB |     52 GiB |     51 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1547 MiB |   3122 MiB |  83044 GiB |  83042 GiB |\n","|       from large pool |   1544 MiB |   3118 MiB |  82663 GiB |  82661 GiB |\n","|       from small pool |      3 MiB |     17 MiB |    381 GiB |    381 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |    4773 K  |    4757 K  |\n","|       from large pool |      98    |     263    |    2906 K  |    2906 K  |\n","|       from small pool |   16251    |   16398    |    1866 K  |    1850 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |    4773 K  |    4757 K  |\n","|       from large pool |      98    |     263    |    2906 K  |    2906 K  |\n","|       from small pool |   16251    |   16398    |    1866 K  |    1850 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     244    |     334    |  271893    |  271649    |\n","|       from large pool |      19    |     102    |  245259    |  245240    |\n","|       from small pool |     225    |     241    |   26634    |   26409    |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      70    |     132    |    2270 K  |    2269 K  |\n","|       from large pool |      13    |      45    |    1523 K  |    1523 K  |\n","|       from small pool |      57    |     101    |     746 K  |     746 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:17/7698 batch_size:250\n","Next token prediction. step:132/209 batch:17/7698 epoch:2/10\n","full seq: During his first visit to Belgrade after assuming his post last month, the UNMIK chief pledged \"more effort will be put towards resolving the issue of Kosovo's final status\" after the election.Ģġġġġġġġġġġġġġġġ\n","pref seq: During his first visit to Belgrade after assuming his post last month, the UNMIK chief pledged \"more effort will be put towards reso\n","next tok:                                                                                                                                    l\n","pred tok:                                                                                                                                    ,\n","Completed batch.\n","epoch:2/10 batch:17/7698 batch_size:250 loss:1.314259648323059 time_for_batch_instance:229.08772993087769 total_batch_time:4312.198029756546 running_batch_average:253.65870763273801\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 655065 KiB |  17946 MiB | 252045 GiB | 252044 GiB |\n","|       from large pool | 197615 KiB |  17503 MiB | 251684 GiB | 251683 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    360 GiB |    360 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 655065 KiB |  17946 MiB | 252045 GiB | 252044 GiB |\n","|       from large pool | 197615 KiB |  17503 MiB | 251684 GiB | 251683 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    360 GiB |    360 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  17911 MiB | 251540 GiB | 251540 GiB |\n","|       from large pool | 189056 KiB |  17472 MiB | 251180 GiB | 251179 GiB |\n","|       from small pool | 453671 KiB |    475 MiB |    360 GiB |    360 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2476 MiB |  18774 MiB |  54556 GiB |  54554 GiB |\n","|       from large pool |   2026 MiB |  18308 MiB |  54501 GiB |  54499 GiB |\n","|       from small pool |    450 MiB |    482 MiB |     55 GiB |     54 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1836 MiB |   3613 MiB |  86900 GiB |  86898 GiB |\n","|       from large pool |   1833 MiB |   3609 MiB |  86497 GiB |  86495 GiB |\n","|       from small pool |      3 MiB |     17 MiB |    402 GiB |    402 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |    5045 K  |    5029 K  |\n","|       from large pool |      98    |     263    |    3072 K  |    3072 K  |\n","|       from small pool |   16251    |   16398    |    1972 K  |    1956 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |    5045 K  |    5029 K  |\n","|       from large pool |      98    |     263    |    3072 K  |    3072 K  |\n","|       from small pool |   16251    |   16398    |    1972 K  |    1956 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     244    |     340    |  288172    |  287928    |\n","|       from large pool |      19    |     107    |  259991    |  259972    |\n","|       from small pool |     225    |     241    |   28181    |   27956    |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      71    |     134    |    2383 K  |    2383 K  |\n","|       from large pool |      18    |      48    |    1594 K  |    1594 K  |\n","|       from small pool |      53    |     101    |     789 K  |     789 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:18/7698 batch_size:250\n","Next token prediction. step:109/209 batch:18/7698 epoch:2/10\n","full seq: Especially significant, according to Zivkovic, was the meeting with Boeing representatives, which focused on strategic co-operation between the company and the Serbian flagship air carrier, JAT.Ģġġġġġġġġġġġġġġ\n","pref seq: Especially significant, according to Zivkovic, was the meeting with Boeing representatives, which focused on \n","next tok:                                                                                                             s\n","pred tok:                                                                                                             ,\n","Completed batch.\n","epoch:2/10 batch:18/7698 batch_size:250 loss:1.1941806077957153 time_for_batch_instance:229.158301115036 total_batch_time:4541.356330871582 running_batch_average:252.29757393731012\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 655065 KiB |  17946 MiB | 264486 GiB | 264486 GiB |\n","|       from large pool | 197615 KiB |  17503 MiB | 264106 GiB | 264106 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    380 GiB |    379 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 655065 KiB |  17946 MiB | 264486 GiB | 264486 GiB |\n","|       from large pool | 197615 KiB |  17503 MiB | 264106 GiB | 264106 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    380 GiB |    379 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  17911 MiB | 263948 GiB | 263947 GiB |\n","|       from large pool | 189056 KiB |  17472 MiB | 263567 GiB | 263567 GiB |\n","|       from small pool | 453671 KiB |    475 MiB |    380 GiB |    379 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2476 MiB |  18774 MiB |  57379 GiB |  57376 GiB |\n","|       from large pool |   2026 MiB |  18308 MiB |  57321 GiB |  57319 GiB |\n","|       from small pool |    450 MiB |    482 MiB |     58 GiB |     57 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1836 MiB |   3844 MiB |  90798 GiB |  90796 GiB |\n","|       from large pool |   1833 MiB |   3841 MiB |  90374 GiB |  90372 GiB |\n","|       from small pool |      3 MiB |     17 MiB |    424 GiB |    424 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |    5317 K  |    5301 K  |\n","|       from large pool |      98    |     263    |    3238 K  |    3238 K  |\n","|       from small pool |   16251    |   16398    |    2079 K  |    2062 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |    5317 K  |    5301 K  |\n","|       from large pool |      98    |     263    |    3238 K  |    3238 K  |\n","|       from small pool |   16251    |   16398    |    2079 K  |    2062 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     244    |     340    |  304412    |  304168    |\n","|       from large pool |      19    |     107    |  274684    |  274665    |\n","|       from small pool |     225    |     241    |   29728    |   29503    |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      71    |     135    |    2497 K  |    2497 K  |\n","|       from large pool |      18    |      48    |    1665 K  |    1665 K  |\n","|       from small pool |      53    |     101    |     831 K  |     831 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:19/7698 batch_size:250\n","Next token prediction. step:64/209 batch:19/7698 epoch:2/10\n","full seq: Resolving the Kosovo crisis and advancing the European perspective of the Western Balkans will be among the priority issues Slovenia will focus on during its six-month tenure at the helm of the EU.Ģġġġġġġġġġġġ\n","pref seq: Resolving the Kosovo crisis and advancing the European perspecti\n","next tok:                                                                v\n","pred tok:                                                                ,\n","Completed batch.\n","epoch:2/10 batch:19/7698 batch_size:250 loss:1.0852210521697998 time_for_batch_instance:229.29386496543884 total_batch_time:4770.650195837021 running_batch_average:251.08685241247477\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 655065 KiB |  17946 MiB | 276928 GiB | 276927 GiB |\n","|       from large pool | 197615 KiB |  17503 MiB | 276528 GiB | 276528 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    399 GiB |    399 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 655065 KiB |  17946 MiB | 276928 GiB | 276927 GiB |\n","|       from large pool | 197615 KiB |  17503 MiB | 276528 GiB | 276528 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    399 GiB |    399 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  17911 MiB | 276355 GiB | 276354 GiB |\n","|       from large pool | 189056 KiB |  17472 MiB | 275955 GiB | 275955 GiB |\n","|       from small pool | 453671 KiB |    475 MiB |    399 GiB |    399 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2476 MiB |  18774 MiB |  60205 GiB |  60203 GiB |\n","|       from large pool |   2026 MiB |  18308 MiB |  60144 GiB |  60142 GiB |\n","|       from small pool |    450 MiB |    482 MiB |     61 GiB |     60 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1836 MiB |   3844 MiB |  94683 GiB |  94681 GiB |\n","|       from large pool |   1833 MiB |   3841 MiB |  94237 GiB |  94235 GiB |\n","|       from small pool |      3 MiB |     17 MiB |    445 GiB |    445 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |    5589 K  |    5573 K  |\n","|       from large pool |      98    |     263    |    3404 K  |    3404 K  |\n","|       from small pool |   16251    |   16398    |    2185 K  |    2168 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |    5589 K  |    5573 K  |\n","|       from large pool |      98    |     263    |    3404 K  |    3404 K  |\n","|       from small pool |   16251    |   16398    |    2185 K  |    2168 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     244    |     340    |  320686    |  320442    |\n","|       from large pool |      19    |     107    |  289411    |  289392    |\n","|       from small pool |     225    |     241    |   31275    |   31050    |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      71    |     134    |    2610 K  |    2610 K  |\n","|       from large pool |      18    |      48    |    1736 K  |    1736 K  |\n","|       from small pool |      53    |     101    |     874 K  |     874 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:20/7698 batch_size:250\n","Next token prediction. step:6/208 batch:20/7698 epoch:2/10\n","full seq: Kosovo will invest in human resources and education as part of its National Science Programme, the Ministry of Education and the EC Liaison Office in Kosovo announced on Tuesday (April 27th).Ģġġġġġġġġġġġġġġġġ\n","pref seq: Kosovo\n","next tok:       \n","pred tok:      (\n","Completed batch.\n","epoch:2/10 batch:20/7698 batch_size:250 loss:0.8671713471412659 time_for_batch_instance:226.43816232681274 total_batch_time:4997.088358163834 running_batch_average:249.8544179081917\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 658104 KiB |  17781 MiB | 289185 GiB | 289185 GiB |\n","|       from large pool | 200654 KiB |  17339 MiB | 288766 GiB | 288766 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    419 GiB |    418 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 658104 KiB |  17781 MiB | 289185 GiB | 289185 GiB |\n","|       from large pool | 200654 KiB |  17339 MiB | 288766 GiB | 288766 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    419 GiB |    418 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  17770 MiB | 288602 GiB | 288601 GiB |\n","|       from large pool | 189056 KiB |  17332 MiB | 288183 GiB | 288183 GiB |\n","|       from small pool | 453671 KiB |    475 MiB |    418 GiB |    418 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   4186 MiB |  18636 MiB |  62536 GiB |  62532 GiB |\n","|       from large pool |   3736 MiB |  18170 MiB |  62472 GiB |  62468 GiB |\n","|       from small pool |    450 MiB |    482 MiB |     64 GiB |     63 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   3543 MiB |   4870 MiB |  98880 GiB |  98877 GiB |\n","|       from large pool |   3540 MiB |   4862 MiB |  98413 GiB |  98410 GiB |\n","|       from small pool |      3 MiB |     17 MiB |    467 GiB |    467 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |    5860 K  |    5843 K  |\n","|       from large pool |      98    |     263    |    3569 K  |    3569 K  |\n","|       from small pool |   16251    |   16398    |    2290 K  |    2274 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |    5860 K  |    5843 K  |\n","|       from large pool |      98    |     263    |    3569 K  |    3569 K  |\n","|       from small pool |   16251    |   16398    |    2290 K  |    2274 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     246    |     332    |  335205    |  334959    |\n","|       from large pool |      21    |     100    |  302359    |  302338    |\n","|       from small pool |     225    |     241    |   32846    |   32621    |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      73    |     165    |    2764 K  |    2764 K  |\n","|       from large pool |      16    |      79    |    1847 K  |    1847 K  |\n","|       from small pool |      57    |     101    |     916 K  |     916 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:21/7698 batch_size:250\n","Next token prediction. step:53/208 batch:21/7698 epoch:2/10\n","full seq: \"Government funds are scarce and should only be used to fund research when the conditions are in place for them to bear fruit,\" the study's lead author, Itzhak Goldberg, stressed. [World Bank]Ģġġġġġġġġġġġġġġġ\n","pref seq: \"Government funds are scarce and should only be used \n","next tok:                                                     t\n","pred tok:                                                     f\n","Completed batch.\n","epoch:2/10 batch:21/7698 batch_size:250 loss:2.389387607574463 time_for_batch_instance:225.55803275108337 total_batch_time:5222.646390914917 running_batch_average:248.69744718642463\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 654287 KiB |  17866 MiB | 301519 GiB | 301518 GiB |\n","|       from large pool | 196837 KiB |  17424 MiB | 301081 GiB | 301080 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    438 GiB |    437 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 654287 KiB |  17866 MiB | 301519 GiB | 301518 GiB |\n","|       from large pool | 196837 KiB |  17424 MiB | 301081 GiB | 301080 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    438 GiB |    437 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  17828 MiB | 300894 GiB | 300893 GiB |\n","|       from large pool | 189056 KiB |  17390 MiB | 300456 GiB | 300456 GiB |\n","|       from small pool | 453671 KiB |    475 MiB |    438 GiB |    437 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2530 MiB |  18676 MiB |  65238 GiB |  65236 GiB |\n","|       from large pool |   2080 MiB |  18210 MiB |  65171 GiB |  65169 GiB |\n","|       from small pool |    450 MiB |    482 MiB |     67 GiB |     66 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1891 MiB |   3553 MiB | 103248 GiB | 103247 GiB |\n","|       from large pool |   1887 MiB |   3547 MiB | 102760 GiB | 102758 GiB |\n","|       from small pool |      3 MiB |     17 MiB |    488 GiB |    488 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |    6131 K  |    6114 K  |\n","|       from large pool |      98    |     263    |    3734 K  |    3734 K  |\n","|       from small pool |   16251    |   16398    |    2396 K  |    2380 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |    6131 K  |    6114 K  |\n","|       from large pool |      98    |     263    |    3734 K  |    3734 K  |\n","|       from small pool |   16251    |   16398    |    2396 K  |    2380 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     245    |     338    |  350958    |  350713    |\n","|       from large pool |      20    |     105    |  316540    |  316520    |\n","|       from small pool |     225    |     241    |   34418    |   34193    |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      77    |     132    |    2881 K  |    2881 K  |\n","|       from large pool |      19    |      46    |    1922 K  |    1921 K  |\n","|       from small pool |      58    |     102    |     959 K  |     959 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:22/7698 batch_size:250\n","Next token prediction. step:28/208 batch:22/7698 epoch:2/10\n","full seq: But when we show, step by step, our efforts and successes, I think we may renegotiate some terms with our EU partners and the dialogue is to start now and continue for ten to15 years,\" Lazar said.Ģġġġġġġġġġġġ\n","pref seq: But when we show, step by st\n","next tok:                            e\n","pred tok:                            M\n","Completed batch.\n","epoch:2/10 batch:22/7698 batch_size:250 loss:0.7934712171554565 time_for_batch_instance:214.90786337852478 total_batch_time:5437.554254293442 running_batch_average:247.16155701333827\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 658104 KiB |  17781 MiB | 313776 GiB | 313776 GiB |\n","|       from large pool | 200654 KiB |  17339 MiB | 313319 GiB | 313319 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    457 GiB |    457 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 658104 KiB |  17781 MiB | 313776 GiB | 313776 GiB |\n","|       from large pool | 200654 KiB |  17339 MiB | 313319 GiB | 313319 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    457 GiB |    457 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  17770 MiB | 313141 GiB | 313140 GiB |\n","|       from large pool | 189056 KiB |  17332 MiB | 312683 GiB | 312683 GiB |\n","|       from small pool | 453671 KiB |    475 MiB |    457 GiB |    456 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   4186 MiB |  18636 MiB |  67558 GiB |  67554 GiB |\n","|       from large pool |   3736 MiB |  18170 MiB |  67488 GiB |  67484 GiB |\n","|       from small pool |    450 MiB |    482 MiB |     70 GiB |     69 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   3543 MiB |   4870 MiB | 107427 GiB | 107423 GiB |\n","|       from large pool |   3540 MiB |   4862 MiB | 106916 GiB | 106913 GiB |\n","|       from small pool |      3 MiB |     17 MiB |    510 GiB |    510 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |    6401 K  |    6385 K  |\n","|       from large pool |      98    |     263    |    3899 K  |    3899 K  |\n","|       from small pool |   16251    |   16398    |    2502 K  |    2485 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |    6401 K  |    6385 K  |\n","|       from large pool |      98    |     263    |    3899 K  |    3899 K  |\n","|       from small pool |   16251    |   16398    |    2502 K  |    2485 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     246    |     332    |  365471    |  365225    |\n","|       from large pool |      21    |     100    |  329482    |  329461    |\n","|       from small pool |     225    |     241    |   35989    |   35764    |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      73    |     167    |    3034 K  |    3034 K  |\n","|       from large pool |      16    |      81    |    2033 K  |    2032 K  |\n","|       from small pool |      57    |     101    |    1001 K  |    1001 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:23/7698 batch_size:250\n","Next token prediction. step:41/207 batch:23/7698 epoch:2/10\n","full seq: After a further pickup in 2006, economic growth in most of the EU's ten former communist states is likely to slow down this year, the World Bank said in a new report, released on January 25th.Ģġġġġġġġġġġġġġġ\n","pref seq: After a further pickup in 2006, economic \n","next tok:                                         g\n","pred tok:                                         (\n","Completed batch.\n","epoch:2/10 batch:23/7698 batch_size:250 loss:0.8921487927436829 time_for_batch_instance:215.79661226272583 total_batch_time:5653.350866556168 running_batch_average:245.79786376331163\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 655569 KiB |  17645 MiB | 325871 GiB | 325870 GiB |\n","|       from large pool | 198119 KiB |  17203 MiB | 325394 GiB | 325394 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    476 GiB |    476 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 655569 KiB |  17645 MiB | 325871 GiB | 325870 GiB |\n","|       from large pool | 198119 KiB |  17203 MiB | 325394 GiB | 325394 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    476 GiB |    476 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  17629 MiB | 325228 GiB | 325227 GiB |\n","|       from large pool | 189056 KiB |  17191 MiB | 324751 GiB | 324751 GiB |\n","|       from small pool | 453671 KiB |    475 MiB |    476 GiB |    476 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2790 MiB |  18494 MiB |  70213 GiB |  70211 GiB |\n","|       from large pool |   2340 MiB |  18028 MiB |  70140 GiB |  70138 GiB |\n","|       from small pool |    450 MiB |    482 MiB |     73 GiB |     72 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   2149 MiB |   3738 MiB | 111402 GiB | 111400 GiB |\n","|       from large pool |   2146 MiB |   3734 MiB | 110870 GiB | 110868 GiB |\n","|       from small pool |      3 MiB |     17 MiB |    531 GiB |    531 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |    6671 K  |    6654 K  |\n","|       from large pool |      98    |     263    |    4063 K  |    4063 K  |\n","|       from small pool |   16251    |   16398    |    2607 K  |    2591 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |    6671 K  |    6654 K  |\n","|       from large pool |      98    |     263    |    4063 K  |    4063 K  |\n","|       from small pool |   16251    |   16398    |    2607 K  |    2591 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     245    |     331    |  381342    |  381097    |\n","|       from large pool |      20    |      98    |  343774    |  343754    |\n","|       from small pool |     225    |     241    |   37568    |   37343    |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      71    |     172    |    3192 K  |    3192 K  |\n","|       from large pool |      15    |      85    |    2148 K  |    2148 K  |\n","|       from small pool |      56    |     102    |    1043 K  |    1043 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:24/7698 batch_size:250\n","Next token prediction. step:26/207 batch:24/7698 epoch:2/10\n","full seq: In an article published in the Swedish daily Dagens Nuhetter on Saturday (September 5th), Davutoglu said his country has implemented reforms that would have been unthinkable several years ago.Ģġġġġġġġġġġġġġġ\n","pref seq: In an article published in\n","next tok:                           \n","pred tok:                          Z\n","Completed batch.\n","epoch:2/10 batch:24/7698 batch_size:250 loss:1.0361051559448242 time_for_batch_instance:217.25277090072632 total_batch_time:5870.603637456894 running_batch_average:244.60848489403725\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 654248 KiB |  17645 MiB | 337965 GiB | 337965 GiB |\n","|       from large pool | 196798 KiB |  17203 MiB | 337469 GiB | 337469 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    496 GiB |    495 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 654248 KiB |  17645 MiB | 337965 GiB | 337965 GiB |\n","|       from large pool | 196798 KiB |  17203 MiB | 337469 GiB | 337469 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    496 GiB |    495 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  17629 MiB | 337315 GiB | 337314 GiB |\n","|       from large pool | 189056 KiB |  17191 MiB | 336819 GiB | 336819 GiB |\n","|       from small pool | 453671 KiB |    475 MiB |    495 GiB |    495 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2950 MiB |  18504 MiB |  72929 GiB |  72926 GiB |\n","|       from large pool |   2500 MiB |  18038 MiB |  72852 GiB |  72850 GiB |\n","|       from small pool |    450 MiB |    482 MiB |     76 GiB |     76 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   2311 MiB |   3508 MiB | 115319 GiB | 115317 GiB |\n","|       from large pool |   2307 MiB |   3504 MiB | 114766 GiB | 114764 GiB |\n","|       from small pool |      3 MiB |     17 MiB |    552 GiB |    552 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |    6940 K  |    6924 K  |\n","|       from large pool |      98    |     263    |    4228 K  |    4228 K  |\n","|       from small pool |   16251    |   16398    |    2712 K  |    2696 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |    6940 K  |    6924 K  |\n","|       from large pool |      98    |     263    |    4228 K  |    4228 K  |\n","|       from small pool |   16251    |   16398    |    2712 K  |    2696 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     247    |     333    |  397265    |  397018    |\n","|       from large pool |      22    |     100    |  358117    |  358095    |\n","|       from small pool |     225    |     241    |   39148    |   38923    |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      77    |     171    |    3350 K  |    3350 K  |\n","|       from large pool |      21    |      85    |    2264 K  |    2264 K  |\n","|       from small pool |      56    |     102    |    1086 K  |    1086 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:25/7698 batch_size:250\n","Next token prediction. step:18/207 batch:25/7698 epoch:2/10\n","full seq: \"The national contributions that are here are entirely the EUFOR's assets and capabilities,\" Leakey said. \"All the operations that EUFOR will conduct here are exclusively the force's operations.Ģġġġġġġġġġġġġ\n","pref seq: \"The national cont\n","next tok:                  r\n","pred tok:                  ,\n","Completed batch.\n","epoch:2/10 batch:25/7698 batch_size:250 loss:0.8971087336540222 time_for_batch_instance:216.11787581443787 total_batch_time:6086.721513271332 running_batch_average:243.46886053085328\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 657576 KiB |  17762 MiB | 350154 GiB | 350153 GiB |\n","|       from large pool | 200126 KiB |  17320 MiB | 349639 GiB | 349638 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    515 GiB |    514 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 657576 KiB |  17762 MiB | 350154 GiB | 350153 GiB |\n","|       from large pool | 200126 KiB |  17320 MiB | 349639 GiB | 349638 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    515 GiB |    514 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  17745 MiB | 349493 GiB | 349492 GiB |\n","|       from large pool | 189056 KiB |  17307 MiB | 348978 GiB | 348978 GiB |\n","|       from small pool | 453671 KiB |    475 MiB |    514 GiB |    514 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   4490 MiB |  18622 MiB |  75228 GiB |  75223 GiB |\n","|       from large pool |   4040 MiB |  18156 MiB |  75148 GiB |  75144 GiB |\n","|       from small pool |    450 MiB |    482 MiB |     79 GiB |     79 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   3847 MiB |   4871 MiB | 119471 GiB | 119468 GiB |\n","|       from large pool |   3844 MiB |   4862 MiB | 118897 GiB | 118893 GiB |\n","|       from small pool |      3 MiB |     18 MiB |    574 GiB |    574 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |    7210 K  |    7193 K  |\n","|       from large pool |      98    |     263    |    4392 K  |    4392 K  |\n","|       from small pool |   16251    |   16398    |    2817 K  |    2801 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |    7210 K  |    7193 K  |\n","|       from large pool |      98    |     263    |    4392 K  |    4392 K  |\n","|       from small pool |   16251    |   16398    |    2817 K  |    2801 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     250    |     331    |  411686    |  411436    |\n","|       from large pool |      25    |      99    |  370977    |  370952    |\n","|       from small pool |     225    |     241    |   40709    |   40484    |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      77    |     165    |    3503 K  |    3503 K  |\n","|       from large pool |      19    |      79    |    2374 K  |    2374 K  |\n","|       from small pool |      58    |     101    |    1128 K  |    1128 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:26/7698 batch_size:250\n","Next token prediction. step:163/205 batch:26/7698 epoch:2/10\n","full seq: Although Turkey's economic plights did not vanish altogether, co-operation with the IMF and a series of austerity measures paved the way for economic stability alongside political stability.Ģġġġġġġġġġġġġġġ\n","pref seq: Although Turkey's economic plights did not vanish altogether, co-operation with the IMF and a series of austerity measures paved the way for economic stability alo\n","next tok:                                                                                                                                                                   n\n","pred tok:                                                                                                                                                                   a\n","Completed batch.\n","epoch:2/10 batch:26/7698 batch_size:250 loss:1.0071568489074707 time_for_batch_instance:217.00875663757324 total_batch_time:6303.730269908905 running_batch_average:242.45116422726556\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 654888 KiB |  17556 MiB | 362076 GiB | 362076 GiB |\n","|       from large pool | 197438 KiB |  17114 MiB | 361542 GiB | 361542 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    534 GiB |    533 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 654888 KiB |  17556 MiB | 362076 GiB | 362076 GiB |\n","|       from large pool | 197438 KiB |  17114 MiB | 361542 GiB | 361542 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    534 GiB |    533 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  17522 MiB | 361399 GiB | 361398 GiB |\n","|       from large pool | 189056 KiB |  17083 MiB | 360865 GiB | 360865 GiB |\n","|       from small pool | 453671 KiB |    475 MiB |    533 GiB |    533 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2968 MiB |  18370 MiB |  77811 GiB |  77808 GiB |\n","|       from large pool |   2516 MiB |  17904 MiB |  77728 GiB |  77726 GiB |\n","|       from small pool |    452 MiB |    482 MiB |     82 GiB |     82 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   2328 MiB |   3856 MiB | 124560 GiB | 124557 GiB |\n","|       from large pool |   2323 MiB |   3849 MiB | 123964 GiB | 123962 GiB |\n","|       from small pool |      5 MiB |     18 MiB |    595 GiB |    595 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |    7476 K  |    7460 K  |\n","|       from large pool |      98    |     263    |    4555 K  |    4554 K  |\n","|       from small pool |   16251    |   16398    |    2921 K  |    2905 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |    7476 K  |    7460 K  |\n","|       from large pool |      98    |     263    |    4555 K  |    4554 K  |\n","|       from small pool |   16251    |   16398    |    2921 K  |    2905 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     256    |     344    |  427393    |  427137    |\n","|       from large pool |      30    |     111    |  385119    |  385089    |\n","|       from small pool |     226    |     241    |   42274    |   42048    |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      83    |     158    |    3652 K  |    3652 K  |\n","|       from large pool |      25    |      73    |    2481 K  |    2481 K  |\n","|       from small pool |      58    |     104    |    1170 K  |    1170 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:27/7698 batch_size:250\n","Next token prediction. step:62/205 batch:27/7698 epoch:2/10\n","full seq: Hafnium is also used in gas-filled and incandescent lamps, as an efficient getter for scavenging oxygen and nitrogen, and in plasma cutting because of its ability to shed electrons into air.Ģġġġġġġġġġġġġġġ\n","pref seq: Hafnium is also used in gas-filled and incandescent lamps, as \n","next tok:                                                              a\n","pred tok:                                                              v\n","Completed batch.\n","epoch:2/10 batch:27/7698 batch_size:250 loss:0.8105903267860413 time_for_batch_instance:217.0999412536621 total_batch_time:6520.830211162567 running_batch_average:241.51223004305805\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 654562 KiB |  17556 MiB | 373999 GiB | 373998 GiB |\n","|       from large pool | 197112 KiB |  17114 MiB | 373446 GiB | 373445 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    553 GiB |    552 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 654562 KiB |  17556 MiB | 373999 GiB | 373998 GiB |\n","|       from large pool | 197112 KiB |  17114 MiB | 373446 GiB | 373445 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    553 GiB |    552 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  17522 MiB | 373305 GiB | 373304 GiB |\n","|       from large pool | 189056 KiB |  17083 MiB | 372752 GiB | 372752 GiB |\n","|       from small pool | 453671 KiB |    475 MiB |    552 GiB |    552 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2872 MiB |  18378 MiB |  80406 GiB |  80403 GiB |\n","|       from large pool |   2420 MiB |  17912 MiB |  80320 GiB |  80318 GiB |\n","|       from small pool |    452 MiB |    482 MiB |     85 GiB |     85 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   2232 MiB |   2880 MiB | 129672 GiB | 129670 GiB |\n","|       from large pool |   2227 MiB |   2875 MiB | 129056 GiB | 129054 GiB |\n","|       from small pool |      5 MiB |     18 MiB |    616 GiB |    616 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |    7743 K  |    7727 K  |\n","|       from large pool |      98    |     263    |    4717 K  |    4717 K  |\n","|       from small pool |   16251    |   16398    |    3025 K  |    3009 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |    7743 K  |    7727 K  |\n","|       from large pool |      98    |     263    |    4717 K  |    4717 K  |\n","|       from small pool |   16251    |   16398    |    3025 K  |    3009 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     258    |     346    |  443197    |  442939    |\n","|       from large pool |      32    |     113    |  399359    |  399327    |\n","|       from small pool |     226    |     241    |   43838    |   43612    |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      85    |     162    |    3801 K  |    3801 K  |\n","|       from large pool |      27    |      75    |    2588 K  |    2588 K  |\n","|       from small pool |      58    |     104    |    1212 K  |    1212 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:28/7698 batch_size:250\n","Next token prediction. step:80/204 batch:28/7698 epoch:2/10\n","full seq: \"We also have huge projects to offer our people at this time,\" he added, saying democracy, freedom and self-governance rights are more important for Diyarbakir than the economy and tourism.Ģġġġġġġġġġġġġġġ\n","pref seq: \"We also have huge projects to offer our people at this time,\" he added, saying \n","next tok:                                                                                d\n","pred tok:                                                                                (\n","Completed batch.\n","epoch:2/10 batch:28/7698 batch_size:250 loss:0.739524781703949 time_for_batch_instance:212.8077039718628 total_batch_time:6733.63791513443 running_batch_average:240.48706839765822\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 654683 KiB |  17477 MiB | 385818 GiB | 385817 GiB |\n","|       from large pool | 197233 KiB |  17035 MiB | 385246 GiB | 385246 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    572 GiB |    571 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 654683 KiB |  17477 MiB | 385818 GiB | 385817 GiB |\n","|       from large pool | 197233 KiB |  17035 MiB | 385246 GiB | 385246 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    572 GiB |    571 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  17439 MiB | 385098 GiB | 385098 GiB |\n","|       from large pool | 189056 KiB |  17001 MiB | 384527 GiB | 384526 GiB |\n","|       from small pool | 453671 KiB |    475 MiB |    571 GiB |    571 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2354 MiB |  18244 MiB |  83075 GiB |  83072 GiB |\n","|       from large pool |   1902 MiB |  17778 MiB |  82986 GiB |  82984 GiB |\n","|       from small pool |    452 MiB |    482 MiB |     88 GiB |     88 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1714 MiB |   3550 MiB | 133378 GiB | 133377 GiB |\n","|       from large pool |   1709 MiB |   3546 MiB | 132741 GiB | 132739 GiB |\n","|       from small pool |      5 MiB |     18 MiB |    637 GiB |    637 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |    8009 K  |    7992 K  |\n","|       from large pool |      98    |     263    |    4879 K  |    4879 K  |\n","|       from small pool |   16251    |   16398    |    3129 K  |    3113 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |    8009 K  |    7992 K  |\n","|       from large pool |      98    |     263    |    4879 K  |    4879 K  |\n","|       from small pool |   16251    |   16398    |    3129 K  |    3113 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     243    |     339    |  459145    |  458902    |\n","|       from large pool |      17    |     106    |  413743    |  413726    |\n","|       from small pool |     226    |     241    |   45402    |   45176    |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      69    |     135    |    3906 K  |    3906 K  |\n","|       from large pool |      14    |      49    |    2651 K  |    2651 K  |\n","|       from small pool |      55    |     103    |    1254 K  |    1254 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:29/7698 batch_size:250\n","Next token prediction. step:149/203 batch:29/7698 epoch:2/10\n","full seq: The recommendations made in that report will serve as the basis for a decision by EU leaders, during their summit in December, on whether to give Ankara a starting date for membership talks.Ģġġġġġġġġġġġġ\n","pref seq: The recommendations made in that report will serve as the basis for a decision by EU leaders, during their summit in December, on whether to give Ank\n","next tok:                                                                                                                                                     a\n","pred tok:                                                                                                                                                     ;\n","Completed batch.\n","epoch:2/10 batch:29/7698 batch_size:250 loss:1.1619064807891846 time_for_batch_instance:212.76379799842834 total_batch_time:6946.401713132858 running_batch_average:239.53109355630545\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 655820 KiB |  17403 MiB | 397528 GiB | 397528 GiB |\n","|       from large pool | 198370 KiB |  16961 MiB | 396937 GiB | 396937 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    590 GiB |    590 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 655820 KiB |  17403 MiB | 397528 GiB | 397528 GiB |\n","|       from large pool | 198370 KiB |  16961 MiB | 396937 GiB | 396937 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    590 GiB |    590 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  17356 MiB | 396780 GiB | 396779 GiB |\n","|       from large pool | 189056 KiB |  16918 MiB | 396189 GiB | 396189 GiB |\n","|       from small pool | 453671 KiB |    474 MiB |    590 GiB |    590 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2876 MiB |  18188 MiB |  85659 GiB |  85656 GiB |\n","|       from large pool |   2424 MiB |  17722 MiB |  85567 GiB |  85565 GiB |\n","|       from small pool |    452 MiB |    482 MiB |     91 GiB |     91 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   2235 MiB |   4117 MiB | 137100 GiB | 137098 GiB |\n","|       from large pool |   2230 MiB |   4113 MiB | 136442 GiB | 136440 GiB |\n","|       from small pool |      5 MiB |     18 MiB |    658 GiB |    658 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |    8273 K  |    8256 K  |\n","|       from large pool |      98    |     263    |    5040 K  |    5040 K  |\n","|       from small pool |   16251    |   16398    |    3232 K  |    3216 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |    8273 K  |    8256 K  |\n","|       from large pool |      98    |     263    |    5040 K  |    5040 K  |\n","|       from small pool |   16251    |   16398    |    3232 K  |    3216 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     246    |     335    |  474603    |  474357    |\n","|       from large pool |      20    |     102    |  427665    |  427645    |\n","|       from small pool |     226    |     241    |   46938    |   46712    |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      73    |     136    |    4018 K  |    4018 K  |\n","|       from large pool |      13    |      49    |    2722 K  |    2722 K  |\n","|       from small pool |      60    |     103    |    1295 K  |    1295 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:30/7698 batch_size:250\n","Next token prediction. step:160/202 batch:30/7698 epoch:2/10\n","full seq: The programme includes a film marathon, exhibitions of paintings and sculptures by BiH artists, a chess tournament and sports contests, folklore dance performances and rock music concerts.Ģġġġġġġġġġġġġġ\n","pref seq: The programme includes a film marathon, exhibitions of paintings and sculptures by BiH artists, a chess tournament and sports contests, folklore dance performan\n","next tok:                                                                                                                                                                c\n","pred tok:                                                                                                                                                                (\n","Completed batch.\n","epoch:2/10 batch:30/7698 batch_size:250 loss:1.1201398372650146 time_for_batch_instance:213.9460756778717 total_batch_time:7160.34778881073 running_batch_average:238.67825962702435\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 658109 KiB |  17293 MiB | 409126 GiB | 409126 GiB |\n","|       from large pool | 200659 KiB |  16851 MiB | 408516 GiB | 408516 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    609 GiB |    609 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 658109 KiB |  17293 MiB | 409126 GiB | 409126 GiB |\n","|       from large pool | 200659 KiB |  16851 MiB | 408516 GiB | 408516 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    609 GiB |    609 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  17273 MiB | 408350 GiB | 408349 GiB |\n","|       from large pool | 189056 KiB |  16835 MiB | 407741 GiB | 407741 GiB |\n","|       from small pool | 453671 KiB |    474 MiB |    609 GiB |    608 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   3836 MiB |  18078 MiB |  88203 GiB |  88200 GiB |\n","|       from large pool |   3386 MiB |  17612 MiB |  88109 GiB |  88105 GiB |\n","|       from small pool |    450 MiB |    482 MiB |     94 GiB |     94 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   3193 MiB |   4014 MiB | 140832 GiB | 140829 GiB |\n","|       from large pool |   3190 MiB |   4010 MiB | 140153 GiB | 140150 GiB |\n","|       from small pool |      3 MiB |     18 MiB |    679 GiB |    679 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |    8536 K  |    8519 K  |\n","|       from large pool |      98    |     263    |    5200 K  |    5200 K  |\n","|       from small pool |   16251    |   16398    |    3335 K  |    3319 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |    8536 K  |    8519 K  |\n","|       from large pool |      98    |     263    |    5200 K  |    5200 K  |\n","|       from small pool |   16251    |   16398    |    3335 K  |    3319 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     247    |     333    |  490145    |  489898    |\n","|       from large pool |      22    |     101    |  441678    |  441656    |\n","|       from small pool |     225    |     241    |   48467    |   48242    |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      74    |     135    |    4129 K  |    4129 K  |\n","|       from large pool |      16    |      50    |    2791 K  |    2791 K  |\n","|       from small pool |      58    |     103    |    1337 K  |    1337 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:31/7698 batch_size:250\n","Next token prediction. step:167/201 batch:31/7698 epoch:2/10\n","full seq: France, said President Nicolas Sarkozy, is determined to work hand-in-hand with the United States and is \"eager\" to see the new president \"get to work so we can change the world with him\".Ģġġġġġġġġġġġġ\n","pref seq: France, said President Nicolas Sarkozy, is determined to work hand-in-hand with the United States and is \"eager\" to see the new president \"get to work so we can change\n","next tok:                                                                                                                                                                        \n","pred tok:                                                                                                                                                                       -\n","Completed batch.\n","epoch:2/10 batch:31/7698 batch_size:250 loss:0.7596257925033569 time_for_batch_instance:214.40416264533997 total_batch_time:7374.75195145607 running_batch_average:237.8952242405184\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 658222 KiB |  17211 MiB | 420622 GiB | 420622 GiB |\n","|       from large pool | 200772 KiB |  16770 MiB | 419994 GiB | 419994 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    628 GiB |    627 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 658222 KiB |  17211 MiB | 420622 GiB | 420622 GiB |\n","|       from large pool | 200772 KiB |  16770 MiB | 419994 GiB | 419994 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    628 GiB |    627 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  17190 MiB | 419809 GiB | 419809 GiB |\n","|       from large pool | 189056 KiB |  16752 MiB | 419182 GiB | 419181 GiB |\n","|       from small pool | 453671 KiB |    474 MiB |    627 GiB |    627 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   4496 MiB |  18030 MiB |  90376 GiB |  90372 GiB |\n","|       from large pool |   4046 MiB |  17564 MiB |  90279 GiB |  90275 GiB |\n","|       from small pool |    450 MiB |    482 MiB |     97 GiB |     97 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   3853 MiB |   4554 MiB | 144834 GiB | 144830 GiB |\n","|       from large pool |   3849 MiB |   4550 MiB | 144134 GiB | 144131 GiB |\n","|       from small pool |      3 MiB |     18 MiB |    699 GiB |    699 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |    8797 K  |    8781 K  |\n","|       from large pool |      98    |     263    |    5360 K  |    5359 K  |\n","|       from small pool |   16251    |   16398    |    3437 K  |    3421 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |    8797 K  |    8781 K  |\n","|       from large pool |      98    |     263    |    5360 K  |    5359 K  |\n","|       from small pool |   16251    |   16398    |    3437 K  |    3421 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     249    |     333    |  504469    |  504220    |\n","|       from large pool |      24    |     100    |  454476    |  454452    |\n","|       from small pool |     225    |     241    |   49993    |   49768    |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      74    |     152    |    4251 K  |    4251 K  |\n","|       from large pool |      19    |      66    |    2872 K  |    2872 K  |\n","|       from small pool |      55    |     103    |    1378 K  |    1378 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:32/7698 batch_size:250\n","Next token prediction. step:81/201 batch:32/7698 epoch:2/10\n","full seq: Dikic, currently with the Goethe University in Frankfurt, has published 78 scientific manuscripts in prestigious journals and has received a number of international awards for his research.Ģġġġġġġġġġġġ\n","pref seq: Dikic, currently with the Goethe University in Frankfurt, has published 78 scient\n","next tok:                                                                                 i\n","pred tok:                                                                                 (\n","Completed batch.\n","epoch:2/10 batch:32/7698 batch_size:250 loss:1.1967015266418457 time_for_batch_instance:214.69060921669006 total_batch_time:7589.44256067276 running_batch_average:237.17008002102375\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 656033 KiB |  17269 MiB | 432153 GiB | 432153 GiB |\n","|       from large pool | 198583 KiB |  16827 MiB | 431506 GiB | 431506 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    646 GiB |    646 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 656033 KiB |  17269 MiB | 432153 GiB | 432153 GiB |\n","|       from large pool | 198583 KiB |  16827 MiB | 431506 GiB | 431506 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    646 GiB |    646 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  17249 MiB | 431313 GiB | 431312 GiB |\n","|       from large pool | 189056 KiB |  16810 MiB | 430666 GiB | 430666 GiB |\n","|       from small pool | 453671 KiB |    474 MiB |    646 GiB |    646 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   3506 MiB |  18050 MiB |  92961 GiB |  92958 GiB |\n","|       from large pool |   3056 MiB |  17584 MiB |  92861 GiB |  92858 GiB |\n","|       from small pool |    450 MiB |    482 MiB |    100 GiB |    100 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   2865 MiB |   4014 MiB | 148509 GiB | 148506 GiB |\n","|       from large pool |   2862 MiB |   4010 MiB | 147788 GiB | 147786 GiB |\n","|       from small pool |      3 MiB |     18 MiB |    720 GiB |    720 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |    9059 K  |    9042 K  |\n","|       from large pool |      98    |     263    |    5519 K  |    5519 K  |\n","|       from small pool |   16251    |   16398    |    3539 K  |    3523 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |    9059 K  |    9042 K  |\n","|       from large pool |      98    |     263    |    5519 K  |    5519 K  |\n","|       from small pool |   16251    |   16398    |    3539 K  |    3523 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     247    |     334    |  520233    |  519986    |\n","|       from large pool |      22    |     101    |  468717    |  468695    |\n","|       from small pool |     225    |     241    |   51516    |   51291    |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      77    |     135    |    4361 K  |    4361 K  |\n","|       from large pool |      19    |      50    |    2942 K  |    2942 K  |\n","|       from small pool |      58    |     103    |    1419 K  |    1419 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:33/7698 batch_size:250\n","Next token prediction. step:9/199 batch:33/7698 epoch:2/10\n","full seq: Romania, Macedonia, Serbia-Montenegro and Albania are among 60 countries where corruption is still rampant, according to Transparency International's Corruption Perceptions Index 2004.Ģġġġġġġġġġġġġġġ\n","pref seq: Romania, \n","next tok:         M\n","pred tok:         (\n","Completed batch.\n","epoch:2/10 batch:33/7698 batch_size:250 loss:0.9816495776176453 time_for_batch_instance:214.74250888824463 total_batch_time:7804.185069561005 running_batch_average:236.49045665336376\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 653737 KiB |  17004 MiB | 443372 GiB | 443372 GiB |\n","|       from large pool | 196287 KiB |  16563 MiB | 442707 GiB | 442707 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    665 GiB |    664 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 653737 KiB |  17004 MiB | 443372 GiB | 443372 GiB |\n","|       from large pool | 196287 KiB |  16563 MiB | 442707 GiB | 442707 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    665 GiB |    664 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  16967 MiB | 442508 GiB | 442508 GiB |\n","|       from large pool | 189056 KiB |  16529 MiB | 441843 GiB | 441843 GiB |\n","|       from small pool | 453671 KiB |    474 MiB |    664 GiB |    664 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1758 MiB |  17800 MiB |  95601 GiB |  95599 GiB |\n","|       from large pool |   1306 MiB |  17334 MiB |  95497 GiB |  95496 GiB |\n","|       from small pool |    452 MiB |    482 MiB |    103 GiB |    103 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1119 MiB |   2866 MiB | 151943 GiB | 151942 GiB |\n","|       from large pool |   1114 MiB |   2862 MiB | 151202 GiB | 151201 GiB |\n","|       from small pool |      5 MiB |     19 MiB |    740 GiB |    740 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |    9318 K  |    9301 K  |\n","|       from large pool |      98    |     263    |    5677 K  |    5677 K  |\n","|       from small pool |   16251    |   16398    |    3640 K  |    3624 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |    9318 K  |    9301 K  |\n","|       from large pool |      98    |     263    |    5677 K  |    5677 K  |\n","|       from small pool |   16251    |   16398    |    3640 K  |    3624 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     250    |     335    |  535928    |  535678    |\n","|       from large pool |      24    |     103    |  482933    |  482909    |\n","|       from small pool |     226    |     241    |   52995    |   52769    |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      77    |     149    |    4498 K  |    4498 K  |\n","|       from large pool |      20    |      64    |    3038 K  |    3038 K  |\n","|       from small pool |      57    |     103    |    1460 K  |    1460 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:34/7698 batch_size:250\n","Next token prediction. step:135/199 batch:34/7698 epoch:2/10\n","full seq: If they sort out the issue of arms exports [to Iraq], they could possibly join Partnership for Peace next year, and they would be one of the candidates for NATO in 2006 or 2007 as well.Ģġġġġġġġġġġġġġ\n","pref seq: If they sort out the issue of arms exports [to Iraq], they could possibly join Partnership for Peace next year, and they would be one o\n","next tok:                                                                                                                                       f\n","pred tok:                                                                                                                                       ,\n","Completed batch.\n","epoch:2/10 batch:34/7698 batch_size:250 loss:1.0141698122024536 time_for_batch_instance:215.04957795143127 total_batch_time:8019.234647512436 running_batch_average:235.85984257389518\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 653737 KiB |  17004 MiB | 454591 GiB | 454591 GiB |\n","|       from large pool | 196287 KiB |  16563 MiB | 453908 GiB | 453908 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    683 GiB |    683 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 653737 KiB |  17004 MiB | 454591 GiB | 454591 GiB |\n","|       from large pool | 196287 KiB |  16563 MiB | 453908 GiB | 453908 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    683 GiB |    683 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  16967 MiB | 453704 GiB | 453703 GiB |\n","|       from large pool | 189056 KiB |  16529 MiB | 453020 GiB | 453020 GiB |\n","|       from small pool | 453671 KiB |    474 MiB |    683 GiB |    682 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1758 MiB |  17800 MiB |  98240 GiB |  98239 GiB |\n","|       from large pool |   1306 MiB |  17334 MiB |  98134 GiB |  98133 GiB |\n","|       from small pool |    452 MiB |    482 MiB |    106 GiB |    105 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1119 MiB |   2556 MiB | 155386 GiB | 155385 GiB |\n","|       from large pool |   1114 MiB |   2550 MiB | 154625 GiB | 154624 GiB |\n","|       from small pool |      5 MiB |     18 MiB |    760 GiB |    760 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |    9576 K  |    9560 K  |\n","|       from large pool |      98    |     263    |    5834 K  |    5834 K  |\n","|       from small pool |   16251    |   16398    |    3742 K  |    3725 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |    9576 K  |    9560 K  |\n","|       from large pool |      98    |     263    |    5834 K  |    5834 K  |\n","|       from small pool |   16251    |   16398    |    3742 K  |    3725 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     250    |     335    |  551604    |  551354    |\n","|       from large pool |      24    |     103    |  497129    |  497105    |\n","|       from small pool |     226    |     241    |   54475    |   54249    |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      77    |     148    |    4635 K  |    4635 K  |\n","|       from large pool |      20    |      62    |    3134 K  |    3134 K  |\n","|       from small pool |      57    |     103    |    1501 K  |    1500 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:35/7698 batch_size:250\n","Next token prediction. step:91/199 batch:35/7698 epoch:2/10\n","full seq: On December 15th, the year-long EU NAVFOR mission, code-named Operation Atalanta, will replace the four-vessel NATO armada currently patrolling one of the world's busiest shipping lanes.Ģġġġġġġġġġġġġ\n","pref seq: On December 15th, the year-long EU NAVFOR mission, code-named Operation Atalanta, will repl\n","next tok:                                                                                           a\n","pred tok:                                                                                           ,\n","Completed batch.\n","epoch:2/10 batch:35/7698 batch_size:250 loss:1.167232871055603 time_for_batch_instance:216.8102126121521 total_batch_time:8236.044860124588 running_batch_average:235.31556743213108\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 653158 KiB |  17043 MiB | 465844 GiB | 465843 GiB |\n","|       from large pool | 195708 KiB |  16601 MiB | 465142 GiB | 465142 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    702 GiB |    701 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 653158 KiB |  17043 MiB | 465844 GiB | 465843 GiB |\n","|       from large pool | 195708 KiB |  16601 MiB | 465142 GiB | 465142 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    702 GiB |    701 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  17025 MiB | 464943 GiB | 464942 GiB |\n","|       from large pool | 189056 KiB |  16587 MiB | 464241 GiB | 464241 GiB |\n","|       from small pool | 453671 KiB |    474 MiB |    701 GiB |    701 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1482 MiB |  17846 MiB | 100948 GiB | 100947 GiB |\n","|       from large pool |   1032 MiB |  17380 MiB | 100839 GiB | 100838 GiB |\n","|       from small pool |    450 MiB |    482 MiB |    109 GiB |    108 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |    844 MiB |   1684 MiB | 158714 GiB | 158713 GiB |\n","|       from large pool |    840 MiB |   1678 MiB | 157933 GiB | 157932 GiB |\n","|       from small pool |      3 MiB |     19 MiB |    781 GiB |    781 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |    9835 K  |    9819 K  |\n","|       from large pool |      98    |     263    |    5992 K  |    5992 K  |\n","|       from small pool |   16251    |   16398    |    3843 K  |    3826 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |    9835 K  |    9819 K  |\n","|       from large pool |      98    |     263    |    5992 K  |    5992 K  |\n","|       from small pool |   16251    |   16398    |    3843 K  |    3826 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     246    |     338    |  567485    |  567239    |\n","|       from large pool |      21    |     105    |  511521    |  511500    |\n","|       from small pool |     225    |     241    |   55964    |   55739    |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      70    |     161    |    4772 K  |    4772 K  |\n","|       from large pool |      16    |      75    |    3231 K  |    3231 K  |\n","|       from small pool |      54    |     104    |    1541 K  |    1541 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:36/7698 batch_size:250\n","Next token prediction. step:95/199 batch:36/7698 epoch:2/10\n","full seq: The international financial institutions are urging the government to strengthen tax collection and ensure timely payments on the debt, which stood at 1 billion euros at the end of 2004.Ģġġġġġġġġġġġġ\n","pref seq: The international financial institutions are urging the government to strengthen tax collection\n","next tok:                                                                                                \n","pred tok:                                                                                               -\n","Completed batch.\n","epoch:2/10 batch:36/7698 batch_size:250 loss:1.131246566772461 time_for_batch_instance:216.0834789276123 total_batch_time:8452.1283390522 running_batch_average:234.78134275145\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 653158 KiB |  17043 MiB | 477096 GiB | 477096 GiB |\n","|       from large pool | 195708 KiB |  16601 MiB | 476376 GiB | 476376 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    720 GiB |    720 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 653158 KiB |  17043 MiB | 477096 GiB | 477096 GiB |\n","|       from large pool | 195708 KiB |  16601 MiB | 476376 GiB | 476376 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    720 GiB |    720 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  17025 MiB | 476182 GiB | 476181 GiB |\n","|       from large pool | 189056 KiB |  16587 MiB | 475462 GiB | 475462 GiB |\n","|       from small pool | 453671 KiB |    474 MiB |    720 GiB |    719 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1482 MiB |  17846 MiB | 103655 GiB | 103654 GiB |\n","|       from large pool |   1032 MiB |  17380 MiB | 103543 GiB | 103542 GiB |\n","|       from small pool |    450 MiB |    482 MiB |    112 GiB |    111 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |    844 MiB |   1684 MiB | 162037 GiB | 162036 GiB |\n","|       from large pool |    840 MiB |   1678 MiB | 161236 GiB | 161235 GiB |\n","|       from small pool |      3 MiB |     18 MiB |    801 GiB |    801 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   10094 K  |   10078 K  |\n","|       from large pool |      98    |     263    |    6150 K  |    6150 K  |\n","|       from small pool |   16251    |   16398    |    3944 K  |    3928 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   10094 K  |   10078 K  |\n","|       from large pool |      98    |     263    |    6150 K  |    6150 K  |\n","|       from small pool |   16251    |   16398    |    3944 K  |    3928 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     246    |     338    |  583352    |  583106    |\n","|       from large pool |      21    |     105    |  525898    |  525877    |\n","|       from small pool |     225    |     241    |   57454    |   57229    |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      70    |     161    |    4910 K  |    4910 K  |\n","|       from large pool |      16    |      75    |    3328 K  |    3328 K  |\n","|       from small pool |      54    |     104    |    1582 K  |    1582 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:37/7698 batch_size:250\n","Next token prediction. step:122/199 batch:37/7698 epoch:2/10\n","full seq: Rapid Guardian 2003 involves American and British components of a recently organised \"Over-The-Horizon-Force\" (OTHF) - a pool of forces from NATO and Partnership for Peace member nations.Ģġġġġġġġġġġġ\n","pref seq: Rapid Guardian 2003 involves American and British components of a recently organised \"Over-The-Horizon-Force\" (OTHF) - a p\n","next tok:                                                                                                                          o\n","pred tok:                                                                                                                          ,\n","Completed batch.\n","epoch:2/10 batch:37/7698 batch_size:250 loss:0.8253651857376099 time_for_batch_instance:213.71970295906067 total_batch_time:8665.848042011261 running_batch_average:234.2121092435476\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 654430 KiB |  17098 MiB | 488388 GiB | 488387 GiB |\n","|       from large pool | 196980 KiB |  16656 MiB | 487649 GiB | 487649 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    738 GiB |    738 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 654430 KiB |  17098 MiB | 488388 GiB | 488387 GiB |\n","|       from large pool | 196980 KiB |  16656 MiB | 487649 GiB | 487649 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    738 GiB |    738 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  17083 MiB | 487464 GiB | 487464 GiB |\n","|       from large pool | 189056 KiB |  16645 MiB | 486726 GiB | 486726 GiB |\n","|       from small pool | 453671 KiB |    474 MiB |    738 GiB |    737 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   3610 MiB |  17924 MiB | 105844 GiB | 105841 GiB |\n","|       from large pool |   3160 MiB |  17458 MiB | 105729 GiB | 105726 GiB |\n","|       from small pool |    450 MiB |    482 MiB |    115 GiB |    114 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   2970 MiB |   4435 MiB | 165776 GiB | 165774 GiB |\n","|       from large pool |   2967 MiB |   4432 MiB | 164955 GiB | 164952 GiB |\n","|       from small pool |      3 MiB |     19 MiB |    821 GiB |    821 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   10353 K  |   10337 K  |\n","|       from large pool |      98    |     263    |    6308 K  |    6307 K  |\n","|       from small pool |   16251    |   16398    |    4045 K  |    4029 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   10353 K  |   10337 K  |\n","|       from large pool |      98    |     263    |    6308 K  |    6307 K  |\n","|       from small pool |   16251    |   16398    |    4045 K  |    4029 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     254    |     335    |  597123    |  596869    |\n","|       from large pool |      29    |     102    |  538177    |  538148    |\n","|       from small pool |     225    |     241    |   58946    |   58721    |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      79    |     165    |    5056 K  |    5056 K  |\n","|       from large pool |      24    |      80    |    3433 K  |    3433 K  |\n","|       from small pool |      55    |     103    |    1623 K  |    1623 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:38/7698 batch_size:250\n","Next token prediction. step:188/198 batch:38/7698 epoch:2/10\n","full seq: Budget cuts, attractive conditions for foreign investment and growth of exports -- requiring an increase in product quality -- will stabilise the dinar and bring down inflation, it says.Ģġġġġġġġġġġġ\n","pref seq: Budget cuts, attractive conditions for foreign investment and growth of exports -- requiring an increase in product quality -- will stabilise the dinar and bring down inflation, it says.Ģġ\n","next tok:                                                                                                                                                                                            ġ\n","pred tok:                                                                                                                                                                                            Ģ\n","Completed batch.\n","epoch:2/10 batch:38/7698 batch_size:250 loss:2.116997241973877 time_for_batch_instance:214.33300471305847 total_batch_time:8880.18104672432 running_batch_average:233.6889749137979\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 655670 KiB |  16984 MiB | 499541 GiB | 499540 GiB |\n","|       from large pool | 198220 KiB |  16542 MiB | 498784 GiB | 498784 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    757 GiB |    756 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 655670 KiB |  16984 MiB | 499541 GiB | 499540 GiB |\n","|       from large pool | 198220 KiB |  16542 MiB | 498784 GiB | 498784 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    757 GiB |    756 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  16942 MiB | 498594 GiB | 498594 GiB |\n","|       from large pool | 189056 KiB |  16504 MiB | 497837 GiB | 497837 GiB |\n","|       from small pool | 453671 KiB |    474 MiB |    756 GiB |    756 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1836 MiB |  17752 MiB | 108465 GiB | 108463 GiB |\n","|       from large pool |   1386 MiB |  17288 MiB | 108347 GiB | 108345 GiB |\n","|       from small pool |    450 MiB |    482 MiB |    118 GiB |    117 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1195 MiB |   2974 MiB | 169194 GiB | 169192 GiB |\n","|       from large pool |   1192 MiB |   2970 MiB | 168351 GiB | 168350 GiB |\n","|       from small pool |      3 MiB |     19 MiB |    842 GiB |    842 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   10611 K  |   10594 K  |\n","|       from large pool |      98    |     263    |    6464 K  |    6464 K  |\n","|       from small pool |   16251    |   16398    |    4146 K  |    4129 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   10611 K  |   10594 K  |\n","|       from large pool |      98    |     263    |    6464 K  |    6464 K  |\n","|       from small pool |   16251    |   16398    |    4146 K  |    4129 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     248    |     338    |  612704    |  612456    |\n","|       from large pool |      23    |     106    |  552286    |  552263    |\n","|       from small pool |     225    |     241    |   60418    |   60193    |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      71    |     149    |    5192 K  |    5192 K  |\n","|       from large pool |      18    |      64    |    3528 K  |    3528 K  |\n","|       from small pool |      53    |     103    |    1663 K  |    1663 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:39/7698 batch_size:250\n","Next token prediction. step:121/197 batch:39/7698 epoch:2/10\n","full seq: (Bloomberg, Standart - 31/07/09; Reuters, Dnevnik, Mediapool, Novinite, Focus - 30/07/09; AFP, Reuters - 29/07/09; Sofia Echo, Mediapool - 28/07/09; FT - 27/07/09; Novinite - 26/07/09)Ģġġġġġġġġġġġġ\n","pref seq: (Bloomberg, Standart - 31/07/09; Reuters, Dnevnik, Mediapool, Novinite, Focus - 30/07/09; AFP, Reuters - 29/07/09; Sofia \n","next tok:                                                                                                                         E\n","pred tok:                                                                                                                         (\n","Completed batch.\n","epoch:2/10 batch:39/7698 batch_size:250 loss:1.6147615909576416 time_for_batch_instance:213.68279814720154 total_batch_time:9093.863844871521 running_batch_average:233.17599602234668\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 654957 KiB |  16885 MiB | 510574 GiB | 510574 GiB |\n","|       from large pool | 197507 KiB |  16443 MiB | 509799 GiB | 509799 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    775 GiB |    774 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 654957 KiB |  16885 MiB | 510574 GiB | 510574 GiB |\n","|       from large pool | 197507 KiB |  16443 MiB | 509799 GiB | 509799 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    775 GiB |    774 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  16859 MiB | 509615 GiB | 509614 GiB |\n","|       from large pool | 189056 KiB |  16421 MiB | 508840 GiB | 508840 GiB |\n","|       from small pool | 453671 KiB |    474 MiB |    774 GiB |    774 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1992 MiB |  17698 MiB | 110944 GiB | 110942 GiB |\n","|       from large pool |   1540 MiB |  17232 MiB | 110823 GiB | 110821 GiB |\n","|       from small pool |    452 MiB |    482 MiB |    120 GiB |    120 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1352 MiB |   2208 MiB | 173337 GiB | 173336 GiB |\n","|       from large pool |   1347 MiB |   2205 MiB | 172475 GiB | 172473 GiB |\n","|       from small pool |      5 MiB |     20 MiB |    862 GiB |    862 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   10867 K  |   10851 K  |\n","|       from large pool |      98    |     263    |    6621 K  |    6620 K  |\n","|       from small pool |   16251    |   16398    |    4246 K  |    4230 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   10867 K  |   10851 K  |\n","|       from large pool |      98    |     263    |    6621 K  |    6620 K  |\n","|       from small pool |   16251    |   16398    |    4246 K  |    4230 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     255    |     347    |  628246    |  627991    |\n","|       from large pool |      29    |     114    |  566345    |  566316    |\n","|       from small pool |     226    |     241    |   61901    |   61675    |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      77    |     161    |    5337 K  |    5337 K  |\n","|       from large pool |      23    |      77    |    3633 K  |    3633 K  |\n","|       from small pool |      54    |     102    |    1704 K  |    1704 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:40/7698 batch_size:250\n","Next token prediction. step:48/196 batch:40/7698 epoch:2/10\n","full seq: If it's useful for people in the Balkans to conduct more trade and business with Turkey -- I don't know if it will be useful -- but I also know that Brussels looks weak at the moment.Ģġġġġġġġġġġġġ\n","pref seq: If it's useful for people in the Balkans to cond\n","next tok:                                                u\n","pred tok:                                                ,\n","Completed batch.\n","epoch:2/10 batch:40/7698 batch_size:250 loss:1.2065035104751587 time_for_batch_instance:212.17182898521423 total_batch_time:9306.035673856735 running_batch_average:232.65089184641838\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 657909 KiB |  16814 MiB | 521508 GiB | 521507 GiB |\n","|       from large pool | 200459 KiB |  16372 MiB | 520715 GiB | 520714 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    793 GiB |    793 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 657909 KiB |  16814 MiB | 521508 GiB | 521507 GiB |\n","|       from large pool | 200459 KiB |  16372 MiB | 520715 GiB | 520714 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    793 GiB |    793 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  16776 MiB | 520528 GiB | 520527 GiB |\n","|       from large pool | 189056 KiB |  16339 MiB | 519735 GiB | 519734 GiB |\n","|       from small pool | 453671 KiB |    474 MiB |    793 GiB |    792 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2420 MiB |  17558 MiB | 113480 GiB | 113478 GiB |\n","|       from large pool |   1968 MiB |  17090 MiB | 113356 GiB | 113355 GiB |\n","|       from small pool |    452 MiB |    482 MiB |    123 GiB |    123 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1777 MiB |   2559 MiB | 176639 GiB | 176637 GiB |\n","|       from large pool |   1772 MiB |   2557 MiB | 175757 GiB | 175755 GiB |\n","|       from small pool |      5 MiB |     19 MiB |    882 GiB |    882 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   11122 K  |   11106 K  |\n","|       from large pool |      98    |     263    |    6776 K  |    6776 K  |\n","|       from small pool |   16251    |   16398    |    4346 K  |    4329 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   11122 K  |   11106 K  |\n","|       from large pool |      98    |     263    |    6776 K  |    6776 K  |\n","|       from small pool |   16251    |   16398    |    4346 K  |    4329 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     245    |     339    |  644161    |  643916    |\n","|       from large pool |      19    |     105    |  580754    |  580735    |\n","|       from small pool |     226    |     241    |   63407    |   63181    |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      72    |     127    |    5436 K  |    5436 K  |\n","|       from large pool |      13    |      41    |    3692 K  |    3692 K  |\n","|       from small pool |      59    |     102    |    1743 K  |    1743 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:41/7698 batch_size:250\n","Next token prediction. step:63/196 batch:41/7698 epoch:2/10\n","full seq: The Lions are demanding to be granted regular police status and their back wages be paid. They also want a meeting with President Boris Trajkovski and Prime Minister Branko Crvenkovski.Ģġġġġġġġġġġ\n","pref seq: The Lions are demanding to be granted regular police status and\n","next tok:                                                                \n","pred tok:                                                               i\n","Completed batch.\n","epoch:2/10 batch:41/7698 batch_size:250 loss:2.059006690979004 time_for_batch_instance:212.139164686203 total_batch_time:9518.174838542938 running_batch_average:232.15060581812045\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 654729 KiB |  16862 MiB | 532476 GiB | 532475 GiB |\n","|       from large pool | 197279 KiB |  16421 MiB | 531664 GiB | 531664 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    811 GiB |    811 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 654729 KiB |  16862 MiB | 532476 GiB | 532475 GiB |\n","|       from large pool | 197279 KiB |  16421 MiB | 531664 GiB | 531664 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    811 GiB |    811 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  16834 MiB | 531483 GiB | 531482 GiB |\n","|       from large pool | 189056 KiB |  16397 MiB | 530672 GiB | 530672 GiB |\n","|       from small pool | 453671 KiB |    474 MiB |    811 GiB |    810 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2102 MiB |  17684 MiB | 115946 GiB | 115944 GiB |\n","|       from large pool |   1650 MiB |  17218 MiB | 115819 GiB | 115818 GiB |\n","|       from small pool |    452 MiB |    482 MiB |    126 GiB |    126 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1462 MiB |   2160 MiB | 180761 GiB | 180760 GiB |\n","|       from large pool |   1457 MiB |   2157 MiB | 179859 GiB | 179857 GiB |\n","|       from small pool |      5 MiB |     20 MiB |    902 GiB |    902 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   11377 K  |   11360 K  |\n","|       from large pool |      98    |     263    |    6931 K  |    6931 K  |\n","|       from small pool |   16251    |   16398    |    4445 K  |    4429 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   11377 K  |   11360 K  |\n","|       from large pool |      98    |     263    |    6931 K  |    6931 K  |\n","|       from small pool |   16251    |   16398    |    4445 K  |    4429 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     256    |     350    |  659742    |  659486    |\n","|       from large pool |      30    |     117    |  594860    |  594830    |\n","|       from small pool |     226    |     241    |   64882    |   64656    |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      78    |     165    |    5580 K  |    5580 K  |\n","|       from large pool |      24    |      79    |    3796 K  |    3796 K  |\n","|       from small pool |      54    |     102    |    1783 K  |    1783 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:42/7698 batch_size:250\n","Next token prediction. step:52/195 batch:42/7698 epoch:2/10\n","full seq: The human resource development component will help prepare candidate countries for management and implementation of the European Social Fund within the European Employment Strategy.Ģġġġġġġġġġġġġġ\n","pref seq: The human resource development component will help p\n","next tok:                                                    r\n","pred tok:                                                    w\n","Completed batch.\n","epoch:2/10 batch:42/7698 batch_size:250 loss:1.0063588619232178 time_for_batch_instance:212.03674960136414 total_batch_time:9730.211588144302 running_batch_average:231.67170447962624\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 654281 KiB |  16732 MiB | 543304 GiB | 543304 GiB |\n","|       from large pool | 196831 KiB |  16291 MiB | 542475 GiB | 542474 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    829 GiB |    829 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 654281 KiB |  16732 MiB | 543304 GiB | 543304 GiB |\n","|       from large pool | 196831 KiB |  16291 MiB | 542475 GiB | 542474 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    829 GiB |    829 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  16694 MiB | 542288 GiB | 542287 GiB |\n","|       from large pool | 189056 KiB |  16256 MiB | 541459 GiB | 541458 GiB |\n","|       from small pool | 453671 KiB |    474 MiB |    829 GiB |    828 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2362 MiB |  17462 MiB | 118443 GiB | 118440 GiB |\n","|       from large pool |   1910 MiB |  16996 MiB | 118313 GiB | 118311 GiB |\n","|       from small pool |    452 MiB |    482 MiB |    129 GiB |    129 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1723 MiB |   3224 MiB | 184058 GiB | 184057 GiB |\n","|       from large pool |   1717 MiB |   3219 MiB | 183137 GiB | 183135 GiB |\n","|       from small pool |      5 MiB |     17 MiB |    921 GiB |    921 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   11630 K  |   11614 K  |\n","|       from large pool |      98    |     263    |    7086 K  |    7086 K  |\n","|       from small pool |   16251    |   16398    |    4544 K  |    4528 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   11630 K  |   11614 K  |\n","|       from large pool |      98    |     263    |    7086 K  |    7086 K  |\n","|       from small pool |   16251    |   16398    |    4544 K  |    4528 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     243    |     334    |  675370    |  675127    |\n","|       from large pool |      17    |     101    |  609030    |  609013    |\n","|       from small pool |     226    |     241    |   66340    |   66114    |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      74    |     133    |    5686 K  |    5686 K  |\n","|       from large pool |      15    |      48    |    3863 K  |    3863 K  |\n","|       from small pool |      59    |     102    |    1823 K  |    1823 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:43/7698 batch_size:250\n","Next token prediction. step:157/194 batch:43/7698 epoch:2/10\n","full seq: The EU's mediator, Robert Cooper, met with officials in Belgrade and Pristina this week in an effort to defuse the crisis in northern Kosovo and get bilateral dialogue back on track.Ģġġġġġġġġġġġ\n","pref seq: The EU's mediator, Robert Cooper, met with officials in Belgrade and Pristina this week in an effort to defuse the crisis in northern Kosovo and get bilatera\n","next tok:                                                                                                                                                             l\n","pred tok:                                                                                                                                                              \n","Completed batch.\n","epoch:2/10 batch:43/7698 batch_size:250 loss:1.969281792640686 time_for_batch_instance:207.9903643131256 total_batch_time:9938.201952457428 running_batch_average:231.12097563854485\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 654104 KiB |  16625 MiB | 554025 GiB | 554024 GiB |\n","|       from large pool | 196654 KiB |  16184 MiB | 553177 GiB | 553177 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    847 GiB |    847 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 654104 KiB |  16625 MiB | 554025 GiB | 554024 GiB |\n","|       from large pool | 196654 KiB |  16184 MiB | 553177 GiB | 553177 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    847 GiB |    847 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  16609 MiB | 552985 GiB | 552985 GiB |\n","|       from large pool | 189056 KiB |  16172 MiB | 552138 GiB | 552138 GiB |\n","|       from small pool | 453671 KiB |    474 MiB |    847 GiB |    846 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   3354 MiB |  17440 MiB | 120658 GiB | 120655 GiB |\n","|       from large pool |   2902 MiB |  16972 MiB | 120526 GiB | 120523 GiB |\n","|       from small pool |    452 MiB |    482 MiB |    132 GiB |    132 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   2715 MiB |   3326 MiB | 188330 GiB | 188327 GiB |\n","|       from large pool |   2709 MiB |   3320 MiB | 187388 GiB | 187386 GiB |\n","|       from small pool |      5 MiB |     19 MiB |    941 GiB |    941 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   11883 K  |   11866 K  |\n","|       from large pool |      98    |     263    |    7239 K  |    7239 K  |\n","|       from small pool |   16251    |   16398    |    4643 K  |    4627 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   11883 K  |   11866 K  |\n","|       from large pool |      98    |     263    |    7239 K  |    7239 K  |\n","|       from small pool |   16251    |   16398    |    4643 K  |    4627 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     252    |     340    |  689581    |  689329    |\n","|       from large pool |      26    |     106    |  621768    |  621742    |\n","|       from small pool |     226    |     241    |   67813    |   67587    |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      82    |     160    |    5809 K  |    5809 K  |\n","|       from large pool |      22    |      74    |    3947 K  |    3947 K  |\n","|       from small pool |      60    |     102    |    1861 K  |    1861 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:44/7698 batch_size:250\n","Next token prediction. step:102/193 batch:44/7698 epoch:2/10\n","full seq: With authorities refusing to acknowledge the defeat the Socialist Party of Serbia and its coalition partner, Yugoslav Left, civil and student protests erupted and lasted for 88 days.Ģġġġġġġġġġġ\n","pref seq: With authorities refusing to acknowledge the defeat the Socialist Party of Serbia and its coalition pa\n","next tok:                                                                                                      r\n","pred tok:                                                                                                      -\n","Completed batch.\n","epoch:2/10 batch:44/7698 batch_size:250 loss:1.181191086769104 time_for_batch_instance:208.02281188964844 total_batch_time:10146.224764347076 running_batch_average:230.59601737152445\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 654104 KiB |  16607 MiB | 564681 GiB | 564681 GiB |\n","|       from large pool | 196654 KiB |  16166 MiB | 563816 GiB | 563816 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    865 GiB |    864 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 654104 KiB |  16607 MiB | 564681 GiB | 564681 GiB |\n","|       from large pool | 196654 KiB |  16166 MiB | 563816 GiB | 563816 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    865 GiB |    864 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  16585 MiB | 563619 GiB | 563618 GiB |\n","|       from large pool | 189056 KiB |  16147 MiB | 562754 GiB | 562754 GiB |\n","|       from small pool | 453671 KiB |    474 MiB |    864 GiB |    864 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   3354 MiB |  17412 MiB | 122857 GiB | 122854 GiB |\n","|       from large pool |   2902 MiB |  16944 MiB | 122722 GiB | 122719 GiB |\n","|       from small pool |    452 MiB |    482 MiB |    135 GiB |    134 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   2715 MiB |   3381 MiB | 192642 GiB | 192640 GiB |\n","|       from large pool |   2709 MiB |   3375 MiB | 191681 GiB | 191679 GiB |\n","|       from small pool |      5 MiB |     17 MiB |    961 GiB |    961 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   12134 K  |   12117 K  |\n","|       from large pool |      98    |     263    |    7392 K  |    7392 K  |\n","|       from small pool |   16251    |   16398    |    4741 K  |    4725 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   12134 K  |   12117 K  |\n","|       from large pool |      98    |     263    |    7392 K  |    7392 K  |\n","|       from small pool |   16251    |   16398    |    4741 K  |    4725 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     252    |     340    |  703744    |  703492    |\n","|       from large pool |      26    |     106    |  634465    |  634439    |\n","|       from small pool |     226    |     241    |   69279    |   69053    |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      77    |     158    |    5931 K  |    5931 K  |\n","|       from large pool |      22    |      73    |    4030 K  |    4030 K  |\n","|       from small pool |      55    |     102    |    1900 K  |    1900 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:45/7698 batch_size:250\n","Next token prediction. step:123/192 batch:45/7698 epoch:2/10\n","full seq: The leaders of the Romanian community in Italy saluted the government's decision to fully open the internal work market for Romanians, pointing out the benefits of such a measure.Ģġġġġġġġġġġġġ\n","pref seq: The leaders of the Romanian community in Italy saluted the government's decision to fully open the internal work market for\n","next tok:                                                                                                                            \n","pred tok:                                                                                                                           (\n","Completed batch.\n","epoch:2/10 batch:45/7698 batch_size:250 loss:1.1032893657684326 time_for_batch_instance:206.24688506126404 total_batch_time:10352.47164940834 running_batch_average:230.05492554240757\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 653574 KiB |  16463 MiB | 575122 GiB | 575122 GiB |\n","|       from large pool | 196124 KiB |  16021 MiB | 574239 GiB | 574239 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    883 GiB |    882 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 653574 KiB |  16463 MiB | 575122 GiB | 575122 GiB |\n","|       from large pool | 196124 KiB |  16021 MiB | 574239 GiB | 574239 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    883 GiB |    882 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  16442 MiB | 574051 GiB | 574050 GiB |\n","|       from large pool | 189056 KiB |  16004 MiB | 573168 GiB | 573168 GiB |\n","|       from small pool | 453671 KiB |    474 MiB |    882 GiB |    882 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   3578 MiB |  17254 MiB | 125050 GiB | 125047 GiB |\n","|       from large pool |   3126 MiB |  16788 MiB | 124912 GiB | 124909 GiB |\n","|       from small pool |    452 MiB |    480 MiB |    138 GiB |    137 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   2939 MiB |   4062 MiB | 196229 GiB | 196227 GiB |\n","|       from large pool |   2934 MiB |   4056 MiB | 195249 GiB | 195246 GiB |\n","|       from small pool |      5 MiB |     17 MiB |    980 GiB |    980 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   12383 K  |   12367 K  |\n","|       from large pool |      98    |     263    |    7544 K  |    7544 K  |\n","|       from small pool |   16251    |   16398    |    4839 K  |    4823 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   12383 K  |   12367 K  |\n","|       from large pool |      98    |     263    |    7544 K  |    7544 K  |\n","|       from small pool |   16251    |   16398    |    4839 K  |    4823 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     248    |     335    |  717803    |  717555    |\n","|       from large pool |      22    |     102    |  647059    |  647037    |\n","|       from small pool |     226    |     240    |   70744    |   70518    |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      86    |     167    |    6070 K  |    6070 K  |\n","|       from large pool |      28    |      82    |    4131 K  |    4131 K  |\n","|       from small pool |      58    |     102    |    1939 K  |    1939 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:46/7698 batch_size:250\n","Next token prediction. step:50/192 batch:46/7698 epoch:2/10\n","full seq: Branimir Glavas, a parliamentary representative from the Croatian region of Slavonia, is the highest-ranking politician in the country to be officially investigated for war crimes.Ģġġġġġġġġġġġ\n","pref seq: Branimir Glavas, a parliamentary representative fr\n","next tok:                                                  o\n","pred tok:                                                  G\n","Completed batch.\n","epoch:2/10 batch:46/7698 batch_size:250 loss:1.7349419593811035 time_for_batch_instance:207.23816394805908 total_batch_time:10559.7098133564 running_batch_average:229.55890898600867\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 655627 KiB |  16462 MiB | 585563 GiB | 585563 GiB |\n","|       from large pool | 198177 KiB |  16021 MiB | 584663 GiB | 584662 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    900 GiB |    900 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 655627 KiB |  16462 MiB | 585563 GiB | 585563 GiB |\n","|       from large pool | 198177 KiB |  16021 MiB | 584663 GiB | 584662 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    900 GiB |    900 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  16442 MiB | 584483 GiB | 584483 GiB |\n","|       from large pool | 189056 KiB |  16004 MiB | 583583 GiB | 583583 GiB |\n","|       from small pool | 453671 KiB |    474 MiB |    900 GiB |    899 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   3676 MiB |  17256 MiB | 127286 GiB | 127282 GiB |\n","|       from large pool |   3224 MiB |  16790 MiB | 127145 GiB | 127142 GiB |\n","|       from small pool |    452 MiB |    480 MiB |    141 GiB |    140 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   3035 MiB |   4145 MiB | 199721 GiB | 199718 GiB |\n","|       from large pool |   3030 MiB |   4140 MiB | 198721 GiB | 198718 GiB |\n","|       from small pool |      5 MiB |     17 MiB |    999 GiB |    999 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   12633 K  |   12617 K  |\n","|       from large pool |      98    |     263    |    7696 K  |    7696 K  |\n","|       from small pool |   16251    |   16398    |    4936 K  |    4920 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   12633 K  |   12617 K  |\n","|       from large pool |      98    |     263    |    7696 K  |    7696 K  |\n","|       from small pool |   16251    |   16398    |    4936 K  |    4920 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     249    |     334    |  732047    |  731798    |\n","|       from large pool |      23    |     101    |  659838    |  659815    |\n","|       from small pool |     226    |     240    |   72209    |   71983    |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      82    |     165    |    6211 K  |    6211 K  |\n","|       from large pool |      24    |      80    |    4233 K  |    4233 K  |\n","|       from small pool |      58    |     102    |    1978 K  |    1978 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:47/7698 batch_size:250\n","Next token prediction. step:12/192 batch:47/7698 epoch:2/10\n","full seq: Nineteen people were killed and nearly 1,000 were injured during the two days of riots, which also led to the destruction or damage of hundreds of homes and Serbian religious sites.Ģġġġġġġġġġġ\n","pref seq: Nineteen peo\n","next tok:            p\n","pred tok:            G\n","Completed batch.\n","epoch:2/10 batch:47/7698 batch_size:250 loss:2.0409486293792725 time_for_batch_instance:206.45069885253906 total_batch_time:10766.160512208939 running_batch_average:229.06724494061572\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 655627 KiB |  16462 MiB | 596005 GiB | 596004 GiB |\n","|       from large pool | 198177 KiB |  16021 MiB | 595086 GiB | 595086 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    918 GiB |    918 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 655627 KiB |  16462 MiB | 596005 GiB | 596004 GiB |\n","|       from large pool | 198177 KiB |  16021 MiB | 595086 GiB | 595086 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    918 GiB |    918 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  16442 MiB | 594916 GiB | 594915 GiB |\n","|       from large pool | 189056 KiB |  16004 MiB | 593998 GiB | 593997 GiB |\n","|       from small pool | 453671 KiB |    474 MiB |    917 GiB |    917 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   3676 MiB |  17256 MiB | 129511 GiB | 129507 GiB |\n","|       from large pool |   3224 MiB |  16790 MiB | 129367 GiB | 129364 GiB |\n","|       from small pool |    452 MiB |    480 MiB |    143 GiB |    143 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   3035 MiB |   4145 MiB | 203228 GiB | 203225 GiB |\n","|       from large pool |   3030 MiB |   4140 MiB | 202209 GiB | 202206 GiB |\n","|       from small pool |      5 MiB |     17 MiB |   1019 GiB |   1019 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   12883 K  |   12866 K  |\n","|       from large pool |      98    |     263    |    7848 K  |    7848 K  |\n","|       from small pool |   16251    |   16398    |    5034 K  |    5018 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   12883 K  |   12866 K  |\n","|       from large pool |      98    |     263    |    7848 K  |    7848 K  |\n","|       from small pool |   16251    |   16398    |    5034 K  |    5018 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     249    |     334    |  746240    |  745991    |\n","|       from large pool |      23    |     101    |  672566    |  672543    |\n","|       from small pool |     226    |     240    |   73674    |   73448    |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      82    |     165    |    6352 K  |    6352 K  |\n","|       from large pool |      24    |      80    |    4335 K  |    4335 K  |\n","|       from small pool |      58    |     102    |    2016 K  |    2016 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:48/7698 batch_size:250\n","Next token prediction. step:60/191 batch:48/7698 epoch:2/10\n","full seq: Although there has been no clear cut explanation for the request, media speculation suggests that the Belgrade group wanted the minority rights discussion dropped from the agenda.Ģġġġġġġġġġġġ\n","pref seq: Although there has been no clear cut explanation for the req\n","next tok:                                                            u\n","pred tok:                                                            j\n","Completed batch.\n","epoch:2/10 batch:48/7698 batch_size:250 loss:1.0013493299484253 time_for_batch_instance:206.5547947883606 total_batch_time:10972.7153069973 running_batch_average:228.59823556244373\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 654216 KiB |  16392 MiB | 606352 GiB | 606352 GiB |\n","|       from large pool | 196766 KiB |  15951 MiB | 605416 GiB | 605416 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    936 GiB |    935 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 654216 KiB |  16392 MiB | 606352 GiB | 606352 GiB |\n","|       from large pool | 196766 KiB |  15951 MiB | 605416 GiB | 605416 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    936 GiB |    935 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  16359 MiB | 605243 GiB | 605242 GiB |\n","|       from large pool | 189056 KiB |  15921 MiB | 604307 GiB | 604307 GiB |\n","|       from small pool | 453671 KiB |    474 MiB |    935 GiB |    935 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   3014 MiB |  17178 MiB | 131761 GiB | 131758 GiB |\n","|       from large pool |   2562 MiB |  16712 MiB | 131615 GiB | 131612 GiB |\n","|       from small pool |    452 MiB |    480 MiB |    146 GiB |    146 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   2375 MiB |   3638 MiB | 206600 GiB | 206597 GiB |\n","|       from large pool |   2369 MiB |   3633 MiB | 205561 GiB | 205558 GiB |\n","|       from small pool |      5 MiB |     17 MiB |   1038 GiB |   1038 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   13131 K  |   13115 K  |\n","|       from large pool |      98    |     263    |    7999 K  |    7999 K  |\n","|       from small pool |   16251    |   16398    |    5131 K  |    5115 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   13131 K  |   13115 K  |\n","|       from large pool |      98    |     263    |    7999 K  |    7999 K  |\n","|       from small pool |   16251    |   16398    |    5131 K  |    5115 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     248    |     335    |     760 K  |     760 K  |\n","|       from large pool |      22    |     102    |     685 K  |     685 K  |\n","|       from small pool |     226    |     240    |      75 K  |      74 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      78    |     145    |    6474 K  |    6474 K  |\n","|       from large pool |      21    |      61    |    4418 K  |    4418 K  |\n","|       from small pool |      57    |     102    |    2055 K  |    2055 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:49/7698 batch_size:250\n","Next token prediction. step:78/190 batch:49/7698 epoch:2/10\n","full seq: In urban areas, 91 per cent of children attend school while in rural areas 90 per cent attend. The vast majority (88 per cent) of the population over 15 years of age is literate.Ģġġġġġġġġġġġ\n","pref seq: In urban areas, 91 per cent of children attend school while in rural areas 90 \n","next tok:                                                                              p\n","pred tok:                                                                              z\n","Completed batch.\n","epoch:2/10 batch:49/7698 batch_size:250 loss:0.9600226283073425 time_for_batch_instance:204.39130544662476 total_batch_time:11177.106612443924 running_batch_average:228.10421658048824\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 654927 KiB |  16368 MiB | 616637 GiB | 616636 GiB |\n","|       from large pool | 197477 KiB |  15927 MiB | 615683 GiB | 615683 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    953 GiB |    953 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 654927 KiB |  16368 MiB | 616637 GiB | 616636 GiB |\n","|       from large pool | 197477 KiB |  15927 MiB | 615683 GiB | 615683 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    953 GiB |    953 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  16334 MiB | 615508 GiB | 615507 GiB |\n","|       from large pool | 189056 KiB |  15897 MiB | 614554 GiB | 614554 GiB |\n","|       from small pool | 453671 KiB |    474 MiB |    953 GiB |    952 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   3542 MiB |  17122 MiB | 133968 GiB | 133965 GiB |\n","|       from large pool |   3090 MiB |  16656 MiB | 133819 GiB | 133816 GiB |\n","|       from small pool |    452 MiB |    480 MiB |    149 GiB |    149 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   2902 MiB |   3843 MiB | 209954 GiB | 209951 GiB |\n","|       from large pool |   2897 MiB |   3839 MiB | 208896 GiB | 208893 GiB |\n","|       from small pool |      5 MiB |     17 MiB |   1058 GiB |   1058 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   13378 K  |   13362 K  |\n","|       from large pool |      98    |     263    |    8150 K  |    8150 K  |\n","|       from small pool |   16251    |   16398    |    5228 K  |    5212 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   13378 K  |   13362 K  |\n","|       from large pool |      98    |     263    |    8150 K  |    8150 K  |\n","|       from small pool |   16251    |   16398    |    5228 K  |    5212 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     247    |     335    |     775 K  |     774 K  |\n","|       from large pool |      21    |     102    |     698 K  |     698 K  |\n","|       from small pool |     226    |     240    |      76 K  |      76 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      75    |     145    |    6595 K  |    6595 K  |\n","|       from large pool |      18    |      59    |    4501 K  |    4501 K  |\n","|       from small pool |      57    |     102    |    2094 K  |    2094 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:50/7698 batch_size:250\n","Next token prediction. step:113/190 batch:50/7698 epoch:2/10\n","full seq: Fearing that they could be infected with the H5 virus, authorities shot dead the rest of the birds in the flock, disinfected the area and set up a surrounding 3km protection zone.Ģġġġġġġġġġġ\n","pref seq: Fearing that they could be infected with the H5 virus, authorities shot dead the rest of the birds in the flock, \n","next tok:                                                                                                                 d\n","pred tok:                                                                                                                 ,\n","Completed batch.\n","epoch:2/10 batch:50/7698 batch_size:250 loss:0.8222107887268066 time_for_batch_instance:204.47818541526794 total_batch_time:11381.584797859192 running_batch_average:227.63169595718384\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 656168 KiB |  16308 MiB | 626878 GiB | 626877 GiB |\n","|       from large pool | 198718 KiB |  15867 MiB | 625907 GiB | 625907 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    971 GiB |    970 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 656168 KiB |  16308 MiB | 626878 GiB | 626877 GiB |\n","|       from large pool | 198718 KiB |  15867 MiB | 625907 GiB | 625907 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    971 GiB |    970 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  16276 MiB | 625730 GiB | 625730 GiB |\n","|       from large pool | 189056 KiB |  15839 MiB | 624760 GiB | 624760 GiB |\n","|       from small pool | 453671 KiB |    474 MiB |    970 GiB |    970 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   3756 MiB |  17066 MiB | 136252 GiB | 136248 GiB |\n","|       from large pool |   3304 MiB |  16598 MiB | 136099 GiB | 136096 GiB |\n","|       from small pool |    452 MiB |    480 MiB |    152 GiB |    151 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   3115 MiB |   3474 MiB | 213306 GiB | 213303 GiB |\n","|       from large pool |   3109 MiB |   3469 MiB | 212228 GiB | 212225 GiB |\n","|       from small pool |      5 MiB |     16 MiB |   1077 GiB |   1077 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   13625 K  |   13609 K  |\n","|       from large pool |      98    |     263    |    8300 K  |    8300 K  |\n","|       from small pool |   16251    |   16398    |    5325 K  |    5308 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   13625 K  |   13609 K  |\n","|       from large pool |      98    |     263    |    8300 K  |    8300 K  |\n","|       from small pool |   16251    |   16398    |    5325 K  |    5308 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     246    |     335    |     789 K  |     789 K  |\n","|       from large pool |      20    |     101    |     711 K  |     711 K  |\n","|       from small pool |     226    |     240    |      78 K  |      77 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      72    |     144    |    6723 K  |    6723 K  |\n","|       from large pool |      16    |      58    |    4591 K  |    4591 K  |\n","|       from small pool |      56    |     102    |    2132 K  |    2132 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:51/7698 batch_size:250\n","Next token prediction. step:8/190 batch:51/7698 epoch:2/10\n","full seq: Arriving in Pristina for consultations with the Kosovo negotiating team, he said he was bringing a message of \"full support\" from Washington for completing the process during 2006.Ģġġġġġġġġġ\n","pref seq: Arriving\n","next tok:         \n","pred tok:        V\n","Completed batch.\n","epoch:2/10 batch:51/7698 batch_size:250 loss:1.1244927644729614 time_for_batch_instance:205.0016496181488 total_batch_time:11586.58644747734 running_batch_average:227.18796955837922\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 655686 KiB |  16308 MiB | 637119 GiB | 637119 GiB |\n","|       from large pool | 198236 KiB |  15866 MiB | 636130 GiB | 636130 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    988 GiB |    988 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 655686 KiB |  16308 MiB | 637119 GiB | 637119 GiB |\n","|       from large pool | 198236 KiB |  15866 MiB | 636130 GiB | 636130 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |    988 GiB |    988 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  16276 MiB | 635953 GiB | 635953 GiB |\n","|       from large pool | 189056 KiB |  15839 MiB | 634965 GiB | 634965 GiB |\n","|       from small pool | 453671 KiB |    474 MiB |    988 GiB |    987 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   3434 MiB |  17076 MiB | 138550 GiB | 138547 GiB |\n","|       from large pool |   2982 MiB |  16608 MiB | 138395 GiB | 138392 GiB |\n","|       from small pool |    452 MiB |    480 MiB |    155 GiB |    154 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   2793 MiB |   3125 MiB | 216702 GiB | 216699 GiB |\n","|       from large pool |   2788 MiB |   3117 MiB | 215605 GiB | 215603 GiB |\n","|       from small pool |      5 MiB |     16 MiB |   1096 GiB |   1096 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   13872 K  |   13856 K  |\n","|       from large pool |      98    |     263    |    8450 K  |    8450 K  |\n","|       from small pool |   16251    |   16398    |    5421 K  |    5405 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   13872 K  |   13856 K  |\n","|       from large pool |      98    |     263    |    8450 K  |    8450 K  |\n","|       from small pool |   16251    |   16398    |    5421 K  |    5405 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     245    |     335    |     804 K  |     804 K  |\n","|       from large pool |      19    |     101    |     724 K  |     724 K  |\n","|       from small pool |     226    |     240    |      79 K  |      79 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      70    |     145    |    6852 K  |    6852 K  |\n","|       from large pool |      14    |      59    |    4681 K  |    4681 K  |\n","|       from small pool |      56    |     102    |    2170 K  |    2170 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:52/7698 batch_size:250\n","Next token prediction. step:67/189 batch:52/7698 epoch:2/10\n","full seq: According to team leader Marlena Krusteva, the site contains evidence about the religion, rituals and practices of the people that once inhabited the ancient region of Apolonia.Ģġġġġġġġġġġġ\n","pref seq: According to team leader Marlena Krusteva, the site contains eviden\n","next tok:                                                                   c\n","pred tok:                                                                   j\n","Completed batch.\n","epoch:2/10 batch:52/7698 batch_size:250 loss:1.093137264251709 time_for_batch_instance:203.58193469047546 total_batch_time:11790.168382167816 running_batch_average:226.73400734938107\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 655093 KiB |  16219 MiB | 647251 GiB | 647250 GiB |\n","|       from large pool | 197643 KiB |  15778 MiB | 646245 GiB | 646245 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |   1006 GiB |   1005 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 655093 KiB |  16219 MiB | 647251 GiB | 647250 GiB |\n","|       from large pool | 197643 KiB |  15778 MiB | 646245 GiB | 646245 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |   1006 GiB |   1005 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  16193 MiB | 646072 GiB | 646071 GiB |\n","|       from large pool | 189056 KiB |  15756 MiB | 645066 GiB | 645066 GiB |\n","|       from small pool | 453671 KiB |    474 MiB |   1005 GiB |   1005 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1956 MiB |  17008 MiB | 140856 GiB | 140854 GiB |\n","|       from large pool |   1504 MiB |  16540 MiB | 140698 GiB | 140696 GiB |\n","|       from small pool |    452 MiB |    480 MiB |    158 GiB |    157 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1316 MiB |   2822 MiB | 220183 GiB | 220181 GiB |\n","|       from large pool |   1310 MiB |   2811 MiB | 219067 GiB | 219066 GiB |\n","|       from small pool |      5 MiB |     17 MiB |   1115 GiB |   1115 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   14118 K  |   14102 K  |\n","|       from large pool |      98    |     263    |    8600 K  |    8600 K  |\n","|       from small pool |   16251    |   16398    |    5518 K  |    5501 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   14118 K  |   14102 K  |\n","|       from large pool |      98    |     263    |    8600 K  |    8600 K  |\n","|       from small pool |   16251    |   16398    |    5518 K  |    5501 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     255    |     350    |     819 K  |     819 K  |\n","|       from large pool |      29    |     117    |     738 K  |     738 K  |\n","|       from small pool |     226    |     240    |      80 K  |      80 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      82    |     156    |    6991 K  |    6991 K  |\n","|       from large pool |      23    |      71    |    4782 K  |    4782 K  |\n","|       from small pool |      59    |     102    |    2208 K  |    2208 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:53/7698 batch_size:250\n","Next token prediction. step:101/187 batch:53/7698 epoch:2/10\n","full seq: Foreign Minister Dora Bakoyannis says she expects \"authorities in Skopje to show a different political approach\", one which is oriented towards a mutually acceptable solution.Ģġġġġġġġġġġġ\n","pref seq: Foreign Minister Dora Bakoyannis says she expects \"authorities in Skopje to show a different politica\n","next tok:                                                                                                     l\n","pred tok:                                                                                                     ,\n","Completed batch.\n","epoch:2/10 batch:53/7698 batch_size:250 loss:0.730208694934845 time_for_batch_instance:201.19002151489258 total_batch_time:11991.358403682709 running_batch_average:226.25204535250393\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 658756 KiB |  16061 MiB | 657184 GiB | 657184 GiB |\n","|       from large pool | 201306 KiB |  15620 MiB | 656161 GiB | 656161 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |   1023 GiB |   1023 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 658756 KiB |  16061 MiB | 657184 GiB | 657184 GiB |\n","|       from large pool | 201306 KiB |  15620 MiB | 656161 GiB | 656161 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |   1023 GiB |   1023 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  16028 MiB | 655984 GiB | 655983 GiB |\n","|       from large pool | 189056 KiB |  15590 MiB | 654961 GiB | 654961 GiB |\n","|       from small pool | 453671 KiB |    474 MiB |   1022 GiB |   1022 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   3904 MiB |  16822 MiB | 142724 GiB | 142720 GiB |\n","|       from large pool |   3452 MiB |  16354 MiB | 142563 GiB | 142560 GiB |\n","|       from small pool |    452 MiB |    480 MiB |    160 GiB |    160 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   3260 MiB |   4728 MiB | 223508 GiB | 223505 GiB |\n","|       from large pool |   3255 MiB |   4719 MiB | 222374 GiB | 222371 GiB |\n","|       from small pool |      5 MiB |     17 MiB |   1134 GiB |   1134 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   14361 K  |   14345 K  |\n","|       from large pool |      98    |     263    |    8748 K  |    8748 K  |\n","|       from small pool |   16251    |   16398    |    5613 K  |    5596 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   14361 K  |   14345 K  |\n","|       from large pool |      98    |     263    |    8748 K  |    8748 K  |\n","|       from small pool |   16251    |   16398    |    5613 K  |    5596 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     247    |     330    |     832 K  |     832 K  |\n","|       from large pool |      21    |      97    |     750 K  |     750 K  |\n","|       from small pool |     226    |     240    |      82 K  |      82 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      73    |     151    |    7101 K  |    7101 K  |\n","|       from large pool |      18    |      65    |    4855 K  |    4855 K  |\n","|       from small pool |      55    |     102    |    2246 K  |    2246 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:54/7698 batch_size:250\n","Next token prediction. step:7/187 batch:54/7698 epoch:2/10\n","full seq: President of the European Commission (EC) Romano Prodi is to finish his tenure in October, after which, rumour has it, he will be involved again on the Italian political scene.Ģġġġġġġġġġġ\n","pref seq: Preside\n","next tok:       n\n","pred tok:       f\n","Completed batch.\n","epoch:2/10 batch:54/7698 batch_size:250 loss:2.180133104324341 time_for_batch_instance:199.87317180633545 total_batch_time:12191.231575489044 running_batch_average:225.76354769424157\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 658756 KiB |  16061 MiB | 667117 GiB | 667117 GiB |\n","|       from large pool | 201306 KiB |  15620 MiB | 666077 GiB | 666077 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |   1040 GiB |   1040 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 658756 KiB |  16061 MiB | 667117 GiB | 667117 GiB |\n","|       from large pool | 201306 KiB |  15620 MiB | 666077 GiB | 666077 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |   1040 GiB |   1040 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  16028 MiB | 665896 GiB | 665895 GiB |\n","|       from large pool | 189056 KiB |  15590 MiB | 664856 GiB | 664856 GiB |\n","|       from small pool | 453671 KiB |    474 MiB |   1040 GiB |   1039 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   3904 MiB |  16822 MiB | 144566 GiB | 144562 GiB |\n","|       from large pool |   3452 MiB |  16354 MiB | 144402 GiB | 144399 GiB |\n","|       from small pool |    452 MiB |    480 MiB |    163 GiB |    163 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   3260 MiB |   4728 MiB | 226834 GiB | 226830 GiB |\n","|       from large pool |   3255 MiB |   4719 MiB | 225680 GiB | 225677 GiB |\n","|       from small pool |      5 MiB |     17 MiB |   1153 GiB |   1153 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   14604 K  |   14588 K  |\n","|       from large pool |      98    |     263    |    8896 K  |    8896 K  |\n","|       from small pool |   16251    |   16398    |    5708 K  |    5692 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   14604 K  |   14588 K  |\n","|       from large pool |      98    |     263    |    8896 K  |    8896 K  |\n","|       from small pool |   16251    |   16398    |    5708 K  |    5692 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     247    |     330    |     845 K  |     845 K  |\n","|       from large pool |      21    |      97    |     761 K  |     761 K  |\n","|       from small pool |     226    |     240    |      83 K  |      83 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      73    |     151    |    7211 K  |    7211 K  |\n","|       from large pool |      18    |      65    |    4927 K  |    4927 K  |\n","|       from small pool |      55    |     102    |    2283 K  |    2283 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:55/7698 batch_size:250\n","Next token prediction. step:55/187 batch:55/7698 epoch:2/10\n","full seq: The makeshift bomb, which was placed at the front door of the Galeria weekly's premises on the first floor of a building in downtown Sofia, went off at about 5:40am (0340 GMT).Ģġġġġġġġġġġ\n","pref seq: The makeshift bomb, which was placed at the front door \n","next tok:                                                       o\n","pred tok:                                                       C\n","Completed batch.\n","epoch:2/10 batch:55/7698 batch_size:250 loss:0.9139953255653381 time_for_batch_instance:200.55759477615356 total_batch_time:12391.789170265198 running_batch_average:225.30525764118542\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 658756 KiB |  16061 MiB | 677051 GiB | 677050 GiB |\n","|       from large pool | 201306 KiB |  15620 MiB | 675993 GiB | 675993 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |   1057 GiB |   1057 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 658756 KiB |  16061 MiB | 677051 GiB | 677050 GiB |\n","|       from large pool | 201306 KiB |  15620 MiB | 675993 GiB | 675993 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |   1057 GiB |   1057 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  16028 MiB | 675808 GiB | 675807 GiB |\n","|       from large pool | 189056 KiB |  15590 MiB | 674751 GiB | 674751 GiB |\n","|       from small pool | 453671 KiB |    474 MiB |   1057 GiB |   1056 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   3904 MiB |  16822 MiB | 146407 GiB | 146403 GiB |\n","|       from large pool |   3452 MiB |  16354 MiB | 146240 GiB | 146237 GiB |\n","|       from small pool |    452 MiB |    480 MiB |    166 GiB |    165 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   3260 MiB |   4728 MiB | 230157 GiB | 230154 GiB |\n","|       from large pool |   3255 MiB |   4719 MiB | 228985 GiB | 228982 GiB |\n","|       from small pool |      5 MiB |     17 MiB |   1172 GiB |   1172 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   14847 K  |   14831 K  |\n","|       from large pool |      98    |     263    |    9044 K  |    9044 K  |\n","|       from small pool |   16251    |   16398    |    5803 K  |    5787 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   14847 K  |   14831 K  |\n","|       from large pool |      98    |     263    |    9044 K  |    9044 K  |\n","|       from small pool |   16251    |   16398    |    5803 K  |    5787 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     247    |     330    |     858 K  |     858 K  |\n","|       from large pool |      21    |      97    |     773 K  |     773 K  |\n","|       from small pool |     226    |     240    |      85 K  |      84 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      73    |     151    |    7320 K  |    7320 K  |\n","|       from large pool |      18    |      65    |    4999 K  |    4999 K  |\n","|       from small pool |      55    |     102    |    2321 K  |    2321 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:56/7698 batch_size:250\n","Next token prediction. step:25/187 batch:56/7698 epoch:2/10\n","full seq: \"We have a memory of history and remember very well that those institutions were an instrument in the hands of Albanian nationalists serving as additional pressure on the Serbs.Ģġġġġġġġġġ\n","pref seq: \"We have a memory of hist\n","next tok:                         o\n","pred tok:                         w\n","Completed batch.\n","epoch:2/10 batch:56/7698 batch_size:250 loss:0.8285330533981323 time_for_batch_instance:197.30416798591614 total_batch_time:12589.093338251114 running_batch_average:224.8052381830556\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 660472 KiB |  16117 MiB | 687018 GiB | 687017 GiB |\n","|       from large pool | 203022 KiB |  15676 MiB | 685943 GiB | 685943 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |   1075 GiB |   1074 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 660472 KiB |  16117 MiB | 687018 GiB | 687017 GiB |\n","|       from large pool | 203022 KiB |  15676 MiB | 685943 GiB | 685943 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |   1075 GiB |   1074 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  16086 MiB | 685761 GiB | 685760 GiB |\n","|       from large pool | 189056 KiB |  15648 MiB | 684687 GiB | 684686 GiB |\n","|       from small pool | 453671 KiB |    474 MiB |   1074 GiB |   1074 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   7896 MiB |  16866 MiB | 147685 GiB | 147677 GiB |\n","|       from large pool |   7444 MiB |  16398 MiB | 147516 GiB | 147509 GiB |\n","|       from small pool |    452 MiB |    480 MiB |    169 GiB |    168 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   7251 MiB |   7832 MiB | 236049 GiB | 236042 GiB |\n","|       from large pool |   7245 MiB |   7828 MiB | 234858 GiB | 234851 GiB |\n","|       from small pool |      5 MiB |     16 MiB |   1190 GiB |   1190 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   15090 K  |   15074 K  |\n","|       from large pool |      98    |     263    |    9192 K  |    9192 K  |\n","|       from small pool |   16251    |   16398    |    5898 K  |    5882 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   15090 K  |   15074 K  |\n","|       from large pool |      98    |     263    |    9192 K  |    9192 K  |\n","|       from small pool |   16251    |   16398    |    5898 K  |    5882 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     258    |     328    |     868 K  |     868 K  |\n","|       from large pool |      32    |      95    |     781 K  |     781 K  |\n","|       from small pool |     226    |     240    |      86 K  |      86 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      84    |     146    |    7424 K  |    7424 K  |\n","|       from large pool |      28    |      61    |    5065 K  |    5065 K  |\n","|       from small pool |      56    |     102    |    2358 K  |    2358 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:57/7698 batch_size:250\n","Next token prediction. step:112/185 batch:57/7698 epoch:2/10\n","full seq: Almost 50% of Romanians are unhappy with the current level of education in the country, according to a study by the research company GfK, published on Thursday (October 8th).Ģġġġġġġġġġġ\n","pref seq: Almost 50% of Romanians are unhappy with the current level of education in the country, according to a study by \n","next tok:                                                                                                                t\n","pred tok:                                                                                                                ,\n","Completed batch.\n","epoch:2/10 batch:57/7698 batch_size:250 loss:0.9872925877571106 time_for_batch_instance:198.6081304550171 total_batch_time:12787.701468706131 running_batch_average:224.34563980186195\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 654616 KiB |  15943 MiB | 696787 GiB | 696787 GiB |\n","|       from large pool | 197166 KiB |  15502 MiB | 695695 GiB | 695695 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |   1092 GiB |   1091 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 654616 KiB |  15943 MiB | 696787 GiB | 696787 GiB |\n","|       from large pool | 197166 KiB |  15502 MiB | 695695 GiB | 695695 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |   1092 GiB |   1091 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  15920 MiB | 695509 GiB | 695508 GiB |\n","|       from large pool | 189056 KiB |  15483 MiB | 694417 GiB | 694417 GiB |\n","|       from small pool | 453671 KiB |    474 MiB |   1091 GiB |   1091 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   3284 MiB |  16714 MiB | 149635 GiB | 149632 GiB |\n","|       from large pool |   2834 MiB |  16248 MiB | 149463 GiB | 149460 GiB |\n","|       from small pool |    450 MiB |    480 MiB |    171 GiB |    171 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   2644 MiB |   7253 MiB | 239943 GiB | 239940 GiB |\n","|       from large pool |   2641 MiB |   7247 MiB | 238733 GiB | 238731 GiB |\n","|       from small pool |      3 MiB |     19 MiB |   1209 GiB |   1209 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   15331 K  |   15315 K  |\n","|       from large pool |      98    |     263    |    9338 K  |    9338 K  |\n","|       from small pool |   16251    |   16398    |    5992 K  |    5976 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   15331 K  |   15315 K  |\n","|       from large pool |      98    |     263    |    9338 K  |    9338 K  |\n","|       from small pool |   16251    |   16398    |    5992 K  |    5976 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     251    |     335    |     881 K  |     881 K  |\n","|       from large pool |      26    |     102    |     793 K  |     793 K  |\n","|       from small pool |     225    |     240    |      88 K  |      87 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      73    |     160    |    7538 K  |    7538 K  |\n","|       from large pool |      20    |      74    |    5142 K  |    5142 K  |\n","|       from small pool |      53    |     103    |    2395 K  |    2395 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:58/7698 batch_size:250\n","Next token prediction. step:65/185 batch:58/7698 epoch:2/10\n","full seq: (AP, Reuters, International Herald Tribune, Zaman - 29/09/05; AFP, Reuters, BBC, RFE/RL, VOA, EurActiv, Turkish Daily News, Cihan News Agency, European Parliament - 28/09/05)Ģġġġġġġġġġġ\n","pref seq: (AP, Reuters, International Herald Tribune, Zaman - 29/09/05; AFP\n","next tok:                                                                 ,\n","pred tok:                                                                 '\n","Completed batch.\n","epoch:2/10 batch:58/7698 batch_size:250 loss:1.0276516675949097 time_for_batch_instance:199.02740120887756 total_batch_time:12986.728869915009 running_batch_average:223.90911844681048\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 655565 KiB |  15892 MiB | 706526 GiB | 706526 GiB |\n","|       from large pool | 198115 KiB |  15451 MiB | 705417 GiB | 705417 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |   1109 GiB |   1108 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 655565 KiB |  15892 MiB | 706526 GiB | 706526 GiB |\n","|       from large pool | 198115 KiB |  15451 MiB | 705417 GiB | 705417 GiB |\n","|       from small pool | 457450 KiB |    478 MiB |   1109 GiB |   1108 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  15862 MiB | 705216 GiB | 705216 GiB |\n","|       from large pool | 189056 KiB |  15425 MiB | 704108 GiB | 704108 GiB |\n","|       from small pool | 453671 KiB |    474 MiB |   1108 GiB |   1108 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   3192 MiB |  16650 MiB | 151867 GiB | 151864 GiB |\n","|       from large pool |   2742 MiB |  16184 MiB | 151693 GiB | 151690 GiB |\n","|       from small pool |    450 MiB |    480 MiB |    174 GiB |    174 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   2551 MiB |   3756 MiB | 243035 GiB | 243033 GiB |\n","|       from large pool |   2548 MiB |   3749 MiB | 241807 GiB | 241805 GiB |\n","|       from small pool |      3 MiB |     16 MiB |   1228 GiB |   1228 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   15571 K  |   15555 K  |\n","|       from large pool |      98    |     263    |    9484 K  |    9484 K  |\n","|       from small pool |   16251    |   16398    |    6087 K  |    6070 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   15571 K  |   15555 K  |\n","|       from large pool |      98    |     263    |    9484 K  |    9484 K  |\n","|       from small pool |   16251    |   16398    |    6087 K  |    6070 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     247    |     336    |     896 K  |     896 K  |\n","|       from large pool |      22    |     103    |     807 K  |     807 K  |\n","|       from small pool |     225    |     240    |      89 K  |      89 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      74    |     153    |    7647 K  |    7647 K  |\n","|       from large pool |      20    |      67    |    5214 K  |    5214 K  |\n","|       from small pool |      54    |     103    |    2433 K  |    2433 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:59/7698 batch_size:250\n","Next token prediction. step:42/184 batch:59/7698 epoch:2/10\n","full seq: (Emportal - 23/01/10; Balkans.com, ACTmedia - 22/01/10; Nine O'clock, Sofia News Agency - 21/01/10; The Heritage Foundation, Reuters, DPA, Standart, MIA, Makfax - 20/01/10)Ģġġġġġġġġġġġ\n","pref seq: (Emportal - 23/01/10; Balkans.com, ACTmedi\n","next tok:                                          a\n","pred tok:                                          ,\n","Completed batch.\n","epoch:2/10 batch:59/7698 batch_size:250 loss:0.9926726222038269 time_for_batch_instance:197.86085605621338 total_batch_time:13184.589725971222 running_batch_average:223.4676224740885\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 653582 KiB |  15810 MiB | 716147 GiB | 716147 GiB |\n","|       from large pool | 196132 KiB |  15369 MiB | 715021 GiB | 715021 GiB |\n","|       from small pool | 457450 KiB |    477 MiB |   1126 GiB |   1125 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 653582 KiB |  15810 MiB | 716147 GiB | 716147 GiB |\n","|       from large pool | 196132 KiB |  15369 MiB | 715021 GiB | 715021 GiB |\n","|       from small pool | 457450 KiB |    477 MiB |   1126 GiB |   1125 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  15779 MiB | 714822 GiB | 714822 GiB |\n","|       from large pool | 189056 KiB |  15342 MiB | 713697 GiB | 713697 GiB |\n","|       from small pool | 453671 KiB |    474 MiB |   1125 GiB |   1125 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2350 MiB |  16566 MiB | 154048 GiB | 154046 GiB |\n","|       from large pool |   1900 MiB |  16100 MiB | 153871 GiB | 153869 GiB |\n","|       from small pool |    450 MiB |    480 MiB |    177 GiB |    176 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1711 MiB |   3077 MiB | 246148 GiB | 246146 GiB |\n","|       from large pool |   1708 MiB |   3070 MiB | 244901 GiB | 244899 GiB |\n","|       from small pool |      3 MiB |     16 MiB |   1246 GiB |   1246 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   15810 K  |   15794 K  |\n","|       from large pool |      98    |     263    |    9630 K  |    9630 K  |\n","|       from small pool |   16251    |   16398    |    6180 K  |    6164 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   15810 K  |   15794 K  |\n","|       from large pool |      98    |     263    |    9630 K  |    9630 K  |\n","|       from small pool |   16251    |   16398    |    6180 K  |    6164 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     241    |     334    |     910 K  |     910 K  |\n","|       from large pool |      16    |     101    |     820 K  |     820 K  |\n","|       from small pool |     225    |     240    |      90 K  |      90 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      67    |     153    |    7772 K  |    7772 K  |\n","|       from large pool |      15    |      68    |    5302 K  |    5302 K  |\n","|       from small pool |      52    |     103    |    2469 K  |    2469 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:60/7698 batch_size:250\n","Next token prediction. step:130/184 batch:60/7698 epoch:2/10\n","full seq: Public opinion analyst Srdjan Bogosavljevic emphasises that public dissatisfaction with the standard of living could have a major impact on voter turnout in the next election.Ģġġġġġġġġ\n","pref seq: Public opinion analyst Srdjan Bogosavljevic emphasises that public dissatisfaction with the standard of living could have a major \n","next tok:                                                                                                                                  i\n","pred tok:                                                                                                                                  ;\n","Completed batch.\n","epoch:2/10 batch:60/7698 batch_size:250 loss:1.4282855987548828 time_for_batch_instance:198.79831075668335 total_batch_time:13383.388036727905 running_batch_average:223.0564672787984\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 654018 KiB |  15811 MiB | 725768 GiB | 725767 GiB |\n","|       from large pool | 196568 KiB |  15370 MiB | 724625 GiB | 724625 GiB |\n","|       from small pool | 457450 KiB |    477 MiB |   1143 GiB |   1142 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 654018 KiB |  15811 MiB | 725768 GiB | 725767 GiB |\n","|       from large pool | 196568 KiB |  15370 MiB | 724625 GiB | 724625 GiB |\n","|       from small pool | 457450 KiB |    477 MiB |   1143 GiB |   1142 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  15779 MiB | 724428 GiB | 724428 GiB |\n","|       from large pool | 189056 KiB |  15342 MiB | 723286 GiB | 723286 GiB |\n","|       from small pool | 453671 KiB |    474 MiB |   1142 GiB |   1141 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2954 MiB |  16544 MiB | 156243 GiB | 156240 GiB |\n","|       from large pool |   2504 MiB |  16078 MiB | 156063 GiB | 156060 GiB |\n","|       from small pool |    450 MiB |    480 MiB |    180 GiB |    179 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   2315 MiB |   3009 MiB | 249302 GiB | 249300 GiB |\n","|       from large pool |   2312 MiB |   3005 MiB | 248037 GiB | 248035 GiB |\n","|       from small pool |      3 MiB |     17 MiB |   1265 GiB |   1265 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   16050 K  |   16033 K  |\n","|       from large pool |      98    |     263    |    9775 K  |    9775 K  |\n","|       from small pool |   16251    |   16398    |    6274 K  |    6258 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   16050 K  |   16033 K  |\n","|       from large pool |      98    |     263    |    9775 K  |    9775 K  |\n","|       from small pool |   16251    |   16398    |    6274 K  |    6258 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     243    |     335    |     925 K  |     925 K  |\n","|       from large pool |      18    |     102    |     833 K  |     833 K  |\n","|       from small pool |     225    |     240    |      92 K  |      91 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      69    |     156    |    7896 K  |    7896 K  |\n","|       from large pool |      17    |      70    |    5390 K  |    5390 K  |\n","|       from small pool |      52    |     103    |    2506 K  |    2506 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:61/7698 batch_size:250\n","Next token prediction. step:106/183 batch:61/7698 epoch:2/10\n","full seq: Romanian director Corneliu Porumboiu's film \"12:08 East of Bucharest\" won awards for Best Film and for Best Screenplay at this year's Copenhagen International Film Festival.Ģġġġġġġġġġ\n","pref seq: Romanian director Corneliu Porumboiu's film \"12:08 East of Bucharest\" won awards for Best Film and for Bes\n","next tok:                                                                                                          t\n","pred tok:                                                                                                          ,\n","Completed batch.\n","epoch:2/10 batch:61/7698 batch_size:250 loss:0.8757410645484924 time_for_batch_instance:195.9051194190979 total_batch_time:13579.293156147003 running_batch_average:222.61136321552465\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 655942 KiB |  15726 MiB | 735289 GiB | 735289 GiB |\n","|       from large pool | 198492 KiB |  15285 MiB | 734129 GiB | 734129 GiB |\n","|       from small pool | 457450 KiB |    477 MiB |   1160 GiB |   1159 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 655942 KiB |  15726 MiB | 735289 GiB | 735289 GiB |\n","|       from large pool | 198492 KiB |  15285 MiB | 734129 GiB | 734129 GiB |\n","|       from small pool | 457450 KiB |    477 MiB |   1160 GiB |   1159 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  15696 MiB | 733933 GiB | 733933 GiB |\n","|       from large pool | 189056 KiB |  15259 MiB | 732774 GiB | 732774 GiB |\n","|       from small pool | 453671 KiB |    474 MiB |   1159 GiB |   1158 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   3210 MiB |  16484 MiB | 158127 GiB | 158124 GiB |\n","|       from large pool |   2760 MiB |  16018 MiB | 157944 GiB | 157941 GiB |\n","|       from small pool |    450 MiB |    480 MiB |    182 GiB |    182 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   2569 MiB |   4130 MiB | 253260 GiB | 253257 GiB |\n","|       from large pool |   2566 MiB |   4126 MiB | 251976 GiB | 251974 GiB |\n","|       from small pool |      3 MiB |     18 MiB |   1283 GiB |   1283 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   16287 K  |   16271 K  |\n","|       from large pool |      98    |     263    |    9920 K  |    9920 K  |\n","|       from small pool |   16251    |   16398    |    6367 K  |    6351 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   16287 K  |   16271 K  |\n","|       from large pool |      98    |     263    |    9920 K  |    9920 K  |\n","|       from small pool |   16251    |   16398    |    6367 K  |    6351 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     253    |     337    |     938 K  |     938 K  |\n","|       from large pool |      28    |     104    |     844 K  |     844 K  |\n","|       from small pool |     225    |     240    |      93 K  |      93 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      76    |     152    |    8021 K  |    8021 K  |\n","|       from large pool |      24    |      67    |    5478 K  |    5478 K  |\n","|       from small pool |      52    |     104    |    2543 K  |    2543 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:62/7698 batch_size:250\n","Next token prediction. step:41/183 batch:62/7698 epoch:2/10\n","full seq: Montenegrins likely hope that NATO membership and a possible fast track to the EU will give them more leverage to attract western capital and reduce the dependency on Russia.Ģġġġġġġġġ\n","pref seq: Montenegrins likely hope that NATO member\n","next tok:                                         s\n","pred tok:                                         ;\n","Completed batch.\n","epoch:2/10 batch:62/7698 batch_size:250 loss:0.7129382491111755 time_for_batch_instance:196.58676528930664 total_batch_time:13775.87992143631 running_batch_average:222.19161163606952\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 654818 KiB |  15725 MiB | 744811 GiB | 744810 GiB |\n","|       from large pool | 197368 KiB |  15285 MiB | 743634 GiB | 743634 GiB |\n","|       from small pool | 457450 KiB |    477 MiB |   1176 GiB |   1176 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 654818 KiB |  15725 MiB | 744811 GiB | 744810 GiB |\n","|       from large pool | 197368 KiB |  15285 MiB | 743634 GiB | 743634 GiB |\n","|       from small pool | 457450 KiB |    477 MiB |   1176 GiB |   1176 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  15696 MiB | 743438 GiB | 743438 GiB |\n","|       from large pool | 189056 KiB |  15259 MiB | 742262 GiB | 742262 GiB |\n","|       from small pool | 453671 KiB |    474 MiB |   1176 GiB |   1175 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   3268 MiB |  16484 MiB | 159998 GiB | 159995 GiB |\n","|       from large pool |   2818 MiB |  16018 MiB | 159812 GiB | 159810 GiB |\n","|       from small pool |    450 MiB |    480 MiB |    185 GiB |    185 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   2628 MiB |   3997 MiB | 257173 GiB | 257170 GiB |\n","|       from large pool |   2625 MiB |   3993 MiB | 255871 GiB | 255868 GiB |\n","|       from small pool |      3 MiB |     18 MiB |   1302 GiB |   1302 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   16525 K  |   16509 K  |\n","|       from large pool |      98    |     263    |   10065 K  |   10064 K  |\n","|       from small pool |   16251    |   16398    |    6460 K  |    6444 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   16525 K  |   16509 K  |\n","|       from large pool |      98    |     263    |   10065 K  |   10064 K  |\n","|       from small pool |   16251    |   16398    |    6460 K  |    6444 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     254    |     336    |     951 K  |     950 K  |\n","|       from large pool |      29    |     103    |     856 K  |     856 K  |\n","|       from small pool |     225    |     240    |      94 K  |      94 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      79    |     152    |    8145 K  |    8145 K  |\n","|       from large pool |      27    |      67    |    5565 K  |    5565 K  |\n","|       from small pool |      52    |     104    |    2580 K  |    2580 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:63/7698 batch_size:250\n","Next token prediction. step:143/181 batch:63/7698 epoch:2/10\n","full seq: While there are hopes of an eased visa regime for students and businesspeople in the near future, the average person will have to wait longer for the situation to improve.Ģġġġġġġġġġ\n","pref seq: While there are hopes of an eased visa regime for students and businesspeople in the near future, the average person will have to wait longer f\n","next tok:                                                                                                                                               o\n","pred tok:                                                                                                                                               g\n","Completed batch.\n","epoch:2/10 batch:63/7698 batch_size:250 loss:2.2795042991638184 time_for_batch_instance:194.09554028511047 total_batch_time:13969.97546172142 running_batch_average:221.74564224954636\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 652808 KiB |  15554 MiB | 754123 GiB | 754122 GiB |\n","|       from large pool | 195358 KiB |  15113 MiB | 752929 GiB | 752929 GiB |\n","|       from small pool | 457450 KiB |    477 MiB |   1193 GiB |   1193 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 652808 KiB |  15554 MiB | 754123 GiB | 754122 GiB |\n","|       from large pool | 195358 KiB |  15113 MiB | 752929 GiB | 752929 GiB |\n","|       from small pool | 457450 KiB |    477 MiB |   1193 GiB |   1193 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  15531 MiB | 752743 GiB | 752743 GiB |\n","|       from large pool | 189056 KiB |  15094 MiB | 751550 GiB | 751550 GiB |\n","|       from small pool | 453671 KiB |    474 MiB |   1192 GiB |   1192 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   3198 MiB |  16364 MiB | 161960 GiB | 161957 GiB |\n","|       from large pool |   2748 MiB |  15898 MiB | 161772 GiB | 161769 GiB |\n","|       from small pool |    450 MiB |    480 MiB |    188 GiB |    187 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   2560 MiB |   4526 MiB | 260922 GiB | 260919 GiB |\n","|       from large pool |   2557 MiB |   4521 MiB | 259601 GiB | 259599 GiB |\n","|       from small pool |      3 MiB |     20 MiB |   1320 GiB |   1320 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   16761 K  |   16744 K  |\n","|       from large pool |      98    |     263    |   10208 K  |   10208 K  |\n","|       from small pool |   16251    |   16398    |    6552 K  |    6536 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   16761 K  |   16744 K  |\n","|       from large pool |      98    |     263    |   10208 K  |   10208 K  |\n","|       from small pool |   16251    |   16398    |    6552 K  |    6536 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     258    |     347    |     964 K  |     964 K  |\n","|       from large pool |      33    |     114    |     868 K  |     868 K  |\n","|       from small pool |     225    |     240    |      96 K  |      96 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      80    |     182    |    8289 K  |    8289 K  |\n","|       from large pool |      29    |      96    |    5672 K  |    5672 K  |\n","|       from small pool |      51    |     103    |    2617 K  |    2617 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:64/7698 batch_size:250\n","Next token prediction. step:102/181 batch:64/7698 epoch:2/10\n","full seq: \"It is not useful at this point to start a hypothetical discussion about what would happen if a referendum next year resulted in [the] secession [of Montenegro],\" he said.Ģġġġġġġġġġ\n","pref seq: \"It is not useful at this point to start a hypothetical discussion about what would happen if a refere\n","next tok:                                                                                                      n\n","pred tok:                                                                                                      M\n","Completed batch.\n","epoch:2/10 batch:64/7698 batch_size:250 loss:1.9110020399093628 time_for_batch_instance:194.44302654266357 total_batch_time:14164.418488264084 running_batch_average:221.3190388791263\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 652573 KiB |  15554 MiB | 763434 GiB | 763434 GiB |\n","|       from large pool | 195123 KiB |  15113 MiB | 762224 GiB | 762224 GiB |\n","|       from small pool | 457450 KiB |    477 MiB |   1210 GiB |   1209 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 652573 KiB |  15554 MiB | 763434 GiB | 763434 GiB |\n","|       from large pool | 195123 KiB |  15113 MiB | 762224 GiB | 762224 GiB |\n","|       from small pool | 457450 KiB |    477 MiB |   1210 GiB |   1209 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  15531 MiB | 762048 GiB | 762048 GiB |\n","|       from large pool | 189056 KiB |  15094 MiB | 760839 GiB | 760839 GiB |\n","|       from small pool | 453671 KiB |    474 MiB |   1209 GiB |   1208 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2886 MiB |  16364 MiB | 163937 GiB | 163934 GiB |\n","|       from large pool |   2436 MiB |  15898 MiB | 163746 GiB | 163744 GiB |\n","|       from small pool |    450 MiB |    480 MiB |    190 GiB |    190 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   2248 MiB |   3186 MiB | 264632 GiB | 264630 GiB |\n","|       from large pool |   2245 MiB |   3179 MiB | 263294 GiB | 263291 GiB |\n","|       from small pool |      3 MiB |     19 MiB |   1338 GiB |   1338 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   16996 K  |   16979 K  |\n","|       from large pool |      98    |     263    |   10351 K  |   10351 K  |\n","|       from small pool |   16251    |   16398    |    6645 K  |    6628 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   16996 K  |   16979 K  |\n","|       from large pool |      98    |     263    |   10351 K  |   10351 K  |\n","|       from small pool |   16251    |   16398    |    6645 K  |    6628 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     257    |     347    |     978 K  |     978 K  |\n","|       from large pool |      32    |     114    |     880 K  |     880 K  |\n","|       from small pool |     225    |     240    |      97 K  |      97 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      79    |     182    |    8432 K  |    8432 K  |\n","|       from large pool |      28    |      96    |    5778 K  |    5778 K  |\n","|       from small pool |      51    |     103    |    2653 K  |    2653 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:65/7698 batch_size:250\n","Next token prediction. step:33/181 batch:65/7698 epoch:2/10\n","full seq: Romania, an EU member state since 2007, filled out the Schengen questionnaire, a complex document consisting of 250 strategic questions covering the acquis, late last year.Ģġġġġġġġġ\n","pref seq: Romania, an EU member state since\n","next tok:                                  \n","pred tok:                                 ,\n","Completed batch.\n","epoch:2/10 batch:65/7698 batch_size:250 loss:1.0423657894134521 time_for_batch_instance:194.30786752700806 total_batch_time:14358.726355791092 running_batch_average:220.90348239678602\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 652455 KiB |  15553 MiB | 772746 GiB | 772746 GiB |\n","|       from large pool | 195005 KiB |  15112 MiB | 771519 GiB | 771519 GiB |\n","|       from small pool | 457450 KiB |    477 MiB |   1226 GiB |   1226 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 652455 KiB |  15553 MiB | 772746 GiB | 772746 GiB |\n","|       from large pool | 195005 KiB |  15112 MiB | 771519 GiB | 771519 GiB |\n","|       from small pool | 457450 KiB |    477 MiB |   1226 GiB |   1226 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  15531 MiB | 771353 GiB | 771353 GiB |\n","|       from large pool | 189056 KiB |  15094 MiB | 770127 GiB | 770127 GiB |\n","|       from small pool | 453671 KiB |    474 MiB |   1226 GiB |   1225 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2666 MiB |  16354 MiB | 165908 GiB | 165905 GiB |\n","|       from large pool |   2216 MiB |  15888 MiB | 165714 GiB | 165712 GiB |\n","|       from small pool |    450 MiB |    480 MiB |    193 GiB |    192 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   2028 MiB |   3186 MiB | 268333 GiB | 268331 GiB |\n","|       from large pool |   2025 MiB |   3179 MiB | 266976 GiB | 266974 GiB |\n","|       from small pool |      3 MiB |     19 MiB |   1356 GiB |   1356 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   17231 K  |   17215 K  |\n","|       from large pool |      98    |     263    |   10494 K  |   10494 K  |\n","|       from small pool |   16251    |   16398    |    6737 K  |    6721 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   17231 K  |   17215 K  |\n","|       from large pool |      98    |     263    |   10494 K  |   10494 K  |\n","|       from small pool |   16251    |   16398    |    6737 K  |    6721 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     258    |     346    |     992 K  |     992 K  |\n","|       from large pool |      33    |     114    |     893 K  |     893 K  |\n","|       from small pool |     225    |     240    |      99 K  |      98 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      80    |     181    |    8576 K  |    8576 K  |\n","|       from large pool |      29    |      95    |    5885 K  |    5885 K  |\n","|       from small pool |      51    |     103    |    2690 K  |    2690 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:66/7698 batch_size:250\n","Next token prediction. step:119/181 batch:66/7698 epoch:2/10\n","full seq: Fifteen Greek athletes -- including the entire weightlifting team -- have tested positive for methyltrienolone, an anabolic steroid that has become widely available online.Ģġġġġġġġġ\n","pref seq: Fifteen Greek athletes -- including the entire weightlifting team -- have tested positive for methyltrienolone, an anab\n","next tok:                                                                                                                       o\n","pred tok:                                                                                                                       ,\n","Completed batch.\n","epoch:2/10 batch:66/7698 batch_size:250 loss:2.171973705291748 time_for_batch_instance:194.150151014328 total_batch_time:14552.87650680542 running_batch_average:220.4981288909912\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 652455 KiB |  15553 MiB | 782058 GiB | 782058 GiB |\n","|       from large pool | 195005 KiB |  15112 MiB | 780815 GiB | 780814 GiB |\n","|       from small pool | 457450 KiB |    477 MiB |   1243 GiB |   1243 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 652455 KiB |  15553 MiB | 782058 GiB | 782058 GiB |\n","|       from large pool | 195005 KiB |  15112 MiB | 780815 GiB | 780814 GiB |\n","|       from small pool | 457450 KiB |    477 MiB |   1243 GiB |   1243 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  15531 MiB | 780658 GiB | 780658 GiB |\n","|       from large pool | 189056 KiB |  15094 MiB | 779416 GiB | 779415 GiB |\n","|       from small pool | 453671 KiB |    474 MiB |   1242 GiB |   1242 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2666 MiB |  16354 MiB | 167887 GiB | 167884 GiB |\n","|       from large pool |   2216 MiB |  15888 MiB | 167690 GiB | 167688 GiB |\n","|       from small pool |    450 MiB |    480 MiB |    196 GiB |    195 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   2028 MiB |   3186 MiB | 272026 GiB | 272024 GiB |\n","|       from large pool |   2025 MiB |   3179 MiB | 270651 GiB | 270649 GiB |\n","|       from small pool |      3 MiB |     19 MiB |   1374 GiB |   1374 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   17466 K  |   17450 K  |\n","|       from large pool |      98    |     263    |   10637 K  |   10637 K  |\n","|       from small pool |   16251    |   16398    |    6829 K  |    6813 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   17466 K  |   17450 K  |\n","|       from large pool |      98    |     263    |   10637 K  |   10637 K  |\n","|       from small pool |   16251    |   16398    |    6829 K  |    6813 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     258    |     347    |    1006 K  |    1005 K  |\n","|       from large pool |      33    |     114    |     905 K  |     905 K  |\n","|       from small pool |     225    |     240    |     100 K  |     100 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      80    |     182    |    8720 K  |    8720 K  |\n","|       from large pool |      29    |      96    |    5992 K  |    5992 K  |\n","|       from small pool |      51    |     103    |    2727 K  |    2727 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:67/7698 batch_size:250\n","Next token prediction. step:117/180 batch:67/7698 epoch:2/10\n","full seq: \"The road towards the EU is paved with reforms to improve the everyday lives of citizens and to comply with the strict EU accession criteria,\" the EC said. [Getty Images]Ģġġġġġġġġġ\n","pref seq: \"The road towards the EU is paved with reforms to improve the everyday lives of citizens and to comply with the stric\n","next tok:                                                                                                                     t\n","pred tok:                                                                                                                     ,\n","Completed batch.\n","epoch:2/10 batch:67/7698 batch_size:250 loss:1.2815985679626465 time_for_batch_instance:192.8775041103363 total_batch_time:14745.754010915756 running_batch_average:220.08588075993666\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 657222 KiB |  15469 MiB |    772 TiB |    772 TiB |\n","|       from large pool | 199772 KiB |  15028 MiB |    771 TiB |    771 TiB |\n","|       from small pool | 457450 KiB |    477 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 657222 KiB |  15469 MiB |    772 TiB |    772 TiB |\n","|       from large pool | 199772 KiB |  15028 MiB |    771 TiB |    771 TiB |\n","|       from small pool | 457450 KiB |    477 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  15448 MiB |    771 TiB |    771 TiB |\n","|       from large pool | 189056 KiB |  15011 MiB |    770 TiB |    770 TiB |\n","|       from small pool | 453671 KiB |    474 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   4028 MiB |  16198 MiB | 169626 GiB | 169622 GiB |\n","|       from large pool |   3578 MiB |  15732 MiB | 169428 GiB | 169424 GiB |\n","|       from small pool |    450 MiB |    480 MiB |    198 GiB |    198 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   3386 MiB |   4578 MiB | 275160 GiB | 275156 GiB |\n","|       from large pool |   3382 MiB |   4574 MiB | 273767 GiB | 273763 GiB |\n","|       from small pool |      3 MiB |     17 MiB |   1393 GiB |   1393 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   17700 K  |   17684 K  |\n","|       from large pool |      98    |     263    |   10779 K  |   10779 K  |\n","|       from small pool |   16251    |   16398    |    6921 K  |    6904 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   17700 K  |   17684 K  |\n","|       from large pool |      98    |     263    |   10779 K  |   10779 K  |\n","|       from small pool |   16251    |   16398    |    6921 K  |    6904 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     248    |     332    |    1018 K  |    1018 K  |\n","|       from large pool |      23    |      99    |     917 K  |     917 K  |\n","|       from small pool |     225    |     240    |     101 K  |     101 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      74    |     151    |    8822 K  |    8822 K  |\n","|       from large pool |      20    |      66    |    6058 K  |    6058 K  |\n","|       from small pool |      54    |     103    |    2764 K  |    2764 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:68/7698 batch_size:250\n","Next token prediction. step:107/179 batch:68/7698 epoch:2/10\n","full seq: \"The Albanian government, supported by the international partners, has to act on this phenomenon,\" said Acting US Ambassador to Tirana Steven Zate. [US Embassy - Tirana]Ģġġġġġġġġġ\n","pref seq: \"The Albanian government, supported by the international partners, has to act on this phenomenon,\" said Act\n","next tok:                                                                                                           i\n","pred tok:                                                                                                           ,\n","Completed batch.\n","epoch:2/10 batch:68/7698 batch_size:250 loss:0.8219291567802429 time_for_batch_instance:192.02017903327942 total_batch_time:14937.774189949036 running_batch_average:219.6731498521917\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 654981 KiB |  15341 MiB |    781 TiB |    781 TiB |\n","|       from large pool | 197531 KiB |  14900 MiB |    780 TiB |    780 TiB |\n","|       from small pool | 457450 KiB |    477 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 654981 KiB |  15341 MiB |    781 TiB |    781 TiB |\n","|       from large pool | 197531 KiB |  14900 MiB |    780 TiB |    780 TiB |\n","|       from small pool | 457450 KiB |    477 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  15307 MiB |    780 TiB |    780 TiB |\n","|       from large pool | 189056 KiB |  14870 MiB |    778 TiB |    778 TiB |\n","|       from small pool | 453671 KiB |    474 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2688 MiB |  16060 MiB | 171620 GiB | 171617 GiB |\n","|       from large pool |   2238 MiB |  15596 MiB | 171418 GiB | 171416 GiB |\n","|       from small pool |    450 MiB |    480 MiB |    201 GiB |    200 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   2048 MiB |   3641 MiB | 278320 GiB | 278318 GiB |\n","|       from large pool |   2045 MiB |   3637 MiB | 276909 GiB | 276907 GiB |\n","|       from small pool |      3 MiB |     20 MiB |   1411 GiB |   1411 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   17933 K  |   17916 K  |\n","|       from large pool |      98    |     263    |   10920 K  |   10920 K  |\n","|       from small pool |   16251    |   16398    |    7012 K  |    6996 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   17933 K  |   17916 K  |\n","|       from large pool |      98    |     263    |   10920 K  |   10920 K  |\n","|       from small pool |   16251    |   16398    |    7012 K  |    6996 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     243    |     336    |    1032 K  |    1032 K  |\n","|       from large pool |      18    |     103    |     929 K  |     929 K  |\n","|       from small pool |     225    |     240    |     103 K  |     102 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      66    |     162    |    8933 K  |    8933 K  |\n","|       from large pool |      15    |      77    |    6132 K  |    6132 K  |\n","|       from small pool |      51    |     102    |    2800 K  |    2800 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:69/7698 batch_size:250\n","Next token prediction. step:139/179 batch:69/7698 epoch:2/10\n","full seq: According to Srdjan Majstorovic of the EU accession office, success in the Schengen visa talks would be a major milestone in terms of Serbian aspirations to join the EU.Ģġġġġġġġġġ\n","pref seq: According to Srdjan Majstorovic of the EU accession office, success in the Schengen visa talks would be a major milestone in terms of Serbi\n","next tok:                                                                                                                                           a\n","pred tok:                                                                                                                                           f\n","Completed batch.\n","epoch:2/10 batch:69/7698 batch_size:250 loss:0.8338528275489807 time_for_batch_instance:192.09151530265808 total_batch_time:15129.865705251694 running_batch_average:219.2734160181405\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 653955 KiB |  15410 MiB |    790 TiB |    790 TiB |\n","|       from large pool | 196505 KiB |  14969 MiB |    789 TiB |    789 TiB |\n","|       from small pool | 457450 KiB |    477 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 653955 KiB |  15410 MiB |    790 TiB |    790 TiB |\n","|       from large pool | 196505 KiB |  14969 MiB |    789 TiB |    789 TiB |\n","|       from small pool | 457450 KiB |    477 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  15365 MiB |    789 TiB |    789 TiB |\n","|       from large pool | 189056 KiB |  14928 MiB |    787 TiB |    787 TiB |\n","|       from small pool | 453671 KiB |    474 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   4120 MiB |  16116 MiB | 173375 GiB | 173371 GiB |\n","|       from large pool |   3670 MiB |  15650 MiB | 173171 GiB | 173168 GiB |\n","|       from small pool |    450 MiB |    480 MiB |    203 GiB |    203 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   3481 MiB |   4386 MiB | 281320 GiB | 281316 GiB |\n","|       from large pool |   3478 MiB |   4382 MiB | 279890 GiB | 279887 GiB |\n","|       from small pool |      3 MiB |     18 MiB |   1429 GiB |   1429 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   18165 K  |   18149 K  |\n","|       from large pool |      98    |     263    |   11062 K  |   11062 K  |\n","|       from small pool |   16251    |   16398    |    7103 K  |    7087 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   18165 K  |   18149 K  |\n","|       from large pool |      98    |     263    |   11062 K  |   11062 K  |\n","|       from small pool |   16251    |   16398    |    7103 K  |    7087 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     245    |     333    |    1045 K  |    1045 K  |\n","|       from large pool |      20    |     100    |     941 K  |     941 K  |\n","|       from small pool |     225    |     240    |     104 K  |     104 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      71    |     154    |    9033 K  |    9033 K  |\n","|       from large pool |      18    |      69    |    6196 K  |    6196 K  |\n","|       from small pool |      53    |     103    |    2837 K  |    2837 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:70/7698 batch_size:250\n","Next token prediction. step:159/179 batch:70/7698 epoch:2/10\n","full seq: Media reports in February 2004 suggested that Gotovina - who received French citizenship after his service in the Legion -- had been living openly in southeastern France.Ģġġġġġġġġ\n","pref seq: Media reports in February 2004 suggested that Gotovina - who received French citizenship after his service in the Legion -- had been living openly in southeast\n","next tok:                                                                                                                                                               e\n","pred tok:                                                                                                                                                               f\n","Completed batch.\n","epoch:2/10 batch:70/7698 batch_size:250 loss:1.0141302347183228 time_for_batch_instance:191.38849997520447 total_batch_time:15321.254205226898 running_batch_average:218.87506007466996\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 653955 KiB |  15410 MiB |    799 TiB |    799 TiB |\n","|       from large pool | 196505 KiB |  14969 MiB |    798 TiB |    798 TiB |\n","|       from small pool | 457450 KiB |    477 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 653955 KiB |  15410 MiB |    799 TiB |    799 TiB |\n","|       from large pool | 196505 KiB |  14969 MiB |    798 TiB |    798 TiB |\n","|       from small pool | 457450 KiB |    477 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  15365 MiB |    797 TiB |    797 TiB |\n","|       from large pool | 189056 KiB |  14928 MiB |    796 TiB |    796 TiB |\n","|       from small pool | 453671 KiB |    474 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   4120 MiB |  16116 MiB | 175118 GiB | 175114 GiB |\n","|       from large pool |   3670 MiB |  15650 MiB | 174911 GiB | 174908 GiB |\n","|       from small pool |    450 MiB |    480 MiB |    206 GiB |    206 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   3481 MiB |   4386 MiB | 284320 GiB | 284317 GiB |\n","|       from large pool |   3478 MiB |   4382 MiB | 282873 GiB | 282869 GiB |\n","|       from small pool |      3 MiB |     20 MiB |   1447 GiB |   1447 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   18398 K  |   18381 K  |\n","|       from large pool |      98    |     263    |   11203 K  |   11203 K  |\n","|       from small pool |   16251    |   16398    |    7194 K  |    7178 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   18398 K  |   18381 K  |\n","|       from large pool |      98    |     263    |   11203 K  |   11203 K  |\n","|       from small pool |   16251    |   16398    |    7194 K  |    7178 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     245    |     333    |    1058 K  |    1058 K  |\n","|       from large pool |      20    |     100    |     952 K  |     952 K  |\n","|       from small pool |     225    |     240    |     105 K  |     105 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      71    |     154    |    9134 K  |    9134 K  |\n","|       from large pool |      18    |      69    |    6261 K  |    6260 K  |\n","|       from small pool |      53    |     103    |    2873 K  |    2873 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:71/7698 batch_size:250\n","Next token prediction. step:11/178 batch:71/7698 epoch:2/10\n","full seq: The song \"Thunder and Lightning\" that will represent Bosnia and Herzegovina (BiH) at the 2010 Eurovision Contest in Oslo is in many ways a typical rock tune about love.Ģġġġġġġġġġ\n","pref seq: The song \"T\n","next tok:           h\n","pred tok:           '\n","Completed batch.\n","epoch:2/10 batch:71/7698 batch_size:250 loss:0.9313682913780212 time_for_batch_instance:191.0828595161438 total_batch_time:15512.337064743042 running_batch_average:218.48362063018368\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 654658 KiB |  15300 MiB |    808 TiB |    808 TiB |\n","|       from large pool | 197208 KiB |  14860 MiB |    806 TiB |    806 TiB |\n","|       from small pool | 457450 KiB |    477 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 654658 KiB |  15300 MiB |    808 TiB |    808 TiB |\n","|       from large pool | 197208 KiB |  14860 MiB |    806 TiB |    806 TiB |\n","|       from small pool | 457450 KiB |    477 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  15282 MiB |    806 TiB |    806 TiB |\n","|       from large pool | 189056 KiB |  14846 MiB |    805 TiB |    805 TiB |\n","|       from small pool | 453671 KiB |    474 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   3780 MiB |  16066 MiB | 177060 GiB | 177056 GiB |\n","|       from large pool |   3330 MiB |  15602 MiB | 176851 GiB | 176847 GiB |\n","|       from small pool |    450 MiB |    480 MiB |    209 GiB |    208 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   3140 MiB |   4073 MiB | 287482 GiB | 287479 GiB |\n","|       from large pool |   3137 MiB |   4069 MiB | 286017 GiB | 286014 GiB |\n","|       from small pool |      3 MiB |     20 MiB |   1465 GiB |   1465 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   18629 K  |   18613 K  |\n","|       from large pool |      98    |     263    |   11344 K  |   11344 K  |\n","|       from small pool |   16251    |   16398    |    7285 K  |    7269 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   18629 K  |   18613 K  |\n","|       from large pool |      98    |     263    |   11344 K  |   11344 K  |\n","|       from small pool |   16251    |   16398    |    7285 K  |    7269 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     249    |     333    |    1072 K  |    1071 K  |\n","|       from large pool |      24    |     100    |     964 K  |     964 K  |\n","|       from small pool |     225    |     240    |     107 K  |     106 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      75    |     162    |    9244 K  |    9244 K  |\n","|       from large pool |      26    |      77    |    6334 K  |    6334 K  |\n","|       from small pool |      49    |     102    |    2910 K  |    2909 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:72/7698 batch_size:250\n","Next token prediction. step:123/177 batch:72/7698 epoch:2/10\n","full seq: Attacking the AKP for \"serving Israel\" and \"collaborating with Western powers\", it more than doubled its percentage of votes gained in 2007, polling slightly above 5%.Ģġġġġġġġġġ\n","pref seq: Attacking the AKP for \"serving Israel\" and \"collaborating with Western powers\", it more than doubled its percentage of vote\n","next tok:                                                                                                                           s\n","pred tok:                                                                                                                           ;\n","Completed batch.\n","epoch:2/10 batch:72/7698 batch_size:250 loss:2.1108200550079346 time_for_batch_instance:189.43430733680725 total_batch_time:15701.77137207985 running_batch_average:218.08015794555345\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 657750 KiB |  15236 MiB |    816 TiB |    816 TiB |\n","|       from large pool | 200300 KiB |  14795 MiB |    815 TiB |    815 TiB |\n","|       from small pool | 457450 KiB |    477 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 657750 KiB |  15236 MiB |    816 TiB |    816 TiB |\n","|       from large pool | 200300 KiB |  14795 MiB |    815 TiB |    815 TiB |\n","|       from small pool | 457450 KiB |    477 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  15200 MiB |    815 TiB |    815 TiB |\n","|       from large pool | 189056 KiB |  14763 MiB |    814 TiB |    814 TiB |\n","|       from small pool | 453671 KiB |    474 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   3450 MiB |  15970 MiB | 178963 GiB | 178959 GiB |\n","|       from large pool |   3000 MiB |  15506 MiB | 178751 GiB | 178748 GiB |\n","|       from small pool |    450 MiB |    480 MiB |    211 GiB |    211 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   2807 MiB |   3830 MiB | 290465 GiB | 290462 GiB |\n","|       from large pool |   2804 MiB |   3826 MiB | 288981 GiB | 288979 GiB |\n","|       from small pool |      3 MiB |     20 MiB |   1483 GiB |   1483 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   18859 K  |   18843 K  |\n","|       from large pool |      98    |     263    |   11483 K  |   11483 K  |\n","|       from small pool |   16251    |   16398    |    7375 K  |    7359 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   18859 K  |   18843 K  |\n","|       from large pool |      98    |     263    |   11483 K  |   11483 K  |\n","|       from small pool |   16251    |   16398    |    7375 K  |    7359 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     249    |     331    |    1085 K  |    1084 K  |\n","|       from large pool |      24    |      98    |     976 K  |     976 K  |\n","|       from small pool |     225    |     240    |     108 K  |     108 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      72    |     142    |    9339 K  |    9339 K  |\n","|       from large pool |      20    |      57    |    6393 K  |    6393 K  |\n","|       from small pool |      52    |     104    |    2946 K  |    2946 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:73/7698 batch_size:250\n","Next token prediction. step:172/177 batch:73/7698 epoch:2/10\n","full seq: Because of the arbitrary nature of the state's rulings, such attention-getting tactics, though illegal, may be necessary to wake people up to the severity of the issue.Ģġġġġġġġġ\n","pref seq: Because of the arbitrary nature of the state's rulings, such attention-getting tactics, though illegal, may be necessary to wake people up to the severity of the issue.Ģġġġ\n","next tok:                                                                                                                                                                            ġ\n","pred tok:                                                                                                                                                                            Ģ\n","Completed batch.\n","epoch:2/10 batch:73/7698 batch_size:250 loss:1.0406488180160522 time_for_batch_instance:189.4001281261444 total_batch_time:15891.171500205994 running_batch_average:217.68728082473964\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 655402 KiB |  15234 MiB |    825 TiB |    825 TiB |\n","|       from large pool | 197952 KiB |  14794 MiB |    824 TiB |    824 TiB |\n","|       from small pool | 457450 KiB |    477 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 655402 KiB |  15234 MiB |    825 TiB |    825 TiB |\n","|       from large pool | 197952 KiB |  14794 MiB |    824 TiB |    824 TiB |\n","|       from small pool | 457450 KiB |    477 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  15200 MiB |    824 TiB |    824 TiB |\n","|       from large pool | 189056 KiB |  14763 MiB |    822 TiB |    822 TiB |\n","|       from small pool | 453671 KiB |    474 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   3030 MiB |  15976 MiB | 180903 GiB | 180900 GiB |\n","|       from large pool |   2580 MiB |  15512 MiB | 180688 GiB | 180686 GiB |\n","|       from small pool |    450 MiB |    480 MiB |    214 GiB |    213 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   2389 MiB |   3270 MiB | 293370 GiB | 293368 GiB |\n","|       from large pool |   2386 MiB |   3267 MiB | 291869 GiB | 291867 GiB |\n","|       from small pool |      3 MiB |     20 MiB |   1500 GiB |   1500 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   19089 K  |   19073 K  |\n","|       from large pool |      98    |     263    |   11623 K  |   11623 K  |\n","|       from small pool |   16251    |   16398    |    7465 K  |    7449 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   19089 K  |   19073 K  |\n","|       from large pool |      98    |     263    |   11623 K  |   11623 K  |\n","|       from small pool |   16251    |   16398    |    7465 K  |    7449 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     247    |     331    |    1098 K  |    1098 K  |\n","|       from large pool |      22    |      98    |     988 K  |     988 K  |\n","|       from small pool |     225    |     240    |     109 K  |     109 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      71    |     140    |    9434 K  |    9434 K  |\n","|       from large pool |      19    |      55    |    6452 K  |    6452 K  |\n","|       from small pool |      52    |     104    |    2982 K  |    2982 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:74/7698 batch_size:250\n","Next token prediction. step:74/175 batch:74/7698 epoch:2/10\n","full seq: \"Croatia and Albania still participate in the Adriatic Group, more out of political solidarity, though they also benefit from it in a wider sense,\" Lazarevski added.Ģġġġġġġġġġ\n","pref seq: \"Croatia and Albania still participate in the Adriatic Group, more out of \n","next tok:                                                                          p\n","pred tok:                                                                          (\n","Completed batch.\n","epoch:2/10 batch:74/7698 batch_size:250 loss:0.8943406939506531 time_for_batch_instance:187.9018533229828 total_batch_time:16079.073353528976 running_batch_average:217.28477504768887\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 653846 KiB |  15055 MiB |    834 TiB |    834 TiB |\n","|       from large pool | 196396 KiB |  14615 MiB |    832 TiB |    832 TiB |\n","|       from small pool | 457450 KiB |    477 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 653846 KiB |  15055 MiB |    834 TiB |    834 TiB |\n","|       from large pool | 196396 KiB |  14615 MiB |    832 TiB |    832 TiB |\n","|       from small pool | 457450 KiB |    477 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  15034 MiB |    832 TiB |    832 TiB |\n","|       from large pool | 189056 KiB |  14597 MiB |    831 TiB |    831 TiB |\n","|       from small pool | 453671 KiB |    473 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   3260 MiB |  15778 MiB | 182665 GiB | 182662 GiB |\n","|       from large pool |   2810 MiB |  15314 MiB | 182448 GiB | 182446 GiB |\n","|       from small pool |    450 MiB |    480 MiB |    216 GiB |    216 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   2621 MiB |   3230 MiB | 296979 GiB | 296976 GiB |\n","|       from large pool |   2618 MiB |   3226 MiB | 295460 GiB | 295458 GiB |\n","|       from small pool |      3 MiB |     17 MiB |   1518 GiB |   1518 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   19316 K  |   19300 K  |\n","|       from large pool |      98    |     263    |   11761 K  |   11761 K  |\n","|       from small pool |   16251    |   16398    |    7554 K  |    7538 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   19316 K  |   19300 K  |\n","|       from large pool |      98    |     263    |   11761 K  |   11761 K  |\n","|       from small pool |   16251    |   16398    |    7554 K  |    7538 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     255    |     339    |    1111 K  |    1111 K  |\n","|       from large pool |      30    |     106    |    1000 K  |    1000 K  |\n","|       from small pool |     225    |     240    |     111 K  |     110 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      78    |     152    |    9557 K  |    9557 K  |\n","|       from large pool |      26    |      66    |    6539 K  |    6539 K  |\n","|       from small pool |      52    |     103    |    3018 K  |    3018 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:75/7698 batch_size:250\n","Next token prediction. step:104/175 batch:75/7698 epoch:2/10\n","full seq: \"I am convinced that PDK had no reason to be concerned over the votes it would win, especially in the two Drenica municipalities, Lipjan and Malishevo,\" Krasniqi said.Ģġġġġġġġ\n","pref seq: \"I am convinced that PDK had no reason to be concerned over the votes it would win, especially in the tw\n","next tok:                                                                                                        o\n","pred tok:                                                                                                        ,\n","Completed batch.\n","epoch:2/10 batch:75/7698 batch_size:250 loss:1.1354774236679077 time_for_batch_instance:187.16023755073547 total_batch_time:16266.233591079712 running_batch_average:216.8831145477295\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 653846 KiB |  15054 MiB |    842 TiB |    842 TiB |\n","|       from large pool | 196396 KiB |  14614 MiB |    841 TiB |    841 TiB |\n","|       from small pool | 457450 KiB |    477 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 653846 KiB |  15054 MiB |    842 TiB |    842 TiB |\n","|       from large pool | 196396 KiB |  14614 MiB |    841 TiB |    841 TiB |\n","|       from small pool | 457450 KiB |    477 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  15034 MiB |    841 TiB |    841 TiB |\n","|       from large pool | 189056 KiB |  14597 MiB |    839 TiB |    839 TiB |\n","|       from small pool | 453671 KiB |    473 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   3260 MiB |  15776 MiB | 184413 GiB | 184410 GiB |\n","|       from large pool |   2810 MiB |  15312 MiB | 184194 GiB | 184191 GiB |\n","|       from small pool |    450 MiB |    480 MiB |    219 GiB |    218 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   2621 MiB |   3230 MiB | 300632 GiB | 300630 GiB |\n","|       from large pool |   2618 MiB |   3226 MiB | 299096 GiB | 299094 GiB |\n","|       from small pool |      3 MiB |     17 MiB |   1536 GiB |   1536 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   19543 K  |   19527 K  |\n","|       from large pool |      98    |     263    |   11899 K  |   11899 K  |\n","|       from small pool |   16251    |   16398    |    7644 K  |    7627 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   19543 K  |   19527 K  |\n","|       from large pool |      98    |     263    |   11899 K  |   11899 K  |\n","|       from small pool |   16251    |   16398    |    7644 K  |    7627 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     255    |     336    |    1123 K  |    1123 K  |\n","|       from large pool |      30    |     103    |    1011 K  |    1011 K  |\n","|       from small pool |     225    |     240    |     112 K  |     112 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      78    |     152    |    9680 K  |    9680 K  |\n","|       from large pool |      26    |      66    |    6626 K  |    6626 K  |\n","|       from small pool |      52    |     103    |    3054 K  |    3054 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:76/7698 batch_size:250\n","Next token prediction. step:126/174 batch:76/7698 epoch:2/10\n","full seq: His government is believed to have played an instrumental role in earlier moves to annul criminal charges against the former Yugoslav president's wife and daughter.Ģġġġġġġġġġ\n","pref seq: His government is believed to have played an instrumental role in earlier moves to annul criminal charges against the former Y\n","next tok:                                                                                                                              u\n","pred tok:                                                                                                                              ,\n","Completed batch.\n","epoch:2/10 batch:76/7698 batch_size:250 loss:1.207443118095398 time_for_batch_instance:184.10401964187622 total_batch_time:16450.337610721588 running_batch_average:216.4518106673893\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 658502 KiB |  14967 MiB |    851 TiB |    851 TiB |\n","|       from large pool | 201052 KiB |  14526 MiB |    849 TiB |    849 TiB |\n","|       from small pool | 457450 KiB |    477 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 658502 KiB |  14967 MiB |    851 TiB |    851 TiB |\n","|       from large pool | 201052 KiB |  14526 MiB |    849 TiB |    849 TiB |\n","|       from small pool | 457450 KiB |    477 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  14951 MiB |    849 TiB |    849 TiB |\n","|       from large pool | 189056 KiB |  14514 MiB |    848 TiB |    848 TiB |\n","|       from small pool | 453671 KiB |    473 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   7974 MiB |  15674 MiB | 185475 GiB | 185467 GiB |\n","|       from large pool |   7522 MiB |  15208 MiB | 185253 GiB | 185246 GiB |\n","|       from small pool |    452 MiB |    480 MiB |    221 GiB |    221 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   7330 MiB |   7458 MiB | 305769 GiB | 305762 GiB |\n","|       from large pool |   7325 MiB |   7453 MiB | 304215 GiB | 304208 GiB |\n","|       from small pool |      5 MiB |     14 MiB |   1553 GiB |   1553 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   19769 K  |   19753 K  |\n","|       from large pool |      98    |     263    |   12037 K  |   12037 K  |\n","|       from small pool |   16251    |   16398    |    7732 K  |    7716 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   19769 K  |   19753 K  |\n","|       from large pool |      98    |     263    |   12037 K  |   12037 K  |\n","|       from small pool |   16251    |   16398    |    7732 K  |    7716 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     259    |     324    |    1133 K  |    1132 K  |\n","|       from large pool |      33    |      91    |    1019 K  |    1019 K  |\n","|       from small pool |     226    |     240    |     113 K  |     113 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      87    |     157    |    9804 K  |    9803 K  |\n","|       from large pool |      30    |      72    |    6714 K  |    6714 K  |\n","|       from small pool |      57    |     100    |    3089 K  |    3089 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:77/7698 batch_size:250\n","Next token prediction. step:130/174 batch:77/7698 epoch:2/10\n","full seq: More recently, the city responded to earthquake damage in Haiti, flood damage in the Albanian city of Skadar and the earthquake-nuclear disaster in Fukushima, Japan.Ģġġġġġġġġ\n","pref seq: More recently, the city responded to earthquake damage in Haiti, flood damage in the Albanian city of Skadar and the earthquake-nu\n","next tok:                                                                                                                                  c\n","pred tok:                                                                                                                                  q\n","Completed batch.\n","epoch:2/10 batch:77/7698 batch_size:250 loss:1.9478367567062378 time_for_batch_instance:182.86024236679077 total_batch_time:16633.19785308838 running_batch_average:216.01555653361532\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 658502 KiB |  14967 MiB |    859 TiB |    859 TiB |\n","|       from large pool | 201052 KiB |  14526 MiB |    858 TiB |    858 TiB |\n","|       from small pool | 457450 KiB |    477 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 658502 KiB |  14967 MiB |    859 TiB |    859 TiB |\n","|       from large pool | 201052 KiB |  14526 MiB |    858 TiB |    858 TiB |\n","|       from small pool | 457450 KiB |    477 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  14951 MiB |    858 TiB |    858 TiB |\n","|       from large pool | 189056 KiB |  14514 MiB |    856 TiB |    856 TiB |\n","|       from small pool | 453671 KiB |    473 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   7974 MiB |  15674 MiB | 186532 GiB | 186524 GiB |\n","|       from large pool |   7522 MiB |  15208 MiB | 186307 GiB | 186300 GiB |\n","|       from small pool |    452 MiB |    480 MiB |    224 GiB |    223 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   7330 MiB |   7355 MiB | 310925 GiB | 310918 GiB |\n","|       from large pool |   7325 MiB |   7349 MiB | 309354 GiB | 309347 GiB |\n","|       from small pool |      5 MiB |     15 MiB |   1571 GiB |   1571 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   19995 K  |   19979 K  |\n","|       from large pool |      98    |     263    |   12174 K  |   12174 K  |\n","|       from small pool |   16251    |   16398    |    7821 K  |    7805 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   19995 K  |   19979 K  |\n","|       from large pool |      98    |     263    |   12174 K  |   12174 K  |\n","|       from small pool |   16251    |   16398    |    7821 K  |    7805 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     259    |     324    |    1142 K  |    1142 K  |\n","|       from large pool |      33    |      91    |    1027 K  |    1027 K  |\n","|       from small pool |     226    |     240    |     114 K  |     114 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      87    |     157    |    9927 K  |    9927 K  |\n","|       from large pool |      30    |      72    |    6802 K  |    6802 K  |\n","|       from small pool |      57    |     100    |    3124 K  |    3124 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:78/7698 batch_size:250\n","Next token prediction. step:135/174 batch:78/7698 epoch:2/10\n","full seq: There are only a few countries in the world and Europe that have similar challenges to what the Macedonian society has -- managing a multiethnic state of this nature.Ģġġġġġġġ\n","pref seq: There are only a few countries in the world and Europe that have similar challenges to what the Macedonian society has -- managing a mu\n","next tok:                                                                                                                                       l\n","pred tok:                                                                                                                                       ,\n","Completed batch.\n","epoch:2/10 batch:78/7698 batch_size:250 loss:2.1357975006103516 time_for_batch_instance:183.33493661880493 total_batch_time:16816.532789707184 running_batch_average:215.59657422701517\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 658502 KiB |  14967 MiB |    868 TiB |    868 TiB |\n","|       from large pool | 201052 KiB |  14526 MiB |    866 TiB |    866 TiB |\n","|       from small pool | 457450 KiB |    477 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 658502 KiB |  14967 MiB |    868 TiB |    868 TiB |\n","|       from large pool | 201052 KiB |  14526 MiB |    866 TiB |    866 TiB |\n","|       from small pool | 457450 KiB |    477 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  14951 MiB |    866 TiB |    866 TiB |\n","|       from large pool | 189056 KiB |  14514 MiB |    865 TiB |    865 TiB |\n","|       from small pool | 453671 KiB |    473 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   7974 MiB |  15674 MiB | 187586 GiB | 187578 GiB |\n","|       from large pool |   7522 MiB |  15208 MiB | 187359 GiB | 187351 GiB |\n","|       from small pool |    452 MiB |    480 MiB |    226 GiB |    226 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   7330 MiB |   7589 MiB | 316072 GiB | 316065 GiB |\n","|       from large pool |   7325 MiB |   7586 MiB | 314484 GiB | 314476 GiB |\n","|       from small pool |      5 MiB |     15 MiB |   1588 GiB |   1588 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   20221 K  |   20205 K  |\n","|       from large pool |      98    |     263    |   12311 K  |   12311 K  |\n","|       from small pool |   16251    |   16398    |    7910 K  |    7893 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   20221 K  |   20205 K  |\n","|       from large pool |      98    |     263    |   12311 K  |   12311 K  |\n","|       from small pool |   16251    |   16398    |    7910 K  |    7893 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     259    |     325    |    1151 K  |    1151 K  |\n","|       from large pool |      33    |      92    |    1035 K  |    1035 K  |\n","|       from small pool |     226    |     240    |     116 K  |     115 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      87    |     157    |   10050 K  |   10050 K  |\n","|       from large pool |      30    |      72    |    6890 K  |    6890 K  |\n","|       from small pool |      57    |     100    |    3160 K  |    3160 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:79/7698 batch_size:250\n","Next token prediction. step:10/173 batch:79/7698 epoch:2/10\n","full seq: Putin is expected to hold talks with Prime Minister Mirko Cvetkovic and President Boris Tadic but the topics are yet to be announced. (Blic, B92, Tanjug - 19/02/11)Ģġġġġġġġġ\n","pref seq: Putin is e\n","next tok:          x\n","pred tok:          ;\n","Completed batch.\n","epoch:2/10 batch:79/7698 batch_size:250 loss:0.8406602144241333 time_for_batch_instance:186.4305546283722 total_batch_time:17002.963344335556 running_batch_average:215.22738410551338\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 651888 KiB |  14886 MiB |    876 TiB |    876 TiB |\n","|       from large pool | 194438 KiB |  14446 MiB |    874 TiB |    874 TiB |\n","|       from small pool | 457450 KiB |    477 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 651888 KiB |  14886 MiB |    876 TiB |    876 TiB |\n","|       from large pool | 194438 KiB |  14446 MiB |    874 TiB |    874 TiB |\n","|       from small pool | 457450 KiB |    477 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  14868 MiB |    874 TiB |    874 TiB |\n","|       from large pool | 189056 KiB |  14432 MiB |    873 TiB |    873 TiB |\n","|       from small pool | 453671 KiB |    473 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1912 MiB |  15636 MiB | 189502 GiB | 189500 GiB |\n","|       from large pool |   1462 MiB |  15172 MiB | 189273 GiB | 189271 GiB |\n","|       from small pool |    450 MiB |    480 MiB |    229 GiB |    228 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1275 MiB |   7333 MiB | 318945 GiB | 318944 GiB |\n","|       from large pool |   1272 MiB |   7327 MiB | 317339 GiB | 317338 GiB |\n","|       from small pool |      3 MiB |     15 MiB |   1606 GiB |   1606 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   20446 K  |   20430 K  |\n","|       from large pool |      98    |     263    |   12448 K  |   12448 K  |\n","|       from small pool |   16251    |   16398    |    7998 K  |    7982 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   20446 K  |   20430 K  |\n","|       from large pool |      98    |     263    |   12448 K  |   12448 K  |\n","|       from small pool |   16251    |   16398    |    7998 K  |    7982 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     254    |     346    |    1165 K  |    1164 K  |\n","|       from large pool |      29    |     113    |    1047 K  |    1047 K  |\n","|       from small pool |     225    |     240    |     117 K  |     117 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      78    |     181    |   10188 K  |   10188 K  |\n","|       from large pool |      24    |      95    |    6993 K  |    6993 K  |\n","|       from small pool |      54    |     102    |    3195 K  |    3195 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:80/7698 batch_size:250\n","Next token prediction. step:133/172 batch:80/7698 epoch:2/10\n","full seq: According to the national co-ordinator for Euro-Atlantic integration, Nikola Dimitrov, officials in Brussels cited judicial reform as a particular area of concern.Ģġġġġġġġġ\n","pref seq: According to the national co-ordinator for Euro-Atlantic integration, Nikola Dimitrov, officials in Brussels cited judicial reform as\n","next tok:                                                                                                                                      \n","pred tok:                                                                                                                                     f\n","Completed batch.\n","epoch:2/10 batch:80/7698 batch_size:250 loss:1.4996880292892456 time_for_batch_instance:179.67064595222473 total_batch_time:17182.63399028778 running_batch_average:214.78292487859727\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 652529 KiB |  14812 MiB |    884 TiB |    884 TiB |\n","|       from large pool | 195079 KiB |  14372 MiB |    883 TiB |    883 TiB |\n","|       from small pool | 457450 KiB |    477 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 652529 KiB |  14812 MiB |    884 TiB |    884 TiB |\n","|       from large pool | 195079 KiB |  14372 MiB |    883 TiB |    883 TiB |\n","|       from small pool | 457450 KiB |    477 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  14786 MiB |    883 TiB |    883 TiB |\n","|       from large pool | 189056 KiB |  14349 MiB |    881 TiB |    881 TiB |\n","|       from small pool | 453671 KiB |    473 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   3800 MiB |  15486 MiB | 191141 GiB | 191137 GiB |\n","|       from large pool |   3350 MiB |  15020 MiB | 190909 GiB | 190906 GiB |\n","|       from small pool |    450 MiB |    480 MiB |    231 GiB |    231 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   3162 MiB |   4091 MiB | 321744 GiB | 321741 GiB |\n","|       from large pool |   3159 MiB |   4087 MiB | 320121 GiB | 320118 GiB |\n","|       from small pool |      3 MiB |     17 MiB |   1623 GiB |   1623 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   20669 K  |   20653 K  |\n","|       from large pool |      98    |     263    |   12583 K  |   12583 K  |\n","|       from small pool |   16251    |   16398    |    8085 K  |    8069 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   20669 K  |   20653 K  |\n","|       from large pool |      98    |     263    |   12583 K  |   12583 K  |\n","|       from small pool |   16251    |   16398    |    8085 K  |    8069 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     246    |     331    |    1177 K  |    1177 K  |\n","|       from large pool |      21    |      98    |    1058 K  |    1058 K  |\n","|       from small pool |     225    |     240    |     118 K  |     118 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      78    |     152    |   10288 K  |   10288 K  |\n","|       from large pool |      20    |      66    |    7056 K  |    7056 K  |\n","|       from small pool |      58    |     100    |    3231 K  |    3231 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:81/7698 batch_size:250\n","Next token prediction. step:3/172 batch:81/7698 epoch:2/10\n","full seq: The Austrian offer comes in response to the FBiH government's invitation for investments in the construction of hydropower plants, thermal power plants and a mine.Ģġġġġġġġġ\n","pref seq: The\n","next tok:    \n","pred tok:   h\n","Completed batch.\n","epoch:2/10 batch:81/7698 batch_size:250 loss:1.2937614917755127 time_for_batch_instance:177.14461088180542 total_batch_time:17359.778601169586 running_batch_average:214.31825433542699\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 652529 KiB |  14812 MiB |    892 TiB |    892 TiB |\n","|       from large pool | 195079 KiB |  14372 MiB |    891 TiB |    891 TiB |\n","|       from small pool | 457450 KiB |    477 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 652529 KiB |  14812 MiB |    892 TiB |    892 TiB |\n","|       from large pool | 195079 KiB |  14372 MiB |    891 TiB |    891 TiB |\n","|       from small pool | 457450 KiB |    477 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  14786 MiB |    891 TiB |    891 TiB |\n","|       from large pool | 189056 KiB |  14349 MiB |    889 TiB |    889 TiB |\n","|       from small pool | 453671 KiB |    473 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   3800 MiB |  15486 MiB | 192751 GiB | 192748 GiB |\n","|       from large pool |   3350 MiB |  15020 MiB | 192517 GiB | 192514 GiB |\n","|       from small pool |    450 MiB |    480 MiB |    234 GiB |    234 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   3162 MiB |   4091 MiB | 324556 GiB | 324553 GiB |\n","|       from large pool |   3159 MiB |   4087 MiB | 322915 GiB | 322912 GiB |\n","|       from small pool |      3 MiB |     17 MiB |   1641 GiB |   1641 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   20893 K  |   20876 K  |\n","|       from large pool |      98    |     263    |   12719 K  |   12719 K  |\n","|       from small pool |   16251    |   16398    |    8173 K  |    8157 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   20893 K  |   20876 K  |\n","|       from large pool |      98    |     263    |   12719 K  |   12719 K  |\n","|       from small pool |   16251    |   16398    |    8173 K  |    8157 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     246    |     332    |    1189 K  |    1189 K  |\n","|       from large pool |      21    |      98    |    1069 K  |    1069 K  |\n","|       from small pool |     225    |     240    |     120 K  |     119 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      78    |     150    |   10386 K  |   10386 K  |\n","|       from large pool |      20    |      65    |    7120 K  |    7120 K  |\n","|       from small pool |      58    |     100    |    3266 K  |    3266 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:82/7698 batch_size:250\n","Next token prediction. step:144/172 batch:82/7698 epoch:2/10\n","full seq: SE Times: High Representative Paddy Ashdown recently said that the largest political obstacles blocking the reform process in BiH come from the Bosnian Serb entity.Ģġġġġġġġ\n","pref seq: SE Times: High Representative Paddy Ashdown recently said that the largest political obstacles blocking the reform process in BiH come from the \n","next tok:                                                                                                                                                B\n","pred tok:                                                                                                                                                ,\n","Completed batch.\n","epoch:2/10 batch:82/7698 batch_size:250 loss:1.0861984491348267 time_for_batch_instance:177.03867483139038 total_batch_time:17536.817276000977 running_batch_average:213.86362531708508\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 652529 KiB |  14812 MiB |    901 TiB |    901 TiB |\n","|       from large pool | 195079 KiB |  14372 MiB |    899 TiB |    899 TiB |\n","|       from small pool | 457450 KiB |    477 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 652529 KiB |  14812 MiB |    901 TiB |    901 TiB |\n","|       from large pool | 195079 KiB |  14372 MiB |    899 TiB |    899 TiB |\n","|       from small pool | 457450 KiB |    477 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  14786 MiB |    899 TiB |    899 TiB |\n","|       from large pool | 189056 KiB |  14349 MiB |    898 TiB |    898 TiB |\n","|       from small pool | 453671 KiB |    473 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   3800 MiB |  15486 MiB | 194364 GiB | 194360 GiB |\n","|       from large pool |   3350 MiB |  15020 MiB | 194127 GiB | 194124 GiB |\n","|       from small pool |    450 MiB |    480 MiB |    236 GiB |    236 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   3162 MiB |   4091 MiB | 327362 GiB | 327359 GiB |\n","|       from large pool |   3159 MiB |   4087 MiB | 325703 GiB | 325700 GiB |\n","|       from small pool |      3 MiB |     17 MiB |   1658 GiB |   1658 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   21116 K  |   21100 K  |\n","|       from large pool |      98    |     263    |   12855 K  |   12855 K  |\n","|       from small pool |   16251    |   16398    |    8261 K  |    8245 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   21116 K  |   21100 K  |\n","|       from large pool |      98    |     263    |   12855 K  |   12855 K  |\n","|       from small pool |   16251    |   16398    |    8261 K  |    8245 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     246    |     332    |    1201 K  |    1201 K  |\n","|       from large pool |      21    |      99    |    1080 K  |    1080 K  |\n","|       from small pool |     225    |     240    |     121 K  |     121 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      78    |     150    |   10485 K  |   10485 K  |\n","|       from large pool |      20    |      65    |    7183 K  |    7183 K  |\n","|       from small pool |      58    |     100    |    3302 K  |    3302 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:83/7698 batch_size:250\n","Next token prediction. step:91/170 batch:83/7698 epoch:2/10\n","full seq: EU special envoy for Montenegro Miroslav Lajcak (left) met with Serbia-Montenegrin President Svetozar Marovic on Thursday (12 January). [Government of Montenegro]Ģġġġġġġġ\n","pref seq: EU special envoy for Montenegro Miroslav Lajcak (left) met with Serbia-Montenegrin Presiden\n","next tok:                                                                                           t\n","pred tok:                                                                                           ,\n","Completed batch.\n","epoch:2/10 batch:83/7698 batch_size:250 loss:0.7784658074378967 time_for_batch_instance:175.78757905960083 total_batch_time:17712.604855060577 running_batch_average:213.4048777718142\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 654148 KiB |  14671 MiB |    909 TiB |    909 TiB |\n","|       from large pool | 196698 KiB |  14231 MiB |    907 TiB |    907 TiB |\n","|       from small pool | 457450 KiB |    477 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 654148 KiB |  14671 MiB |    909 TiB |    909 TiB |\n","|       from large pool | 196698 KiB |  14231 MiB |    907 TiB |    907 TiB |\n","|       from small pool | 457450 KiB |    477 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  14620 MiB |    907 TiB |    907 TiB |\n","|       from large pool | 189056 KiB |  14184 MiB |    906 TiB |    906 TiB |\n","|       from small pool | 453671 KiB |    473 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2710 MiB |  15334 MiB | 196134 GiB | 196131 GiB |\n","|       from large pool |   2260 MiB |  14868 MiB | 195894 GiB | 195892 GiB |\n","|       from small pool |    450 MiB |    480 MiB |    239 GiB |    239 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   2071 MiB |   3770 MiB | 330208 GiB | 330206 GiB |\n","|       from large pool |   2067 MiB |   3765 MiB | 328533 GiB | 328531 GiB |\n","|       from small pool |      3 MiB |     17 MiB |   1675 GiB |   1675 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   21337 K  |   21321 K  |\n","|       from large pool |      98    |     263    |   12989 K  |   12989 K  |\n","|       from small pool |   16251    |   16398    |    8348 K  |    8331 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   21337 K  |   21321 K  |\n","|       from large pool |      98    |     263    |   12989 K  |   12989 K  |\n","|       from small pool |   16251    |   16398    |    8348 K  |    8331 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     244    |     334    |    1214 K  |    1214 K  |\n","|       from large pool |      19    |     101    |    1091 K  |    1091 K  |\n","|       from small pool |     225    |     240    |     122 K  |     122 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      75    |     145    |   10579 K  |   10579 K  |\n","|       from large pool |      17    |      59    |    7241 K  |    7241 K  |\n","|       from small pool |      58    |     101    |    3337 K  |    3337 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:84/7698 batch_size:250\n"]}],"source":["runner = Runner(runner_hyperparameters_name=\"SETimesByT5Vaswani2017Kocmi2018_1\")\n","\n","runner.load_dataset()\n","runner.load_model()\n","runner.load_trainer()\n","runner.run_trainer()"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOJ4/tLrpFESkIS5AU0spAb","gpuType":"A100","machine_shape":"hm","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}