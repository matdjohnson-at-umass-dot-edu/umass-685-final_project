{"cells":[{"cell_type":"markdown","metadata":{"id":"XxChZLAKliXg"},"source":["Content taken from GitHub repository hosting the code:\n","\n","https://github.com/matthewjohnson42/umass-cs685-finalproject\n","\n","Substantial modifications made to adapt to Colab training environment."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33952,"status":"ok","timestamp":1715909653295,"user":{"displayName":"Matthew Johnson","userId":"09672185346885346735"},"user_tz":240},"id":"U0NG9bOzleFZ","outputId":"d5937599-f058-4df8-89e4-b4abcd6e391b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":1}],"source":["from google.colab import drive\n","\n","import torch\n","import numpy as np\n","\n","import random\n","from typing import Optional\n","import time\n","import os\n","import gc\n","\n","\n","drive.mount('/content/drive', force_remount=True)\n","root_filepath = '/content/drive/MyDrive/CS685-NLP-GroupProject/Code/singleNotebookFromPythonFilesStructure/'\n","is_remote_execution = True\n","\n","torch.device(\"cuda\")"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":193,"status":"ok","timestamp":1715909653486,"user":{"displayName":"Matthew Johnson","userId":"09672185346885346735"},"user_tz":240},"id":"sllajv_0n2Vu"},"outputs":[],"source":["SETimesByT5Vaswani2017Kocmi2018_0 = {\n","    'dataset_transformer_name': 'dataset_transformer_setimesbyt5',\n","    'model_name': 'transformer_vaswani2017',\n","    'trainer_name': 'model_trainer_kocmi2018',\n","    'latest_param_filename_tag': '1715741500',\n","    # corresponds to dictionary 'get' calls in the dataset_loader constructor\n","    'dataset_transformer_hyperparameters': {\n","        'sentence_length_min_percentile': 5,\n","        'sentence_length_max_percentile': 95,\n","        'parsed_dataset_filename': 'setimes_parsed-1715586293'\n","    },\n","    # corresponds to dictionary 'get' calls in the model constructor\n","    'model_hyperparameters': {\n","        'd_model': 256,\n","        'nhead': 8,\n","        # number of encoders is 3 times that of decoders, following Xue 2021 - ByT5 - Sec 3.1\n","        'num_encoder_layers': 9,\n","        'num_decoder_layers': 3,\n","        'dim_feedforward': 2048,\n","        'dropout': 0.1,\n","        'activation': torch.nn.functional.relu,\n","        'custom_encoder': None,\n","        'custom_decoder': None,\n","        'layer_norm_eps': 1e-5,\n","        'batch_first': True,\n","        'norm_first': False,\n","        'bias': True,\n","        'device': None,\n","        'dtype': None\n","    },\n","    # corresponds to dictionary 'get' calls in the trainer constructor\n","    'trainer_hyperparameters': {\n","        # optimization and lr schedule following Kocmi 2018 - Trivial TL - Sec 3\n","        'optimizer_name': 'Adam',\n","        'lr_scheduler_name': 'ExponentialLR',\n","        'initial_lr': 0.001,\n","        'exp_decay': 0.5,\n","        'epochs': 10,\n","        'epoch_starting_index': 1,\n","        'batch_size_limit': 175,\n","        'element_difference_limit': 19,\n","        'batch_starting_index': 0\n","    }\n","}\n","\n","SETimesByT5Vaswani2017Kocmi2018_1 = {\n","    'dataset_transformer_name': 'dataset_transformer_setimesbyt5',\n","    'model_name': 'transformer_vaswani2017',\n","    'trainer_name': 'model_trainer_kocmi2018',\n","    'latest_param_filename_tag': '1715741441',\n","    # corresponds to dictionary 'get' calls in the dataset_loader constructor\n","    'dataset_transformer_hyperparameters': {\n","        'sentence_length_min_percentile': 5,\n","        'sentence_length_max_percentile': 95,\n","        'parsed_dataset_filename': 'setimes_parsed-1715586974'\n","    },\n","    # corresponds to dictionary 'get' calls in the model constructor\n","    'model_hyperparameters': {\n","        'd_model': 256,\n","        'nhead': 8,\n","        # number of encoders is 3 times that of decoders, following Xue 2021 - ByT5 - Sec 3.1\n","        'num_encoder_layers': 9,\n","        'num_decoder_layers': 3,\n","        'dim_feedforward': 1796,\n","        'dropout': 0.1,\n","        'activation': torch.nn.functional.relu,\n","        'custom_encoder': None,\n","        'custom_decoder': None,\n","        'layer_norm_eps': 1e-5,\n","        'batch_first': True,\n","        'norm_first': False,\n","        'bias': True,\n","        'device': None,\n","        'dtype': None\n","    },\n","    # corresponds to dictionary 'get' calls in the trainer constructor\n","    'trainer_hyperparameters': {\n","        # optimization and lr schedule following Kocmi 2018 - Trivial TL - Sec 3\n","        'optimizer_name': 'Adam',\n","        'lr_scheduler_name': 'ExponentialLR',\n","        'initial_lr': 0.001,\n","        'exp_decay': 0.5,\n","        'epochs': 10,\n","        'epoch_starting_index': 1,\n","        'batch_size_limit': 250,\n","        'element_difference_limit': 19,\n","        'batch_starting_index': 84\n","    }\n","}\n","\n","SETimesByT5Vaswani2017Kocmi2018_2 = {\n","    'dataset_transformer_name': 'dataset_transformer_setimesbyt5',\n","    'model_name': 'transformer_vaswani2017',\n","    'trainer_name': 'model_trainer_kocmi2018',\n","    'latest_param_filename_tag': '1715672061',\n","    # corresponds to dictionary 'get' calls in the dataset_loader constructor\n","    'dataset_transformer_hyperparameters': {\n","        'sentence_length_min_percentile': 5,\n","        'sentence_length_max_percentile': 95,\n","        'parsed_dataset_filename': 'setimes_parsed-1715586361'\n","    },\n","    # corresponds to dictionary 'get' calls in the model constructor\n","    'model_hyperparameters': {\n","        'd_model': 128,\n","        'nhead': 8,\n","        # number of encoders is 3 times that of decoders, following Xue 2021 - ByT5 - Sec 3.1\n","        'num_encoder_layers': 9,\n","        'num_decoder_layers': 3,\n","        'dim_feedforward': 1024,\n","        'dropout': 0.1,\n","        'activation': torch.nn.functional.relu,\n","        'custom_encoder': None,\n","        'custom_decoder': None,\n","        'layer_norm_eps': 1e-5,\n","        'batch_first': True,\n","        'norm_first': False,\n","        'bias': True,\n","        'device': None,\n","        'dtype': None\n","    },\n","    # corresponds to dictionary 'get' calls in the trainer constructor\n","    'trainer_hyperparameters': {\n","        # optimization and lr schedule following Kocmi 2018 - Trivial TL - Sec 3\n","        'optimizer_name': 'Adam',\n","        'lr_scheduler_name': 'ExponentialLR',\n","        'initial_lr': 0.001,\n","        'exp_decay': 0.5,\n","        'epochs': 10,\n","        'epoch_starting_index': 1,\n","        'batch_size_limit': 400,\n","        'element_difference_limit': 19,\n","        'batch_starting_index': 0\n","    }\n","}\n","\n","loss_weights_0 = torch.tensor([0, 0, 0.244293498, 0.354252208, 0.119055746, 0.129490827, 0.234447, 0.331966255, 0.062493498, 0.200436672, 0.128134531, 0.115730135, 0.114789455, 0.111928721, 0.120232896, 0.172708905, 0.091552235, 0.18382728, 0.167772254, 0.221570123, 0.26933557, 0.207267199, 0.161156936, 0.163208063, 0.206129376, 0.1923278, 0.246448966, 0.309805116, 0.312319847, 0.341492611, 0.287077958, 0.317765776, 0.282694925, 0.328107375, 0.305618951, 0.342956521, 0.33013427, 0.36810305, 0.29995848, 0.39787945, 0.36195021, 0.231575726, 0.238716465, 0.228047462, 0.589442629, 0.428540415, 0.349514641, 0.428583838, 0.372321337, 0.35910363, 0.314836573, 0.359830778, 0.329628544, 0.358553271, 0.38731315, 0.301171514, 0.414866271, 0.454463773, 0.410552656, 0.418645272, 0.489374491, 0.60674051, 0.415410876, 0.387694004, 0.469862412, 0.387466491, 0.404244134, 0.410692024, 0.3650963, 0.328332631, 0.362047807, 0.390990331, 0.407611852, 0.353090879, 0.519082435, 0.465516001, 0.382984849, 0.382904558, 0.417591599, 0.47406963, 0.513595183, 0.561900207, 0.600687916, 0.552947486, 0.672534847, 0.775971182, 0.728910416, 0.783069437, 0.726598021, 0.870987145, 0.761128877, 0.716818395, 0.708372474, 0.70507743, 0.731312344, 0.718124592, 0.931839821, 0.675783865, 0.863679642, 0.79786095, 0.870987145, 0.888835536, 0.845831251, 0.845831251, 0.870987145, 0.831986963, 0.817320914, 0.888835536, 0.82798286, 0.931839821, 0.900147142, 0.91399143, 0.91399143, 0.956995715, 0.931839821, 1, 0.900147142, 0.870987145, 0.870987145, 1, 0.900147142, 0.888835536, 0.956995715, 0.824221583, 1, 1, 0.956995715, 1, 0.931839821, 0.931839821, 0.956995715, 0.956995715, 0.956995715, 0.888835536, 0.931839821, 1, 0.900147142, 0.91399143, 0.956995715, 0.956995715, 0.956995715, 1, 1, 1, 0.900147142, 0.931839821, 0.900147142, 0.931839821, 0.956995715, 0.91399143, 1, 0.956995715, 1, 1, 1, 1, 1, 0.956995715, 1, 1, 1, 1, 1, 1, 1, 0.931839821, 1, 0.956995715, 1, 1, 0.956995715])\n","loss_weights_1 = torch.tensor([0, 0, 0.283786926, 0.387999164, 0.165094134, 0.174983875, 0.274455009, 0.366877881, 0.111487844, 0.242222071, 0.173698459, 0.16194232, 0.1610508, 0.158339569, 0.166209765, 0.215943364, 0.139027964, 0.226480689, 0.211264704, 0.262251081, 0.307520293, 0.248695632, 0.204995104, 0.206939038, 0.247617272, 0.23453697, 0.285829749, 0.345874889, 0.3482582, 0.375906387, 0.324335459, 0.353419523, 0.320181484, 0.363220667, 0.341907494, 0.377293793, 0.365141636, 0.401126157, 0.336542841, 0.429346435, 0.395294867, 0.271733788, 0.27850135, 0.268389913, 0.610898469, 0.458405049, 0.383509184, 0.458446203, 0.405123996, 0.39259705, 0.350643401, 0.393286196, 0.36466234, 0.392075452, 0.419332333, 0.337692481, 0.44544552, 0.482973645, 0.441357336, 0.449027029, 0.51605992, 0.627292358, 0.445961663, 0.419693282, 0.497567547, 0.419477659, 0.435378499, 0.44148942, 0.398276541, 0.363434152, 0.395387363, 0.422817343, 0.438570219, 0.386898527, 0.544215318, 0.493448281, 0.415230229, 0.415154135, 0.448028421, 0.501554895, 0.539014832, 0.584795422, 0.621556075, 0.576310573, 0.689648265, 0.78767899, 0.743077631, 0.794406288, 0.740886083, 0.877729392, 0.773612348, 0.731617543, 0.723613008, 0.720490164, 0.745354034, 0.732855478, 0.93540189, 0.692727489, 0.870803781, 0.808424792, 0.877729392, 0.894645021, 0.853888152, 0.853888152, 0.877729392, 0.84076737, 0.826867773, 0.894645021, 0.836972522, 0.93540189, 0.90536548, 0.918486261, 0.918486261, 0.959243131, 0.93540189, 1, 0.90536548, 0.877729392, 0.877729392, 1, 0.90536548, 0.894645021, 0.959243131, 0.833407811, 1, 1, 0.959243131, 1, 0.93540189, 0.93540189, 0.959243131, 0.959243131, 0.959243131, 0.894645021, 0.93540189, 1, 0.90536548, 0.918486261, 0.959243131, 0.959243131, 0.959243131, 1, 1, 1, 0.90536548, 0.93540189, 0.90536548, 0.93540189, 0.959243131, 0.918486261, 1, 0.959243131, 1, 1, 1, 1, 1, 0.959243131, 1, 1, 1, 1, 1, 1, 1, 0.93540189, 1, 0.959243131, 1, 1, 0.959243131])\n","\n","english_char_mappings = {\n","    ord(\" \"): ord(\" \"),\n","    ord(\"e\"): ord(\"e\"),\n","    ord(\"t\"): ord(\"t\"),\n","    ord(\"a\"): ord(\"a\"),\n","    ord(\"i\"): ord(\"i\"),\n","    ord(\"o\"): ord(\"o\"),\n","    ord(\"n\"): ord(\"n\"),\n","    ord(\"r\"): ord(\"r\"),\n","    ord(\"s\"): ord(\"s\"),\n","    ord(\"h\"): ord(\"h\"),\n","    ord(\"l\"): ord(\"l\"),\n","    ord(\"d\"): ord(\"d\"),\n","    ord(\"c\"): ord(\"c\"),\n","    ord(\"u\"): ord(\"u\"),\n","    ord(\"m\"): ord(\"m\"),\n","    ord(\"p\"): ord(\"p\"),\n","    ord(\"f\"): ord(\"f\"),\n","    ord(\"g\"): ord(\"g\"),\n","    ord(\"y\"): ord(\"y\"),\n","    ord(\"b\"): ord(\"b\"),\n","    ord(\"w\"): ord(\"w\"),\n","    ord(\"v\"): ord(\"v\"),\n","    ord(\",\"): ord(\",\"),\n","    ord(\".\"): ord(\".\"),\n","    ord(\"k\"): ord(\"k\"),\n","    ord(\"T\"): ord(\"T\"),\n","    ord(\"S\"): ord(\"S\"),\n","    ord(\"0\"): ord(\"0\"),\n","    ord(\"A\"): ord(\"A\"),\n","    ord(\"-\"): ord(\"-\"),\n","    ord(\"B\"): ord(\"B\"),\n","    ord(\"M\"): ord(\"M\"),\n","    ord(\"\\\"\"): ord(\"\\\"\"),\n","    ord(\"E\"): ord(\"E\"),\n","    ord(\"P\"): ord(\"P\"),\n","    ord(\"C\"): ord(\"C\"),\n","    ord(\"I\"): ord(\"I\"),\n","    ord(\"1\"): ord(\"1\"),\n","    ord(\"'\"): ord(\"'\"),\n","    ord(\"j\"): ord(\"j\"),\n","    ord(\"2\"): ord(\"2\"),\n","    ord(\"R\"): ord(\"R\"),\n","    ord(\"U\"): ord(\"U\"),\n","    ord(\"K\"): ord(\"K\"),\n","    ord(\"D\"): ord(\"D\"),\n","    ord(\"x\"): ord(\"x\"),\n","    ord(\"H\"): ord(\"H\"),\n","    ord(\"F\"): ord(\"F\"),\n","    ord(\"N\"): ord(\"N\"),\n","    ord(\"G\"): ord(\"G\"),\n","    ord(\"/\"): ord(\"/\"),\n","    ord(\"O\"): ord(\"O\"),\n","    ord(\")\"): ord(\")\"),\n","    ord(\"(\"): ord(\"(\"),\n","    ord(\"9\"): ord(\"9\"),\n","    ord(\"W\"): ord(\"W\"),\n","    ord(\"z\"): ord(\"z\"),\n","    ord(\"5\"): ord(\"5\"),\n","    ord(\"3\"): ord(\"3\"),\n","    ord(\"J\"): ord(\"J\"),\n","    ord(\"4\"): ord(\"4\"),\n","    ord(\"q\"): ord(\"q\"),\n","    ord(\"L\"): ord(\"L\"),\n","    ord(\"6\"): ord(\"6\"),\n","    ord(\"7\"): ord(\"7\"),\n","    ord(\"8\"): ord(\"8\"),\n","    ord(\"V\"): ord(\"V\"),\n","    ord(\"[\"): ord(\"[\"),\n","    ord(\"]\"): ord(\"]\"),\n","    ord(\":\"): ord(\":\"),\n","    ord(\"Z\"): ord(\"Z\"),\n","    ord(\"%\"): ord(\"%\"),\n","    ord(\"Y\"): ord(\"Y\"),\n","    ord(\";\"): ord(\";\"),\n","    ord(\"–\"): ord(\"-\"),\n","    ord(\"?\"): ord(\"?\"),\n","    ord(\"X\"): ord(\"X\"),\n","    ord(\"$\"): ord(\"$\"),\n","    ord(\"’\"): ord(\"'\"),\n","    ord(\"Q\"): ord(\"Q\"),\n","    ord(\"…\"): ord(\"\\u0120\"),\n","    ord(\"!\"): ord(\"\\u0120\"),\n","    ord(\"&\"): ord(\"\\u0120\"),\n","    ord(\"ć\"): ord(\"\\u0120\"),\n","    ord(\"”\"): ord(\"\\\"\"),\n","    ord(\"é\"): ord(\"\\u0120\"),\n","    ord(\"“\"): ord(\"\\\"\"),\n","    ord(\"ı\"): ord(\"\\u0120\"),\n","    ord(\"ü\"): ord(\"\\u0120\"),\n","    ord(\"+\"): ord(\"\\u0120\"),\n","    ord(\"ç\"): ord(\"\\u0120\"),\n","    ord(\"ˈ\"): ord(\"'\"),\n","    ord(\"ö\"): ord(\"\\u0120\"),\n","    ord(\"ë\"): ord(\"\\u0120\"),\n","    ord(\"Ç\"): ord(\"\\u0120\"),\n","    ord(\"ğ\"): ord(\"\\u0120\"),\n","    ord(\"č\"): ord(\"\\u0120\"),\n","    ord(\"š\"): ord(\"\\u0120\"),\n","    ord(\"‘\"): ord(\"'\"),\n","    ord(\"ž\"): ord(\"\\u0120\"),\n","    ord(\"*\"): ord(\"\\u0120\"),\n","    ord(\"ş\"): ord(\"\\u0120\"),\n","    ord(\"б\"): ord(\"\\u0120\"),\n","    ord(\"Š\"): ord(\"\\u0120\"),\n","    ord(\"İ\"): ord(\"\\u0120\"),\n","    ord(\"à\"): ord(\"\\u0120\"),\n","    ord(\"г\"): ord(\"\\u0120\"),\n","    ord(\"ï\"): ord(\"\\u0120\"),\n","    ord(\"Ü\"): ord(\"\\u0120\"),\n","    ord(\"—\"): ord(\"-\"),\n","    ord(\"€\"): ord(\"\\u0120\"),\n","    ord(\"Ö\"): ord(\"\\u0120\"),\n","    ord(\"đ\"): ord(\"\\u0120\"),\n","    ord(\"\\\\\"): ord(\"\\u0120\"),\n","    ord(\"Ι\"): ord(\"\\u0120\"),\n","    ord(\"Α\"): ord(\"A\"),\n","    ord(\"`\"): ord(\"'\"),\n","    ord(\"_\"): ord(\"\\u0120\"),\n","    ord(\"=\"): ord(\"\\u0120\"),\n","    ord(\"@\"): ord(\"\\u0120\"),\n","    ord(\"А\"): ord(\"A\"),\n","    ord(\"ó\"): ord(\"\\u0120\"),\n","    ord(\"í\"): ord(\"\\u0120\"),\n","    ord(\"â\"): ord(\"\\u0120\"),\n","    ord(\"\\x80\"): ord(\"\\u0120\"),\n","    ord(\"Ž\"): ord(\"\\u0120\"),\n","    ord(\"Κ\"): ord(\"K\"),\n","    ord(\"Ο\"): ord(\"O\"),\n","    ord(\"р\"): ord(\"p\"),\n","    ord(\"Ş\"): ord(\"\\u0120\"),\n","    ord(\"á\"): ord(\"\\u0120\"),\n","    ord(\"у\"): ord(\"y\"),\n","    ord(\"\\x93\"): ord(\"\\u0120\"),\n","    ord(\"°\"): ord(\"\\u0120\"),\n","    ord(\"<\"): ord(\"\\u0120\"),\n","    ord(\"½\"): ord(\"\\u0120\"),\n","    ord(\"Т\"): ord(\"T\"),\n","    ord(\"ø\"): ord(\"\\u0120\"),\n","    ord(\"Ε\"): ord(\"E\"),\n","    ord(\"#\"): ord(\"\\u0120\"),\n","    ord(\"ý\"): ord(\"\\u0120\"),\n","    ord(\"л\"): ord(\"\\u0120\"),\n","    ord(\"я\"): ord(\"\\u0120\"),\n","    ord(\"�\"): ord(\"\\u0120\"),\n","    ord(\"º\"): ord(\"\\u0120\"),\n","    ord(\"ä\"): ord(\"\\u0120\"),\n","    ord(\"е\"): ord(\"e\"),\n","    ord(\"о\"): ord(\"o\"),\n","    ord(\"Đ\"): ord(\"\\u0120\"),\n","    ord(\"è\"): ord(\"\\u0120\"),\n","    ord(\"¾\"): ord(\"\\u0120\"),\n","    ord(\"\\x96\"): ord(\"\\u0120\"),\n","    ord(\"æ\"): ord(\"\\u0120\"),\n","    ord(\">\"): ord(\"\\u0120\"),\n","    ord(\"¦\"): ord(\"\\u0120\"),\n","    ord(\"μ\"): ord(\"\\u0120\"),\n","    ord(\"Č\"): ord(\"\\u0120\"),\n","    ord(\"ñ\"): ord(\"\\u0120\"),\n","    ord(\"х\"): ord(\"x\"),\n","    ord(\"М\"): ord(\"M\"),\n","    ord(\"É\"): ord(\"\\u0120\"),\n","    ord(\"±\"): ord(\"\\u0120\"),\n","    ord(\"£\"): ord(\"\\u0120\"),\n","    ord(\"{\"): ord(\"\\u0120\"),\n","    ord(\"}\"): ord(\"\\u0120\"),\n","    ord(\"ъ\"): ord(\"\\u0120\"),\n","    ord(\"а\"): ord(\"\\u0120\"),\n","    ord(\"и\"): ord(\"\\u0120\")\n","}\n","\n","turkish_char_mappings = {\n","    ord(\" \"): ord(\" \"),\n","    ord(\"a\"): ord(\"a\"),\n","    ord(\"e\"): ord(\"e\"),\n","    ord(\"i\"): ord(\"i\"),\n","    ord(\"n\"): ord(\"n\"),\n","    ord(\"r\"): ord(\"r\"),\n","    ord(\"l\"): ord(\"l\"),\n","    ord(\"ı\"): ord(\"ı\"),\n","    ord(\"k\"): ord(\"k\"),\n","    ord(\"d\"): ord(\"d\"),\n","    ord(\"t\"): ord(\"t\"),\n","    ord(\"s\"): ord(\"s\"),\n","    ord(\"u\"): ord(\"u\"),\n","    ord(\"m\"): ord(\"m\"),\n","    ord(\"y\"): ord(\"y\"),\n","    ord(\"o\"): ord(\"o\"),\n","    ord(\"ü\"): ord(\"ü\"),\n","    ord(\"b\"): ord(\"b\"),\n","    ord(\"ş\"): ord(\"ş\"),\n","    ord(\"v\"): ord(\"v\"),\n","    ord(\"g\"): ord(\"g\"),\n","    ord(\"z\"): ord(\"z\"),\n","    ord(\"ç\"): ord(\"ç\"),\n","    ord(\"ğ\"): ord(\"ğ\"),\n","    ord(\".\"): ord(\".\"),\n","    ord(\",\"): ord(\",\"),\n","    ord(\"c\"): ord(\"c\"),\n","    ord(\"h\"): ord(\"h\"),\n","    ord(\"p\"): ord(\"p\"),\n","    ord(\"ö\"): ord(\"ö\"),\n","    ord(\"'\"): ord(\"'\"),\n","    ord(\"B\"): ord(\"B\"),\n","    ord(\"A\"): ord(\"A\"),\n","    ord(\"f\"): ord(\"f\"),\n","    ord(\"S\"): ord(\"S\"),\n","    ord(\"K\"): ord(\"K\"),\n","    ord(\"0\"): ord(\"0\"),\n","    ord(\"\\\"\"): ord(\"\\\"\"),\n","    ord(\"T\"): ord(\"T\"),\n","    ord(\"M\"): ord(\"M\"),\n","    ord(\"1\"): ord(\"1\"),\n","    ord(\"P\"): ord(\"P\"),\n","    ord(\"D\"): ord(\"D\"),\n","    ord(\"H\"): ord(\"H\"),\n","    ord(\"2\"): ord(\"2\"),\n","    ord(\"E\"): ord(\"E\"),\n","    ord(\"R\"): ord(\"R\"),\n","    ord(\"-\"): ord(\"-\"),\n","    ord(\"G\"): ord(\"G\"),\n","    ord(\"j\"): ord(\"j\"),\n","    ord(\"Y\"): ord(\"Y\"),\n","    ord(\"C\"): ord(\"C\"),\n","    ord(\"İ\"): ord(\"İ\"),\n","    ord(\"O\"): ord(\"O\"),\n","    ord(\"/\"): ord(\"/\"),\n","    ord(\"F\"): ord(\"F\"),\n","    ord(\"N\"): ord(\"N\"),\n","    ord(\"9\"): ord(\"9\"),\n","    ord(\"5\"): ord(\"5\"),\n","    ord(\"3\"): ord(\"3\"),\n","    ord(\"I\"): ord(\"I\"),\n","    ord(\"4\"): ord(\"4\"),\n","    ord(\"L\"): ord(\"L\"),\n","    ord(\"6\"): ord(\"6\"),\n","    ord(\")\"): ord(\")\"),\n","    ord(\"(\"): ord(\"(\"),\n","    ord(\"7\"): ord(\"7\"),\n","    ord(\"8\"): ord(\"8\"),\n","    ord(\"U\"): ord(\"U\"),\n","    ord(\"V\"): ord(\"V\"),\n","    ord(\":\"): ord(\":\"),\n","    ord(\"[\"): ord(\"[\"),\n","    ord(\"]\"): ord(\"]\"),\n","    ord(\"’\"): ord(\"'\"),\n","    ord(\"Z\"): ord(\"Z\"),\n","    ord(\"Ç\"): ord(\"Ç\"),\n","    ord(\"J\"): ord(\"J\"),\n","    ord(\"Ü\"): ord(\"Ü\"),\n","    ord(\"Ş\"): ord(\"Ş\"),\n","    ord(\"Ö\"): ord(\"Ö\"),\n","    ord(\"%\"): ord(\"%\"),\n","    ord(\";\"): ord(\";\"),\n","    ord(\"w\"): ord(\"w\"),\n","    ord(\"W\"): ord(\"W\"),\n","    ord(\"â\"): ord(\"â\"),\n","    ord(\"–\"): ord(\"-\"),\n","    ord(\"?\"): ord(\"?\"),\n","    ord(\"x\"): ord(\"x\"),\n","    ord(\"“\"): ord(\"\\\"\"),\n","    ord(\"”\"): ord(\"\\\"\"),\n","    ord(\"X\"): ord(\"X\"),\n","    ord(\"q\"): ord(\"q\"),\n","    ord(\"î\"): ord(\"\\u0120\"),\n","    ord(\"&\"): ord(\"\\u0120\"),\n","    ord(\"!\"): ord(\"\\u0120\"),\n","    ord(\"ð\"): ord(\"\\u0120\"),\n","    ord(\"Q\"): ord(\"\\u0120\"),\n","    ord(\"+\"): ord(\"\\u0120\"),\n","    ord(\"þ\"): ord(\"\\u0120\"),\n","    ord(\"‘\"): ord(\"'\"),\n","    ord(\"é\"): ord(\"\\u0120\"),\n","    ord(\"º\"): ord(\"\\u0120\"),\n","    ord(\"ë\"): ord(\"\\u0120\"),\n","    ord(\"…\"): ord(\"\\u0120\"),\n","    ord(\"б\"): ord(\"\\u0120\"),\n","    ord(\"*\"): ord(\"\\u0120\"),\n","    ord(\"=\"): ord(\"\\u0120\"),\n","    ord(\"`\"): ord(\"'\"),\n","    ord(\"ć\"): ord(\"\\u0120\"),\n","    ord(\"û\"): ord(\"\\u0120\"),\n","    ord(\"Ý\"): ord(\"\\u0120\"),\n","    ord(\"г\"): ord(\"\\u0120\"),\n","    ord(\"—\"): ord(\"\\u0120\"),\n","    ord(\"\\\\\"): ord(\"\\u0120\"),\n","    ord(\"°\"): ord(\"\\u0120\"),\n","    ord(\"@\"): ord(\"\\u0120\"),\n","    ord(\"č\"): ord(\"\\u0120\"),\n","    ord(\"ó\"): ord(\"\\u0120\"),\n","    ord(\"š\"): ord(\"\\u0120\"),\n","    ord(\"р\"): ord(\"\\u0120\"),\n","    ord(\"_\"): ord(\"\\u0120\"),\n","    ord(\"{\"): ord(\"\\u0120\"),\n","    ord(\"#\"): ord(\"\\u0120\"),\n","    ord(\"^\"): ord(\"\\u0120\"),\n","    ord(\">\"): ord(\"\\u0120\"),\n","    ord(\"$\"): ord(\"\\u0120\"),\n","    ord(\"đ\"): ord(\"\\u0120\"),\n","    ord(\"í\"): ord(\"\\u0120\"),\n","    ord(\"ø\"): ord(\"\\u0120\"),\n","    ord(\"Š\"): ord(\"\\u0120\"),\n","    ord(\"ž\"): ord(\"\\u0120\"),\n","    ord(\"Þ\"): ord(\"\\u0120\"),\n","    ord(\"л\"): ord(\"\\u0120\"),\n","    ord(\"я\"): ord(\"\\u0120\"),\n","    ord(\"}\"): ord(\"\\u0120\"),\n","    ord(\"±\"): ord(\"\\u0120\"),\n","    ord(\"½\"): ord(\"\\u0120\"),\n","    ord(\"¾\"): ord(\"\\u0120\"),\n","    ord(\"ª\"): ord(\"\\u0120\"),\n","    ord(\"á\"): ord(\"\\u0120\"),\n","    ord(\"É\"): ord(\"\\u0120\"),\n","    ord(\"è\"): ord(\"\\u0120\"),\n","    ord(\"Ğ\"): ord(\"\\u0120\"),\n","    ord(\"ï\"): ord(\"\\u0120\"),\n","    ord(\"ñ\"): ord(\"\\u0120\"),\n","    ord(\"ý\"): ord(\"\\u0120\"),\n","    ord(\"Ž\"): ord(\"\\u0120\"),\n","    ord(\"μ\"): ord(\"\\u0120\"),\n","    ord(\"а\"): ord(\"\\u0120\"),\n","    ord(\"и\"): ord(\"\\u0120\"),\n","    ord(\"у\"): ord(\"\\u0120\"),\n","    ord(\"х\"): ord(\"\\u0120\"),\n","    ord(\"ъ\"): ord(\"\\u0120\"),\n","}\n"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1715909653486,"user":{"displayName":"Matthew Johnson","userId":"09672185346885346735"},"user_tz":240},"id":"RJAevV6XnuW1"},"outputs":[],"source":["class DatasetHolder:\n","\n","    def __init__(self):\n","        self.unknown_vocabulary_type = None\n","        self.padding_vocabulary_type = None\n","        self.end_of_sequence_type = None\n","        self.target_vocab = None\n","        self.target_vocab_array = None\n","        self.target_vocab_counts = None\n","        self.source_vocab = None\n","        self.source_vocab_array = None\n","        self.source_vocab_counts = None\n","        self.target_encodings = None\n","        self.target_encodings_train = None\n","        self.target_encodings_test = None\n","        self.source_encodings = None\n","        self.source_encodings_train = None\n","        self.source_encodings_test = None\n","        self.max_src_seq_obs = 0\n","        self.max_tgt_seq_obs = 0\n","\n","    def get_unknown_vocabulary_type(self):\n","        return self.unknown_vocabulary_type\n","\n","    def set_unknown_vocabulary_type(self, unknown_vocabulary_type):\n","        self.unknown_vocabulary_type = unknown_vocabulary_type\n","\n","    def get_padding_vocabulary_type(self):\n","        return self.padding_vocabulary_type\n","\n","    def set_padding_vocabulary_type(self, padding_vocabulary_type):\n","        self.padding_vocabulary_type = padding_vocabulary_type\n","\n","    def get_end_of_sequence_vocabulary_type(self):\n","        return self.end_of_sequence_type\n","\n","    def set_end_of_sequence_vocabulary_type(self, end_of_sequence_type):\n","        self.end_of_sequence_type = end_of_sequence_type\n","\n","    def get_target_vocab(self):\n","        return self.target_vocab\n","\n","    def set_target_vocab(self, target_vocab):\n","        self.target_vocab = target_vocab\n","\n","    def get_target_vocab_numpy(self):\n","        if self.target_vocab_array is None:\n","            self.target_vocab_array = np.array(self.target_vocab)\n","        return self.target_vocab_array\n","\n","    def get_target_vocab_counts(self):\n","        return self.target_vocab_counts\n","\n","    def set_target_vocab_counts(self, target_vocab_counts):\n","        self.target_vocab_counts = target_vocab_counts\n","\n","    def get_source_vocab(self):\n","        return self.source_vocab\n","\n","    def set_source_vocab(self, source_vocab):\n","        self.source_vocab = source_vocab\n","\n","    def get_source_vocab_numpy(self):\n","        if self.source_vocab_array is None:\n","            self.source_vocab_array = np.array(self.source_vocab)\n","        return self.source_vocab_array\n","\n","    def get_source_vocab_counts(self):\n","        return self.source_vocab_counts\n","\n","    def set_source_vocab_counts(self, source_vocab_counts):\n","        self.source_vocab_counts = source_vocab_counts\n","\n","    def get_target_encodings(self):\n","        return self.target_encodings\n","\n","    def set_target_encodings(self, target_encodings):\n","        del self.target_encodings\n","        self.target_encodings = target_encodings\n","        if is_remote_execution:\n","            torch.cuda.empty_cache()\n","\n","    def get_source_encodings(self):\n","        return self.source_encodings\n","\n","    def set_source_encodings(self, source_encodings):\n","        del self.source_encodings\n","        self.source_encodings = source_encodings\n","        if is_remote_execution:\n","            torch.cuda.empty_cache()\n","\n","    def get_target_encodings_train(self):\n","        return self.target_encodings_train\n","\n","    def set_target_encodings_train(self, target_encodings_train):\n","        del self.target_encodings_train\n","        self.target_encodings_train = target_encodings_train\n","        if is_remote_execution:\n","            torch.cuda.empty_cache()\n","\n","    def get_source_encodings_train(self):\n","        return self.source_encodings_train\n","\n","    def set_source_encodings_train(self, source_encodings_train):\n","        del self.source_encodings_train\n","        self.source_encodings_train = source_encodings_train\n","        if is_remote_execution:\n","            torch.cuda.empty_cache()\n","\n","    def get_target_encodings_test(self):\n","        return self.target_encodings_test\n","\n","    def set_target_encodings_test(self, target_encodings_test):\n","        del self.target_encodings_test\n","        self.target_encodings_test = target_encodings_test\n","        if is_remote_execution:\n","            torch.cuda.empty_cache()\n","\n","    def get_source_encodings_test(self):\n","        return self.source_encodings_test\n","\n","    def set_source_encodings_test(self, source_encodings_test):\n","        del self.source_encodings_test\n","        self.source_encodings_test = source_encodings_test\n","        if is_remote_execution:\n","            torch.cuda.empty_cache()\n","\n","    def get_max_src_seq_obs(self):\n","        return self.max_src_seq_obs\n","\n","    def set_max_src_seq_obs(self, max_src_seq_obs):\n","        self.max_src_seq_obs = max_src_seq_obs\n","\n","    def get_max_tgt_seq_obs(self):\n","        return self.max_tgt_seq_obs\n","\n","    def set_max_tgt_seq_obs(self, max_tgt_seq_obs):\n","        self.max_tgt_seq_obs = max_tgt_seq_obs\n","\n","\n","# class name matches file name\n","class dataset_transformer_setimesbyt5():\n","\n","    def __init__(self,\n","                 datasets_directory=root_filepath+\"resources\",\n","                 raw_dataset_directory=\"raw_datasets/setimes\",\n","                 parsed_dataset_directory=\"parsed_datasets/setimes\",\n","                 ids_filename='SETIMES.en-tr.ids',\n","                 en_filename='SETIMES.en-tr.en',\n","                 tr_filename='SETIMES.en-tr.tr',\n","                 dataset_hyperparameters=None):\n","        self.datasets_directory = datasets_directory\n","        self.raw_dataset_directory = raw_dataset_directory\n","        self.parsed_dataset_directory = parsed_dataset_directory\n","        self.ids_filename = ids_filename\n","        self.en_filename = en_filename\n","        self.tr_filename = tr_filename\n","        self.parsed_dataset_filename = None\n","        if 'parsed_dataset_filename' in dataset_hyperparameters:\n","            self.parsed_dataset_filename = dataset_hyperparameters['parsed_dataset_filename']\n","        self.sentence_length_min_percentile = None\n","        if 'sentence_length_min_percentile' in dataset_hyperparameters:\n","            self.sentence_length_min_percentile = dataset_hyperparameters['sentence_length_min_percentile']\n","        self.sentence_length_max_percentile = None\n","        if 'sentence_length_max_percentile' in dataset_hyperparameters:\n","            self.sentence_length_max_percentile = dataset_hyperparameters['sentence_length_max_percentile']\n","\n","\n","    def read_dataset(self):\n","        dataset_holder = None\n","        if self.parsed_dataset_filename is not None:\n","            dataset_holder = torch.load(self.datasets_directory + \"/\"\n","                                        + self.parsed_dataset_directory + \"/\"\n","                                        + self.parsed_dataset_filename)\n","        else:\n","            target_sentences = list()\n","            source_sentences = list()\n","            index_file = open(self.datasets_directory + \"/\" + self.raw_dataset_directory + \"/\" + self.ids_filename)\n","            en_file = open(self.datasets_directory + \"/\" + self.raw_dataset_directory + \"/\" + self.en_filename)\n","            tr_file = open(self.datasets_directory + \"/\" + self.raw_dataset_directory + \"/\" + self.tr_filename)\n","            indices = list()\n","            en_sentences = list()\n","            tr_sentences = list()\n","            line_number = 1\n","            for line in index_file:\n","                line_segments = line.strip().split()\n","                if len(line_segments) != 4:\n","                    print(\"Line segmentation error on line \" + str(line_number))\n","                    print(\"Content: \" + line)\n","                    continue\n","                if line_segments[0].startswith(\"en\") and line_segments[1].startswith(\"tr\"):\n","                    indices.append((int(line_segments[2]), int(line_segments[3])))\n","                elif line_segments[0].startswith(\"tr\") and line_segments[1].startswith(\"en\"):\n","                    indices.append((int(line_segments[3]), int(line_segments[2])))\n","                else:\n","                    print(\"Index parsing error on line \" + str(line_number))\n","                    print(\"Content: \" + line)\n","                    continue\n","                line_number = line_number + 1\n","            for line in en_file:\n","                en_sentences.append(line.strip())\n","            for line in tr_file:\n","                tr_sentences.append(line.strip())\n","            for index in indices:\n","                target_sentences.append(en_sentences[index[0] - 1])\n","                source_sentences.append(tr_sentences[index[1] - 1])\n","            target_sentence_lengths = list()\n","            for sentence in target_sentences:\n","                target_sentence_lengths.append(len(sentence))\n","            source_sentence_lengths = list()\n","            for sentence in source_sentences:\n","                source_sentence_lengths.append(len(sentence))\n","            target_sentences_length_limited = list()\n","            source_sentences_length_limited = list()\n","            target_min_len = int(np.percentile(sorted(target_sentence_lengths), self.sentence_length_min_percentile))\n","            target_max_len = int(np.percentile(sorted(target_sentence_lengths), self.sentence_length_max_percentile))\n","            source_min_len = int(np.percentile(sorted(source_sentence_lengths), self.sentence_length_min_percentile))\n","            source_max_len = int(np.percentile(sorted(source_sentence_lengths), self.sentence_length_max_percentile))\n","            max_src_seq_obs = 0\n","            max_tgt_seq_obs = 0\n","            for i in range(0, len(target_sentences)):\n","                if (len(target_sentences[i]) > target_min_len and len(target_sentences[i]) <= target_max_len\n","                        and len(source_sentences[i]) > source_min_len and len(source_sentences[i]) <= source_max_len):\n","                    if len(source_sentences[i]) > max_src_seq_obs:\n","                        max_src_seq_obs = len(source_sentences[i])\n","                    if len(target_sentences[i]) > max_tgt_seq_obs:\n","                        max_tgt_seq_obs = len(target_sentences[i])\n","                    target_sentences_length_limited.append(target_sentences[i].translate(english_char_mappings))\n","                    source_sentences_length_limited.append(source_sentences[i].translate(turkish_char_mappings))\n","            dataset_holder = DatasetHolder()\n","            dataset_holder.set_max_src_seq_obs(max_src_seq_obs)\n","            dataset_holder.set_max_tgt_seq_obs(max_tgt_seq_obs)\n","            # encode to Pytorch tensors as raw UTF-8 character vocabulary\n","            # method replicated from Xue 2021 - ByT5 - Introduction, sec 3.1\n","            unknown_vocabulary_type = \"\\u0120\".encode('utf-8').decode('utf-8')\n","            padding_vocabulary_type = \"\\u0121\".encode('utf-8').decode('utf-8')\n","            end_of_sequence_vocabulary_type = \"\\u0122\".encode('utf-8').decode('utf-8')\n","            dataset_holder.set_unknown_vocabulary_type(unknown_vocabulary_type)\n","            dataset_holder.set_padding_vocabulary_type(padding_vocabulary_type)\n","            dataset_holder.set_end_of_sequence_vocabulary_type(end_of_sequence_vocabulary_type)\n","            target_vocab = list([unknown_vocabulary_type, padding_vocabulary_type, end_of_sequence_vocabulary_type])\n","            source_vocab = list([unknown_vocabulary_type, padding_vocabulary_type, end_of_sequence_vocabulary_type])\n","            target_encodings = list()\n","            source_encodings = list()\n","            for entry in target_sentences_length_limited:\n","                encoding = list()\n","                for character in entry:\n","                    if character not in target_vocab:\n","                        target_vocab.append(character)\n","                    encoding.append(target_vocab.index(character))\n","                encoding.append(target_vocab.index(end_of_sequence_vocabulary_type))\n","                target_encodings.append(torch.tensor(encoding))\n","            for entry in source_sentences_length_limited:\n","                encoding = list()\n","                for character in entry:\n","                    if character not in source_vocab:\n","                        source_vocab.append(character)\n","                    encoding.append(source_vocab.index(character))\n","                encoding.append(target_vocab.index(end_of_sequence_vocabulary_type))\n","                source_encodings.append(torch.tensor(encoding))\n","            # fix vocabulary indices using tuple type\n","            dataset_holder.set_target_vocab(tuple(target_vocab))\n","            dataset_holder.set_target_encodings(target_encodings)\n","            dataset_holder.set_source_vocab(tuple(source_vocab))\n","            dataset_holder.set_source_encodings(source_encodings)\n","            dataset_holder = DatasetUtils.create_dataset_segments(dataset_holder)\n","            torch.save(dataset_holder,\n","                       self.datasets_directory + \"/\" +\n","                       self.parsed_dataset_directory + \"/\" +\n","                       \"setimes_parsed-\" + str(int(time.time())))\n","        return dataset_holder\n","\n","\n","class Utils:\n","\n","    def __init__(self):\n","        pass\n","\n","    @staticmethod\n","    def load_python_object(object_path: str, object_attribute: str):\n","        path_segments = object_path.split('.')\n","        module = __import__(object_path)\n","        for segment in path_segments[1:]:\n","            module = getattr(module, segment)\n","        return getattr(module, object_attribute)\n","\n","\n","class DatasetUtils:\n","\n","    @staticmethod\n","    def shuffle_dataset(dataset_holder: DatasetHolder):\n","        new_source_encodings, new_target_encodings = (\n","            DatasetUtils.shuffle_lists(\n","                dataset_holder.get_source_encodings(),\n","                dataset_holder.get_target_encodings()\n","            )\n","        )\n","        dataset_holder.set_source_encodings(new_source_encodings)\n","        dataset_holder.set_target_encodings(new_target_encodings)\n","        return dataset_holder\n","\n","    @staticmethod\n","    def shuffle_training_dataset(dataset_holder: DatasetHolder):\n","        new_source_encodings, new_target_encodings = (\n","            DatasetUtils.shuffle_lists(\n","                dataset_holder.get_source_encodings_train(),\n","                dataset_holder.get_target_encodings_train()\n","            )\n","        )\n","        dataset_holder.set_source_encodings(new_source_encodings)\n","        dataset_holder.set_target_encodings(new_target_encodings)\n","        return dataset_holder\n","\n","    @staticmethod\n","    def shuffle_test_dataset(dataset_holder: DatasetHolder):\n","        new_source_encodings, new_target_encodings = (\n","            DatasetUtils.shuffle_lists(\n","                dataset_holder.get_source_encodings_test(),\n","                dataset_holder.get_target_encodings_test()\n","            )\n","        )\n","        dataset_holder.set_source_encodings(new_source_encodings)\n","        dataset_holder.set_target_encodings(new_target_encodings)\n","        return dataset_holder\n","\n","    @staticmethod\n","    def shuffle_lists(source_list, target_list):\n","        assert len(source_list) == len(target_list)\n","        list_element_shuffle_indices = list(range(0, len(source_list)))\n","        random.shuffle(list_element_shuffle_indices)\n","        new_source_list = list()\n","        new_target_list = list()\n","        for i in list_element_shuffle_indices:\n","            new_source_list.append(source_list[i])\n","            new_target_list.append(target_list[i])\n","        assert (len(new_source_list) == len(new_target_list)\n","                == len(source_list) == len(target_list))\n","        return new_source_list, new_target_list\n","\n","    @staticmethod\n","    def create_dataset_segments(dataset_holder: DatasetHolder):\n","        split_with_even_target_distribution = False\n","        iteration = 1\n","        best_split_target_encodings = None\n","        best_split_source_encodings = None\n","        best_split_deviation_from_desired = 1\n","        segments = 20\n","        split_size = len(dataset_holder.get_target_encodings()) // segments\n","        train_size = split_size * (segments - 1)\n","        while not split_with_even_target_distribution and iteration <= 100:\n","            segment_attempt_start = time.time()\n","            dataset_holder = DatasetUtils.shuffle_dataset(dataset_holder)\n","            target_encodings = dataset_holder.get_target_encodings()\n","            source_encodings = dataset_holder.get_source_encodings()\n","            train_set_target_enc = target_encodings[0:train_size]\n","            test_set_target_enc = target_encodings[train_size:]\n","            numpy_encodings = list()\n","            for encoding in train_set_target_enc:\n","                numpy_encodings.append(encoding.flatten().numpy())\n","            train_set_target_enc_cts = np.bincount(\n","                np.concatenate([\n","                    np.concatenate(numpy_encodings),\n","                    np.arange(0, 170)\n","                ])\n","            )\n","            numpy_encodings = list()\n","            for encoding in test_set_target_enc:\n","                numpy_encodings.append(encoding.flatten().numpy())\n","            test_set_target_enc_cts = np.bincount(\n","                np.concatenate([\n","                    np.concatenate(numpy_encodings),\n","                    np.arange(0, 170)\n","                ])\n","            )\n","            # terms with probability ~ 1%\n","            total_5 = train_set_target_enc_cts[5] + test_set_target_enc_cts[5]\n","            total_40 = train_set_target_enc_cts[40] + test_set_target_enc_cts[40]\n","            total_42 = train_set_target_enc_cts[42] + test_set_target_enc_cts[42]\n","            # top 3 terms\n","            total_7 = train_set_target_enc_cts[7] + test_set_target_enc_cts[7]\n","            total_15 = train_set_target_enc_cts[15] + test_set_target_enc_cts[15]\n","            total_12 = train_set_target_enc_cts[12] + test_set_target_enc_cts[12]\n","            train_dist_goal = (segments - 1)/segments\n","            test_dist_goal = (1 / segments)\n","            deviation_from_desired = (\n","                    np.abs(((segments - 2)/segments) - (train_set_target_enc_cts[5] / total_5)) +\n","                    np.abs(train_dist_goal - (train_set_target_enc_cts[40] / total_40)) +\n","                    np.abs(train_dist_goal - (train_set_target_enc_cts[42] / total_42)) +\n","                    np.abs(train_dist_goal - (train_set_target_enc_cts[7] / total_7)) +\n","                    np.abs(train_dist_goal - (train_set_target_enc_cts[15] / total_15)) +\n","                    np.abs(train_dist_goal - (train_set_target_enc_cts[12] / total_12)) +\n","                    np.abs(test_dist_goal - (test_set_target_enc_cts[5] / total_5)) +\n","                    np.abs(test_dist_goal - (test_set_target_enc_cts[40] / total_40)) +\n","                    np.abs(test_dist_goal - (test_set_target_enc_cts[42] / total_42)) +\n","                    np.abs(test_dist_goal - (test_set_target_enc_cts[7] / total_7)) +\n","                    np.abs(test_dist_goal - (test_set_target_enc_cts[15] / total_15)) +\n","                    np.abs(test_dist_goal - (test_set_target_enc_cts[12] / total_12))\n","            )\n","            if deviation_from_desired <= 12 * 0.0001:\n","                split_with_even_target_distribution = True\n","                best_split_target_encodings = target_encodings\n","                best_split_source_encodings = source_encodings\n","                print(f\"Found dataset split within tolerance for deviation from uniform distribution over characters\")\n","            if deviation_from_desired < best_split_deviation_from_desired:\n","                best_split_target_encodings = target_encodings\n","                best_split_source_encodings = source_encodings\n","                best_split_deviation_from_desired = deviation_from_desired\n","            segment_attempt_end = time.time()\n","            print(f\"Completed data split attempt. \"\n","                  f\"iteration:{iteration} \"\n","                  f\"best_split_deviation_from_desired:{best_split_deviation_from_desired} \"\n","                  f\"time_to_complete_attempt:{segment_attempt_end-segment_attempt_start}\")\n","            iteration = iteration + 1\n","        best_split_source_encodings_train = best_split_source_encodings[0:train_size]\n","        best_split_target_encodings_train = best_split_target_encodings[0:train_size]\n","        assert len(best_split_source_encodings_train) == len(best_split_target_encodings_train)\n","        train_split_encoding_length_sum_and_encoding_index_pairs = list()\n","        for i in range(0, len(best_split_source_encodings_train)):\n","            train_split_encoding_length_sum_and_encoding_index_pairs.append(\n","                list([\n","                    best_split_source_encodings_train[i].shape[0] + best_split_target_encodings_train[i].shape[0],\n","                    np.abs(best_split_source_encodings_train[i].shape[0] - best_split_target_encodings_train[i].shape[0]),\n","                    i\n","                ])\n","            )\n","        train_split_encoding_length_sum_and_encoding_index_pairs = sorted(\n","            train_split_encoding_length_sum_and_encoding_index_pairs,\n","            key=lambda pair: (pair[0], pair[1])\n","        )\n","        train_source_encs_length_sorted = list()\n","        train_target_encs_length_sorted = list()\n","        for encoding_length_sum_and_encoding_index_pair in train_split_encoding_length_sum_and_encoding_index_pairs:\n","            train_source_encs_length_sorted.append(best_split_source_encodings_train[encoding_length_sum_and_encoding_index_pair[2]])\n","            train_target_encs_length_sorted.append(best_split_target_encodings_train[encoding_length_sum_and_encoding_index_pair[2]])\n","        best_split_source_encodings_test = best_split_source_encodings[train_size:]\n","        best_split_target_encodings_test = best_split_target_encodings[train_size:]\n","        assert len(best_split_source_encodings_test) == len(best_split_target_encodings_test)\n","        test_split_encoding_length_sum_and_encoding_index_pairs = list()\n","        for i in range(0, len(best_split_source_encodings_test)):\n","            test_split_encoding_length_sum_and_encoding_index_pairs.append(\n","                list([\n","                    best_split_source_encodings_test[i].shape[0] + best_split_target_encodings_test[i].shape[0],\n","                    np.abs(best_split_source_encodings_test[i].shape[0] - best_split_target_encodings_test[i].shape[0]),\n","                    i\n","                ])\n","            )\n","        test_split_encoding_length_sum_and_encoding_index_pairs = sorted(\n","            test_split_encoding_length_sum_and_encoding_index_pairs,\n","            key=lambda pair: (pair[0], pair[1])\n","        )\n","        test_source_encs_length_sorted = list()\n","        test_target_encs_length_sorted = list()\n","        for encoding_length_sum_and_encoding_index_pair in test_split_encoding_length_sum_and_encoding_index_pairs:\n","            test_source_encs_length_sorted.append(best_split_source_encodings_test[encoding_length_sum_and_encoding_index_pair[2]])\n","            test_target_encs_length_sorted.append(best_split_target_encodings_test[encoding_length_sum_and_encoding_index_pair[2]])\n","        dataset_holder.set_source_encodings(best_split_source_encodings)\n","        dataset_holder.set_target_encodings(best_split_target_encodings)\n","        dataset_holder.set_source_encodings_train(train_source_encs_length_sorted)\n","        dataset_holder.set_target_encodings_train(train_target_encs_length_sorted)\n","        dataset_holder.set_source_encodings_test(test_source_encs_length_sorted)\n","        dataset_holder.set_target_encodings_test(test_target_encs_length_sorted)\n","        return dataset_holder\n","\n","    # use a dedicated padding token to pad batches as in Xue 2021 - ByT5 - Sec 3.1\n","    @staticmethod\n","    def prepare_batches(\n","            source_encodings,\n","            target_encodings,\n","            source_vocab,\n","            target_vocab,\n","            batch_size_limit: int,\n","            element_difference_limit: int,\n","            padding_value):\n","        assert len(source_encodings) == len(target_encodings)\n","        total_elements = len(source_encodings)\n","        source_encodings_batches = list()\n","        target_encodings_batches = list()\n","        source_encodings_tensors = list()\n","        target_encodings_tensors = list()\n","        encodings_index = 0\n","        while encodings_index < total_elements - 1:\n","            batch_size = 0\n","            batch_end_reached = False\n","            min_source_enc_len = source_encodings[encodings_index+batch_size].shape[0]\n","            max_source_enc_len = source_encodings[encodings_index+batch_size].shape[0]\n","            min_target_enc_len = target_encodings[encodings_index+batch_size].shape[0]\n","            max_target_enc_len = target_encodings[encodings_index+batch_size].shape[0]\n","            while not batch_end_reached:\n","                if (max(abs(source_encodings[encodings_index+batch_size].shape[0] - min_source_enc_len),\n","                        abs(source_encodings[encodings_index+batch_size].shape[0] - max_source_enc_len)) > element_difference_limit\n","                        or max(abs(target_encodings[encodings_index+batch_size].shape[0] - min_target_enc_len),\n","                               abs(target_encodings[encodings_index+batch_size].shape[0] - max_target_enc_len)) > element_difference_limit):\n","                    batch_end_reached = True\n","                if batch_size == batch_size_limit - 1:\n","                    batch_end_reached = True\n","                if encodings_index + batch_size + 1 < total_elements:\n","                    batch_size = batch_size + 1\n","                else:\n","                    batch_end_reached = True\n","            max_src_len_for_batch = 0\n","            max_tgt_len_for_batch = 0\n","            for batch_index in range(0, batch_size):\n","                if len(source_encodings[encodings_index+batch_index]) > max_src_len_for_batch:\n","                    max_src_len_for_batch = len(source_encodings[encodings_index+batch_index])\n","                if len(target_encodings[encodings_index+batch_index]) > max_tgt_len_for_batch:\n","                    max_tgt_len_for_batch = len(target_encodings[encodings_index+batch_index])\n","            for batch_index in range(0, batch_size):\n","                source_encoding = source_encodings[encodings_index]\n","                target_encoding = target_encodings[encodings_index]\n","                source_encodings_tensors.append(\n","                    torch.nn.functional.pad(\n","                        source_encoding,\n","                        (0, max_src_len_for_batch - len(source_encoding)),\n","                        value=source_vocab.index(padding_value)\n","                    )\n","                )\n","                target_encodings_tensors.append(\n","                    torch.nn.functional.pad(\n","                        target_encoding,\n","                        (0, max_tgt_len_for_batch - len(target_encoding)),\n","                        value=target_vocab.index(padding_value)\n","                    )\n","                )\n","                encodings_index = encodings_index + 1\n","            if batch_size > 0:\n","                source_batch = torch.stack(source_encodings_tensors)\n","                target_batch = torch.stack(target_encodings_tensors)\n","                source_encodings_batches.append(source_batch)\n","                target_encodings_batches.append(target_batch)\n","            source_encodings_tensors = list()\n","            target_encodings_tensors = list()\n","        target_encodings_batches_with_index = list()\n","        for i in range(0, len(target_encodings_batches)):\n","            target_encodings_batches_with_index.append(list([target_encodings_batches[i], i]))\n","        assert len(target_encodings_batches_with_index) == len(target_encodings_batches)\n","        target_encodings_batches_with_index_sorted = sorted(\n","            target_encodings_batches_with_index,\n","            key=lambda batch_pair: (-batch_pair[0].shape[0], -batch_pair[0].shape[1])\n","        )\n","        source_encodings_batches_sorted = list()\n","        target_encodings_batches_sorted = list()\n","        for i in range(0, len(target_encodings_batches_with_index_sorted)):\n","            source_encodings_batches_sorted.append(\n","                source_encodings_batches[target_encodings_batches_with_index_sorted[i][1]]\n","            )\n","            target_encodings_batches_sorted.append(\n","                target_encodings_batches[target_encodings_batches_with_index_sorted[i][1]]\n","            )\n","        del source_encodings_tensors\n","        del target_encodings_tensors\n","        del source_encodings_batches\n","        del target_encodings_batches\n","        del target_encodings_batches_with_index_sorted\n","        return source_encodings_batches_sorted, target_encodings_batches_sorted\n","\n","    @staticmethod\n","    def prepare_training_batches(\n","            dataset_holder: DatasetHolder,\n","            batch_size_limit: int,\n","            element_difference_limit: int):\n","        source_encodings_batches, target_encodings_batches = DatasetUtils.prepare_batches(\n","            dataset_holder.get_source_encodings_train(),\n","            dataset_holder.get_target_encodings_train(),\n","            dataset_holder.get_source_vocab(),\n","            dataset_holder.get_target_vocab(),\n","            batch_size_limit,\n","            element_difference_limit,\n","            dataset_holder.get_padding_vocabulary_type()\n","        )\n","\n","        source_vocab_counts = {}\n","        for source_encoding_batch in source_encodings_batches:\n","            for source_encoding in source_encoding_batch:\n","                for character in source_encoding:\n","                    if character.item() not in source_vocab_counts:\n","                        source_vocab_counts[character.item()] = 0\n","                    source_vocab_counts[character.item()] = source_vocab_counts[character.item()] + 1\n","        target_vocab_counts = {}\n","        for target_vocab_batch in target_encodings_batches:\n","            for target_encoding in target_vocab_batch:\n","                for character in target_encoding:\n","                    if character.item() not in target_vocab_counts:\n","                        target_vocab_counts[character.item()] = 0\n","                    target_vocab_counts[character.item()] = target_vocab_counts[character.item()] + 1\n","        dataset_holder.set_source_vocab_counts(source_vocab_counts)\n","        dataset_holder.set_target_vocab_counts(target_vocab_counts)\n","        return source_encodings_batches, target_encodings_batches\n","\n","    @staticmethod\n","    def decode_target_tensor(dataset_holder: DatasetHolder, tensor_to_decode):\n","        vocab = dataset_holder.get_target_vocab_numpy()\n","        decoded_tensor = np.take(vocab, tensor_to_decode.detach().to(device=\"cpu\").flatten().numpy())\n","        return \"\".join(decoded_tensor.tolist())\n","\n","    @staticmethod\n","    def decode_source_tensor(dataset_holder: DatasetHolder, tensor_to_decode):\n","        vocab = dataset_holder.get_source_vocab_numpy()\n","        decoded_tensor = np.take(vocab, tensor_to_decode.detach().to(device=\"cpu\").flatten().numpy())\n","        return \"\".join(decoded_tensor.tolist())\n","\n","\n","# class name matches file name\n","class transformer_vaswani2017(torch.nn.Transformer):\n","\n","    def __init__(self,\n","                 model_hyperparameters):\n","        super().__init__(\n","            d_model=model_hyperparameters['d_model'],\n","            nhead=model_hyperparameters['nhead'],\n","            num_encoder_layers=model_hyperparameters['num_encoder_layers'],\n","            num_decoder_layers=model_hyperparameters['num_decoder_layers'],\n","            dim_feedforward=model_hyperparameters['dim_feedforward'],\n","            dropout=model_hyperparameters['dropout'],\n","            activation=model_hyperparameters['activation'],\n","            custom_encoder=model_hyperparameters['custom_encoder'],\n","            custom_decoder=model_hyperparameters['custom_decoder'],\n","            layer_norm_eps=model_hyperparameters['layer_norm_eps'],\n","            batch_first=model_hyperparameters['batch_first'],\n","            norm_first=model_hyperparameters['norm_first'],\n","            bias=model_hyperparameters['bias'],\n","            device=model_hyperparameters['device'],\n","            dtype=model_hyperparameters['dtype']\n","        )\n","        # add one for the end of sequence token\n","        self.max_src_seq_len = model_hyperparameters['max_src_seq_len'] + 1\n","        self.max_tgt_seq_len = model_hyperparameters['max_tgt_seq_len'] + 1\n","        self.src_embeddings = torch.nn.Embedding(\n","            model_hyperparameters['src_vocab_size'],\n","            model_hyperparameters['d_model']\n","        )\n","        self.tgt_embeddings = torch.nn.Embedding(\n","            model_hyperparameters['tgt_vocab_size'],\n","            model_hyperparameters['d_model']\n","        )\n","        self.src_pos_enc = torch.nn.Embedding(\n","            self.max_src_seq_len,\n","            model_hyperparameters['d_model']\n","        ).requires_grad_(False)\n","        self.tgt_pos_enc = torch.nn.Embedding(\n","            self.max_tgt_seq_len,\n","            model_hyperparameters['d_model']\n","        ).requires_grad_(False)\n","        self.linear_output_projection_1 = torch.nn.Linear(\n","            self.max_tgt_seq_len,\n","            1,\n","            bias=False\n","        )\n","        self.linear_output_projection_2 = torch.nn.Linear(\n","            model_hyperparameters['d_model'],\n","            model_hyperparameters['tgt_vocab_size'],\n","            bias=False\n","        )\n","        self.logsoftmax_output = torch.nn.LogSoftmax(dim=1)\n","        self.model_hyperparameters = model_hyperparameters\n","        self.tgt_mask_cache = {}\n","        for i in range(1, self.max_tgt_seq_len + 1):\n","            tgt_mask = self.generate_square_subsequent_mask(i)\n","            if is_remote_execution:\n","                self.tgt_mask_cache[i] = tgt_mask.to(device=\"cuda\")\n","            self.tgt_mask_cache[i] = tgt_mask\n","        self.indices_cache = {}\n","        for i in range(1, max([self.max_src_seq_len, self.max_tgt_seq_len]) + 1):\n","            indices = torch.tensor(np.arange(0, i), dtype=torch.long)\n","            if is_remote_execution:\n","                indices = indices.to(device=\"cuda\")\n","            self.indices_cache[i] = indices\n","\n","    def forward(self,\n","                src: torch.Tensor,\n","                tgt: torch.Tensor,\n","                src_mask: Optional[torch.Tensor] = None,\n","                tgt_mask: Optional[torch.Tensor] = None,\n","                memory_mask: Optional[torch.Tensor] = None,\n","                src_key_padding_mask: Optional[torch.Tensor] = None,\n","                tgt_key_padding_mask: Optional[torch.Tensor] = None,\n","                memory_key_padding_mask: Optional[torch.Tensor] = None,\n","                src_is_causal: Optional[bool] = None,\n","                tgt_is_causal: Optional[bool] = True,\n","                memory_is_causal: bool = False) -> torch.Tensor:\n","        src_embedding_pos_enc = self.src_embeddings(src) + self.src_pos_enc(self.indices_cache[src.shape[1]])\n","        tgt_embedding_pos_enc = self.tgt_embeddings(tgt) + self.tgt_pos_enc(self.indices_cache[tgt.shape[1]])\n","        tgt_mask = self.tgt_mask_cache[tgt.shape[1]]\n","        transformer_output = super().forward(src_embedding_pos_enc, tgt_embedding_pos_enc, src_mask,\n","                                             tgt_mask, memory_mask, src_key_padding_mask,\n","                                             tgt_key_padding_mask, memory_key_padding_mask,\n","                                             src_is_causal, tgt_is_causal, memory_is_causal)\n","        transformer_output = torch.swapaxes(transformer_output, -1, -2)\n","        transformer_output = torch.nn.functional.pad(\n","            transformer_output,\n","            (0, self.max_tgt_seq_len - transformer_output.shape[2]),\n","            value=0\n","        )\n","        output = self.logsoftmax_output(\n","            self.linear_output_projection_2(\n","                torch.squeeze(\n","                    self.linear_output_projection_1(\n","                        transformer_output\n","                    ),\n","                    dim=2\n","                )\n","            )\n","        )\n","        del src_embedding_pos_enc\n","        del tgt_embedding_pos_enc\n","        del transformer_output\n","        return output\n","\n","\n","class model_trainer_kocmi2018():\n","\n","    def __init__(self,\n","                 trainer_hyperparameters=None,\n","                 model_parameter_directory=None,\n","                 trainer_parameter_directory=None,\n","                 runner_hyperparameters_name=None,\n","                 latest_param_filename_tag=None):\n","        self.trainer_hyperparameters = trainer_hyperparameters\n","        self.optimizer_name = self.trainer_hyperparameters['optimizer_name']\n","        self.initial_lr = self.trainer_hyperparameters['initial_lr']\n","        self.exp_decay = self.trainer_hyperparameters['exp_decay']\n","        self.lr_scheduler_name = self.trainer_hyperparameters['lr_scheduler_name']\n","        self.epochs = self.trainer_hyperparameters['epochs']\n","        self.epoch_starting_index = self.trainer_hyperparameters['epoch_starting_index']\n","        self.batch_size_limit = self.trainer_hyperparameters['batch_size_limit']\n","        self.element_difference_limit = self.trainer_hyperparameters['element_difference_limit']\n","        self.batch_starting_index = self.trainer_hyperparameters['batch_starting_index']\n","        self.model_parameter_directory = model_parameter_directory\n","        self.trainer_parameter_directory = trainer_parameter_directory\n","        self.runner_hyperparameters_name = runner_hyperparameters_name\n","        self.latest_param_filename_tag = latest_param_filename_tag\n","        self.dataset_holder = None\n","        self.model = None\n","        self.source_encoding_batches = None\n","        self.target_encoding_batches = None\n","        self.optimizer = None\n","        self.lr_scheduler = None\n","        self.loss_fcn = None\n","\n","    def init_trainer(self):\n","        self.source_encoding_batches, self.target_encoding_batches = (\n","            DatasetUtils.prepare_training_batches(\n","                self.dataset_holder,\n","                self.batch_size_limit,\n","                self.element_difference_limit\n","            )\n","        )\n","        # get_target_vocab_counts requires that training batches have been prepared\n","        # this ensures that vocab counts include padding and eos tokens\n","        loss_weights = list()\n","        for vocab_term in self.dataset_holder.get_target_vocab():\n","            loss_weights.append(\n","                1 / self.dataset_holder.get_target_vocab_counts()[\n","                    self.dataset_holder.get_target_vocab().index(vocab_term)\n","                ]\n","            )\n","        # set padding to have 0 weight\n","        loss_weights[\n","            self.dataset_holder.get_target_vocab().index(self.dataset_holder.get_padding_vocabulary_type())] = 0\n","        loss_weights = torch.tensor(loss_weights, dtype=torch.float)\n","        if is_remote_execution:\n","            torch.cuda.empty_cache()\n","            self.model.cuda()\n","            loss_weights = loss_weights.to(device=\"cuda\")\n","        self.loss_fcn = torch.nn.NLLLoss(weight=loss_weights)\n","        _optimizer_class_ = Utils.load_python_object('torch.optim', self.optimizer_name)\n","        self.optimizer = _optimizer_class_(self.model.parameters(), lr=self.initial_lr)\n","        _lr_scheduler_class_ = Utils.load_python_object('torch.optim.lr_scheduler', self.lr_scheduler_name)\n","        # constructor call assumes that the scheduler is the ExponentialLR scheduler\n","        self.lr_scheduler = _lr_scheduler_class_(self.optimizer, self.exp_decay)\n","        scheduler_parameter_filepath = self.trainer_parameter_directory + \"/\" + self.runner_hyperparameters_name + \"-\" + self.latest_param_filename_tag + \"-scheduler.params\"\n","        scheduler_parameters = torch.load(scheduler_parameter_filepath)\n","        self.lr_scheduler.load_state_dict(scheduler_parameters)\n","        parameter_count = 0\n","        bytes_consumed = 0\n","        for parameter in self.model.parameters():\n","            if parameter.requires_grad:\n","                parameter_count = parameter_count + np.prod(parameter.data.shape)\n","                bytes_consumed = bytes_consumed + parameter.data.nbytes\n","        gb_consumed = bytes_consumed / 1024 / 1024 / 1024\n","        print(f\"Model trainer initialization complete.\"\n","              f\"Trainer will run on model with parameter count {parameter_count} \"\n","              f\"and parameter memory use {gb_consumed} GB\")\n","\n","    # pretraining is not used for monolingual english as described in Xue 2021 - ByT5 - Sec 3.1\n","    def run_trainer(self):\n","        assert self.epoch_starting_index < self.epochs\n","        for i in range(self.epoch_starting_index, self.epochs):\n","            while self.lr_scheduler.state_dict()['last_epoch'] > i:\n","                print(f\"Updating lr_scheduler: {self.lr_scheduler.state_dict()}\")\n","                self.lr_scheduler.step()\n","            epoch_start = time.time()\n","            print(f\"Beginning epoch {i+1} of {self.epochs} with scheduler {self.lr_scheduler.state_dict()}\")\n","            # if i > 0:\n","            #     self.source_encoding_batches, self.target_encoding_batches = DatasetUtils.shuffle_lists(\n","            #         self.source_encoding_batches, self.target_encoding_batches\n","            #     )\n","            source_batches = None\n","            target_batches = None\n","            if is_remote_execution:\n","                source_batches = list()\n","                target_batches = list()\n","                for batch in self.source_encoding_batches:\n","                    source_batches.append(batch.to(device=\"cuda\"))\n","                    del batch\n","                for batch in self.target_encoding_batches:\n","                    target_batches.append(batch.to(device=\"cuda\"))\n","                    del batch\n","                torch.cuda.empty_cache()\n","            else:\n","                source_batches = self.source_encoding_batches\n","                target_batches = self.target_encoding_batches\n","            assert len(source_batches) == len(target_batches)\n","            batch_ct = len(source_batches)\n","            batch_size = source_batches[0].shape[0]\n","            samples_passed = 0\n","            last_log = 0\n","            last_loss = 0\n","            note_step_prediction = False\n","            step_prediction_at_percentage_of_sample = 0\n","            total_batch_time = 0\n","            assert self.batch_starting_index < batch_ct\n","            for j in range(self.batch_starting_index, batch_ct):\n","                batch_start = time.time()\n","                batch_sequence_length = target_batches[j].shape[1]\n","                step_prediction_step_number = int(batch_sequence_length * step_prediction_at_percentage_of_sample)\n","                print(f\"Starting batch.\")\n","                print(f\"epoch:{i+1}/{self.epochs} batch:{j+1}/{batch_ct} batch_size:{target_batches[j].shape[0]}\")\n","                for k in range(1, batch_sequence_length-1):\n","                    target_batch_slices = torch.tensor_split(target_batches[j], [k], dim=1)\n","                    self.model.zero_grad()\n","                    output_logits = self.model.forward(\n","                        source_batches[j],\n","                        target_batch_slices[0]\n","                    )\n","                    next_word_indices = target_batch_slices[1][:, 0]\n","                    last_loss = self.loss_fcn(output_logits, next_word_indices)\n","                    last_loss.backward()\n","                    self.optimizer.step()\n","                    if note_step_prediction and k == step_prediction_step_number:\n","                        note_step_prediction = False\n","                        full_sequence = DatasetUtils.decode_target_tensor(self.dataset_holder, target_batches[j][0])\n","                        prefix_sequence = DatasetUtils.decode_target_tensor(\n","                            self.dataset_holder,\n","                            target_batch_slices[0][0]\n","                        )\n","                        next_token = DatasetUtils.decode_target_tensor(\n","                            self.dataset_holder,\n","                            next_word_indices[0]\n","                        )\n","                        predicted_token = DatasetUtils.decode_target_tensor(\n","                            self.dataset_holder,\n","                            torch.argmax(output_logits[0])\n","                        )\n","                        print(f\"Next token prediction. step:{k}/{batch_sequence_length} \"\n","                              f\"batch:{j+1}/{batch_ct} epoch:{i+1}/{self.epochs}\")\n","                        print(f\"full seq: {full_sequence}\")\n","                        print(f\"pref seq: {prefix_sequence}\")\n","                        print(f\"next tok: {next_token.rjust(k, ' ')}\")\n","                        print(f\"pred tok: {predicted_token.rjust(k, ' ')}\")\n","                        del full_sequence\n","                        del prefix_sequence\n","                        del next_token\n","                        del predicted_token\n","                    del target_batch_slices\n","                    del output_logits\n","                    del next_word_indices\n","                    last_loss = last_loss.detach()\n","                    gc.collect()\n","                    if is_remote_execution:\n","                        torch.cuda.empty_cache()\n","                batch_end = time.time()\n","                batch_time = batch_end - batch_start\n","                total_batch_time = total_batch_time + batch_time\n","                print(f\"Completed batch.\")\n","                print(f\"epoch:{i+1}/{self.epochs} batch:{j+1}/{batch_ct} batch_size:{target_batches[j].shape[0]} loss:{last_loss} \"\n","                      f\"time_for_batch_instance:{batch_time} total_batch_time:{total_batch_time} running_batch_average:{total_batch_time/(j+1)}\")\n","                samples_passed = samples_passed + batch_size\n","                if samples_passed - last_log > 100:\n","                    last_log = samples_passed\n","                    note_step_prediction = True\n","                    step_prediction_at_percentage_of_sample = random.random()\n","                    if is_remote_execution:\n","                        print(f\"Memory usage summary:\")\n","                        print(f\"{torch.cuda.memory_summary()}\")\n","                        torch.cuda.reset_max_memory_allocated()\n","                        torch.cuda.reset_max_memory_cached()\n","                        torch.cuda.reset_peak_memory_stats()\n","                    param_filename_tag = str(int(time.time()))\n","                    torch.save(\n","                        self.model.state_dict(),\n","                        self.model_parameter_directory + \"/\" + self.runner_hyperparameters_name + \"-\" + param_filename_tag + \"-model.params\"\n","                    )\n","                    torch.save(\n","                        self.lr_scheduler.state_dict(),\n","                        self.trainer_parameter_directory + \"/\" + self.runner_hyperparameters_name + \"-\" + param_filename_tag + \"-scheduler.params\"\n","                    )\n","                    torch.save(\n","                        f\"epoch:{i+1}/{self.epochs} batch:{j+1}/{batch_ct}\",\n","                        self.trainer_parameter_directory + \"/\" + self.runner_hyperparameters_name + \"-\" + param_filename_tag + \"-trainer.params\"\n","                    )\n","            del source_batches\n","            del target_batches\n","            gc.collect()\n","            if is_remote_execution:\n","                torch.cuda.empty_cache()\n","            self.lr_scheduler.step()\n","            epoch_end = time.time()\n","            print(f\"Completed epoch {i+1}/{self.epochs} in {(epoch_end - epoch_start) / 60 }m\")\n","            print(f\"epoch:{i+1}, batch:{j+1}/{batch_ct}, loss:{last_loss}\")\n","\n","    def get_dataset_holder(self):\n","        return self.dataset_holder\n","\n","    def set_dataset_holder(self, dataset_holder):\n","        self.dataset_holder = dataset_holder\n","\n","    def get_model(self):\n","        return self.model\n","\n","    def set_model(self, model):\n","        self.model = model\n","\n","\n","class Runner:\n","\n","    def __init__(self,\n","                 model_parameter_directory=root_filepath+\"resources/model_parameters\",\n","                 trainer_parameter_directory=root_filepath+\"resources/trainer_parameters\",\n","                 runner_hyperparameters_name=\"SETimesByT5Vaswani2017Kocmi2018_1\"):\n","        self.model_parameter_directory = model_parameter_directory\n","        self.trainer_parameter_directory = trainer_parameter_directory\n","        self.runner_hyperparameters_name = runner_hyperparameters_name\n","        self.runner_hyperparameters = SETimesByT5Vaswani2017Kocmi2018_1\n","        self.dataset_holder: DatasetHolder = None\n","        self.model = None\n","        self.trainer = None\n","        self.latest_param_filename_tag = None\n","        if 'latest_param_filename_tag' in self.runner_hyperparameters:\n","            self.latest_param_filename_tag = self.runner_hyperparameters['latest_param_filename_tag']\n","        print(f\"Initialized runner {runner_hyperparameters_name} with parameters {self.runner_hyperparameters}\")\n","\n","    def load_dataset(self):\n","        dataset_transformer_name = self.runner_hyperparameters.get('dataset_transformer_name')\n","        dataset_hyperparameters = self.runner_hyperparameters.get('dataset_transformer_hyperparameters')\n","        dataset_transformer = dataset_transformer_setimesbyt5(dataset_hyperparameters=dataset_hyperparameters)\n","        self.dataset_holder = dataset_transformer.read_dataset()\n","\n","    def load_model(self):\n","        model_hyperparameters = self.runner_hyperparameters.get('model_hyperparameters')\n","        model_hyperparameters['src_vocab_size'] = len(self.dataset_holder.get_source_vocab())\n","        model_hyperparameters['tgt_vocab_size'] = len(self.dataset_holder.get_target_vocab())\n","        model_hyperparameters['max_src_seq_len'] = self.dataset_holder.get_max_src_seq_obs()\n","        model_hyperparameters['max_tgt_seq_len'] = self.dataset_holder.get_max_tgt_seq_obs()\n","        model_parameter_filepath = self.model_parameter_directory + \"/\" + self.runner_hyperparameters_name + \"-\" + self.latest_param_filename_tag + \"-model.params\"\n","        self.model = transformer_vaswani2017(model_hyperparameters=model_hyperparameters)\n","        model_parameters = torch.load(model_parameter_filepath)\n","        self.model.load_state_dict(model_parameters)\n","\n","    def load_trainer(self):\n","        trainer_hyperparameters = self.runner_hyperparameters.get('trainer_hyperparameters')\n","        self.trainer = model_trainer_kocmi2018(\n","            trainer_hyperparameters=trainer_hyperparameters,\n","            model_parameter_directory=self.model_parameter_directory,\n","            trainer_parameter_directory=self.trainer_parameter_directory,\n","            runner_hyperparameters_name=self.runner_hyperparameters_name,\n","            latest_param_filename_tag=self.latest_param_filename_tag\n","        )\n","\n","    def run_trainer(self):\n","        self.trainer.set_dataset_holder(self.dataset_holder)\n","        self.trainer.set_model(self.model)\n","        self.trainer.init_trainer()\n","        self.trainer.run_trainer()\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1qcv-CZAnpo1","outputId":"58d02806-454e-41ef-b6fc-05689d22dd83"},"outputs":[{"output_type":"stream","name":"stdout","text":["Initialized runner SETimesByT5Vaswani2017Kocmi2018_1 with parameters {'dataset_transformer_name': 'dataset_transformer_setimesbyt5', 'model_name': 'transformer_vaswani2017', 'trainer_name': 'model_trainer_kocmi2018', 'latest_param_filename_tag': '1715741441', 'dataset_transformer_hyperparameters': {'sentence_length_min_percentile': 5, 'sentence_length_max_percentile': 95, 'parsed_dataset_filename': 'setimes_parsed-1715586974'}, 'model_hyperparameters': {'d_model': 256, 'nhead': 8, 'num_encoder_layers': 9, 'num_decoder_layers': 3, 'dim_feedforward': 1796, 'dropout': 0.1, 'activation': <function relu at 0x7a85187ba9e0>, 'custom_encoder': None, 'custom_decoder': None, 'layer_norm_eps': 1e-05, 'batch_first': True, 'norm_first': False, 'bias': True, 'device': None, 'dtype': None}, 'trainer_hyperparameters': {'optimizer_name': 'Adam', 'lr_scheduler_name': 'ExponentialLR', 'initial_lr': 0.001, 'exp_decay': 0.5, 'epochs': 10, 'epoch_starting_index': 1, 'batch_size_limit': 250, 'element_difference_limit': 19, 'batch_starting_index': 84}}\n","Model trainer initialization complete.Trainer will run on model with parameter count 15086641 and parameter memory use 0.05620211735367775 GB\n","Beginning epoch 2 of 10 with scheduler {'gamma': 0.5, 'base_lrs': [0.001], 'last_epoch': 0, 'verbose': False, '_step_count': 1, '_get_lr_called_within_step': False, '_last_lr': [0.001]}\n","Starting batch.\n","epoch:2/10 batch:85/7698 batch_size:250\n","Completed batch.\n","epoch:2/10 batch:85/7698 batch_size:250 loss:0.9555677175521851 time_for_batch_instance:181.99569630622864 total_batch_time:181.99569630622864 running_batch_average:2.1411258388968073\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 651797 KiB |  14563 MiB |   8177 GiB |   8176 GiB |\n","|       from large pool | 194347 KiB |  14123 MiB |   8161 GiB |   8161 GiB |\n","|       from small pool | 457450 KiB |    477 MiB |     15 GiB |     15 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 651797 KiB |  14563 MiB |   8177 GiB |   8176 GiB |\n","|       from large pool | 194347 KiB |  14123 MiB |   8161 GiB |   8161 GiB |\n","|       from small pool | 457450 KiB |    477 MiB |     15 GiB |     15 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  14537 MiB |   8148 GiB |   8147 GiB |\n","|       from large pool | 189056 KiB |  14101 MiB |   8132 GiB |   8132 GiB |\n","|       from small pool | 453671 KiB |    473 MiB |     15 GiB |     15 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2406 MiB |  15260 MiB |   1928 GiB |   1926 GiB |\n","|       from large pool |   1956 MiB |  14794 MiB |   1925 GiB |   1923 GiB |\n","|       from small pool |    450 MiB |    480 MiB |      2 GiB |      2 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1769 MiB |   2517 MiB |   2489 GiB |   2487 GiB |\n","|       from large pool |   1766 MiB |   2513 MiB |   2471 GiB |   2469 GiB |\n","|       from small pool |      3 MiB |     17 MiB |     17 GiB |     17 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |  236017    |  219668    |\n","|       from large pool |      98    |     263    |  133320    |  133222    |\n","|       from small pool |   16251    |   16398    |  102697    |   86446    |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |  236017    |  219668    |\n","|       from large pool |      98    |     263    |  133320    |  133222    |\n","|       from small pool |   16251    |   16398    |  102697    |   86446    |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     243    |     331    |   14025    |   13782    |\n","|       from large pool |      18    |      98    |   12541    |   12523    |\n","|       from small pool |     225    |     240    |    1484    |    1259    |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      74    |     143    |   90387    |   90313    |\n","|       from large pool |      19    |      57    |   56102    |   56083    |\n","|       from small pool |      55    |     106    |   34285    |   34230    |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:86/7698 batch_size:250\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/cuda/memory.py:330: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/cuda/memory.py:356: FutureWarning: torch.cuda.reset_max_memory_cached now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","| Non-releasable memory |   1562 MiB |   2155 MiB | 242335 GiB | 242334 GiB |\n","|       from large pool |   1554 MiB |   2145 MiB | 240659 GiB | 240657 GiB |\n","|       from small pool |      7 MiB |     19 MiB |   1676 GiB |   1676 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   21305 K  |   21289 K  |\n","|       from large pool |      98    |     248    |   12846 K  |   12846 K  |\n","|       from small pool |   16251    |   16398    |    8458 K  |    8442 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   21305 K  |   21289 K  |\n","|       from large pool |      98    |     248    |   12846 K  |   12846 K  |\n","|       from small pool |   16251    |   16398    |    8458 K  |    8442 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     245    |     331    |    1222 K  |    1222 K  |\n","|       from large pool |      18    |      98    |    1099 K  |    1099 K  |\n","|       from small pool |     227    |     244    |     122 K  |     122 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      83    |     150    |   10665 K  |   10665 K  |\n","|       from large pool |      20    |      60    |    7319 K  |    7319 K  |\n","|       from small pool |      63    |     106    |    3346 K  |    3346 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:198/7698 batch_size:250\n","Next token prediction. step:121/127 batch:198/7698 epoch:2/10\n","full seq: A banner hangs on the EU headquarters in Brussels welcoming Cyprus and Malta to the Eurogroup. [Getty Images]Ģġġġġġġġġġġġġġġġġġ\n","pref seq: A banner hangs on the EU headquarters in Brussels welcoming Cyprus and Malta to the Eurogroup. [Getty Images]Ģġġġġġġġġġġġ\n","next tok:                                                                                                                         ġ\n","pred tok:                                                                                                                         Ģ\n","Completed batch.\n","epoch:2/10 batch:198/7698 batch_size:250 loss:1.0099042654037476 time_for_batch_instance:134.05077981948853 total_batch_time:17587.156172275543 running_batch_average:88.8240210720987\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 653709 KiB |  11086 MiB | 699223 GiB | 699223 GiB |\n","|       from large pool | 196259 KiB |  10633 MiB | 697669 GiB | 697669 GiB |\n","|       from small pool | 457450 KiB |    484 MiB |   1554 GiB |   1553 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 653709 KiB |  11086 MiB | 699223 GiB | 699223 GiB |\n","|       from large pool | 196259 KiB |  10633 MiB | 697669 GiB | 697669 GiB |\n","|       from small pool | 457450 KiB |    484 MiB |   1554 GiB |   1553 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  11052 MiB | 697498 GiB | 697498 GiB |\n","|       from large pool | 189056 KiB |  10603 MiB | 695945 GiB | 695945 GiB |\n","|       from small pool | 453671 KiB |    481 MiB |   1553 GiB |   1552 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2714 MiB |  11642 MiB | 146498 GiB | 146496 GiB |\n","|       from large pool |   2260 MiB |  11176 MiB | 146257 GiB | 146254 GiB |\n","|       from small pool |    454 MiB |    488 MiB |    241 GiB |    241 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   2075 MiB |   2265 MiB | 243949 GiB | 243947 GiB |\n","|       from large pool |   2068 MiB |   2257 MiB | 242256 GiB | 242254 GiB |\n","|       from small pool |      7 MiB |     19 MiB |   1692 GiB |   1692 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   21469 K  |   21453 K  |\n","|       from large pool |      98    |     248    |   12942 K  |   12942 K  |\n","|       from small pool |   16251    |   16398    |    8527 K  |    8510 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   21469 K  |   21453 K  |\n","|       from large pool |      98    |     248    |   12942 K  |   12942 K  |\n","|       from small pool |   16251    |   16398    |    8527 K  |    8510 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     253    |     333    |    1231 K  |    1231 K  |\n","|       from large pool |      26    |     100    |    1107 K  |    1107 K  |\n","|       from small pool |     227    |     244    |     123 K  |     123 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      88    |     156    |   10734 K  |   10733 K  |\n","|       from large pool |      28    |      66    |    7361 K  |    7361 K  |\n","|       from small pool |      60    |     106    |    3372 K  |    3372 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:199/7698 batch_size:250\n","Next token prediction. step:108/127 batch:199/7698 epoch:2/10\n","full seq: The film's plot centres around the love story of two young people, which is abruptly ended by the start of the conflict.Ģġġġġġġ\n","pref seq: The film's plot centres around the love story of two young people, which is abruptly ended by the start of t\n","next tok:                                                                                                            h\n","pred tok:                                                                                                            Ģ\n","Completed batch.\n","epoch:2/10 batch:199/7698 batch_size:250 loss:1.5855480432510376 time_for_batch_instance:134.16903233528137 total_batch_time:17721.325204610825 running_batch_average:89.05188545030565\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 653124 KiB |  11083 MiB | 703915 GiB | 703914 GiB |\n","|       from large pool | 195674 KiB |  10631 MiB | 702346 GiB | 702346 GiB |\n","|       from small pool | 457450 KiB |    484 MiB |   1568 GiB |   1568 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 653124 KiB |  11083 MiB | 703915 GiB | 703914 GiB |\n","|       from large pool | 195674 KiB |  10631 MiB | 702346 GiB | 702346 GiB |\n","|       from small pool | 457450 KiB |    484 MiB |   1568 GiB |   1568 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  11052 MiB | 702161 GiB | 702161 GiB |\n","|       from large pool | 189056 KiB |  10603 MiB | 700593 GiB | 700593 GiB |\n","|       from small pool | 453671 KiB |    481 MiB |   1567 GiB |   1567 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2890 MiB |  11644 MiB | 147502 GiB | 147499 GiB |\n","|       from large pool |   2436 MiB |  11178 MiB | 147259 GiB | 147256 GiB |\n","|       from small pool |    454 MiB |    488 MiB |    243 GiB |    242 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   2252 MiB |   2258 MiB | 245560 GiB | 245558 GiB |\n","|       from large pool |   2244 MiB |   2254 MiB | 243851 GiB | 243849 GiB |\n","|       from small pool |      7 MiB |     19 MiB |   1708 GiB |   1708 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   21633 K  |   21617 K  |\n","|       from large pool |      98    |     248    |   13038 K  |   13038 K  |\n","|       from small pool |   16251    |   16398    |    8595 K  |    8579 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   21633 K  |   21617 K  |\n","|       from large pool |      98    |     248    |   13038 K  |   13038 K  |\n","|       from small pool |   16251    |   16398    |    8595 K  |    8579 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     253    |     335    |    1241 K  |    1240 K  |\n","|       from large pool |      26    |     102    |    1116 K  |    1116 K  |\n","|       from small pool |     227    |     244    |     124 K  |     124 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      89    |     154    |   10802 K  |   10802 K  |\n","|       from large pool |      29    |      64    |    7403 K  |    7403 K  |\n","|       from small pool |      60    |     106    |    3399 K  |    3399 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:200/7698 batch_size:250\n","Next token prediction. step:25/127 batch:200/7698 epoch:2/10\n","full seq: Djankov and central bank officials have said however that the peg will stay unchanged until Bulgaria joins the euro zone.Ģġġġġġ\n","pref seq: Djankov and central bank \n","next tok:                         o\n","pred tok:                         w\n","Completed batch.\n","epoch:2/10 batch:200/7698 batch_size:250 loss:0.9292408227920532 time_for_batch_instance:135.84947752952576 total_batch_time:17857.17468214035 running_batch_average:89.28587341070175\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 652973 KiB |  11085 MiB | 708606 GiB | 708606 GiB |\n","|       from large pool | 195523 KiB |  10632 MiB | 707023 GiB | 707022 GiB |\n","|       from small pool | 457450 KiB |    484 MiB |   1583 GiB |   1583 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 652973 KiB |  11085 MiB | 708606 GiB | 708606 GiB |\n","|       from large pool | 195523 KiB |  10632 MiB | 707023 GiB | 707022 GiB |\n","|       from small pool | 457450 KiB |    484 MiB |   1583 GiB |   1583 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  11052 MiB | 706824 GiB | 706824 GiB |\n","|       from large pool | 189056 KiB |  10603 MiB | 705242 GiB | 705241 GiB |\n","|       from small pool | 453671 KiB |    481 MiB |   1582 GiB |   1582 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2662 MiB |  11656 MiB | 148506 GiB | 148503 GiB |\n","|       from large pool |   2208 MiB |  11190 MiB | 148261 GiB | 148259 GiB |\n","|       from small pool |    454 MiB |    488 MiB |    245 GiB |    244 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   2024 MiB |   2264 MiB | 247174 GiB | 247172 GiB |\n","|       from large pool |   2017 MiB |   2253 MiB | 245449 GiB | 245447 GiB |\n","|       from small pool |      7 MiB |     19 MiB |   1725 GiB |   1725 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   21797 K  |   21781 K  |\n","|       from large pool |      98    |     248    |   13133 K  |   13133 K  |\n","|       from small pool |   16251    |   16398    |    8664 K  |    8647 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   21797 K  |   21781 K  |\n","|       from large pool |      98    |     248    |   13133 K  |   13133 K  |\n","|       from small pool |   16251    |   16398    |    8664 K  |    8647 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     254    |     335    |    1250 K  |    1250 K  |\n","|       from large pool |      27    |     102    |    1125 K  |    1125 K  |\n","|       from small pool |     227    |     244    |     125 K  |     125 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      90    |     154    |   10871 K  |   10871 K  |\n","|       from large pool |      30    |      64    |    7445 K  |    7445 K  |\n","|       from small pool |      60    |     106    |    3426 K  |    3425 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:201/7698 batch_size:250\n","Next token prediction. step:117/127 batch:201/7698 epoch:2/10\n","full seq: The programme, intended to curb job cuts in the private sector, began five years ago and will continue through September.Ģġġġġġ\n","pref seq: The programme, intended to curb job cuts in the private sector, began five years ago and will continue through Septem\n","next tok:                                                                                                                     b\n","pred tok:                                                                                                                     Ģ\n","Completed batch.\n","epoch:2/10 batch:201/7698 batch_size:250 loss:0.7879863977432251 time_for_batch_instance:134.97013807296753 total_batch_time:17992.144820213318 running_batch_average:89.513158309519\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 652973 KiB |  11085 MiB | 713298 GiB | 713297 GiB |\n","|       from large pool | 195523 KiB |  10632 MiB | 711699 GiB | 711699 GiB |\n","|       from small pool | 457450 KiB |    484 MiB |   1598 GiB |   1598 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 652973 KiB |  11085 MiB | 713298 GiB | 713297 GiB |\n","|       from large pool | 195523 KiB |  10632 MiB | 711699 GiB | 711699 GiB |\n","|       from small pool | 457450 KiB |    484 MiB |   1598 GiB |   1598 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  11052 MiB | 711487 GiB | 711487 GiB |\n","|       from large pool | 189056 KiB |  10603 MiB | 709890 GiB | 709889 GiB |\n","|       from small pool | 453671 KiB |    481 MiB |   1597 GiB |   1597 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2662 MiB |  11656 MiB | 149511 GiB | 149508 GiB |\n","|       from large pool |   2208 MiB |  11190 MiB | 149264 GiB | 149262 GiB |\n","|       from small pool |    454 MiB |    488 MiB |    246 GiB |    246 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   2024 MiB |   2162 MiB | 248804 GiB | 248802 GiB |\n","|       from large pool |   2017 MiB |   2156 MiB | 247063 GiB | 247061 GiB |\n","|       from small pool |      7 MiB |     19 MiB |   1741 GiB |   1741 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   21962 K  |   21945 K  |\n","|       from large pool |      98    |     248    |   13229 K  |   13229 K  |\n","|       from small pool |   16251    |   16398    |    8732 K  |    8716 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   21962 K  |   21945 K  |\n","|       from large pool |      98    |     248    |   13229 K  |   13229 K  |\n","|       from small pool |   16251    |   16398    |    8732 K  |    8716 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     254    |     337    |    1259 K  |    1259 K  |\n","|       from large pool |      27    |     104    |    1133 K  |    1133 K  |\n","|       from small pool |     227    |     244    |     126 K  |     126 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      90    |     154    |   10941 K  |   10941 K  |\n","|       from large pool |      30    |      64    |    7488 K  |    7488 K  |\n","|       from small pool |      60    |     106    |    3452 K  |    3452 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:202/7698 batch_size:250\n","Next token prediction. step:74/127 batch:202/7698 epoch:2/10\n","full seq: For example, in France, the ombudsman appoints citizens who inspect prisons and penal institutions weekly,\" said Delevoye.Ģġġġġ\n","pref seq: For example, in France, the ombudsman appoints citizens who inspect prison\n","next tok:                                                                          s\n","pred tok:                                                                          ;\n","Completed batch.\n","epoch:2/10 batch:202/7698 batch_size:250 loss:1.9077579975128174 time_for_batch_instance:134.95584797859192 total_batch_time:18127.10066819191 running_batch_average:89.73812211976193\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 653018 KiB |  11087 MiB | 717989 GiB | 717989 GiB |\n","|       from large pool | 195568 KiB |  10634 MiB | 716376 GiB | 716376 GiB |\n","|       from small pool | 457450 KiB |    484 MiB |   1613 GiB |   1612 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 653018 KiB |  11087 MiB | 717989 GiB | 717989 GiB |\n","|       from large pool | 195568 KiB |  10634 MiB | 716376 GiB | 716376 GiB |\n","|       from small pool | 457450 KiB |    484 MiB |   1613 GiB |   1612 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  11052 MiB | 716150 GiB | 716149 GiB |\n","|       from large pool | 189056 KiB |  10603 MiB | 714538 GiB | 714538 GiB |\n","|       from small pool | 453671 KiB |    481 MiB |   1612 GiB |   1611 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2758 MiB |  11646 MiB | 150505 GiB | 150502 GiB |\n","|       from large pool |   2304 MiB |  11180 MiB | 150257 GiB | 150255 GiB |\n","|       from small pool |    454 MiB |    488 MiB |    248 GiB |    247 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   2120 MiB |   2157 MiB | 250451 GiB | 250449 GiB |\n","|       from large pool |   2113 MiB |   2149 MiB | 248693 GiB | 248691 GiB |\n","|       from small pool |      7 MiB |     19 MiB |   1757 GiB |   1757 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   22126 K  |   22109 K  |\n","|       from large pool |      98    |     248    |   13325 K  |   13324 K  |\n","|       from small pool |   16251    |   16398    |    8801 K  |    8784 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   22126 K  |   22109 K  |\n","|       from large pool |      98    |     248    |   13325 K  |   13324 K  |\n","|       from small pool |   16251    |   16398    |    8801 K  |    8784 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     253    |     335    |    1269 K  |    1268 K  |\n","|       from large pool |      26    |     102    |    1142 K  |    1142 K  |\n","|       from small pool |     227    |     244    |     127 K  |     126 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      89    |     155    |   11010 K  |   11010 K  |\n","|       from large pool |      29    |      65    |    7531 K  |    7531 K  |\n","|       from small pool |      60    |     106    |    3479 K  |    3479 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:203/7698 batch_size:250\n","Next token prediction. step:42/126 batch:203/7698 epoch:2/10\n","full seq: Countries from Southeast Europe should consider carefully the pros and the cons of rushing into euro adoption.Ģġġġġġġġġġġġġġġġ\n","pref seq: Countries from Southeast Europe should con\n","next tok:                                          s\n","pred tok:                                          ;\n","Completed batch.\n","epoch:2/10 batch:203/7698 batch_size:250 loss:1.28005850315094 time_for_batch_instance:134.20619297027588 total_batch_time:18261.306861162186 running_batch_average:89.95717665597135\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 652090 KiB |  10983 MiB | 722590 GiB | 722589 GiB |\n","|       from large pool | 194640 KiB |  10530 MiB | 720962 GiB | 720961 GiB |\n","|       from small pool | 457450 KiB |    484 MiB |   1627 GiB |   1627 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 652090 KiB |  10983 MiB | 722590 GiB | 722589 GiB |\n","|       from large pool | 194640 KiB |  10530 MiB | 720962 GiB | 720961 GiB |\n","|       from small pool | 457450 KiB |    484 MiB |   1627 GiB |   1627 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  10970 MiB | 720743 GiB | 720742 GiB |\n","|       from large pool | 189056 KiB |  10521 MiB | 719116 GiB | 719115 GiB |\n","|       from small pool | 453671 KiB |    480 MiB |   1626 GiB |   1626 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2460 MiB |  11552 MiB | 151544 GiB | 151542 GiB |\n","|       from large pool |   2006 MiB |  11086 MiB | 151294 GiB | 151292 GiB |\n","|       from small pool |    454 MiB |    488 MiB |    249 GiB |    249 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1823 MiB |   2210 MiB | 251938 GiB | 251936 GiB |\n","|       from large pool |   1815 MiB |   2198 MiB | 250164 GiB | 250163 GiB |\n","|       from small pool |      7 MiB |     19 MiB |   1773 GiB |   1773 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   22289 K  |   22272 K  |\n","|       from large pool |      98    |     248    |   13419 K  |   13419 K  |\n","|       from small pool |   16251    |   16398    |    8869 K  |    8852 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   22289 K  |   22272 K  |\n","|       from large pool |      98    |     248    |   13419 K  |   13419 K  |\n","|       from small pool |   16251    |   16398    |    8869 K  |    8852 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     245    |     329    |    1278 K  |    1278 K  |\n","|       from large pool |      18    |      96    |    1150 K  |    1150 K  |\n","|       from small pool |     227    |     244    |     127 K  |     127 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      81    |     159    |   11094 K  |   11094 K  |\n","|       from large pool |      18    |      68    |    7589 K  |    7589 K  |\n","|       from small pool |      63    |     107    |    3505 K  |    3505 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:204/7698 batch_size:250\n","Next token prediction. step:94/126 batch:204/7698 epoch:2/10\n","full seq: A Bulgarian collects belongings from his flood-devastated house in the village of Bial Briag, 370km northeast of Sofia.Ģġġġġġġ\n","pref seq: A Bulgarian collects belongings from his flood-devastated house in the village of Bial Briag, \n","next tok:                                                                                              3\n","pred tok:                                                                                              ,\n","Completed batch.\n","epoch:2/10 batch:204/7698 batch_size:250 loss:0.9181075096130371 time_for_batch_instance:133.7368245124817 total_batch_time:18395.043685674667 running_batch_average:90.17178277291504\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 652691 KiB |  10982 MiB | 727190 GiB | 727189 GiB |\n","|       from large pool | 195241 KiB |  10530 MiB | 725547 GiB | 725547 GiB |\n","|       from small pool | 457450 KiB |    484 MiB |   1642 GiB |   1642 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 652691 KiB |  10982 MiB | 727190 GiB | 727189 GiB |\n","|       from large pool | 195241 KiB |  10530 MiB | 725547 GiB | 725547 GiB |\n","|       from small pool | 457450 KiB |    484 MiB |   1642 GiB |   1642 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  10970 MiB | 725335 GiB | 725334 GiB |\n","|       from large pool | 189056 KiB |  10521 MiB | 723694 GiB | 723693 GiB |\n","|       from small pool | 453671 KiB |    480 MiB |   1641 GiB |   1641 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2582 MiB |  11552 MiB | 152524 GiB | 152522 GiB |\n","|       from large pool |   2128 MiB |  11086 MiB | 152273 GiB | 152271 GiB |\n","|       from small pool |    454 MiB |    488 MiB |    251 GiB |    251 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1944 MiB |   2386 MiB | 253456 GiB | 253454 GiB |\n","|       from large pool |   1937 MiB |   2378 MiB | 251666 GiB | 251665 GiB |\n","|       from small pool |      7 MiB |     20 MiB |   1789 GiB |   1789 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   22451 K  |   22435 K  |\n","|       from large pool |      98    |     248    |   13514 K  |   13514 K  |\n","|       from small pool |   16251    |   16398    |    8937 K  |    8920 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   22451 K  |   22435 K  |\n","|       from large pool |      98    |     248    |   13514 K  |   13514 K  |\n","|       from small pool |   16251    |   16398    |    8937 K  |    8920 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     246    |     328    |    1287 K  |    1287 K  |\n","|       from large pool |      19    |      95    |    1159 K  |    1159 K  |\n","|       from small pool |     227    |     244    |     128 K  |     128 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      82    |     158    |   11178 K  |   11178 K  |\n","|       from large pool |      19    |      68    |    7646 K  |    7646 K  |\n","|       from small pool |      63    |     107    |    3531 K  |    3531 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:205/7698 batch_size:250\n","Next token prediction. step:44/126 batch:205/7698 epoch:2/10\n","full seq: (International Herald Tribune, Newsday - 20/04/04; UN, AP, AFP, Transitions Online - 19/04/04; UNMIK, Reuters- 18/04/04)Ģġġġġġ\n","pref seq: (International Herald Tribune, Newsday - 20/\n","next tok:                                            0\n","pred tok:                                            ,\n","Completed batch.\n","epoch:2/10 batch:205/7698 batch_size:250 loss:1.6502633094787598 time_for_batch_instance:133.61186385154724 total_batch_time:18528.655549526215 running_batch_average:90.38368560744495\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 652691 KiB |  10982 MiB | 731790 GiB | 731789 GiB |\n","|       from large pool | 195241 KiB |  10530 MiB | 730133 GiB | 730132 GiB |\n","|       from small pool | 457450 KiB |    484 MiB |   1657 GiB |   1656 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 652691 KiB |  10982 MiB | 731790 GiB | 731789 GiB |\n","|       from large pool | 195241 KiB |  10530 MiB | 730133 GiB | 730132 GiB |\n","|       from small pool | 457450 KiB |    484 MiB |   1657 GiB |   1656 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  10970 MiB | 729928 GiB | 729927 GiB |\n","|       from large pool | 189056 KiB |  10521 MiB | 728271 GiB | 728271 GiB |\n","|       from small pool | 453671 KiB |    480 MiB |   1656 GiB |   1655 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2582 MiB |  11552 MiB | 153489 GiB | 153486 GiB |\n","|       from large pool |   2128 MiB |  11086 MiB | 153235 GiB | 153233 GiB |\n","|       from small pool |    454 MiB |    488 MiB |    253 GiB |    252 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1944 MiB |   2371 MiB | 254982 GiB | 254980 GiB |\n","|       from large pool |   1937 MiB |   2365 MiB | 253176 GiB | 253174 GiB |\n","|       from small pool |      7 MiB |     22 MiB |   1805 GiB |   1805 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   22614 K  |   22598 K  |\n","|       from large pool |      98    |     248    |   13609 K  |   13609 K  |\n","|       from small pool |   16251    |   16398    |    9005 K  |    8988 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   22614 K  |   22598 K  |\n","|       from large pool |      98    |     248    |   13609 K  |   13609 K  |\n","|       from small pool |   16251    |   16398    |    9005 K  |    8988 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     246    |     328    |    1296 K  |    1296 K  |\n","|       from large pool |      19    |      95    |    1167 K  |    1167 K  |\n","|       from small pool |     227    |     244    |     129 K  |     129 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      82    |     158    |   11262 K  |   11261 K  |\n","|       from large pool |      19    |      68    |    7704 K  |    7704 K  |\n","|       from small pool |      63    |     107    |    3557 K  |    3557 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:206/7698 batch_size:250\n","Next token prediction. step:17/125 batch:206/7698 epoch:2/10\n","full seq: \"I expect the matter of refugees' return to be resolved, as well as the issue of war crimes indictees on both sides.Ģġġġġġġġġ\n","pref seq: \"I expect the mat\n","next tok:                 t\n","pred tok:                 ;\n","Completed batch.\n","epoch:2/10 batch:206/7698 batch_size:250 loss:1.0673167705535889 time_for_batch_instance:130.988951921463 total_batch_time:18659.644501447678 running_batch_average:90.58079855071688\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 654429 KiB |  10898 MiB | 736323 GiB | 736322 GiB |\n","|       from large pool | 196979 KiB |  10446 MiB | 734651 GiB | 734651 GiB |\n","|       from small pool | 457450 KiB |    484 MiB |   1671 GiB |   1671 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 654429 KiB |  10898 MiB | 736323 GiB | 736322 GiB |\n","|       from large pool | 196979 KiB |  10446 MiB | 734651 GiB | 734651 GiB |\n","|       from small pool | 457450 KiB |    484 MiB |   1671 GiB |   1671 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  10887 MiB | 734450 GiB | 734450 GiB |\n","|       from large pool | 189056 KiB |  10438 MiB | 732780 GiB | 732780 GiB |\n","|       from small pool | 453671 KiB |    480 MiB |   1670 GiB |   1670 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   4736 MiB |  11494 MiB | 154141 GiB | 154136 GiB |\n","|       from large pool |   4284 MiB |  11028 MiB | 153886 GiB | 153882 GiB |\n","|       from small pool |    452 MiB |    488 MiB |    254 GiB |    254 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   4096 MiB |   4514 MiB | 257403 GiB | 257399 GiB |\n","|       from large pool |   4091 MiB |   4505 MiB | 255582 GiB | 255578 GiB |\n","|       from small pool |      5 MiB |     19 MiB |   1821 GiB |   1821 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   22776 K  |   22759 K  |\n","|       from large pool |      98    |     248    |   13703 K  |   13703 K  |\n","|       from small pool |   16251    |   16398    |    9072 K  |    9056 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   22776 K  |   22759 K  |\n","|       from large pool |      98    |     248    |   13703 K  |   13703 K  |\n","|       from small pool |   16251    |   16398    |    9072 K  |    9056 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     252    |     325    |    1304 K  |    1303 K  |\n","|       from large pool |      26    |      92    |    1173 K  |    1173 K  |\n","|       from small pool |     226    |     244    |     130 K  |     130 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      82    |     173    |   11346 K  |   11346 K  |\n","|       from large pool |      25    |      82    |    7762 K  |    7762 K  |\n","|       from small pool |      57    |     106    |    3583 K  |    3583 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:207/7698 batch_size:250\n","Next token prediction. step:98/125 batch:207/7698 epoch:2/10\n","full seq: The turnout threshold does not prevent citizens from turning out to vote, said SDSM parliamentarian Karolina Ristova.Ģġġġġġġġ\n","pref seq: The turnout threshold does not prevent citizens from turning out to vote, said SDSM parliamentaria\n","next tok:                                                                                                  n\n","pred tok:                                                                                                  Ģ\n","Completed batch.\n","epoch:2/10 batch:207/7698 batch_size:250 loss:0.801737368106842 time_for_batch_instance:131.55735540390015 total_batch_time:18791.201856851578 running_batch_average:90.77875293165013\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 654185 KiB |  10898 MiB | 740856 GiB | 740855 GiB |\n","|       from large pool | 196735 KiB |  10446 MiB | 739170 GiB | 739169 GiB |\n","|       from small pool | 457450 KiB |    484 MiB |   1686 GiB |   1685 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 654185 KiB |  10898 MiB | 740856 GiB | 740855 GiB |\n","|       from large pool | 196735 KiB |  10446 MiB | 739170 GiB | 739169 GiB |\n","|       from small pool | 457450 KiB |    484 MiB |   1686 GiB |   1685 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  10887 MiB | 738973 GiB | 738972 GiB |\n","|       from large pool | 189056 KiB |  10438 MiB | 737288 GiB | 737288 GiB |\n","|       from small pool | 453671 KiB |    480 MiB |   1685 GiB |   1684 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   4736 MiB |  11494 MiB | 154799 GiB | 154794 GiB |\n","|       from large pool |   4284 MiB |  11028 MiB | 154542 GiB | 154538 GiB |\n","|       from small pool |    452 MiB |    488 MiB |    256 GiB |    255 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   4097 MiB |   4449 MiB | 259823 GiB | 259819 GiB |\n","|       from large pool |   4091 MiB |   4443 MiB | 257985 GiB | 257981 GiB |\n","|       from small pool |      5 MiB |     20 MiB |   1837 GiB |   1837 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   22937 K  |   22921 K  |\n","|       from large pool |      98    |     248    |   13797 K  |   13797 K  |\n","|       from small pool |   16251    |   16398    |    9139 K  |    9123 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   22937 K  |   22921 K  |\n","|       from large pool |      98    |     248    |   13797 K  |   13797 K  |\n","|       from small pool |   16251    |   16398    |    9139 K  |    9123 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     252    |     325    |    1311 K  |    1311 K  |\n","|       from large pool |      26    |      92    |    1180 K  |    1180 K  |\n","|       from small pool |     226    |     244    |     131 K  |     130 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      82    |     173    |   11430 K  |   11430 K  |\n","|       from large pool |      25    |      82    |    7820 K  |    7820 K  |\n","|       from small pool |      57    |     106    |    3609 K  |    3609 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:208/7698 batch_size:250\n","Next token prediction. step:87/125 batch:208/7698 epoch:2/10\n","full seq: It is no secret that people in the Balkans like to dress well and meticulously follow latest fashion trends.Ģġġġġġġġġġġġġġġġġ\n","pref seq: It is no secret that people in the Balkans like to dress well and meticulously follow l\n","next tok:                                                                                       a\n","pred tok:                                                                                       ,\n","Completed batch.\n","epoch:2/10 batch:208/7698 batch_size:250 loss:0.8435360193252563 time_for_batch_instance:131.39983439445496 total_batch_time:18922.601691246033 running_batch_average:90.974046592529\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 654429 KiB |  10898 MiB | 745389 GiB | 745388 GiB |\n","|       from large pool | 196979 KiB |  10446 MiB | 743688 GiB | 743688 GiB |\n","|       from small pool | 457450 KiB |    484 MiB |   1700 GiB |   1700 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 654429 KiB |  10898 MiB | 745389 GiB | 745388 GiB |\n","|       from large pool | 196979 KiB |  10446 MiB | 743688 GiB | 743688 GiB |\n","|       from small pool | 457450 KiB |    484 MiB |   1700 GiB |   1700 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  10887 MiB | 743496 GiB | 743495 GiB |\n","|       from large pool | 189056 KiB |  10438 MiB | 741796 GiB | 741796 GiB |\n","|       from small pool | 453671 KiB |    480 MiB |   1699 GiB |   1699 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   4736 MiB |  11494 MiB | 155457 GiB | 155453 GiB |\n","|       from large pool |   4284 MiB |  11028 MiB | 155199 GiB | 155195 GiB |\n","|       from small pool |    452 MiB |    488 MiB |    257 GiB |    257 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   4096 MiB |   4377 MiB | 262246 GiB | 262242 GiB |\n","|       from large pool |   4091 MiB |   4371 MiB | 260392 GiB | 260388 GiB |\n","|       from small pool |      5 MiB |     20 MiB |   1853 GiB |   1853 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   23099 K  |   23082 K  |\n","|       from large pool |      98    |     248    |   13891 K  |   13891 K  |\n","|       from small pool |   16251    |   16398    |    9207 K  |    9191 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   23099 K  |   23082 K  |\n","|       from large pool |      98    |     248    |   13891 K  |   13891 K  |\n","|       from small pool |   16251    |   16398    |    9207 K  |    9191 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     252    |     325    |    1318 K  |    1318 K  |\n","|       from large pool |      26    |      92    |    1186 K  |    1186 K  |\n","|       from small pool |     226    |     244    |     131 K  |     131 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      82    |     173    |   11514 K  |   11514 K  |\n","|       from large pool |      25    |      82    |    7879 K  |    7879 K  |\n","|       from small pool |      57    |     106    |    3635 K  |    3635 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:209/7698 batch_size:250\n","Next token prediction. step:67/125 batch:209/7698 epoch:2/10\n","full seq: Hamogelo tou Paidiou in Kareas cares for children while their parents look for work. [Courtesy of Hamogelo tou Paidiou]Ģġġġġġ\n","pref seq: Hamogelo tou Paidiou in Kareas cares for children while their paren\n","next tok:                                                                   t\n","pred tok:                                                                   ,\n","Completed batch.\n","epoch:2/10 batch:209/7698 batch_size:250 loss:0.888526201248169 time_for_batch_instance:131.43717050552368 total_batch_time:19054.038861751556 running_batch_average:91.16765005622754\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 654429 KiB |  10898 MiB | 749922 GiB | 749921 GiB |\n","|       from large pool | 196979 KiB |  10446 MiB | 748207 GiB | 748206 GiB |\n","|       from small pool | 457450 KiB |    484 MiB |   1715 GiB |   1714 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 654429 KiB |  10898 MiB | 749922 GiB | 749921 GiB |\n","|       from large pool | 196979 KiB |  10446 MiB | 748207 GiB | 748206 GiB |\n","|       from small pool | 457450 KiB |    484 MiB |   1715 GiB |   1714 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  10887 MiB | 748019 GiB | 748018 GiB |\n","|       from large pool | 189056 KiB |  10438 MiB | 746304 GiB | 746304 GiB |\n","|       from small pool | 453671 KiB |    480 MiB |   1714 GiB |   1713 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   4736 MiB |  11494 MiB | 156116 GiB | 156111 GiB |\n","|       from large pool |   4284 MiB |  11028 MiB | 155856 GiB | 155852 GiB |\n","|       from small pool |    452 MiB |    488 MiB |    259 GiB |    258 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   4096 MiB |   4357 MiB | 264664 GiB | 264660 GiB |\n","|       from large pool |   4091 MiB |   4350 MiB | 262795 GiB | 262791 GiB |\n","|       from small pool |      5 MiB |     20 MiB |   1868 GiB |   1868 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   23260 K  |   23244 K  |\n","|       from large pool |      98    |     248    |   13985 K  |   13985 K  |\n","|       from small pool |   16251    |   16398    |    9274 K  |    9258 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   23260 K  |   23244 K  |\n","|       from large pool |      98    |     248    |   13985 K  |   13985 K  |\n","|       from small pool |   16251    |   16398    |    9274 K  |    9258 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     252    |     326    |    1325 K  |    1325 K  |\n","|       from large pool |      26    |      93    |    1193 K  |    1193 K  |\n","|       from small pool |     226    |     244    |     132 K  |     132 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      82    |     173    |   11599 K  |   11599 K  |\n","|       from large pool |      25    |      82    |    7937 K  |    7937 K  |\n","|       from small pool |      57    |     106    |    3661 K  |    3661 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:210/7698 batch_size:250\n","Next token prediction. step:22/125 batch:210/7698 epoch:2/10\n","full seq: Presidential spokeswoman Mimoza Kociu said that the decision followed a recommendation from Prime Minister Sali Berisha.Ģġġġġ\n","pref seq: Presidential spokeswom\n","next tok:                      a\n","pred tok:                      w\n","Completed batch.\n","epoch:2/10 batch:210/7698 batch_size:250 loss:1.4649441242218018 time_for_batch_instance:131.41357016563416 total_batch_time:19185.45243191719 running_batch_average:91.35929729484377\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 654429 KiB |  10898 MiB | 754455 GiB | 754454 GiB |\n","|       from large pool | 196979 KiB |  10446 MiB | 752725 GiB | 752725 GiB |\n","|       from small pool | 457450 KiB |    484 MiB |   1729 GiB |   1729 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 654429 KiB |  10898 MiB | 754455 GiB | 754454 GiB |\n","|       from large pool | 196979 KiB |  10446 MiB | 752725 GiB | 752725 GiB |\n","|       from small pool | 457450 KiB |    484 MiB |   1729 GiB |   1729 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  10887 MiB | 752541 GiB | 752541 GiB |\n","|       from large pool | 189056 KiB |  10438 MiB | 750813 GiB | 750812 GiB |\n","|       from small pool | 453671 KiB |    480 MiB |   1728 GiB |   1728 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   4736 MiB |  11494 MiB | 156774 GiB | 156769 GiB |\n","|       from large pool |   4284 MiB |  11028 MiB | 156513 GiB | 156509 GiB |\n","|       from small pool |    452 MiB |    488 MiB |    260 GiB |    260 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   4096 MiB |   4421 MiB | 267091 GiB | 267087 GiB |\n","|       from large pool |   4091 MiB |   4415 MiB | 265207 GiB | 265203 GiB |\n","|       from small pool |      5 MiB |     20 MiB |   1884 GiB |   1884 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   23422 K  |   23405 K  |\n","|       from large pool |      98    |     248    |   14079 K  |   14079 K  |\n","|       from small pool |   16251    |   16398    |    9342 K  |    9326 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   23422 K  |   23405 K  |\n","|       from large pool |      98    |     248    |   14079 K  |   14079 K  |\n","|       from small pool |   16251    |   16398    |    9342 K  |    9326 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     252    |     326    |    1333 K  |    1332 K  |\n","|       from large pool |      26    |      93    |    1199 K  |    1199 K  |\n","|       from small pool |     226    |     244    |     133 K  |     133 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      82    |     173    |   11683 K  |   11683 K  |\n","|       from large pool |      25    |      82    |    7995 K  |    7995 K  |\n","|       from small pool |      57    |     106    |    3687 K  |    3687 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:211/7698 batch_size:250\n","Next token prediction. step:81/124 batch:211/7698 epoch:2/10\n","full seq: Syrian President Bashar al-Assad (left) and Turkish Prime Minister Recep Tayyip Erdogan in Istanbul. [Getty Images]Ģġġġġġġġġ\n","pref seq: Syrian President Bashar al-Assad (left) and Turkish Prime Minister Recep Tayyip E\n","next tok:                                                                                 r\n","pred tok:                                                                                 w\n","Completed batch.\n","epoch:2/10 batch:211/7698 batch_size:250 loss:0.7214142084121704 time_for_batch_instance:131.30895590782166 total_batch_time:19316.761387825012 running_batch_average:91.54863216978679\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 650835 KiB |  10815 MiB | 758912 GiB | 758912 GiB |\n","|       from large pool | 193385 KiB |  10363 MiB | 757168 GiB | 757168 GiB |\n","|       from small pool | 457450 KiB |    484 MiB |   1744 GiB |   1743 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 650835 KiB |  10815 MiB | 758912 GiB | 758912 GiB |\n","|       from large pool | 193385 KiB |  10363 MiB | 757168 GiB | 757168 GiB |\n","|       from small pool | 457450 KiB |    484 MiB |   1744 GiB |   1743 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  10804 MiB | 756995 GiB | 756994 GiB |\n","|       from large pool | 189056 KiB |  10355 MiB | 755252 GiB | 755252 GiB |\n","|       from small pool | 453671 KiB |    480 MiB |   1743 GiB |   1742 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2818 MiB |  11394 MiB | 157598 GiB | 157596 GiB |\n","|       from large pool |   2366 MiB |  10928 MiB | 157336 GiB | 157334 GiB |\n","|       from small pool |    452 MiB |    488 MiB |    262 GiB |    261 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   2182 MiB |   4108 MiB | 268702 GiB | 268699 GiB |\n","|       from large pool |   2177 MiB |   4100 MiB | 266801 GiB | 266799 GiB |\n","|       from small pool |      5 MiB |     19 MiB |   1900 GiB |   1900 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   23582 K  |   23566 K  |\n","|       from large pool |      98    |     248    |   14173 K  |   14173 K  |\n","|       from small pool |   16251    |   16398    |    9409 K  |    9392 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   23582 K  |   23566 K  |\n","|       from large pool |      98    |     248    |   14173 K  |   14173 K  |\n","|       from small pool |   16251    |   16398    |    9409 K  |    9392 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     245    |     329    |    1341 K  |    1341 K  |\n","|       from large pool |      19    |      96    |    1207 K  |    1207 K  |\n","|       from small pool |     226    |     244    |     134 K  |     134 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      78    |     183    |   11775 K  |   11775 K  |\n","|       from large pool |      21    |      93    |    8061 K  |    8061 K  |\n","|       from small pool |      57    |     107    |    3713 K  |    3713 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:212/7698 batch_size:250\n","Next token prediction. step:122/124 batch:212/7698 epoch:2/10\n","full seq: The delegation conveyed the interest of Israeli firms in the energy sector, tourism, agro-industry and other areas.Ģġġġġġġġġ\n","pref seq: The delegation conveyed the interest of Israeli firms in the energy sector, tourism, agro-industry and other areas.Ģġġġġġġ\n","next tok:                                                                                                                          ġ\n","pred tok:                                                                                                                          Ģ\n","Completed batch.\n","epoch:2/10 batch:212/7698 batch_size:250 loss:2.3408560752868652 time_for_batch_instance:131.22768712043762 total_batch_time:19447.98907494545 running_batch_average:91.73579752332759\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 652157 KiB |  10815 MiB | 763370 GiB | 763369 GiB |\n","|       from large pool | 194707 KiB |  10363 MiB | 761611 GiB | 761611 GiB |\n","|       from small pool | 457450 KiB |    484 MiB |   1758 GiB |   1758 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 652157 KiB |  10815 MiB | 763370 GiB | 763369 GiB |\n","|       from large pool | 194707 KiB |  10363 MiB | 761611 GiB | 761611 GiB |\n","|       from small pool | 457450 KiB |    484 MiB |   1758 GiB |   1758 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  10804 MiB | 761448 GiB | 761448 GiB |\n","|       from large pool | 189056 KiB |  10355 MiB | 759691 GiB | 759691 GiB |\n","|       from small pool | 453671 KiB |    480 MiB |   1757 GiB |   1756 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2912 MiB |  11392 MiB | 158442 GiB | 158439 GiB |\n","|       from large pool |   2458 MiB |  10926 MiB | 158178 GiB | 158175 GiB |\n","|       from small pool |    454 MiB |    488 MiB |    263 GiB |    263 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   2275 MiB |   3007 MiB | 270208 GiB | 270206 GiB |\n","|       from large pool |   2267 MiB |   3000 MiB | 268292 GiB | 268290 GiB |\n","|       from small pool |      7 MiB |     19 MiB |   1916 GiB |   1916 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   23742 K  |   23726 K  |\n","|       from large pool |      98    |     248    |   14266 K  |   14266 K  |\n","|       from small pool |   16251    |   16398    |    9476 K  |    9459 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   23742 K  |   23726 K  |\n","|       from large pool |      98    |     248    |   14266 K  |   14266 K  |\n","|       from small pool |   16251    |   16398    |    9476 K  |    9459 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     246    |     327    |    1350 K  |    1349 K  |\n","|       from large pool |      19    |      94    |    1214 K  |    1214 K  |\n","|       from small pool |     227    |     244    |     135 K  |     134 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      82    |     184    |   11868 K  |   11867 K  |\n","|       from large pool |      21    |      94    |    8128 K  |    8128 K  |\n","|       from small pool |      61    |     107    |    3739 K  |    3739 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:213/7698 batch_size:250\n","Next token prediction. step:23/124 batch:213/7698 epoch:2/10\n","full seq: Some 20 artists from Australia, Bulgaria, Italy, Romania, Serbia-Montenegro and Slovenia are participating.Ģġġġġġġġġġġġġġġġġ\n","pref seq: Some 20 artists from Au\n","next tok:                       s\n","pred tok:                       ,\n","Completed batch.\n","epoch:2/10 batch:213/7698 batch_size:250 loss:1.0538674592971802 time_for_batch_instance:130.2083706855774 total_batch_time:19578.197445631027 running_batch_average:91.91641993254004\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 652157 KiB |  10815 MiB | 767827 GiB | 767826 GiB |\n","|       from large pool | 194707 KiB |  10363 MiB | 766054 GiB | 766054 GiB |\n","|       from small pool | 457450 KiB |    484 MiB |   1772 GiB |   1772 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 652157 KiB |  10815 MiB | 767827 GiB | 767826 GiB |\n","|       from large pool | 194707 KiB |  10363 MiB | 766054 GiB | 766054 GiB |\n","|       from small pool | 457450 KiB |    484 MiB |   1772 GiB |   1772 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  10804 MiB | 765902 GiB | 765901 GiB |\n","|       from large pool | 189056 KiB |  10355 MiB | 764130 GiB | 764130 GiB |\n","|       from small pool | 453671 KiB |    480 MiB |   1771 GiB |   1771 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2912 MiB |  11392 MiB | 159282 GiB | 159280 GiB |\n","|       from large pool |   2458 MiB |  10926 MiB | 159017 GiB | 159015 GiB |\n","|       from small pool |    454 MiB |    488 MiB |    265 GiB |    264 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   2275 MiB |   3007 MiB | 271730 GiB | 271728 GiB |\n","|       from large pool |   2267 MiB |   3000 MiB | 269798 GiB | 269796 GiB |\n","|       from small pool |      7 MiB |     20 MiB |   1931 GiB |   1931 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   23902 K  |   23886 K  |\n","|       from large pool |      98    |     248    |   14359 K  |   14359 K  |\n","|       from small pool |   16251    |   16398    |    9542 K  |    9526 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   23902 K  |   23886 K  |\n","|       from large pool |      98    |     248    |   14359 K  |   14359 K  |\n","|       from small pool |   16251    |   16398    |    9542 K  |    9526 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     246    |     327    |    1358 K  |    1358 K  |\n","|       from large pool |      19    |      94    |    1222 K  |    1222 K  |\n","|       from small pool |     227    |     244    |     135 K  |     135 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      82    |     184    |   11960 K  |   11960 K  |\n","|       from large pool |      21    |      94    |    8194 K  |    8194 K  |\n","|       from small pool |      61    |     107    |    3765 K  |    3765 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:214/7698 batch_size:250\n","Next token prediction. step:69/124 batch:214/7698 epoch:2/10\n","full seq: Greek Prime Minister George Papandreou heads to the Presidential Palace in Athens on Saturday (November 5th). [Reuters]Ģġġġġ\n","pref seq: Greek Prime Minister George Papandreou heads to the Presidential Pala\n","next tok:                                                                     c\n","pred tok:                                                                     ,\n","Completed batch.\n","epoch:2/10 batch:214/7698 batch_size:250 loss:2.0271847248077393 time_for_batch_instance:131.49805617332458 total_batch_time:19709.69550180435 running_batch_average:92.10138084955305\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 652157 KiB |  10815 MiB | 772284 GiB | 772284 GiB |\n","|       from large pool | 194707 KiB |  10363 MiB | 770497 GiB | 770497 GiB |\n","|       from small pool | 457450 KiB |    484 MiB |   1787 GiB |   1786 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 652157 KiB |  10815 MiB | 772284 GiB | 772284 GiB |\n","|       from large pool | 194707 KiB |  10363 MiB | 770497 GiB | 770497 GiB |\n","|       from small pool | 457450 KiB |    484 MiB |   1787 GiB |   1786 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  10804 MiB | 770355 GiB | 770354 GiB |\n","|       from large pool | 189056 KiB |  10355 MiB | 768569 GiB | 768569 GiB |\n","|       from small pool | 453671 KiB |    480 MiB |   1786 GiB |   1785 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2912 MiB |  11392 MiB | 160123 GiB | 160120 GiB |\n","|       from large pool |   2458 MiB |  10926 MiB | 159856 GiB | 159853 GiB |\n","|       from small pool |    454 MiB |    488 MiB |    266 GiB |    266 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   2275 MiB |   3007 MiB | 273250 GiB | 273248 GiB |\n","|       from large pool |   2267 MiB |   3000 MiB | 271303 GiB | 271300 GiB |\n","|       from small pool |      7 MiB |     20 MiB |   1947 GiB |   1947 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   24063 K  |   24046 K  |\n","|       from large pool |      98    |     248    |   14453 K  |   14453 K  |\n","|       from small pool |   16251    |   16398    |    9609 K  |    9593 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   24063 K  |   24046 K  |\n","|       from large pool |      98    |     248    |   14453 K  |   14453 K  |\n","|       from small pool |   16251    |   16398    |    9609 K  |    9593 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     246    |     327    |    1366 K  |    1366 K  |\n","|       from large pool |      19    |      94    |    1230 K  |    1230 K  |\n","|       from small pool |     227    |     244    |     136 K  |     136 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      82    |     184    |   12052 K  |   12052 K  |\n","|       from large pool |      21    |      94    |    8260 K  |    8260 K  |\n","|       from small pool |      61    |     107    |    3791 K  |    3791 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:215/7698 batch_size:250\n","Next token prediction. step:64/124 batch:215/7698 epoch:2/10\n","full seq: (EUobserver - 27/01/04; AFP, AP, Reuters, BBC, Dow Jones, UN, Anadolu Agency, Athens News Agency, NTV MSNBC - 26/01/04)Ģġġġġ\n","pref seq: (EUobserver - 27/01/04; AFP, AP, Reuters, BBC, Dow Jones, UN, An\n","next tok:                                                                a\n","pred tok:                                                                ;\n","Completed batch.\n","epoch:2/10 batch:215/7698 batch_size:250 loss:1.674204707145691 time_for_batch_instance:132.46608424186707 total_batch_time:19842.16158604622 running_batch_average:92.28912365602892\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 652157 KiB |  10815 MiB | 776742 GiB | 776741 GiB |\n","|       from large pool | 194707 KiB |  10363 MiB | 774940 GiB | 774940 GiB |\n","|       from small pool | 457450 KiB |    484 MiB |   1801 GiB |   1801 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 652157 KiB |  10815 MiB | 776742 GiB | 776741 GiB |\n","|       from large pool | 194707 KiB |  10363 MiB | 774940 GiB | 774940 GiB |\n","|       from small pool | 457450 KiB |    484 MiB |   1801 GiB |   1801 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  10804 MiB | 774808 GiB | 774808 GiB |\n","|       from large pool | 189056 KiB |  10355 MiB | 773008 GiB | 773008 GiB |\n","|       from small pool | 453671 KiB |    480 MiB |   1800 GiB |   1799 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2912 MiB |  11392 MiB | 160965 GiB | 160962 GiB |\n","|       from large pool |   2458 MiB |  10926 MiB | 160696 GiB | 160694 GiB |\n","|       from small pool |    454 MiB |    488 MiB |    268 GiB |    268 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   2275 MiB |   3007 MiB | 274760 GiB | 274758 GiB |\n","|       from large pool |   2267 MiB |   3000 MiB | 272797 GiB | 272795 GiB |\n","|       from small pool |      7 MiB |     19 MiB |   1963 GiB |   1963 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   24223 K  |   24206 K  |\n","|       from large pool |      98    |     248    |   14546 K  |   14546 K  |\n","|       from small pool |   16251    |   16398    |    9676 K  |    9660 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   24223 K  |   24206 K  |\n","|       from large pool |      98    |     248    |   14546 K  |   14546 K  |\n","|       from small pool |   16251    |   16398    |    9676 K  |    9660 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     246    |     327    |    1375 K  |    1375 K  |\n","|       from large pool |      19    |      94    |    1237 K  |    1237 K  |\n","|       from small pool |     227    |     244    |     137 K  |     137 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      82    |     184    |   12144 K  |   12144 K  |\n","|       from large pool |      21    |      94    |    8326 K  |    8326 K  |\n","|       from small pool |      61    |     107    |    3817 K  |    3817 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:216/7698 batch_size:250\n","Completed batch.\n","epoch:2/10 batch:216/7698 batch_size:250 loss:1.0824480056762695 time_for_batch_instance:130.0020763874054 total_batch_time:19972.163662433624 running_batch_average:92.46372065941493\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 651844 KiB |  10738 MiB | 781130 GiB | 781130 GiB |\n","|       from large pool | 194394 KiB |  10286 MiB | 779314 GiB | 779314 GiB |\n","|       from small pool | 457450 KiB |    484 MiB |   1815 GiB |   1815 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 651844 KiB |  10738 MiB | 781130 GiB | 781130 GiB |\n","|       from large pool | 194394 KiB |  10286 MiB | 779314 GiB | 779314 GiB |\n","|       from small pool | 457450 KiB |    484 MiB |   1815 GiB |   1815 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  10721 MiB | 779193 GiB | 779193 GiB |\n","|       from large pool | 189056 KiB |  10272 MiB | 777379 GiB | 777378 GiB |\n","|       from small pool | 453671 KiB |    480 MiB |   1814 GiB |   1814 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2296 MiB |  11358 MiB | 161865 GiB | 161862 GiB |\n","|       from large pool |   1844 MiB |  10892 MiB | 161595 GiB | 161593 GiB |\n","|       from small pool |    452 MiB |    488 MiB |    270 GiB |    269 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1659 MiB |   2299 MiB | 276344 GiB | 276342 GiB |\n","|       from large pool |   1654 MiB |   2285 MiB | 274365 GiB | 274363 GiB |\n","|       from small pool |      5 MiB |     21 MiB |   1978 GiB |   1978 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   24382 K  |   24365 K  |\n","|       from large pool |      98    |     248    |   14639 K  |   14638 K  |\n","|       from small pool |   16251    |   16398    |    9743 K  |    9726 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   24382 K  |   24365 K  |\n","|       from large pool |      98    |     248    |   14639 K  |   14638 K  |\n","|       from small pool |   16251    |   16398    |    9743 K  |    9726 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     255    |     336    |    1383 K  |    1383 K  |\n","|       from large pool |      29    |     103    |    1245 K  |    1245 K  |\n","|       from small pool |     226    |     244    |     138 K  |     138 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      89    |     190    |   12237 K  |   12237 K  |\n","|       from large pool |      28    |     100    |    8394 K  |    8394 K  |\n","|       from small pool |      61    |     107    |    3843 K  |    3843 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:217/7698 batch_size:250\n","Next token prediction. step:77/123 batch:217/7698 epoch:2/10\n","full seq: The government nominates ambassadors and consular officials, but it is up to the president to accept the nominations.Ģġġġġġ\n","pref seq: The government nominates ambassadors and consular officials, but it is up to \n","next tok:                                                                             t\n","pred tok:                                                                             ,\n","Completed batch.\n","epoch:2/10 batch:217/7698 batch_size:250 loss:1.4123481512069702 time_for_batch_instance:131.36171293258667 total_batch_time:20103.52537536621 running_batch_average:92.64297408002862\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 651844 KiB |  10738 MiB | 785519 GiB | 785518 GiB |\n","|       from large pool | 194394 KiB |  10286 MiB | 783689 GiB | 783689 GiB |\n","|       from small pool | 457450 KiB |    484 MiB |   1830 GiB |   1829 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 651844 KiB |  10738 MiB | 785519 GiB | 785518 GiB |\n","|       from large pool | 194394 KiB |  10286 MiB | 783689 GiB | 783689 GiB |\n","|       from small pool | 457450 KiB |    484 MiB |   1830 GiB |   1829 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  10721 MiB | 783578 GiB | 783577 GiB |\n","|       from large pool | 189056 KiB |  10272 MiB | 781749 GiB | 781749 GiB |\n","|       from small pool | 453671 KiB |    480 MiB |   1828 GiB |   1828 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2296 MiB |  11358 MiB | 162766 GiB | 162764 GiB |\n","|       from large pool |   1844 MiB |  10892 MiB | 162495 GiB | 162493 GiB |\n","|       from small pool |    452 MiB |    488 MiB |    271 GiB |    271 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1659 MiB |   1842 MiB | 277910 GiB | 277908 GiB |\n","|       from large pool |   1654 MiB |   1834 MiB | 275915 GiB | 275914 GiB |\n","|       from small pool |      5 MiB |     19 MiB |   1994 GiB |   1994 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   24540 K  |   24524 K  |\n","|       from large pool |      98    |     248    |   14731 K  |   14731 K  |\n","|       from small pool |   16251    |   16398    |    9809 K  |    9793 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   24540 K  |   24524 K  |\n","|       from large pool |      98    |     248    |   14731 K  |   14731 K  |\n","|       from small pool |   16251    |   16398    |    9809 K  |    9793 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     255    |     337    |    1392 K  |    1392 K  |\n","|       from large pool |      29    |     104    |    1253 K  |    1253 K  |\n","|       from small pool |     226    |     244    |     139 K  |     138 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      89    |     190    |   12331 K  |   12331 K  |\n","|       from large pool |      28    |     100    |    8462 K  |    8462 K  |\n","|       from small pool |      61    |     107    |    3869 K  |    3869 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:218/7698 batch_size:250\n","Next token prediction. step:64/123 batch:218/7698 epoch:2/10\n","full seq: \"The Serbian power grid is connected to eight states and is unavoidable in the transmission and trade of electricity.Ģġġġġġ\n","pref seq: \"The Serbian power grid is connected to eight states and is unav\n","next tok:                                                                o\n","pred tok:                                                                w\n","Completed batch.\n","epoch:2/10 batch:218/7698 batch_size:250 loss:1.043147087097168 time_for_batch_instance:129.56721901893616 total_batch_time:20233.092594385147 running_batch_average:92.81235135039059\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 651814 KiB |  10738 MiB |    771 TiB |    771 TiB |\n","|       from large pool | 194364 KiB |  10286 MiB |    769 TiB |    769 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 651814 KiB |  10738 MiB |    771 TiB |    771 TiB |\n","|       from large pool | 194364 KiB |  10286 MiB |    769 TiB |    769 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  10721 MiB |    769 TiB |    769 TiB |\n","|       from large pool | 189056 KiB |  10272 MiB |    767 TiB |    767 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2326 MiB |  11360 MiB | 163667 GiB | 163664 GiB |\n","|       from large pool |   1874 MiB |  10894 MiB | 163394 GiB | 163392 GiB |\n","|       from small pool |    452 MiB |    488 MiB |    273 GiB |    272 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1689 MiB |   1873 MiB | 279470 GiB | 279469 GiB |\n","|       from large pool |   1684 MiB |   1866 MiB | 277460 GiB | 277459 GiB |\n","|       from small pool |      5 MiB |     19 MiB |   2009 GiB |   2009 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   24699 K  |   24683 K  |\n","|       from large pool |      98    |     248    |   14824 K  |   14824 K  |\n","|       from small pool |   16251    |   16398    |    9875 K  |    9859 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   24699 K  |   24683 K  |\n","|       from large pool |      98    |     248    |   14824 K  |   14824 K  |\n","|       from small pool |   16251    |   16398    |    9875 K  |    9859 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     255    |     336    |    1400 K  |    1400 K  |\n","|       from large pool |      29    |     103    |    1261 K  |    1261 K  |\n","|       from small pool |     226    |     244    |     139 K  |     139 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      89    |     191    |   12424 K  |   12424 K  |\n","|       from large pool |      28    |     101    |    8530 K  |    8530 K  |\n","|       from small pool |      61    |     107    |    3894 K  |    3894 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:219/7698 batch_size:250\n","Next token prediction. step:80/123 batch:219/7698 epoch:2/10\n","full seq: (Rompres, International Herald Tribune, Seeurope.net - 25/08/03; Washington Times - 24/08/03; Reuters, AFP - 23/08/03)Ģġġġġ\n","pref seq: (Rompres, International Herald Tribune, Seeurope.net - 25/08/03; Washington Time\n","next tok:                                                                                s\n","pred tok:                                                                                ;\n","Completed batch.\n","epoch:2/10 batch:219/7698 batch_size:250 loss:1.2616453170776367 time_for_batch_instance:129.95670533180237 total_batch_time:20363.04929971695 running_batch_average:92.98196027268014\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 651844 KiB |  10738 MiB |    775 TiB |    775 TiB |\n","|       from large pool | 194394 KiB |  10286 MiB |    773 TiB |    773 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 651844 KiB |  10738 MiB |    775 TiB |    775 TiB |\n","|       from large pool | 194394 KiB |  10286 MiB |    773 TiB |    773 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  10721 MiB |    773 TiB |    773 TiB |\n","|       from large pool | 189056 KiB |  10272 MiB |    771 TiB |    771 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2296 MiB |  11358 MiB | 164567 GiB | 164565 GiB |\n","|       from large pool |   1844 MiB |  10892 MiB | 164292 GiB | 164291 GiB |\n","|       from small pool |    452 MiB |    488 MiB |    274 GiB |    274 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1659 MiB |   1906 MiB | 281034 GiB | 281033 GiB |\n","|       from large pool |   1654 MiB |   1898 MiB | 279009 GiB | 279007 GiB |\n","|       from small pool |      5 MiB |     21 MiB |   2025 GiB |   2025 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   24858 K  |   24842 K  |\n","|       from large pool |      98    |     248    |   14916 K  |   14916 K  |\n","|       from small pool |   16251    |   16398    |    9942 K  |    9925 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   24858 K  |   24842 K  |\n","|       from large pool |      98    |     248    |   14916 K  |   14916 K  |\n","|       from small pool |   16251    |   16398    |    9942 K  |    9925 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     255    |     336    |    1409 K  |    1409 K  |\n","|       from large pool |      29    |     103    |    1268 K  |    1268 K  |\n","|       from small pool |     226    |     244    |     140 K  |     140 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      89    |     191    |   12518 K  |   12518 K  |\n","|       from large pool |      28    |     101    |    8598 K  |    8598 K  |\n","|       from small pool |      61    |     107    |    3920 K  |    3920 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:220/7698 batch_size:250\n","Completed batch.\n","epoch:2/10 batch:220/7698 batch_size:250 loss:1.2951648235321045 time_for_batch_instance:131.64629077911377 total_batch_time:20494.695590496063 running_batch_average:93.15770722952756\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 651257 KiB |  10666 MiB |    779 TiB |    779 TiB |\n","|       from large pool | 193807 KiB |  10214 MiB |    778 TiB |    778 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 651257 KiB |  10666 MiB |    779 TiB |    779 TiB |\n","|       from large pool | 193807 KiB |  10214 MiB |    778 TiB |    778 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  10638 MiB |    777 TiB |    777 TiB |\n","|       from large pool | 189056 KiB |  10190 MiB |    776 TiB |    776 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1954 MiB |  11242 MiB | 165536 GiB | 165534 GiB |\n","|       from large pool |   1500 MiB |  10776 MiB | 165260 GiB | 165258 GiB |\n","|       from small pool |    454 MiB |    488 MiB |    276 GiB |    275 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1318 MiB |   1820 MiB | 282435 GiB | 282433 GiB |\n","|       from large pool |   1310 MiB |   1810 MiB | 280394 GiB | 280393 GiB |\n","|       from small pool |      7 MiB |     19 MiB |   2040 GiB |   2040 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   25016 K  |   24999 K  |\n","|       from large pool |      98    |     248    |   15008 K  |   15008 K  |\n","|       from small pool |   16251    |   16398    |   10007 K  |    9991 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   25016 K  |   24999 K  |\n","|       from large pool |      98    |     248    |   15008 K  |   15008 K  |\n","|       from small pool |   16251    |   16398    |   10007 K  |    9991 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     244    |     333    |    1418 K  |    1418 K  |\n","|       from large pool |      17    |     100    |    1277 K  |    1277 K  |\n","|       from small pool |     227    |     244    |     141 K  |     141 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      82    |     165    |   12585 K  |   12585 K  |\n","|       from large pool |      21    |      75    |    8640 K  |    8640 K  |\n","|       from small pool |      61    |     107    |    3945 K  |    3945 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:221/7698 batch_size:250\n","Next token prediction. step:27/121 batch:221/7698 epoch:2/10\n","full seq: We will not be able to change some things radically, if they should be changed, without constitutional reforms.\"Ģġġġġġġġġ\n","pref seq: We will not be able to chan\n","next tok:                           g\n","pred tok:                           w\n","Completed batch.\n","epoch:2/10 batch:221/7698 batch_size:250 loss:1.5383970737457275 time_for_batch_instance:129.52137732505798 total_batch_time:20624.21696782112 running_batch_average:93.32224872317249\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 649867 KiB |  10642 MiB |    784 TiB |    784 TiB |\n","|       from large pool | 192417 KiB |  10190 MiB |    782 TiB |    782 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 649867 KiB |  10642 MiB |    784 TiB |    784 TiB |\n","|       from large pool | 192417 KiB |  10190 MiB |    782 TiB |    782 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  10613 MiB |    782 TiB |    782 TiB |\n","|       from large pool | 189056 KiB |  10165 MiB |    780 TiB |    780 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2142 MiB |  11232 MiB | 166509 GiB | 166507 GiB |\n","|       from large pool |   1688 MiB |  10766 MiB | 166231 GiB | 166230 GiB |\n","|       from small pool |    454 MiB |    488 MiB |    277 GiB |    277 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1507 MiB |   1735 MiB | 283746 GiB | 283745 GiB |\n","|       from large pool |   1500 MiB |   1729 MiB | 281690 GiB | 281689 GiB |\n","|       from small pool |      7 MiB |     19 MiB |   2056 GiB |   2056 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   25172 K  |   25156 K  |\n","|       from large pool |      98    |     248    |   15099 K  |   15099 K  |\n","|       from small pool |   16251    |   16398    |   10073 K  |   10056 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   25172 K  |   25156 K  |\n","|       from large pool |      98    |     248    |   15099 K  |   15099 K  |\n","|       from small pool |   16251    |   16398    |   10073 K  |   10056 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     246    |     332    |    1428 K  |    1427 K  |\n","|       from large pool |      19    |      99    |    1285 K  |    1285 K  |\n","|       from small pool |     227    |     244    |     142 K  |     141 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      88    |     166    |   12650 K  |   12650 K  |\n","|       from large pool |      24    |      76    |    8680 K  |    8680 K  |\n","|       from small pool |      64    |     107    |    3970 K  |    3969 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:222/7698 batch_size:250\n","Next token prediction. step:58/121 batch:222/7698 epoch:2/10\n","full seq: As though in response to the AKP's bid for dominance, the political map is going through some major realignments.Ģġġġġġġġ\n","pref seq: As though in response to the AKP's bid for dominance, the \n","next tok:                                                          p\n","pred tok:                                                          w\n","Completed batch.\n","epoch:2/10 batch:222/7698 batch_size:250 loss:1.1103466749191284 time_for_batch_instance:131.84426164627075 total_batch_time:20756.061229467392 running_batch_average:93.49577130390718\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 654048 KiB |  10599 MiB |    788 TiB |    788 TiB |\n","|       from large pool | 196598 KiB |  10146 MiB |    786 TiB |    786 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 654048 KiB |  10599 MiB |    788 TiB |    788 TiB |\n","|       from large pool | 196598 KiB |  10146 MiB |    786 TiB |    786 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  10555 MiB |    786 TiB |    786 TiB |\n","|       from large pool | 189056 KiB |  10107 MiB |    784 TiB |    784 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2022 MiB |  11166 MiB | 167501 GiB | 167499 GiB |\n","|       from large pool |   1568 MiB |  10700 MiB | 167222 GiB | 167220 GiB |\n","|       from small pool |    454 MiB |    488 MiB |    279 GiB |    278 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1383 MiB |   1914 MiB | 285017 GiB | 285016 GiB |\n","|       from large pool |   1376 MiB |   1908 MiB | 282946 GiB | 282945 GiB |\n","|       from small pool |      7 MiB |     23 MiB |   2071 GiB |   2071 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   25328 K  |   25312 K  |\n","|       from large pool |      98    |     248    |   15190 K  |   15190 K  |\n","|       from small pool |   16251    |   16398    |   10138 K  |   10122 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   25328 K  |   25312 K  |\n","|       from large pool |      98    |     248    |   15190 K  |   15190 K  |\n","|       from small pool |   16251    |   16398    |   10138 K  |   10122 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     245    |     331    |    1437 K  |    1437 K  |\n","|       from large pool |      18    |      98    |    1294 K  |    1294 K  |\n","|       from small pool |     227    |     244    |     142 K  |     142 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      82    |     155    |   12712 K  |   12712 K  |\n","|       from large pool |      20    |      65    |    8717 K  |    8717 K  |\n","|       from small pool |      62    |     107    |    3994 K  |    3994 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:223/7698 batch_size:250\n","Next token prediction. step:68/121 batch:223/7698 epoch:2/10\n","full seq: The leaders of Serbia, Croatia and Bosnia and Herzegovina backed each other's Euro-Atlantic integration.Ģġġġġġġġġġġġġġġġġ\n","pref seq: The leaders of Serbia, Croatia and Bosnia and Herzegovina backed eac\n","next tok:                                                                    h\n","pred tok:                                                                    w\n","Completed batch.\n","epoch:2/10 batch:223/7698 batch_size:250 loss:1.1067277193069458 time_for_batch_instance:134.32392191886902 total_batch_time:20890.38515138626 running_batch_average:93.6788571811043\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 650734 KiB |  10644 MiB |    792 TiB |    792 TiB |\n","|       from large pool | 193284 KiB |  10192 MiB |    790 TiB |    790 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 650734 KiB |  10644 MiB |    792 TiB |    792 TiB |\n","|       from large pool | 193284 KiB |  10192 MiB |    790 TiB |    790 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  10613 MiB |    790 TiB |    790 TiB |\n","|       from large pool | 189056 KiB |  10165 MiB |    788 TiB |    788 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1744 MiB |  11220 MiB | 168507 GiB | 168506 GiB |\n","|       from large pool |   1290 MiB |  10754 MiB | 168227 GiB | 168225 GiB |\n","|       from small pool |    454 MiB |    488 MiB |    280 GiB |    280 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1108 MiB |   1582 MiB | 286278 GiB | 286276 GiB |\n","|       from large pool |   1101 MiB |   1576 MiB | 284191 GiB | 284190 GiB |\n","|       from small pool |      7 MiB |     19 MiB |   2086 GiB |   2086 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   25484 K  |   25468 K  |\n","|       from large pool |      98    |     248    |   15281 K  |   15281 K  |\n","|       from small pool |   16251    |   16398    |   10203 K  |   10187 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   25484 K  |   25468 K  |\n","|       from large pool |      98    |     248    |   15281 K  |   15281 K  |\n","|       from small pool |   16251    |   16398    |   10203 K  |   10187 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     244    |     332    |    1447 K  |    1446 K  |\n","|       from large pool |      17    |      99    |    1303 K  |    1303 K  |\n","|       from small pool |     227    |     244    |     143 K  |     143 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      86    |     163    |   12776 K  |   12776 K  |\n","|       from large pool |      22    |      73    |    8756 K  |    8756 K  |\n","|       from small pool |      64    |     107    |    4019 K  |    4019 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:224/7698 batch_size:250\n","Next token prediction. step:73/121 batch:224/7698 epoch:2/10\n","full seq: The group recommended a series of steps that should be taken to prevent the destabilisation of the Presevo Valley.Ģġġġġġġ\n","pref seq: The group recommended a series of steps that should be taken to prevent t\n","next tok:                                                                         h\n","pred tok:                                                                         b\n","Completed batch.\n","epoch:2/10 batch:224/7698 batch_size:250 loss:0.9432928562164307 time_for_batch_instance:127.45741772651672 total_batch_time:21017.842569112778 running_batch_average:93.82965432639632\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 653904 KiB |  10599 MiB |    796 TiB |    796 TiB |\n","|       from large pool | 196454 KiB |  10146 MiB |    794 TiB |    794 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 653904 KiB |  10599 MiB |    796 TiB |    796 TiB |\n","|       from large pool | 196454 KiB |  10146 MiB |    794 TiB |    794 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  10555 MiB |    794 TiB |    794 TiB |\n","|       from large pool | 189056 KiB |  10107 MiB |    792 TiB |    792 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2152 MiB |  11166 MiB | 169507 GiB | 169505 GiB |\n","|       from large pool |   1698 MiB |  10700 MiB | 169225 GiB | 169223 GiB |\n","|       from small pool |    454 MiB |    488 MiB |    282 GiB |    281 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1513 MiB |   1914 MiB | 287526 GiB | 287524 GiB |\n","|       from large pool |   1506 MiB |   1908 MiB | 285424 GiB | 285423 GiB |\n","|       from small pool |      7 MiB |     23 MiB |   2101 GiB |   2101 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   25641 K  |   25624 K  |\n","|       from large pool |      98    |     248    |   15372 K  |   15372 K  |\n","|       from small pool |   16251    |   16398    |   10268 K  |   10252 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   25641 K  |   25624 K  |\n","|       from large pool |      98    |     248    |   15372 K  |   15372 K  |\n","|       from small pool |   16251    |   16398    |   10268 K  |   10252 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     245    |     333    |    1456 K  |    1456 K  |\n","|       from large pool |      18    |     100    |    1312 K  |    1312 K  |\n","|       from small pool |     227    |     244    |     144 K  |     144 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      83    |     155    |   12838 K  |   12838 K  |\n","|       from large pool |      21    |      65    |    8794 K  |    8794 K  |\n","|       from small pool |      62    |     107    |    4044 K  |    4044 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:225/7698 batch_size:250\n","Next token prediction. step:25/121 batch:225/7698 epoch:2/10\n","full seq: Croatia's first major championship game as an independent team was in 1996, at the European Championship in England.Ģġġġġ\n","pref seq: Croatia's first major cha\n","next tok:                         m\n","pred tok:                         w\n","Completed batch.\n","epoch:2/10 batch:225/7698 batch_size:250 loss:0.8564395308494568 time_for_batch_instance:128.177668094635 total_batch_time:21146.020237207413 running_batch_average:93.98231216536628\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 655945 KiB |  10598 MiB |    800 TiB |    800 TiB |\n","|       from large pool | 198495 KiB |  10146 MiB |    798 TiB |    798 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 655945 KiB |  10598 MiB |    800 TiB |    800 TiB |\n","|       from large pool | 198495 KiB |  10146 MiB |    798 TiB |    798 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  10555 MiB |    798 TiB |    798 TiB |\n","|       from large pool | 189056 KiB |  10107 MiB |    796 TiB |    796 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2490 MiB |  11174 MiB | 170467 GiB | 170464 GiB |\n","|       from large pool |   2036 MiB |  10708 MiB | 170183 GiB | 170181 GiB |\n","|       from small pool |    454 MiB |    488 MiB |    283 GiB |    283 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1849 MiB |   1876 MiB | 288845 GiB | 288844 GiB |\n","|       from large pool |   1842 MiB |   1870 MiB | 286729 GiB | 286727 GiB |\n","|       from small pool |      7 MiB |     19 MiB |   2116 GiB |   2116 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   25797 K  |   25781 K  |\n","|       from large pool |      98    |     248    |   15463 K  |   15463 K  |\n","|       from small pool |   16251    |   16398    |   10334 K  |   10317 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   25797 K  |   25781 K  |\n","|       from large pool |      98    |     248    |   15463 K  |   15463 K  |\n","|       from small pool |   16251    |   16398    |   10334 K  |   10317 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     247    |     330    |    1465 K  |    1465 K  |\n","|       from large pool |      20    |      97    |    1320 K  |    1320 K  |\n","|       from small pool |     227    |     244    |     145 K  |     145 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      84    |     155    |   12901 K  |   12901 K  |\n","|       from large pool |      22    |      65    |    8832 K  |    8832 K  |\n","|       from small pool |      62    |     107    |    4069 K  |    4069 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:226/7698 batch_size:250\n","Next token prediction. step:85/121 batch:226/7698 epoch:2/10\n","full seq: For these people, the manipulation and exploitation of financial markets and systems is a profession and a business.Ģġġġġ\n","pref seq: For these people, the manipulation and exploitation of financial markets and systems \n","next tok:                                                                                     i\n","pred tok:                                                                                     ;\n","Completed batch.\n","epoch:2/10 batch:226/7698 batch_size:250 loss:1.2083978652954102 time_for_batch_instance:128.18761706352234 total_batch_time:21274.207854270935 running_batch_average:94.13366307199529\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 653904 KiB |  10599 MiB |    804 TiB |    804 TiB |\n","|       from large pool | 196454 KiB |  10146 MiB |    803 TiB |    803 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 653904 KiB |  10599 MiB |    804 TiB |    804 TiB |\n","|       from large pool | 196454 KiB |  10146 MiB |    803 TiB |    803 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  10555 MiB |    802 TiB |    802 TiB |\n","|       from large pool | 189056 KiB |  10107 MiB |    801 TiB |    801 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1974 MiB |  11174 MiB | 171440 GiB | 171438 GiB |\n","|       from large pool |   1520 MiB |  10708 MiB | 171154 GiB | 171153 GiB |\n","|       from small pool |    454 MiB |    488 MiB |    285 GiB |    285 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1335 MiB |   1903 MiB | 290133 GiB | 290131 GiB |\n","|       from large pool |   1328 MiB |   1896 MiB | 288001 GiB | 287999 GiB |\n","|       from small pool |      7 MiB |     23 MiB |   2132 GiB |   2132 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   25953 K  |   25937 K  |\n","|       from large pool |      98    |     248    |   15554 K  |   15554 K  |\n","|       from small pool |   16251    |   16398    |   10399 K  |   10383 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   25953 K  |   25937 K  |\n","|       from large pool |      98    |     248    |   15554 K  |   15554 K  |\n","|       from small pool |   16251    |   16398    |   10399 K  |   10383 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     245    |     332    |    1475 K  |    1474 K  |\n","|       from large pool |      18    |      99    |    1329 K  |    1328 K  |\n","|       from small pool |     227    |     244    |     146 K  |     145 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      83    |     156    |   12963 K  |   12963 K  |\n","|       from large pool |      21    |      66    |    8869 K  |    8869 K  |\n","|       from small pool |      62    |     107    |    4093 K  |    4093 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:227/7698 batch_size:250\n","Next token prediction. step:93/120 batch:227/7698 epoch:2/10\n","full seq: It suggested a new government arrangement with the IMF similar to the ones negotiated with Serbia and Turkey.Ģġġġġġġġġġġ\n","pref seq: It suggested a new government arrangement with the IMF similar to the ones negotiated with Se\n","next tok:                                                                                             r\n","pred tok:                                                                                             b\n","Completed batch.\n","epoch:2/10 batch:227/7698 batch_size:250 loss:0.895913302898407 time_for_batch_instance:126.9419596195221 total_batch_time:21401.149813890457 running_batch_average:94.2781930127333\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 653411 KiB |  10497 MiB |    809 TiB |    809 TiB |\n","|       from large pool | 195961 KiB |  10045 MiB |    807 TiB |    807 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 653411 KiB |  10497 MiB |    809 TiB |    809 TiB |\n","|       from large pool | 195961 KiB |  10045 MiB |    807 TiB |    807 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  10473 MiB |    807 TiB |    807 TiB |\n","|       from large pool | 189056 KiB |  10024 MiB |    805 TiB |    805 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   3092 MiB |  11100 MiB | 172350 GiB | 172347 GiB |\n","|       from large pool |   2640 MiB |  10634 MiB | 172063 GiB | 172060 GiB |\n","|       from small pool |    452 MiB |    486 MiB |    287 GiB |    286 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   2453 MiB |   2561 MiB | 291483 GiB | 291481 GiB |\n","|       from large pool |   2448 MiB |   2553 MiB | 289336 GiB | 289333 GiB |\n","|       from small pool |      5 MiB |     19 MiB |   2147 GiB |   2147 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   26108 K  |   26092 K  |\n","|       from large pool |      98    |     248    |   15644 K  |   15644 K  |\n","|       from small pool |   16251    |   16398    |   10464 K  |   10447 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   26108 K  |   26092 K  |\n","|       from large pool |      98    |     248    |   15644 K  |   15644 K  |\n","|       from small pool |   16251    |   16398    |   10464 K  |   10447 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     248    |     330    |    1484 K  |    1483 K  |\n","|       from large pool |      22    |      97    |    1337 K  |    1337 K  |\n","|       from small pool |     226    |     243    |     146 K  |     146 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      92    |     149    |   13026 K  |   13026 K  |\n","|       from large pool |      24    |      59    |    8907 K  |    8907 K  |\n","|       from small pool |      68    |     108    |    4118 K  |    4118 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:228/7698 batch_size:250\n","Next token prediction. step:75/120 batch:228/7698 epoch:2/10\n","full seq: Theatre groups from Belgium, Greece and the United States have already confirmed their participation.Ģġġġġġġġġġġġġġġġġġġ\n","pref seq: Theatre groups from Belgium, Greece and the United States have already conf\n","next tok:                                                                           i\n","pred tok:                                                                           w\n","Completed batch.\n","epoch:2/10 batch:228/7698 batch_size:250 loss:1.0119301080703735 time_for_batch_instance:127.62665510177612 total_batch_time:21528.776468992233 running_batch_average:94.42445819733436\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 654055 KiB |  10496 MiB |    813 TiB |    813 TiB |\n","|       from large pool | 196605 KiB |  10044 MiB |    811 TiB |    811 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 654055 KiB |  10496 MiB |    813 TiB |    813 TiB |\n","|       from large pool | 196605 KiB |  10044 MiB |    811 TiB |    811 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  10473 MiB |    811 TiB |    811 TiB |\n","|       from large pool | 189056 KiB |  10024 MiB |    809 TiB |    809 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   3184 MiB |  11086 MiB | 173254 GiB | 173251 GiB |\n","|       from large pool |   2732 MiB |  10620 MiB | 172966 GiB | 172963 GiB |\n","|       from small pool |    452 MiB |    486 MiB |    288 GiB |    288 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   2545 MiB |   2722 MiB | 292785 GiB | 292783 GiB |\n","|       from large pool |   2540 MiB |   2716 MiB | 290623 GiB | 290621 GiB |\n","|       from small pool |      5 MiB |     19 MiB |   2162 GiB |   2162 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   26263 K  |   26247 K  |\n","|       from large pool |      98    |     248    |   15734 K  |   15734 K  |\n","|       from small pool |   16251    |   16398    |   10528 K  |   10512 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   26263 K  |   26247 K  |\n","|       from large pool |      98    |     248    |   15734 K  |   15734 K  |\n","|       from small pool |   16251    |   16398    |   10528 K  |   10512 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     248    |     330    |    1492 K  |    1492 K  |\n","|       from large pool |      22    |      97    |    1345 K  |    1345 K  |\n","|       from small pool |     226    |     243    |     147 K  |     147 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      90    |     145    |   13087 K  |   13087 K  |\n","|       from large pool |      22    |      55    |    8943 K  |    8943 K  |\n","|       from small pool |      68    |     108    |    4143 K  |    4143 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:229/7698 batch_size:250\n","Next token prediction. step:77/120 batch:229/7698 epoch:2/10\n","full seq: The project will aim to increase corruption awareness and establish a regional anti-corruption network.Ģġġġġġġġġġġġġġġġġ\n","pref seq: The project will aim to increase corruption awareness and establish a regiona\n","next tok:                                                                             l\n","pred tok:                                                                             w\n","Completed batch.\n","epoch:2/10 batch:229/7698 batch_size:250 loss:2.7465875148773193 time_for_batch_instance:126.47216558456421 total_batch_time:21655.248634576797 running_batch_average:94.56440451780261\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 653461 KiB |  10497 MiB |    817 TiB |    817 TiB |\n","|       from large pool | 196011 KiB |  10045 MiB |    815 TiB |    815 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 653461 KiB |  10497 MiB |    817 TiB |    817 TiB |\n","|       from large pool | 196011 KiB |  10045 MiB |    815 TiB |    815 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  10473 MiB |    815 TiB |    815 TiB |\n","|       from large pool | 189056 KiB |  10024 MiB |    813 TiB |    813 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   3148 MiB |  11086 MiB | 174135 GiB | 174132 GiB |\n","|       from large pool |   2696 MiB |  10620 MiB | 173845 GiB | 173842 GiB |\n","|       from small pool |    452 MiB |    486 MiB |    290 GiB |    289 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   2509 MiB |   2686 MiB | 294139 GiB | 294136 GiB |\n","|       from large pool |   2504 MiB |   2681 MiB | 291962 GiB | 291959 GiB |\n","|       from small pool |      5 MiB |     19 MiB |   2177 GiB |   2177 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   26418 K  |   26402 K  |\n","|       from large pool |      98    |     248    |   15825 K  |   15824 K  |\n","|       from small pool |   16251    |   16398    |   10593 K  |   10577 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   26418 K  |   26402 K  |\n","|       from large pool |      98    |     248    |   15825 K  |   15824 K  |\n","|       from small pool |   16251    |   16398    |   10593 K  |   10577 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     248    |     327    |    1501 K  |    1501 K  |\n","|       from large pool |      22    |      94    |    1352 K  |    1352 K  |\n","|       from small pool |     226    |     243    |     148 K  |     148 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      91    |     146    |   13148 K  |   13148 K  |\n","|       from large pool |      23    |      56    |    8980 K  |    8980 K  |\n","|       from small pool |      68    |     108    |    4168 K  |    4168 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:230/7698 batch_size:250\n","Next token prediction. step:71/120 batch:230/7698 epoch:2/10\n","full seq: The board of directors at the European Investment Bank (EIB) approved a 150m euro credit to Toyota Otomotiv Sanayi.Ģġġġġ\n","pref seq: The board of directors at the European Investment Bank (EIB) approved a\n","next tok:                                                                        \n","pred tok:                                                                       w\n","Completed batch.\n","epoch:2/10 batch:230/7698 batch_size:250 loss:1.9152470827102661 time_for_batch_instance:127.8839819431305 total_batch_time:21783.132616519928 running_batch_average:94.70927224573882\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 653021 KiB |  10558 MiB |    821 TiB |    821 TiB |\n","|       from large pool | 195571 KiB |  10106 MiB |    819 TiB |    819 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 653021 KiB |  10558 MiB |    821 TiB |    821 TiB |\n","|       from large pool | 195571 KiB |  10106 MiB |    819 TiB |    819 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  10531 MiB |    819 TiB |    819 TiB |\n","|       from large pool | 189056 KiB |  10082 MiB |    817 TiB |    817 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2494 MiB |  11166 MiB | 175127 GiB | 175125 GiB |\n","|       from large pool |   2042 MiB |  10700 MiB | 174836 GiB | 174834 GiB |\n","|       from small pool |    452 MiB |    488 MiB |    291 GiB |    291 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1856 MiB |   2531 MiB | 295374 GiB | 295372 GiB |\n","|       from large pool |   1851 MiB |   2520 MiB | 293182 GiB | 293180 GiB |\n","|       from small pool |      5 MiB |     19 MiB |   2192 GiB |   2192 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   26573 K  |   26557 K  |\n","|       from large pool |      98    |     248    |   15915 K  |   15915 K  |\n","|       from small pool |   16251    |   16398    |   10658 K  |   10641 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   26573 K  |   26557 K  |\n","|       from large pool |      98    |     248    |   15915 K  |   15915 K  |\n","|       from small pool |   16251    |   16398    |   10658 K  |   10641 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     245    |     331    |    1510 K  |    1510 K  |\n","|       from large pool |      19    |      98    |    1361 K  |    1361 K  |\n","|       from small pool |     226    |     244    |     149 K  |     149 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      81    |     155    |   13210 K  |   13210 K  |\n","|       from large pool |      20    |      65    |    9017 K  |    9017 K  |\n","|       from small pool |      61    |     107    |    4192 K  |    4192 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:231/7698 batch_size:250\n","Next token prediction. step:14/120 batch:231/7698 epoch:2/10\n","full seq: But in September the deal was suspended, with Delta claiming that authorities in Zagreb were putting up roadblocks.Ģġġġġ\n","pref seq: But in Septemb\n","next tok:              e\n","pred tok:              x\n","Completed batch.\n","epoch:2/10 batch:231/7698 batch_size:250 loss:1.6838046312332153 time_for_batch_instance:127.74359965324402 total_batch_time:21910.876216173172 running_batch_average:94.85227799209166\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 654613 KiB |  10496 MiB |    825 TiB |    825 TiB |\n","|       from large pool | 197163 KiB |  10044 MiB |    823 TiB |    823 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 654613 KiB |  10496 MiB |    825 TiB |    825 TiB |\n","|       from large pool | 197163 KiB |  10044 MiB |    823 TiB |    823 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  10473 MiB |    823 TiB |    823 TiB |\n","|       from large pool | 189056 KiB |  10024 MiB |    821 TiB |    821 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   3172 MiB |  11094 MiB | 176076 GiB | 176073 GiB |\n","|       from large pool |   2720 MiB |  10628 MiB | 175783 GiB | 175781 GiB |\n","|       from small pool |    452 MiB |    486 MiB |    293 GiB |    292 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   2532 MiB |   2709 MiB | 296665 GiB | 296662 GiB |\n","|       from large pool |   2527 MiB |   2704 MiB | 294458 GiB | 294455 GiB |\n","|       from small pool |      5 MiB |     19 MiB |   2207 GiB |   2207 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   26728 K  |   26711 K  |\n","|       from large pool |      98    |     248    |   16005 K  |   16005 K  |\n","|       from small pool |   16251    |   16398    |   10722 K  |   10706 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   26728 K  |   26711 K  |\n","|       from large pool |      98    |     248    |   16005 K  |   16005 K  |\n","|       from small pool |   16251    |   16398    |   10722 K  |   10706 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     247    |     330    |    1520 K  |    1519 K  |\n","|       from large pool |      21    |      97    |    1369 K  |    1369 K  |\n","|       from small pool |     226    |     243    |     150 K  |     149 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      88    |     146    |   13271 K  |   13271 K  |\n","|       from large pool |      20    |      56    |    9054 K  |    9054 K  |\n","|       from small pool |      68    |     108    |    4217 K  |    4217 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:232/7698 batch_size:250\n","Next token prediction. step:104/119 batch:232/7698 epoch:2/10\n","full seq: In a culmination of the political crisis in Kosovo, parliament voted to disband itself on Tuesday (November 2nd).Ģġġġġġ\n","pref seq: In a culmination of the political crisis in Kosovo, parliament voted to disband itself on Tuesday (Novem\n","next tok:                                                                                                        b\n","pred tok:                                                                                                        Ģ\n","Completed batch.\n","epoch:2/10 batch:232/7698 batch_size:250 loss:0.9582092761993408 time_for_batch_instance:125.32560348510742 total_batch_time:22036.20181965828 running_batch_average:94.98362853300982\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 654050 KiB |  10344 MiB |    829 TiB |    829 TiB |\n","|       from large pool | 196600 KiB |   9892 MiB |    827 TiB |    827 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 654050 KiB |  10344 MiB |    829 TiB |    829 TiB |\n","|       from large pool | 196600 KiB |   9892 MiB |    827 TiB |    827 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  10332 MiB |    827 TiB |    827 TiB |\n","|       from large pool | 189056 KiB |   9883 MiB |    825 TiB |    825 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   4508 MiB |  10972 MiB | 176677 GiB | 176672 GiB |\n","|       from large pool |   4056 MiB |  10506 MiB | 176382 GiB | 176378 GiB |\n","|       from small pool |    452 MiB |    486 MiB |    294 GiB |    294 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   3869 MiB |   4142 MiB | 298843 GiB | 298839 GiB |\n","|       from large pool |   3864 MiB |   4135 MiB | 296621 GiB | 296617 GiB |\n","|       from small pool |      5 MiB |     21 MiB |   2222 GiB |   2222 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   26881 K  |   26865 K  |\n","|       from large pool |      98    |     248    |   16094 K  |   16094 K  |\n","|       from small pool |   16251    |   16398    |   10787 K  |   10770 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   26881 K  |   26865 K  |\n","|       from large pool |      98    |     248    |   16094 K  |   16094 K  |\n","|       from small pool |   16251    |   16398    |   10787 K  |   10770 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     252    |     326    |    1527 K  |    1526 K  |\n","|       from large pool |      26    |      92    |    1376 K  |    1376 K  |\n","|       from small pool |     226    |     243    |     150 K  |     150 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      88    |     177    |   13355 K  |   13355 K  |\n","|       from large pool |      25    |      87    |    9113 K  |    9113 K  |\n","|       from small pool |      63    |     108    |    4242 K  |    4242 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:233/7698 batch_size:250\n","Next token prediction. step:9/119 batch:233/7698 epoch:2/10\n","full seq: \"Gajovic was fifth at the World Championship. He is 35 and he will be one of the older athletes at this Olympics.Ģġġġġġ\n","pref seq: \"Gajovic \n","next tok:         w\n","pred tok:         ;\n","Completed batch.\n","epoch:2/10 batch:233/7698 batch_size:250 loss:0.8967028856277466 time_for_batch_instance:126.43889164924622 total_batch_time:22162.640711307526 running_batch_average:95.11862966226406\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 650946 KiB |  10418 MiB |    833 TiB |    833 TiB |\n","|       from large pool | 193496 KiB |   9966 MiB |    831 TiB |    831 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 650946 KiB |  10418 MiB |    833 TiB |    833 TiB |\n","|       from large pool | 193496 KiB |   9966 MiB |    831 TiB |    831 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  10390 MiB |    831 TiB |    831 TiB |\n","|       from large pool | 189056 KiB |   9941 MiB |    829 TiB |    829 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1564 MiB |  11018 MiB | 177596 GiB | 177594 GiB |\n","|       from large pool |   1112 MiB |  10552 MiB | 177300 GiB | 177299 GiB |\n","|       from small pool |    452 MiB |    486 MiB |    296 GiB |    295 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |    928 MiB |   3881 MiB | 300135 GiB | 300134 GiB |\n","|       from large pool |    923 MiB |   3873 MiB | 297898 GiB | 297897 GiB |\n","|       from small pool |      5 MiB |     23 MiB |   2237 GiB |   2237 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   27035 K  |   27019 K  |\n","|       from large pool |      98    |     248    |   16184 K  |   16184 K  |\n","|       from small pool |   16251    |   16398    |   10851 K  |   10834 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   27035 K  |   27019 K  |\n","|       from large pool |      98    |     248    |   16184 K  |   16184 K  |\n","|       from small pool |   16251    |   16398    |   10851 K  |   10834 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     246    |     336    |    1536 K  |    1535 K  |\n","|       from large pool |      20    |     102    |    1384 K  |    1384 K  |\n","|       from small pool |     226    |     243    |     151 K  |     151 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      85    |     151    |   13419 K  |   13418 K  |\n","|       from large pool |      21    |      61    |    9152 K  |    9152 K  |\n","|       from small pool |      64    |     108    |    4266 K  |    4266 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:234/7698 batch_size:250\n","Next token prediction. step:25/119 batch:234/7698 epoch:2/10\n","full seq: The experts are reportedly due to attend a meeting in Brussels on 2 December to present the results of the review.Ģġġġġ\n","pref seq: The experts are reportedl\n","next tok:                         y\n","pred tok:                         w\n","Completed batch.\n","epoch:2/10 batch:234/7698 batch_size:250 loss:1.670814037322998 time_for_batch_instance:126.22412180900574 total_batch_time:22288.86483311653 running_batch_average:95.25155911588261\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 650373 KiB |  10420 MiB |    837 TiB |    837 TiB |\n","|       from large pool | 192923 KiB |   9968 MiB |    835 TiB |    835 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 650373 KiB |  10420 MiB |    837 TiB |    837 TiB |\n","|       from large pool | 192923 KiB |   9968 MiB |    835 TiB |    835 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  10390 MiB |    835 TiB |    835 TiB |\n","|       from large pool | 189056 KiB |   9941 MiB |    833 TiB |    833 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1624 MiB |  11008 MiB | 178510 GiB | 178508 GiB |\n","|       from large pool |   1172 MiB |  10542 MiB | 178212 GiB | 178211 GiB |\n","|       from small pool |    452 MiB |    486 MiB |    297 GiB |    297 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |    988 MiB |   1675 MiB | 301426 GiB | 301425 GiB |\n","|       from large pool |    983 MiB |   1666 MiB | 299174 GiB | 299173 GiB |\n","|       from small pool |      5 MiB |     18 MiB |   2252 GiB |   2252 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   27189 K  |   27172 K  |\n","|       from large pool |      98    |     248    |   16273 K  |   16273 K  |\n","|       from small pool |   16251    |   16398    |   10915 K  |   10899 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   27189 K  |   27172 K  |\n","|       from large pool |      98    |     248    |   16273 K  |   16273 K  |\n","|       from small pool |   16251    |   16398    |   10915 K  |   10899 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     247    |     336    |    1545 K  |    1545 K  |\n","|       from large pool |      21    |     103    |    1392 K  |    1392 K  |\n","|       from small pool |     226    |     243    |     152 K  |     152 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      86    |     150    |   13482 K  |   13482 K  |\n","|       from large pool |      22    |      60    |    9191 K  |    9191 K  |\n","|       from small pool |      64    |     108    |    4291 K  |    4291 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:235/7698 batch_size:250\n","Next token prediction. step:81/118 batch:235/7698 epoch:2/10\n","full seq: The ghettoisation of the city, which began some 15 years ago, is now becoming all the more outward.Ģġġġġġġġġġġġġġġġġġġ\n","pref seq: The ghettoisation of the city, which began some 15 years ago, is now becoming all\n","next tok:                                                                                  \n","pred tok:                                                                                 x\n","Completed batch.\n","epoch:2/10 batch:235/7698 batch_size:250 loss:2.0690011978149414 time_for_batch_instance:123.9396824836731 total_batch_time:22412.804515600204 running_batch_average:95.37363623659661\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 653661 KiB |  10316 MiB |    841 TiB |    841 TiB |\n","|       from large pool | 196211 KiB |   9863 MiB |    839 TiB |    839 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 653661 KiB |  10316 MiB |    841 TiB |    841 TiB |\n","|       from large pool | 196211 KiB |   9863 MiB |    839 TiB |    839 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  10307 MiB |    839 TiB |    839 TiB |\n","|       from large pool | 189056 KiB |   9859 MiB |    837 TiB |    837 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   4304 MiB |  10966 MiB | 179103 GiB | 179099 GiB |\n","|       from large pool |   3852 MiB |  10500 MiB | 178803 GiB | 178800 GiB |\n","|       from small pool |    452 MiB |    486 MiB |    299 GiB |    298 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   3665 MiB |   4245 MiB | 303572 GiB | 303569 GiB |\n","|       from large pool |   3660 MiB |   4238 MiB | 301305 GiB | 301302 GiB |\n","|       from small pool |      5 MiB |     21 MiB |   2266 GiB |   2266 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   27341 K  |   27325 K  |\n","|       from large pool |      98    |     248    |   16362 K  |   16362 K  |\n","|       from small pool |   16251    |   16398    |   10978 K  |   10962 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   27341 K  |   27325 K  |\n","|       from large pool |      98    |     248    |   16362 K  |   16362 K  |\n","|       from small pool |   16251    |   16398    |   10978 K  |   10962 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     251    |     325    |    1552 K  |    1551 K  |\n","|       from large pool |      25    |      92    |    1398 K  |    1398 K  |\n","|       from small pool |     226    |     243    |     153 K  |     153 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      86    |     176    |   13566 K  |   13566 K  |\n","|       from large pool |      24    |      86    |    9250 K  |    9250 K  |\n","|       from small pool |      62    |     108    |    4315 K  |    4315 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:236/7698 batch_size:250\n","Next token prediction. step:79/118 batch:236/7698 epoch:2/10\n","full seq: The SDP wants a greater degree of state interventionism, arguing that standards of living must be protected.Ģġġġġġġġġġ\n","pref seq: The SDP wants a greater degree of state interventionism, arguing that standards\n","next tok:                                                                                \n","pred tok:                                                                               w\n","Completed batch.\n","epoch:2/10 batch:236/7698 batch_size:250 loss:0.890881359577179 time_for_batch_instance:123.61829447746277 total_batch_time:22536.422810077667 running_batch_average:95.49331699185453\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 653661 KiB |  10315 MiB |    845 TiB |    845 TiB |\n","|       from large pool | 196211 KiB |   9863 MiB |    843 TiB |    843 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 653661 KiB |  10315 MiB |    845 TiB |    845 TiB |\n","|       from large pool | 196211 KiB |   9863 MiB |    843 TiB |    843 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  10307 MiB |    843 TiB |    843 TiB |\n","|       from large pool | 189056 KiB |   9859 MiB |    841 TiB |    841 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   4304 MiB |  10958 MiB | 179694 GiB | 179690 GiB |\n","|       from large pool |   3852 MiB |  10492 MiB | 179393 GiB | 179389 GiB |\n","|       from small pool |    452 MiB |    486 MiB |    300 GiB |    300 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   3665 MiB |   4148 MiB | 305713 GiB | 305709 GiB |\n","|       from large pool |   3660 MiB |   4140 MiB | 303431 GiB | 303427 GiB |\n","|       from small pool |      5 MiB |     21 MiB |   2281 GiB |   2281 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   27493 K  |   27477 K  |\n","|       from large pool |      98    |     248    |   16451 K  |   16451 K  |\n","|       from small pool |   16251    |   16398    |   11042 K  |   11026 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   27493 K  |   27477 K  |\n","|       from large pool |      98    |     248    |   16451 K  |   16451 K  |\n","|       from small pool |   16251    |   16398    |   11042 K  |   11026 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     251    |     324    |    1559 K  |    1558 K  |\n","|       from large pool |      25    |      91    |    1405 K  |    1405 K  |\n","|       from small pool |     226    |     243    |     154 K  |     153 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      86    |     177    |   13649 K  |   13649 K  |\n","|       from large pool |      24    |      87    |    9309 K  |    9309 K  |\n","|       from small pool |      62    |     108    |    4339 K  |    4339 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:237/7698 batch_size:250\n","Next token prediction. step:112/118 batch:237/7698 epoch:2/10\n","full seq: Darko Saric and his group are suspected of smuggling 2.5 tonnes of cocaine from South America. [Getty Images]Ģġġġġġġġġ\n","pref seq: Darko Saric and his group are suspected of smuggling 2.5 tonnes of cocaine from South America. [Getty Images]Ģġġ\n","next tok:                                                                                                                ġ\n","pred tok:                                                                                                                Ģ\n","Completed batch.\n","epoch:2/10 batch:237/7698 batch_size:250 loss:0.8738243579864502 time_for_batch_instance:125.48792052268982 total_batch_time:22661.910730600357 running_batch_average:95.61987650042344\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 651411 KiB |  10388 MiB |    849 TiB |    849 TiB |\n","|       from large pool | 193961 KiB |   9935 MiB |    847 TiB |    847 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 651411 KiB |  10388 MiB |    849 TiB |    849 TiB |\n","|       from large pool | 193961 KiB |   9935 MiB |    847 TiB |    847 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  10365 MiB |    847 TiB |    847 TiB |\n","|       from large pool | 189056 KiB |   9917 MiB |    845 TiB |    845 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2072 MiB |  10998 MiB | 180604 GiB | 180602 GiB |\n","|       from large pool |   1620 MiB |  10532 MiB | 180302 GiB | 180300 GiB |\n","|       from small pool |    452 MiB |    486 MiB |    302 GiB |    301 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1435 MiB |   3680 MiB | 306982 GiB | 306980 GiB |\n","|       from large pool |   1430 MiB |   3671 MiB | 304685 GiB | 304684 GiB |\n","|       from small pool |      5 MiB |     19 MiB |   2296 GiB |   2296 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   27646 K  |   27629 K  |\n","|       from large pool |      98    |     248    |   16539 K  |   16539 K  |\n","|       from small pool |   16251    |   16398    |   11106 K  |   11089 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   27646 K  |   27629 K  |\n","|       from large pool |      98    |     248    |   16539 K  |   16539 K  |\n","|       from small pool |   16251    |   16398    |   11106 K  |   11089 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     248    |     335    |    1568 K  |    1567 K  |\n","|       from large pool |      22    |     102    |    1413 K  |    1413 K  |\n","|       from small pool |     226    |     243    |     154 K  |     154 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      89    |     151    |   13712 K  |   13711 K  |\n","|       from large pool |      25    |      61    |    9348 K  |    9348 K  |\n","|       from small pool |      64    |     108    |    4363 K  |    4363 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:238/7698 batch_size:250\n","Next token prediction. step:30/118 batch:238/7698 epoch:2/10\n","full seq: Montenegrin Army soldiers hold an anti-terrorism drill at an army base in Danilovgrad on December 7th.Ģġġġġġġġġġġġġġġġ\n","pref seq: Montenegrin Army soldiers hold\n","next tok:                               \n","pred tok:                              w\n","Completed batch.\n","epoch:2/10 batch:238/7698 batch_size:250 loss:0.9000562429428101 time_for_batch_instance:123.85966372489929 total_batch_time:22785.770394325256 running_batch_average:95.73853106859352\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 653661 KiB |  10315 MiB |    853 TiB |    853 TiB |\n","|       from large pool | 196211 KiB |   9863 MiB |    851 TiB |    851 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 653661 KiB |  10315 MiB |    853 TiB |    853 TiB |\n","|       from large pool | 196211 KiB |   9863 MiB |    851 TiB |    851 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  10307 MiB |    851 TiB |    851 TiB |\n","|       from large pool | 189056 KiB |   9859 MiB |    849 TiB |    849 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   4304 MiB |  10958 MiB | 181196 GiB | 181192 GiB |\n","|       from large pool |   3852 MiB |  10492 MiB | 180892 GiB | 180888 GiB |\n","|       from small pool |    452 MiB |    486 MiB |    303 GiB |    303 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   3665 MiB |   4270 MiB | 309131 GiB | 309127 GiB |\n","|       from large pool |   3660 MiB |   4264 MiB | 306820 GiB | 306816 GiB |\n","|       from small pool |      5 MiB |     21 MiB |   2311 GiB |   2311 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   27798 K  |   27782 K  |\n","|       from large pool |      98    |     248    |   16628 K  |   16628 K  |\n","|       from small pool |   16251    |   16398    |   11169 K  |   11153 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   27798 K  |   27782 K  |\n","|       from large pool |      98    |     248    |   16628 K  |   16628 K  |\n","|       from small pool |   16251    |   16398    |   11169 K  |   11153 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     251    |     324    |    1575 K  |    1574 K  |\n","|       from large pool |      25    |      91    |    1419 K  |    1419 K  |\n","|       from small pool |     226    |     243    |     155 K  |     155 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      86    |     177    |   13795 K  |   13795 K  |\n","|       from large pool |      24    |      87    |    9407 K  |    9407 K  |\n","|       from small pool |      62    |     108    |    4388 K  |    4388 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:239/7698 batch_size:250\n","Next token prediction. step:104/118 batch:239/7698 epoch:2/10\n","full seq: The court also ordered the seizure of 10,000 euros, several vehicles, a residential building, and land.Ģġġġġġġġġġġġġġġ\n","pref seq: The court also ordered the seizure of 10,000 euros, several vehicles, a residential building, and land.Ģ\n","next tok:                                                                                                        ġ\n","pred tok:                                                                                                        Ģ\n","Completed batch.\n","epoch:2/10 batch:239/7698 batch_size:250 loss:0.8644406199455261 time_for_batch_instance:123.12671756744385 total_batch_time:22908.8971118927 running_batch_average:95.85312599118285\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 653661 KiB |  10315 MiB |    857 TiB |    857 TiB |\n","|       from large pool | 196211 KiB |   9863 MiB |    855 TiB |    855 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 653661 KiB |  10315 MiB |    857 TiB |    857 TiB |\n","|       from large pool | 196211 KiB |   9863 MiB |    855 TiB |    855 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  10307 MiB |    855 TiB |    855 TiB |\n","|       from large pool | 189056 KiB |   9859 MiB |    853 TiB |    853 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   4304 MiB |  10958 MiB | 181787 GiB | 181782 GiB |\n","|       from large pool |   3852 MiB |  10492 MiB | 181481 GiB | 181477 GiB |\n","|       from small pool |    452 MiB |    486 MiB |    305 GiB |    305 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   3665 MiB |   4084 MiB | 311281 GiB | 311278 GiB |\n","|       from large pool |   3660 MiB |   4075 MiB | 308955 GiB | 308952 GiB |\n","|       from small pool |      5 MiB |     19 MiB |   2325 GiB |   2325 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   27950 K  |   27934 K  |\n","|       from large pool |      98    |     248    |   16717 K  |   16717 K  |\n","|       from small pool |   16251    |   16398    |   11233 K  |   11217 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   27950 K  |   27934 K  |\n","|       from large pool |      98    |     248    |   16717 K  |   16717 K  |\n","|       from small pool |   16251    |   16398    |   11233 K  |   11217 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     251    |     324    |    1581 K  |    1581 K  |\n","|       from large pool |      25    |      91    |    1425 K  |    1425 K  |\n","|       from small pool |     226    |     243    |     156 K  |     156 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      86    |     177    |   13878 K  |   13878 K  |\n","|       from large pool |      24    |      87    |    9466 K  |    9466 K  |\n","|       from small pool |      62    |     108    |    4412 K  |    4412 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:240/7698 batch_size:250\n","Next token prediction. step:13/118 batch:240/7698 epoch:2/10\n","full seq: Nihat Ali Ozcan, an expert on security matters, says fueling ethnic separatism is central to the PKK's strategy.Ģġġġġġ\n","pref seq: Nihat Ali Ozc\n","next tok:             a\n","pred tok:             '\n","Completed batch.\n","epoch:2/10 batch:240/7698 batch_size:250 loss:1.4729039669036865 time_for_batch_instance:122.97386717796326 total_batch_time:23031.870979070663 running_batch_average:95.9661290794611\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 653661 KiB |  10315 MiB |    861 TiB |    861 TiB |\n","|       from large pool | 196211 KiB |   9863 MiB |    859 TiB |    859 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 653661 KiB |  10315 MiB |    861 TiB |    861 TiB |\n","|       from large pool | 196211 KiB |   9863 MiB |    859 TiB |    859 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  10307 MiB |    859 TiB |    859 TiB |\n","|       from large pool | 189056 KiB |   9859 MiB |    857 TiB |    857 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   4304 MiB |  10958 MiB | 182377 GiB | 182373 GiB |\n","|       from large pool |   3852 MiB |  10492 MiB | 182070 GiB | 182066 GiB |\n","|       from small pool |    452 MiB |    486 MiB |    306 GiB |    306 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   3665 MiB |   4084 MiB | 313431 GiB | 313427 GiB |\n","|       from large pool |   3660 MiB |   4075 MiB | 311090 GiB | 311087 GiB |\n","|       from small pool |      5 MiB |     19 MiB |   2340 GiB |   2340 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   28102 K  |   28086 K  |\n","|       from large pool |      98    |     248    |   16805 K  |   16805 K  |\n","|       from small pool |   16251    |   16398    |   11297 K  |   11280 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   28102 K  |   28086 K  |\n","|       from large pool |      98    |     248    |   16805 K  |   16805 K  |\n","|       from small pool |   16251    |   16398    |   11297 K  |   11280 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     251    |     328    |    1588 K  |    1588 K  |\n","|       from large pool |      25    |      95    |    1431 K  |    1431 K  |\n","|       from small pool |     226    |     243    |     157 K  |     156 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      86    |     177    |   13962 K  |   13962 K  |\n","|       from large pool |      24    |      87    |    9525 K  |    9525 K  |\n","|       from small pool |      62    |     108    |    4436 K  |    4436 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:241/7698 batch_size:250\n","Next token prediction. step:113/118 batch:241/7698 epoch:2/10\n","full seq: On Tuesday, Meimarakis and BiH counterpart Selmo Cikotic are expected to seal a military co-operation agreement.Ģġġġġġ\n","pref seq: On Tuesday, Meimarakis and BiH counterpart Selmo Cikotic are expected to seal a military co-operation agreement.Ģ\n","next tok:                                                                                                                 ġ\n","pred tok:                                                                                                                 Ģ\n","Completed batch.\n","epoch:2/10 batch:241/7698 batch_size:250 loss:1.1887407302856445 time_for_batch_instance:122.83271646499634 total_batch_time:23154.70369553566 running_batch_average:96.0776086951687\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 653661 KiB |  10315 MiB |    865 TiB |    865 TiB |\n","|       from large pool | 196211 KiB |   9863 MiB |    863 TiB |    863 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 653661 KiB |  10315 MiB |    865 TiB |    865 TiB |\n","|       from large pool | 196211 KiB |   9863 MiB |    863 TiB |    863 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  10307 MiB |    863 TiB |    863 TiB |\n","|       from large pool | 189056 KiB |   9859 MiB |    861 TiB |    861 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   4304 MiB |  10958 MiB | 182966 GiB | 182962 GiB |\n","|       from large pool |   3852 MiB |  10492 MiB | 182658 GiB | 182654 GiB |\n","|       from small pool |    452 MiB |    486 MiB |    308 GiB |    308 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   3665 MiB |   4084 MiB | 315578 GiB | 315574 GiB |\n","|       from large pool |   3660 MiB |   4075 MiB | 313222 GiB | 313219 GiB |\n","|       from small pool |      5 MiB |     19 MiB |   2355 GiB |   2355 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   28255 K  |   28238 K  |\n","|       from large pool |      98    |     248    |   16894 K  |   16894 K  |\n","|       from small pool |   16251    |   16398    |   11360 K  |   11344 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   28255 K  |   28238 K  |\n","|       from large pool |      98    |     248    |   16894 K  |   16894 K  |\n","|       from small pool |   16251    |   16398    |   11360 K  |   11344 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     251    |     328    |    1595 K  |    1595 K  |\n","|       from large pool |      25    |      95    |    1437 K  |    1437 K  |\n","|       from small pool |     226    |     243    |     157 K  |     157 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      86    |     177    |   14046 K  |   14045 K  |\n","|       from large pool |      24    |      87    |    9584 K  |    9584 K  |\n","|       from small pool |      62    |     108    |    4461 K  |    4461 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:242/7698 batch_size:250\n","Next token prediction. step:88/117 batch:242/7698 epoch:2/10\n","full seq: In September, a gang beat Ognyan Stefanov, the editor of the Frog News web site, into a three-day coma.Ģġġġġġġġġġġġġġ\n","pref seq: In September, a gang beat Ognyan Stefanov, the editor of the Frog News web site, into a \n","next tok:                                                                                        t\n","pred tok:                                                                                        ,\n","Completed batch.\n","epoch:2/10 batch:242/7698 batch_size:250 loss:1.2006702423095703 time_for_batch_instance:122.45655035972595 total_batch_time:23277.160245895386 running_batch_average:96.18661258634457\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 652120 KiB |  10235 MiB |    869 TiB |    869 TiB |\n","|       from large pool | 194670 KiB |   9783 MiB |    867 TiB |    867 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 652120 KiB |  10235 MiB |    869 TiB |    869 TiB |\n","|       from large pool | 194670 KiB |   9783 MiB |    867 TiB |    867 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  10224 MiB |    867 TiB |    867 TiB |\n","|       from large pool | 189056 KiB |   9776 MiB |    864 TiB |    864 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   3144 MiB |  10864 MiB | 183699 GiB | 183696 GiB |\n","|       from large pool |   2692 MiB |  10398 MiB | 183389 GiB | 183386 GiB |\n","|       from small pool |    452 MiB |    486 MiB |    309 GiB |    309 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   2507 MiB |   3680 MiB | 316997 GiB | 316994 GiB |\n","|       from large pool |   2501 MiB |   3671 MiB | 314627 GiB | 314624 GiB |\n","|       from small pool |      5 MiB |     19 MiB |   2370 GiB |   2370 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   28406 K  |   28389 K  |\n","|       from large pool |      98    |     248    |   16982 K  |   16982 K  |\n","|       from small pool |   16251    |   16398    |   11423 K  |   11407 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   28406 K  |   28389 K  |\n","|       from large pool |      98    |     248    |   16982 K  |   16982 K  |\n","|       from small pool |   16251    |   16398    |   11423 K  |   11407 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     250    |     329    |    1603 K  |    1603 K  |\n","|       from large pool |      24    |      96    |    1445 K  |    1445 K  |\n","|       from small pool |     226    |     243    |     158 K  |     158 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      84    |     173    |   14124 K  |   14124 K  |\n","|       from large pool |      23    |      83    |    9639 K  |    9639 K  |\n","|       from small pool |      61    |     107    |    4485 K  |    4485 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:243/7698 batch_size:250\n","Next token prediction. step:72/117 batch:243/7698 epoch:2/10\n","full seq: Despite the alarming headlines that depict Greece as paralysed by strikes, the actual situation is more complex.Ģġġġġ\n","pref seq: Despite the alarming headlines that depict Greece as paralysed by strike\n","next tok:                                                                        s\n","pred tok:                                                                        w\n","Completed batch.\n","epoch:2/10 batch:243/7698 batch_size:250 loss:1.5945775508880615 time_for_batch_instance:122.79578518867493 total_batch_time:23399.95603108406 running_batch_average:96.29611535425539\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 651933 KiB |  10235 MiB |    873 TiB |    873 TiB |\n","|       from large pool | 194483 KiB |   9783 MiB |    870 TiB |    870 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 651933 KiB |  10235 MiB |    873 TiB |    873 TiB |\n","|       from large pool | 194483 KiB |   9783 MiB |    870 TiB |    870 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  10224 MiB |    870 TiB |    870 TiB |\n","|       from large pool | 189056 KiB |   9776 MiB |    868 TiB |    868 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2942 MiB |  10864 MiB | 184451 GiB | 184448 GiB |\n","|       from large pool |   2490 MiB |  10398 MiB | 184140 GiB | 184137 GiB |\n","|       from small pool |    452 MiB |    486 MiB |    311 GiB |    311 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   2305 MiB |   2999 MiB | 318328 GiB | 318325 GiB |\n","|       from large pool |   2300 MiB |   2993 MiB | 315943 GiB | 315941 GiB |\n","|       from small pool |      5 MiB |     19 MiB |   2384 GiB |   2384 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   28557 K  |   28540 K  |\n","|       from large pool |      98    |     248    |   17070 K  |   17070 K  |\n","|       from small pool |   16251    |   16398    |   11486 K  |   11470 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   28557 K  |   28540 K  |\n","|       from large pool |      98    |     248    |   17070 K  |   17070 K  |\n","|       from small pool |   16251    |   16398    |   11486 K  |   11470 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     249    |     326    |    1611 K  |    1611 K  |\n","|       from large pool |      23    |      93    |    1452 K  |    1452 K  |\n","|       from small pool |     226    |     243    |     159 K  |     159 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      83    |     173    |   14203 K  |   14203 K  |\n","|       from large pool |      22    |      83    |    9693 K  |    9693 K  |\n","|       from small pool |      61    |     107    |    4509 K  |    4509 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:244/7698 batch_size:250\n","Completed batch.\n","epoch:2/10 batch:244/7698 batch_size:250 loss:1.2447874546051025 time_for_batch_instance:121.4557716846466 total_batch_time:23521.411802768707 running_batch_average:96.39922869987176\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 652815 KiB |  10158 MiB |    876 TiB |    876 TiB |\n","|       from large pool | 195365 KiB |   9706 MiB |    874 TiB |    874 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 652815 KiB |  10158 MiB |    876 TiB |    876 TiB |\n","|       from large pool | 195365 KiB |   9706 MiB |    874 TiB |    874 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  10142 MiB |    874 TiB |    874 TiB |\n","|       from large pool | 189056 KiB |   9693 MiB |    872 TiB |    872 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2896 MiB |  10758 MiB | 185231 GiB | 185229 GiB |\n","|       from large pool |   2444 MiB |  10292 MiB | 184918 GiB | 184916 GiB |\n","|       from small pool |    452 MiB |    486 MiB |    313 GiB |    312 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   2258 MiB |   3138 MiB | 319798 GiB | 319796 GiB |\n","|       from large pool |   2253 MiB |   3130 MiB | 317399 GiB | 317397 GiB |\n","|       from small pool |      5 MiB |     19 MiB |   2399 GiB |   2399 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   28706 K  |   28690 K  |\n","|       from large pool |      98    |     248    |   17157 K  |   17157 K  |\n","|       from small pool |   16251    |   16398    |   11549 K  |   11533 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   28706 K  |   28690 K  |\n","|       from large pool |      98    |     248    |   17157 K  |   17157 K  |\n","|       from small pool |   16251    |   16398    |   11549 K  |   11533 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     247    |     329    |    1620 K  |    1619 K  |\n","|       from large pool |      21    |      96    |    1459 K  |    1459 K  |\n","|       from small pool |     226    |     243    |     160 K  |     160 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      87    |     180    |   14288 K  |   14288 K  |\n","|       from large pool |      28    |      90    |    9755 K  |    9755 K  |\n","|       from small pool |      59    |     107    |    4533 K  |    4533 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:245/7698 batch_size:250\n","Next token prediction. step:52/116 batch:245/7698 epoch:2/10\n","full seq: The summit participants said they want to encourage further positive developments in the region. [Getty Images]Ģġġġġ\n","pref seq: The summit participants said they want to encourage \n","next tok:                                                    f\n","pred tok:                                                    ;\n","Completed batch.\n","epoch:2/10 batch:245/7698 batch_size:250 loss:2.4162607192993164 time_for_batch_instance:121.40092945098877 total_batch_time:23642.812732219696 running_batch_average:96.50127645803957\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 651301 KiB |  10157 MiB |    880 TiB |    880 TiB |\n","|       from large pool | 193851 KiB |   9705 MiB |    878 TiB |    878 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 651301 KiB |  10157 MiB |    880 TiB |    880 TiB |\n","|       from large pool | 193851 KiB |   9705 MiB |    878 TiB |    878 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  10142 MiB |    878 TiB |    878 TiB |\n","|       from large pool | 189056 KiB |   9693 MiB |    876 TiB |    876 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2028 MiB |  10774 MiB | 186002 GiB | 186000 GiB |\n","|       from large pool |   1576 MiB |  10308 MiB | 185688 GiB | 185686 GiB |\n","|       from small pool |    452 MiB |    486 MiB |    314 GiB |    314 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1391 MiB |   2556 MiB | 321270 GiB | 321269 GiB |\n","|       from large pool |   1386 MiB |   2549 MiB | 318857 GiB | 318855 GiB |\n","|       from small pool |      5 MiB |     19 MiB |   2413 GiB |   2413 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   28856 K  |   28840 K  |\n","|       from large pool |      98    |     248    |   17244 K  |   17244 K  |\n","|       from small pool |   16251    |   16398    |   11611 K  |   11595 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   28856 K  |   28840 K  |\n","|       from large pool |      98    |     248    |   17244 K  |   17244 K  |\n","|       from small pool |   16251    |   16398    |   11611 K  |   11595 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     244    |     330    |    1628 K  |    1628 K  |\n","|       from large pool |      18    |      97    |    1467 K  |    1467 K  |\n","|       from small pool |     226    |     243    |     161 K  |     160 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      82    |     184    |   14374 K  |   14374 K  |\n","|       from large pool |      23    |      94    |    9817 K  |    9816 K  |\n","|       from small pool |      59    |     107    |    4557 K  |    4557 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:246/7698 batch_size:250\n","Next token prediction. step:1/115 batch:246/7698 epoch:2/10\n","full seq: Protesters rally in front of the Greek parliament against austerity economic measures. [Reuters]Ģġġġġġġġġġġġġġġġġġġ\n","pref seq: P\n","next tok: r\n","pred tok: ;\n","Completed batch.\n","epoch:2/10 batch:246/7698 batch_size:250 loss:1.1506773233413696 time_for_batch_instance:120.37455916404724 total_batch_time:23763.187291383743 running_batch_average:96.59832232269814\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 652501 KiB |  10133 MiB |    884 TiB |    884 TiB |\n","|       from large pool | 195051 KiB |   9681 MiB |    882 TiB |    882 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 652501 KiB |  10133 MiB |    884 TiB |    884 TiB |\n","|       from large pool | 195051 KiB |   9681 MiB |    882 TiB |    882 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  10117 MiB |    882 TiB |    882 TiB |\n","|       from large pool | 189056 KiB |   9668 MiB |    880 TiB |    880 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2496 MiB |  10744 MiB | 186812 GiB | 186809 GiB |\n","|       from large pool |   2044 MiB |  10278 MiB | 186496 GiB | 186494 GiB |\n","|       from small pool |    452 MiB |    486 MiB |    315 GiB |    315 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1858 MiB |   2694 MiB | 322643 GiB | 322641 GiB |\n","|       from large pool |   1853 MiB |   2685 MiB | 320215 GiB | 320213 GiB |\n","|       from small pool |      5 MiB |     19 MiB |   2428 GiB |   2428 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   29004 K  |   28988 K  |\n","|       from large pool |      98    |     248    |   17330 K  |   17330 K  |\n","|       from small pool |   16251    |   16398    |   11673 K  |   11657 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   29004 K  |   28988 K  |\n","|       from large pool |      98    |     248    |   17330 K  |   17330 K  |\n","|       from small pool |   16251    |   16398    |   11673 K  |   11657 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     245    |     329    |    1636 K  |    1636 K  |\n","|       from large pool |      19    |      96    |    1474 K  |    1474 K  |\n","|       from small pool |     226    |     243    |     161 K  |     161 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      82    |     181    |   14458 K  |   14458 K  |\n","|       from large pool |      25    |      91    |    9877 K  |    9877 K  |\n","|       from small pool |      57    |     107    |    4581 K  |    4581 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:247/7698 batch_size:250\n","Next token prediction. step:79/115 batch:247/7698 epoch:2/10\n","full seq: So is the civic movement MjaftĠ (EnoughĠ), which has been campaigning for action on the electricity issue.Ģġġġġġġġġ\n","pref seq: So is the civic movement MjaftĠ (EnoughĠ), which has been campaigning for actio\n","next tok:                                                                               n\n","pred tok:                                                                               ,\n","Completed batch.\n","epoch:2/10 batch:247/7698 batch_size:250 loss:0.9374374747276306 time_for_batch_instance:121.03691577911377 total_batch_time:23884.224207162857 running_batch_average:96.69726399661076\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 650028 KiB |  10075 MiB |    888 TiB |    888 TiB |\n","|       from large pool | 192578 KiB |   9623 MiB |    886 TiB |    886 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 650028 KiB |  10075 MiB |    888 TiB |    888 TiB |\n","|       from large pool | 192578 KiB |   9623 MiB |    886 TiB |    886 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  10059 MiB |    886 TiB |    886 TiB |\n","|       from large pool | 189056 KiB |   9610 MiB |    883 TiB |    883 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1990 MiB |  10696 MiB | 187623 GiB | 187621 GiB |\n","|       from large pool |   1538 MiB |  10230 MiB | 187305 GiB | 187304 GiB |\n","|       from small pool |    452 MiB |    486 MiB |    317 GiB |    317 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1355 MiB |   1883 MiB | 324076 GiB | 324074 GiB |\n","|       from large pool |   1349 MiB |   1872 MiB | 321633 GiB | 321632 GiB |\n","|       from small pool |      5 MiB |     21 MiB |   2442 GiB |   2442 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   29153 K  |   29136 K  |\n","|       from large pool |      98    |     248    |   17417 K  |   17417 K  |\n","|       from small pool |   16251    |   16398    |   11735 K  |   11719 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   29153 K  |   29136 K  |\n","|       from large pool |      98    |     248    |   17417 K  |   17417 K  |\n","|       from small pool |   16251    |   16398    |   11735 K  |   11719 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     254    |     339    |    1644 K  |    1644 K  |\n","|       from large pool |      28    |     106    |    1482 K  |    1482 K  |\n","|       from small pool |     226    |     243    |     162 K  |     162 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      84    |     192    |   14546 K  |   14546 K  |\n","|       from large pool |      27    |     102    |    9941 K  |    9941 K  |\n","|       from small pool |      57    |     107    |    4604 K  |    4604 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:248/7698 batch_size:250\n","Next token prediction. step:30/115 batch:248/7698 epoch:2/10\n","full seq: Croatia's Blanka Vlasic, 23, won the world high-jump championship title in Osaka on Sunday (September 2nd).Ģġġġġġġġ\n","pref seq: Croatia's Blanka Vlasic, 23, w\n","next tok:                              o\n","pred tok:                              ,\n","Completed batch.\n","epoch:2/10 batch:248/7698 batch_size:250 loss:1.018872618675232 time_for_batch_instance:121.84916996955872 total_batch_time:24006.073377132416 running_batch_average:96.79868297230813\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 650028 KiB |  10075 MiB |    892 TiB |    892 TiB |\n","|       from large pool | 192578 KiB |   9623 MiB |    889 TiB |    889 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 650028 KiB |  10075 MiB |    892 TiB |    892 TiB |\n","|       from large pool | 192578 KiB |   9623 MiB |    889 TiB |    889 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  10059 MiB |    889 TiB |    889 TiB |\n","|       from large pool | 189056 KiB |   9610 MiB |    887 TiB |    887 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1990 MiB |  10692 MiB | 188434 GiB | 188432 GiB |\n","|       from large pool |   1538 MiB |  10226 MiB | 188115 GiB | 188113 GiB |\n","|       from small pool |    452 MiB |    486 MiB |    318 GiB |    318 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1355 MiB |   1551 MiB | 325510 GiB | 325508 GiB |\n","|       from large pool |   1349 MiB |   1543 MiB | 323053 GiB | 323051 GiB |\n","|       from small pool |      5 MiB |     19 MiB |   2456 GiB |   2456 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   29301 K  |   29285 K  |\n","|       from large pool |      98    |     248    |   17503 K  |   17503 K  |\n","|       from small pool |   16251    |   16398    |   11797 K  |   11781 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   29301 K  |   29285 K  |\n","|       from large pool |      98    |     248    |   17503 K  |   17503 K  |\n","|       from small pool |   16251    |   16398    |   11797 K  |   11781 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     254    |     339    |    1653 K  |    1652 K  |\n","|       from large pool |      28    |     106    |    1489 K  |    1489 K  |\n","|       from small pool |     226    |     243    |     163 K  |     163 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      84    |     192    |   14634 K  |   14634 K  |\n","|       from large pool |      27    |     102    |   10005 K  |   10005 K  |\n","|       from small pool |      57    |     107    |    4628 K  |    4628 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:249/7698 batch_size:250\n","Next token prediction. step:108/115 batch:249/7698 epoch:2/10\n","full seq: They reiterated their expectations for the EU mission's neutrality on the issue of Kosovo's status.Ģġġġġġġġġġġġġġġġ\n","pref seq: They reiterated their expectations for the EU mission's neutrality on the issue of Kosovo's status.Ģġġġġġġġġ\n","next tok:                                                                                                            ġ\n","pred tok:                                                                                                            Ģ\n","Completed batch.\n","epoch:2/10 batch:249/7698 batch_size:250 loss:1.187271237373352 time_for_batch_instance:121.77772068977356 total_batch_time:24127.85109782219 running_batch_average:96.8990003928602\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 650028 KiB |  10075 MiB |    895 TiB |    895 TiB |\n","|       from large pool | 192578 KiB |   9623 MiB |    893 TiB |    893 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 650028 KiB |  10075 MiB |    895 TiB |    895 TiB |\n","|       from large pool | 192578 KiB |   9623 MiB |    893 TiB |    893 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  10059 MiB |    893 TiB |    893 TiB |\n","|       from large pool | 189056 KiB |   9610 MiB |    891 TiB |    891 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1990 MiB |  10696 MiB | 189236 GiB | 189234 GiB |\n","|       from large pool |   1538 MiB |  10230 MiB | 188916 GiB | 188914 GiB |\n","|       from small pool |    452 MiB |    486 MiB |    320 GiB |    320 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1355 MiB |   1588 MiB | 326970 GiB | 326968 GiB |\n","|       from large pool |   1349 MiB |   1580 MiB | 324499 GiB | 324497 GiB |\n","|       from small pool |      5 MiB |     19 MiB |   2471 GiB |   2471 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   29449 K  |   29433 K  |\n","|       from large pool |      98    |     248    |   17590 K  |   17589 K  |\n","|       from small pool |   16251    |   16398    |   11859 K  |   11843 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   29449 K  |   29433 K  |\n","|       from large pool |      98    |     248    |   17590 K  |   17589 K  |\n","|       from small pool |   16251    |   16398    |   11859 K  |   11843 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     254    |     339    |    1661 K  |    1661 K  |\n","|       from large pool |      28    |     106    |    1497 K  |    1497 K  |\n","|       from small pool |     226    |     243    |     164 K  |     163 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      84    |     192    |   14722 K  |   14722 K  |\n","|       from large pool |      27    |     102    |   10069 K  |   10069 K  |\n","|       from small pool |      57    |     107    |    4652 K  |    4652 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:250/7698 batch_size:250\n","Next token prediction. step:20/115 batch:250/7698 epoch:2/10\n","full seq: Human rights issues obstruct the Western Balkans EU integration process, according to a new report. [Reuters]Ģġġġġġ\n","pref seq: Human rights issues \n","next tok:                    o\n","pred tok:                    ,\n","Completed batch.\n","epoch:2/10 batch:250/7698 batch_size:250 loss:1.7930790185928345 time_for_batch_instance:121.95744824409485 total_batch_time:24249.808546066284 running_batch_average:96.99923418426513\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 649890 KiB |  10075 MiB |    899 TiB |    899 TiB |\n","|       from large pool | 192440 KiB |   9623 MiB |    897 TiB |    897 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 649890 KiB |  10075 MiB |    899 TiB |    899 TiB |\n","|       from large pool | 192440 KiB |   9623 MiB |    897 TiB |    897 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  10059 MiB |    897 TiB |    897 TiB |\n","|       from large pool | 189056 KiB |   9610 MiB |    895 TiB |    895 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2132 MiB |  10692 MiB | 190042 GiB | 190040 GiB |\n","|       from large pool |   1680 MiB |  10226 MiB | 189720 GiB | 189718 GiB |\n","|       from small pool |    452 MiB |    486 MiB |    321 GiB |    321 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1497 MiB |   1588 MiB | 328417 GiB | 328416 GiB |\n","|       from large pool |   1492 MiB |   1579 MiB | 325932 GiB | 325930 GiB |\n","|       from small pool |      5 MiB |     19 MiB |   2485 GiB |   2485 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   29598 K  |   29581 K  |\n","|       from large pool |      98    |     248    |   17676 K  |   17676 K  |\n","|       from small pool |   16251    |   16398    |   11921 K  |   11905 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   29598 K  |   29581 K  |\n","|       from large pool |      98    |     248    |   17676 K  |   17676 K  |\n","|       from small pool |   16251    |   16398    |   11921 K  |   11905 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     255    |     337    |    1669 K  |    1669 K  |\n","|       from large pool |      29    |     104    |    1504 K  |    1504 K  |\n","|       from small pool |     226    |     243    |     164 K  |     164 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      85    |     192    |   14810 K  |   14810 K  |\n","|       from large pool |      28    |     102    |   10134 K  |   10134 K  |\n","|       from small pool |      57    |     107    |    4676 K  |    4676 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:251/7698 batch_size:250\n","Next token prediction. step:92/115 batch:251/7698 epoch:2/10\n","full seq: (Blic - 19/08/05; RFE/RL, Radio B92, Beta, Reporters Without Borders - 18/08/05; FT, AP, Radio B92 - 17/08/05)Ģġġġġ\n","pref seq: (Blic - 19/08/05; RFE/RL, Radio B92, Beta, Reporters Without Borders - 18/08/05; FT, AP, Rad\n","next tok:                                                                                            i\n","pred tok:                                                                                            Ģ\n","Completed batch.\n","epoch:2/10 batch:251/7698 batch_size:250 loss:0.7659521102905273 time_for_batch_instance:121.74203896522522 total_batch_time:24371.55058503151 running_batch_average:97.09781109574307\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 649890 KiB |  10075 MiB |    903 TiB |    903 TiB |\n","|       from large pool | 192440 KiB |   9623 MiB |    901 TiB |    901 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 649890 KiB |  10075 MiB |    903 TiB |    903 TiB |\n","|       from large pool | 192440 KiB |   9623 MiB |    901 TiB |    901 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  10059 MiB |    901 TiB |    901 TiB |\n","|       from large pool | 189056 KiB |   9610 MiB |    898 TiB |    898 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2132 MiB |  10688 MiB | 190846 GiB | 190844 GiB |\n","|       from large pool |   1680 MiB |  10222 MiB | 190522 GiB | 190521 GiB |\n","|       from small pool |    452 MiB |    486 MiB |    323 GiB |    322 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1497 MiB |   1601 MiB | 329874 GiB | 329872 GiB |\n","|       from large pool |   1492 MiB |   1596 MiB | 327374 GiB | 327372 GiB |\n","|       from small pool |      5 MiB |     19 MiB |   2499 GiB |   2499 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   29746 K  |   29730 K  |\n","|       from large pool |      98    |     248    |   17762 K  |   17762 K  |\n","|       from small pool |   16251    |   16398    |   11983 K  |   11967 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   29746 K  |   29730 K  |\n","|       from large pool |      98    |     248    |   17762 K  |   17762 K  |\n","|       from small pool |   16251    |   16398    |   11983 K  |   11967 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     255    |     336    |    1677 K  |    1677 K  |\n","|       from large pool |      29    |     103    |    1512 K  |    1512 K  |\n","|       from small pool |     226    |     243    |     165 K  |     165 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      85    |     190    |   14898 K  |   14898 K  |\n","|       from large pool |      28    |     100    |   10198 K  |   10198 K  |\n","|       from small pool |      57    |     107    |    4699 K  |    4699 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:252/7698 batch_size:250\n","Next token prediction. step:16/115 batch:252/7698 epoch:2/10\n","full seq: Last year, the \"Macedonia -- Country of Computer Experts\" project oversaw the distribution of 12,222 vouchers.Ģġġġġ\n","pref seq: Last year, the \"\n","next tok:                M\n","pred tok:                ;\n","Completed batch.\n","epoch:2/10 batch:252/7698 batch_size:250 loss:1.5372697114944458 time_for_batch_instance:121.7182388305664 total_batch_time:24493.268823862076 running_batch_average:97.19551120580189\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 649854 KiB |  10075 MiB |    907 TiB |    907 TiB |\n","|       from large pool | 192404 KiB |   9623 MiB |    904 TiB |    904 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 649854 KiB |  10075 MiB |    907 TiB |    907 TiB |\n","|       from large pool | 192404 KiB |   9623 MiB |    904 TiB |    904 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |  10059 MiB |    904 TiB |    904 TiB |\n","|       from large pool | 189056 KiB |   9610 MiB |    902 TiB |    902 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1960 MiB |  10688 MiB | 191646 GiB | 191644 GiB |\n","|       from large pool |   1508 MiB |  10222 MiB | 191321 GiB | 191320 GiB |\n","|       from small pool |    452 MiB |    486 MiB |    324 GiB |    324 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1325 MiB |   1676 MiB | 331335 GiB | 331333 GiB |\n","|       from large pool |   1320 MiB |   1667 MiB | 328821 GiB | 328819 GiB |\n","|       from small pool |      5 MiB |     19 MiB |   2514 GiB |   2514 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   29894 K  |   29878 K  |\n","|       from large pool |      98    |     248    |   17849 K  |   17849 K  |\n","|       from small pool |   16251    |   16398    |   12045 K  |   12029 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   29894 K  |   29878 K  |\n","|       from large pool |      98    |     248    |   17849 K  |   17849 K  |\n","|       from small pool |   16251    |   16398    |   12045 K  |   12029 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     253    |     335    |    1685 K  |    1685 K  |\n","|       from large pool |      27    |     102    |    1519 K  |    1519 K  |\n","|       from small pool |     226    |     243    |     166 K  |     166 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      84    |     190    |   14986 K  |   14985 K  |\n","|       from large pool |      27    |     100    |   10262 K  |   10262 K  |\n","|       from small pool |      57    |     107    |    4723 K  |    4723 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:253/7698 batch_size:250\n","Next token prediction. step:49/114 batch:253/7698 epoch:2/10\n","full seq: The new law repeals custom duties for raw materials in agriculture and textile industry and machinery. [AFP]Ģġġġġġ\n","pref seq: The new law repeals custom duties for raw materia\n","next tok:                                                 l\n","pred tok:                                                 ,\n","Completed batch.\n","epoch:2/10 batch:253/7698 batch_size:250 loss:1.148041844367981 time_for_batch_instance:121.21397471427917 total_batch_time:24614.482798576355 running_batch_average:97.29044584417531\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 654060 KiB |  10011 MiB |    910 TiB |    910 TiB |\n","|       from large pool | 196610 KiB |   9559 MiB |    908 TiB |    908 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 654060 KiB |  10011 MiB |    910 TiB |    910 TiB |\n","|       from large pool | 196610 KiB |   9559 MiB |    908 TiB |    908 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |   9976 MiB |    908 TiB |    908 TiB |\n","|       from large pool | 189056 KiB |   9528 MiB |    906 TiB |    906 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2420 MiB |  10554 MiB | 192487 GiB | 192484 GiB |\n","|       from large pool |   1968 MiB |  10088 MiB | 192160 GiB | 192158 GiB |\n","|       from small pool |    452 MiB |    486 MiB |    326 GiB |    325 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1781 MiB |   1888 MiB | 332568 GiB | 332566 GiB |\n","|       from large pool |   1775 MiB |   1882 MiB | 330040 GiB | 330038 GiB |\n","|       from small pool |      5 MiB |     19 MiB |   2528 GiB |   2528 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   30041 K  |   30025 K  |\n","|       from large pool |      98    |     248    |   17934 K  |   17934 K  |\n","|       from small pool |   16251    |   16398    |   12107 K  |   12091 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   30041 K  |   30025 K  |\n","|       from large pool |      98    |     248    |   17934 K  |   17934 K  |\n","|       from small pool |   16251    |   16398    |   12107 K  |   12091 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     246    |     330    |    1694 K  |    1694 K  |\n","|       from large pool |      20    |      97    |    1527 K  |    1527 K  |\n","|       from small pool |     226    |     243    |     167 K  |     166 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      80    |     147    |   15041 K  |   15041 K  |\n","|       from large pool |      22    |      57    |   10294 K  |   10294 K  |\n","|       from small pool |      58    |     107    |    4747 K  |    4747 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:254/7698 batch_size:250\n","Next token prediction. step:44/113 batch:254/7698 epoch:2/10\n","full seq: RS holds a 41% stake in the company and the Federation of BiH (FBiH) holds the remaining 59%.Ģġġġġġġġġġġġġġġġġġġġ\n","pref seq: RS holds a 41% stake in the company and the \n","next tok:                                            F\n","pred tok:                                            f\n","Completed batch.\n","epoch:2/10 batch:254/7698 batch_size:250 loss:0.8039593696594238 time_for_batch_instance:119.57134342193604 total_batch_time:24734.05414199829 running_batch_average:97.37816591337909\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 654686 KiB |   9930 MiB |    914 TiB |    914 TiB |\n","|       from large pool | 197236 KiB |   9478 MiB |    912 TiB |    912 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 654686 KiB |   9930 MiB |    914 TiB |    914 TiB |\n","|       from large pool | 197236 KiB |   9478 MiB |    912 TiB |    912 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |   9893 MiB |    912 TiB |    912 TiB |\n","|       from large pool | 189056 KiB |   9445 MiB |    909 TiB |    909 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2574 MiB |  10500 MiB | 193306 GiB | 193304 GiB |\n","|       from large pool |   2122 MiB |  10034 MiB | 192978 GiB | 192976 GiB |\n","|       from small pool |    452 MiB |    486 MiB |    327 GiB |    327 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1934 MiB |   1966 MiB | 333783 GiB | 333781 GiB |\n","|       from large pool |   1929 MiB |   1960 MiB | 331241 GiB | 331239 GiB |\n","|       from small pool |      5 MiB |     19 MiB |   2542 GiB |   2542 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   30187 K  |   30171 K  |\n","|       from large pool |      98    |     248    |   18019 K  |   18019 K  |\n","|       from small pool |   16251    |   16398    |   12168 K  |   12151 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   30187 K  |   30171 K  |\n","|       from large pool |      98    |     248    |   18019 K  |   18019 K  |\n","|       from small pool |   16251    |   16398    |   12168 K  |   12151 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     247    |     332    |    1702 K  |    1702 K  |\n","|       from large pool |      21    |      99    |    1535 K  |    1535 K  |\n","|       from small pool |     226    |     243    |     167 K  |     167 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      79    |     149    |   15099 K  |   15099 K  |\n","|       from large pool |      21    |      59    |   10329 K  |   10329 K  |\n","|       from small pool |      58    |     107    |    4770 K  |    4770 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:255/7698 batch_size:250\n","Next token prediction. step:26/113 batch:255/7698 epoch:2/10\n","full seq: Police have equipped 500 new vehicles, including armored vehicles, for use by the delegations.Ģġġġġġġġġġġġġġġġġġġ\n","pref seq: Police have equipped 500 n\n","next tok:                          e\n","pred tok:                          :\n","Completed batch.\n","epoch:2/10 batch:255/7698 batch_size:250 loss:1.0276120901107788 time_for_batch_instance:119.78662323951721 total_batch_time:24853.84076523781 running_batch_average:97.46604221661886\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 656539 KiB |   9927 MiB |    918 TiB |    918 TiB |\n","|       from large pool | 199089 KiB |   9475 MiB |    915 TiB |    915 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 656539 KiB |   9927 MiB |    918 TiB |    918 TiB |\n","|       from large pool | 199089 KiB |   9475 MiB |    915 TiB |    915 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |   9893 MiB |    915 TiB |    915 TiB |\n","|       from large pool | 189056 KiB |   9445 MiB |    913 TiB |    913 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2950 MiB |  10486 MiB | 194093 GiB | 194090 GiB |\n","|       from large pool |   2498 MiB |  10020 MiB | 193764 GiB | 193761 GiB |\n","|       from small pool |    452 MiB |    486 MiB |    329 GiB |    328 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   2308 MiB |   2369 MiB | 335032 GiB | 335030 GiB |\n","|       from large pool |   2303 MiB |   2363 MiB | 332475 GiB | 332473 GiB |\n","|       from small pool |      5 MiB |     19 MiB |   2556 GiB |   2556 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   30333 K  |   30317 K  |\n","|       from large pool |      98    |     248    |   18104 K  |   18104 K  |\n","|       from small pool |   16251    |   16398    |   12229 K  |   12212 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   30333 K  |   30317 K  |\n","|       from large pool |      98    |     248    |   18104 K  |   18104 K  |\n","|       from small pool |   16251    |   16398    |   12229 K  |   12212 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     249    |     327    |    1711 K  |    1710 K  |\n","|       from large pool |      23    |      94    |    1542 K  |    1542 K  |\n","|       from small pool |     226    |     243    |     168 K  |     168 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      81    |     153    |   15158 K  |   15158 K  |\n","|       from large pool |      23    |      63    |   10365 K  |   10365 K  |\n","|       from small pool |      58    |     107    |    4793 K  |    4793 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:256/7698 batch_size:250\n","Next token prediction. step:18/113 batch:256/7698 epoch:2/10\n","full seq: By HK Tzanis and Menekse Tokyay for Southeast European Times in Athens and Istanbul -- 14/02/12Ģġġġġġġġġġġġġġġġġġ\n","pref seq: By HK Tzanis and M\n","next tok:                  e\n","pred tok:                  :\n","Completed batch.\n","epoch:2/10 batch:256/7698 batch_size:250 loss:0.9398831725120544 time_for_batch_instance:119.9199149608612 total_batch_time:24973.76068019867 running_batch_average:97.55375265702605\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 651202 KiB |   9991 MiB |    921 TiB |    921 TiB |\n","|       from large pool | 193752 KiB |   9539 MiB |    919 TiB |    919 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 651202 KiB |   9991 MiB |    921 TiB |    921 TiB |\n","|       from large pool | 193752 KiB |   9539 MiB |    919 TiB |    919 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |   9951 MiB |    919 TiB |    919 TiB |\n","|       from large pool | 189056 KiB |   9503 MiB |    917 TiB |    917 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2598 MiB |  10538 MiB | 194959 GiB | 194957 GiB |\n","|       from large pool |   2146 MiB |  10072 MiB | 194629 GiB | 194627 GiB |\n","|       from small pool |    452 MiB |    486 MiB |    330 GiB |    330 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1962 MiB |   2324 MiB | 336169 GiB | 336167 GiB |\n","|       from large pool |   1956 MiB |   2315 MiB | 333599 GiB | 333597 GiB |\n","|       from small pool |      5 MiB |     19 MiB |   2570 GiB |   2570 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   30479 K  |   30462 K  |\n","|       from large pool |      98    |     248    |   18189 K  |   18189 K  |\n","|       from small pool |   16251    |   16398    |   12289 K  |   12273 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   30479 K  |   30462 K  |\n","|       from large pool |      98    |     248    |   18189 K  |   18189 K  |\n","|       from small pool |   16251    |   16398    |   12289 K  |   12273 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     246    |     331    |    1720 K  |    1719 K  |\n","|       from large pool |      20    |      97    |    1550 K  |    1550 K  |\n","|       from small pool |     226    |     243    |     169 K  |     169 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      81    |     148    |   15210 K  |   15210 K  |\n","|       from large pool |      24    |      58    |   10393 K  |   10393 K  |\n","|       from small pool |      57    |     107    |    4816 K  |    4816 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:257/7698 batch_size:250\n","Next token prediction. step:18/113 batch:257/7698 epoch:2/10\n","full seq: When the issue is explained in detail, the people will see that their reactions are baseless,\" Guler said.Ģġġġġġġ\n","pref seq: When the issue is \n","next tok:                  e\n","pred tok:                  w\n","Completed batch.\n","epoch:2/10 batch:257/7698 batch_size:250 loss:0.8968321681022644 time_for_batch_instance:119.59163737297058 total_batch_time:25093.35231757164 running_batch_average:97.6395031812126\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 655485 KiB |   9930 MiB |    925 TiB |    925 TiB |\n","|       from large pool | 198035 KiB |   9478 MiB |    923 TiB |    923 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 655485 KiB |   9930 MiB |    925 TiB |    925 TiB |\n","|       from large pool | 198035 KiB |   9478 MiB |    923 TiB |    923 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |   9893 MiB |    923 TiB |    923 TiB |\n","|       from large pool | 189056 KiB |   9445 MiB |    920 TiB |    920 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2452 MiB |  10480 MiB | 195785 GiB | 195783 GiB |\n","|       from large pool |   2000 MiB |  10014 MiB | 195453 GiB | 195451 GiB |\n","|       from small pool |    452 MiB |    486 MiB |    332 GiB |    331 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1811 MiB |   1973 MiB | 337349 GiB | 337347 GiB |\n","|       from large pool |   1806 MiB |   1964 MiB | 334765 GiB | 334763 GiB |\n","|       from small pool |      5 MiB |     19 MiB |   2584 GiB |   2584 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   30624 K  |   30608 K  |\n","|       from large pool |      98    |     248    |   18273 K  |   18273 K  |\n","|       from small pool |   16251    |   16398    |   12350 K  |   12334 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   30624 K  |   30608 K  |\n","|       from large pool |      98    |     248    |   18273 K  |   18273 K  |\n","|       from small pool |   16251    |   16398    |   12350 K  |   12334 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     247    |     329    |    1728 K  |    1728 K  |\n","|       from large pool |      21    |      96    |    1558 K  |    1558 K  |\n","|       from small pool |     226    |     243    |     170 K  |     169 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      78    |     149    |   15269 K  |   15268 K  |\n","|       from large pool |      20    |      59    |   10429 K  |   10428 K  |\n","|       from small pool |      58    |     107    |    4840 K  |    4839 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:258/7698 batch_size:250\n","Next token prediction. step:20/113 batch:258/7698 epoch:2/10\n","full seq: Serbia's blocking of wheat exports to Kosovo has also impacted the price of basic food products like bread.Ģġġġġġ\n","pref seq: Serbia's blocking of\n","next tok:                     \n","pred tok:                    w\n","Completed batch.\n","epoch:2/10 batch:258/7698 batch_size:250 loss:2.059385299682617 time_for_batch_instance:119.42244935035706 total_batch_time:25212.774766921997 running_batch_average:97.72393320512401\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 655822 KiB |   9928 MiB |    929 TiB |    929 TiB |\n","|       from large pool | 198372 KiB |   9476 MiB |    926 TiB |    926 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 655822 KiB |   9928 MiB |    929 TiB |    929 TiB |\n","|       from large pool | 198372 KiB |   9476 MiB |    926 TiB |    926 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |   9893 MiB |    926 TiB |    926 TiB |\n","|       from large pool | 189056 KiB |   9445 MiB |    924 TiB |    924 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2754 MiB |  10484 MiB | 196569 GiB | 196567 GiB |\n","|       from large pool |   2302 MiB |  10018 MiB | 196236 GiB | 196233 GiB |\n","|       from small pool |    452 MiB |    486 MiB |    333 GiB |    333 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   2113 MiB |   2237 MiB | 338566 GiB | 338564 GiB |\n","|       from large pool |   2108 MiB |   2230 MiB | 335967 GiB | 335965 GiB |\n","|       from small pool |      5 MiB |     19 MiB |   2598 GiB |   2598 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   30770 K  |   30754 K  |\n","|       from large pool |      98    |     248    |   18358 K  |   18358 K  |\n","|       from small pool |   16251    |   16398    |   12411 K  |   12395 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   30770 K  |   30754 K  |\n","|       from large pool |      98    |     248    |   18358 K  |   18358 K  |\n","|       from small pool |   16251    |   16398    |   12411 K  |   12395 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     248    |     327    |    1736 K  |    1736 K  |\n","|       from large pool |      22    |      94    |    1565 K  |    1565 K  |\n","|       from small pool |     226    |     243    |     170 K  |     170 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      80    |     151    |   15327 K  |   15327 K  |\n","|       from large pool |      22    |      61    |   10464 K  |   10464 K  |\n","|       from small pool |      58    |     107    |    4863 K  |    4863 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:259/7698 batch_size:250\n","Next token prediction. step:11/113 batch:259/7698 epoch:2/10\n","full seq: The Croatian company Supernova Hrvatska announced it will build a new trade centre in the suburbs of Zagreb.Ģġġġġ\n","pref seq: The Croatia\n","next tok:           n\n","pred tok:           ,\n","Completed batch.\n","epoch:2/10 batch:259/7698 batch_size:250 loss:1.4645655155181885 time_for_batch_instance:119.44684529304504 total_batch_time:25332.221612215042 running_batch_average:97.80780545256773\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 656074 KiB |   9928 MiB |    932 TiB |    932 TiB |\n","|       from large pool | 198624 KiB |   9476 MiB |    930 TiB |    930 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 656074 KiB |   9928 MiB |    932 TiB |    932 TiB |\n","|       from large pool | 198624 KiB |   9476 MiB |    930 TiB |    930 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |   9893 MiB |    930 TiB |    930 TiB |\n","|       from large pool | 189056 KiB |   9445 MiB |    928 TiB |    928 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2756 MiB |  10486 MiB | 197341 GiB | 197338 GiB |\n","|       from large pool |   2304 MiB |  10020 MiB | 197005 GiB | 197003 GiB |\n","|       from small pool |    452 MiB |    486 MiB |    335 GiB |    334 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   2115 MiB |   2268 MiB | 339820 GiB | 339817 GiB |\n","|       from large pool |   2110 MiB |   2261 MiB | 337207 GiB | 337205 GiB |\n","|       from small pool |      5 MiB |     19 MiB |   2612 GiB |   2612 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   30916 K  |   30899 K  |\n","|       from large pool |      98    |     248    |   18443 K  |   18443 K  |\n","|       from small pool |   16251    |   16398    |   12472 K  |   12456 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   30916 K  |   30899 K  |\n","|       from large pool |      98    |     248    |   18443 K  |   18443 K  |\n","|       from small pool |   16251    |   16398    |   12472 K  |   12456 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     249    |     328    |    1744 K  |    1744 K  |\n","|       from large pool |      23    |      95    |    1572 K  |    1572 K  |\n","|       from small pool |     226    |     243    |     171 K  |     171 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      81    |     153    |   15386 K  |   15386 K  |\n","|       from large pool |      23    |      63    |   10500 K  |   10500 K  |\n","|       from small pool |      58    |     107    |    4886 K  |    4886 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:260/7698 batch_size:250\n","Next token prediction. step:87/112 batch:260/7698 epoch:2/10\n","full seq: \"We were told the uninominal vote would bring responsible and professional people to parliament.Ģġġġġġġġġġġġġġġġ\n","pref seq: \"We were told the uninominal vote would bring responsible and professional people to pa\n","next tok:                                                                                       r\n","pred tok:                                                                                       x\n","Completed batch.\n","epoch:2/10 batch:260/7698 batch_size:250 loss:1.8501312732696533 time_for_batch_instance:118.26118421554565 total_batch_time:25450.482796430588 running_batch_average:97.8864722939638\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 651672 KiB |   9825 MiB |    936 TiB |    936 TiB |\n","|       from large pool | 194222 KiB |   9373 MiB |    934 TiB |    934 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 651672 KiB |   9825 MiB |    936 TiB |    936 TiB |\n","|       from large pool | 194222 KiB |   9373 MiB |    934 TiB |    934 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |   9810 MiB |    934 TiB |    934 TiB |\n","|       from large pool | 189056 KiB |   9362 MiB |    931 TiB |    931 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2142 MiB |  10416 MiB | 198096 GiB | 198094 GiB |\n","|       from large pool |   1690 MiB |   9950 MiB | 197760 GiB | 197758 GiB |\n","|       from small pool |    452 MiB |    486 MiB |    336 GiB |    336 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1505 MiB |   2130 MiB | 341116 GiB | 341115 GiB |\n","|       from large pool |   1500 MiB |   2121 MiB | 338490 GiB | 338488 GiB |\n","|       from small pool |      5 MiB |     19 MiB |   2626 GiB |   2626 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   31060 K  |   31044 K  |\n","|       from large pool |      98    |     248    |   18527 K  |   18527 K  |\n","|       from small pool |   16251    |   16398    |   12533 K  |   12516 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   31060 K  |   31044 K  |\n","|       from large pool |      98    |     248    |   18527 K  |   18527 K  |\n","|       from small pool |   16251    |   16398    |   12533 K  |   12516 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     250    |     336    |    1752 K  |    1752 K  |\n","|       from large pool |      24    |     103    |    1579 K  |    1579 K  |\n","|       from small pool |     226    |     243    |     172 K  |     172 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      80    |     159    |   15450 K  |   15450 K  |\n","|       from large pool |      24    |      69    |   10540 K  |   10540 K  |\n","|       from small pool |      56    |     107    |    4909 K  |    4909 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:261/7698 batch_size:250\n","Next token prediction. step:73/112 batch:261/7698 epoch:2/10\n","full seq: Rebecca Doffing, a US citizen living in Istanbul, has had more than her fair share of taxi scams.Ģġġġġġġġġġġġġġġ\n","pref seq: Rebecca Doffing, a US citizen living in Istanbul, has had more than her f\n","next tok:                                                                         a\n","pred tok:                                                                         w\n","Completed batch.\n","epoch:2/10 batch:261/7698 batch_size:250 loss:2.2934377193450928 time_for_batch_instance:118.09813189506531 total_batch_time:25568.580928325653 running_batch_average:97.96391160278029\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 651452 KiB |   9825 MiB |    940 TiB |    940 TiB |\n","|       from large pool | 194002 KiB |   9373 MiB |    937 TiB |    937 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 651452 KiB |   9825 MiB |    940 TiB |    940 TiB |\n","|       from large pool | 194002 KiB |   9373 MiB |    937 TiB |    937 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |   9810 MiB |    937 TiB |    937 TiB |\n","|       from large pool | 189056 KiB |   9362 MiB |    935 TiB |    935 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2058 MiB |  10416 MiB | 198853 GiB | 198850 GiB |\n","|       from large pool |   1606 MiB |   9950 MiB | 198514 GiB | 198513 GiB |\n","|       from small pool |    452 MiB |    486 MiB |    338 GiB |    337 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1421 MiB |   2065 MiB | 342406 GiB | 342404 GiB |\n","|       from large pool |   1416 MiB |   2059 MiB | 339765 GiB | 339764 GiB |\n","|       from small pool |      5 MiB |     19 MiB |   2640 GiB |   2640 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   31205 K  |   31188 K  |\n","|       from large pool |      98    |     248    |   18611 K  |   18611 K  |\n","|       from small pool |   16251    |   16398    |   12593 K  |   12577 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   31205 K  |   31188 K  |\n","|       from large pool |      98    |     248    |   18611 K  |   18611 K  |\n","|       from small pool |   16251    |   16398    |   12593 K  |   12577 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     249    |     336    |    1760 K  |    1760 K  |\n","|       from large pool |      23    |     103    |    1587 K  |    1587 K  |\n","|       from small pool |     226    |     243    |     173 K  |     172 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      79    |     159    |   15513 K  |   15513 K  |\n","|       from large pool |      23    |      69    |   10580 K  |   10580 K  |\n","|       from small pool |      56    |     107    |    4933 K  |    4933 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:262/7698 batch_size:250\n","Next token prediction. step:36/112 batch:262/7698 epoch:2/10\n","full seq: Romanians head to the polls Sunday for the country's first elections held under a uninominal voting system.Ģġġġġ\n","pref seq: Romanians head to the polls Sunday f\n","next tok:                                    o\n","pred tok:                                    ;\n","Completed batch.\n","epoch:2/10 batch:262/7698 batch_size:250 loss:1.1264657974243164 time_for_batch_instance:118.00655341148376 total_batch_time:25686.587481737137 running_batch_average:98.04041023563792\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 651892 KiB |   9825 MiB |    943 TiB |    943 TiB |\n","|       from large pool | 194442 KiB |   9373 MiB |    941 TiB |    941 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 651892 KiB |   9825 MiB |    943 TiB |    943 TiB |\n","|       from large pool | 194442 KiB |   9373 MiB |    941 TiB |    941 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |   9810 MiB |    941 TiB |    941 TiB |\n","|       from large pool | 189056 KiB |   9362 MiB |    938 TiB |    938 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2226 MiB |  10416 MiB | 199609 GiB | 199607 GiB |\n","|       from large pool |   1774 MiB |   9950 MiB | 199270 GiB | 199268 GiB |\n","|       from small pool |    452 MiB |    486 MiB |    339 GiB |    339 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1589 MiB |   2065 MiB | 343696 GiB | 343694 GiB |\n","|       from large pool |   1584 MiB |   2059 MiB | 341041 GiB | 341040 GiB |\n","|       from small pool |      5 MiB |     19 MiB |   2654 GiB |   2654 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   31349 K  |   31333 K  |\n","|       from large pool |      98    |     248    |   18695 K  |   18695 K  |\n","|       from small pool |   16251    |   16398    |   12653 K  |   12637 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   31349 K  |   31333 K  |\n","|       from large pool |      98    |     248    |   18695 K  |   18695 K  |\n","|       from small pool |   16251    |   16398    |   12653 K  |   12637 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     251    |     336    |    1768 K  |    1767 K  |\n","|       from large pool |      25    |     103    |    1594 K  |    1594 K  |\n","|       from small pool |     226    |     243    |     173 K  |     173 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      81    |     159    |   15577 K  |   15577 K  |\n","|       from large pool |      25    |      69    |   10620 K  |   10620 K  |\n","|       from small pool |      56    |     107    |    4956 K  |    4956 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:263/7698 batch_size:250\n","Next token prediction. step:97/111 batch:263/7698 epoch:2/10\n","full seq: MPs also elected the seven deputy speakers, representing each of the parties in parliament.Ģġġġġġġġġġġġġġġġġġġġ\n","pref seq: MPs also elected the seven deputy speakers, representing each of the parties in parliament.Ģġġġġġ\n","next tok:                                                                                                 ġ\n","pred tok:                                                                                                 Ģ\n","Completed batch.\n","epoch:2/10 batch:263/7698 batch_size:250 loss:0.9042062759399414 time_for_batch_instance:116.42711615562439 total_batch_time:25803.01459789276 running_batch_average:98.11032166499149\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 653799 KiB |   9746 MiB |    947 TiB |    947 TiB |\n","|       from large pool | 196349 KiB |   9294 MiB |    944 TiB |    944 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 653799 KiB |   9746 MiB |    947 TiB |    947 TiB |\n","|       from large pool | 196349 KiB |   9294 MiB |    944 TiB |    944 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |   9727 MiB |    944 TiB |    944 TiB |\n","|       from large pool | 189056 KiB |   9279 MiB |    942 TiB |    942 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   3496 MiB |  10350 MiB | 200192 GiB | 200189 GiB |\n","|       from large pool |   3044 MiB |   9884 MiB | 199851 GiB | 199848 GiB |\n","|       from small pool |    452 MiB |    486 MiB |    341 GiB |    340 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   2857 MiB |   3392 MiB | 345478 GiB | 345476 GiB |\n","|       from large pool |   2852 MiB |   3386 MiB | 342810 GiB | 342807 GiB |\n","|       from small pool |      5 MiB |     19 MiB |   2668 GiB |   2668 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   31492 K  |   31476 K  |\n","|       from large pool |      98    |     248    |   18778 K  |   18778 K  |\n","|       from small pool |   16251    |   16398    |   12713 K  |   12697 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   31492 K  |   31476 K  |\n","|       from large pool |      98    |     248    |   18778 K  |   18778 K  |\n","|       from small pool |   16251    |   16398    |   12713 K  |   12697 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     254    |     329    |    1775 K  |    1774 K  |\n","|       from large pool |      28    |      96    |    1600 K  |    1600 K  |\n","|       from small pool |     226    |     243    |     174 K  |     174 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      86    |     170    |   15641 K  |   15641 K  |\n","|       from large pool |      27    |      80    |   10661 K  |   10661 K  |\n","|       from small pool |      59    |     107    |    4979 K  |    4979 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:264/7698 batch_size:250\n","Next token prediction. step:34/111 batch:264/7698 epoch:2/10\n","full seq: While the Kosovo institutions have achieved much progress, they \"still have much work to do\", Lehne said.Ģġġġġġ\n","pref seq: While the Kosovo institutions have\n","next tok:                                   \n","pred tok:                                  w\n","Completed batch.\n","epoch:2/10 batch:264/7698 batch_size:250 loss:1.044379472732544 time_for_batch_instance:116.51456546783447 total_batch_time:25919.529163360596 running_batch_average:98.18003470969923\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 653285 KiB |   9744 MiB |    950 TiB |    950 TiB |\n","|       from large pool | 195835 KiB |   9293 MiB |    948 TiB |    948 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 653285 KiB |   9744 MiB |    950 TiB |    950 TiB |\n","|       from large pool | 195835 KiB |   9293 MiB |    948 TiB |    948 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |   9727 MiB |    948 TiB |    948 TiB |\n","|       from large pool | 189056 KiB |   9279 MiB |    945 TiB |    945 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   3360 MiB |  10350 MiB | 200782 GiB | 200779 GiB |\n","|       from large pool |   2908 MiB |   9884 MiB | 200440 GiB | 200437 GiB |\n","|       from small pool |    452 MiB |    486 MiB |    342 GiB |    342 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   2722 MiB |   3460 MiB | 347217 GiB | 347214 GiB |\n","|       from large pool |   2716 MiB |   3455 MiB | 344535 GiB | 344533 GiB |\n","|       from small pool |      5 MiB |     19 MiB |   2681 GiB |   2681 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   31635 K  |   31619 K  |\n","|       from large pool |      98    |     248    |   18862 K  |   18862 K  |\n","|       from small pool |   16251    |   16398    |   12773 K  |   12757 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   31635 K  |   31619 K  |\n","|       from large pool |      98    |     248    |   18862 K  |   18862 K  |\n","|       from small pool |   16251    |   16398    |   12773 K  |   12757 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     254    |     328    |    1782 K  |    1781 K  |\n","|       from large pool |      28    |      95    |    1606 K  |    1606 K  |\n","|       from small pool |     226    |     243    |     175 K  |     175 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      86    |     171    |   15705 K  |   15705 K  |\n","|       from large pool |      27    |      82    |   10702 K  |   10702 K  |\n","|       from small pool |      59    |     107    |    5003 K  |    5003 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:265/7698 batch_size:250\n","Next token prediction. step:107/111 batch:265/7698 epoch:2/10\n","full seq: But Croatia has also claimed jurisdiction over the case, since the crimes were committed on its territory.Ģġġġġ\n","pref seq: But Croatia has also claimed jurisdiction over the case, since the crimes were committed on its territory.Ģ\n","next tok:                                                                                                           ġ\n","pred tok:                                                                                                           Ģ\n","Completed batch.\n","epoch:2/10 batch:265/7698 batch_size:250 loss:1.2439641952514648 time_for_batch_instance:116.4290702342987 total_batch_time:26035.958233594894 running_batch_average:98.24889899469771\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 651642 KiB |   9745 MiB |    954 TiB |    954 TiB |\n","|       from large pool | 194192 KiB |   9293 MiB |    951 TiB |    951 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 651642 KiB |   9745 MiB |    954 TiB |    954 TiB |\n","|       from large pool | 194192 KiB |   9293 MiB |    951 TiB |    951 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |   9727 MiB |    951 TiB |    951 TiB |\n","|       from large pool | 189056 KiB |   9279 MiB |    949 TiB |    949 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   3328 MiB |  10346 MiB | 201372 GiB | 201369 GiB |\n","|       from large pool |   2876 MiB |   9880 MiB | 201028 GiB | 201025 GiB |\n","|       from small pool |    452 MiB |    486 MiB |    344 GiB |    343 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   2691 MiB |   3460 MiB | 348956 GiB | 348953 GiB |\n","|       from large pool |   2686 MiB |   3456 MiB | 346260 GiB | 346257 GiB |\n","|       from small pool |      5 MiB |     19 MiB |   2695 GiB |   2695 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   31778 K  |   31762 K  |\n","|       from large pool |      98    |     248    |   18945 K  |   18945 K  |\n","|       from small pool |   16251    |   16398    |   12833 K  |   12816 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   31778 K  |   31762 K  |\n","|       from large pool |      98    |     248    |   18945 K  |   18945 K  |\n","|       from small pool |   16251    |   16398    |   12833 K  |   12816 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     252    |     328    |    1789 K  |    1788 K  |\n","|       from large pool |      26    |      94    |    1612 K  |    1612 K  |\n","|       from small pool |     226    |     243    |     176 K  |     175 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      85    |     169    |   15769 K  |   15769 K  |\n","|       from large pool |      26    |      79    |   10743 K  |   10743 K  |\n","|       from small pool |      59    |     107    |    5026 K  |    5026 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:266/7698 batch_size:250\n","Next token prediction. step:6/111 batch:266/7698 epoch:2/10\n","full seq: Leb i Sol members Kokan Dimusevski, Garabet Tavitjan, Bodan Arsovski and Vlatko Stefanovski. [Getty Images]Ģġġġ\n","pref seq: Leb i \n","next tok:      S\n","pred tok:      ;\n","Completed batch.\n","epoch:2/10 batch:266/7698 batch_size:250 loss:1.3979237079620361 time_for_batch_instance:116.8120641708374 total_batch_time:26152.77029776573 running_batch_average:98.31868532994636\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 653799 KiB |   9746 MiB |    957 TiB |    957 TiB |\n","|       from large pool | 196349 KiB |   9294 MiB |    955 TiB |    955 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 653799 KiB |   9746 MiB |    957 TiB |    957 TiB |\n","|       from large pool | 196349 KiB |   9294 MiB |    955 TiB |    955 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |   9727 MiB |    955 TiB |    955 TiB |\n","|       from large pool | 189056 KiB |   9279 MiB |    952 TiB |    952 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   3496 MiB |  10350 MiB | 201954 GiB | 201951 GiB |\n","|       from large pool |   3044 MiB |   9884 MiB | 201609 GiB | 201606 GiB |\n","|       from small pool |    452 MiB |    486 MiB |    345 GiB |    345 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   2857 MiB |   3344 MiB | 350714 GiB | 350711 GiB |\n","|       from large pool |   2852 MiB |   3339 MiB | 348005 GiB | 348002 GiB |\n","|       from small pool |      5 MiB |     19 MiB |   2709 GiB |   2709 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   31921 K  |   31905 K  |\n","|       from large pool |      98    |     248    |   19028 K  |   19028 K  |\n","|       from small pool |   16251    |   16398    |   12893 K  |   12876 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   31921 K  |   31905 K  |\n","|       from large pool |      98    |     248    |   19028 K  |   19028 K  |\n","|       from small pool |   16251    |   16398    |   12893 K  |   12876 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     254    |     329    |    1796 K  |    1795 K  |\n","|       from large pool |      28    |      96    |    1619 K  |    1619 K  |\n","|       from small pool |     226    |     243    |     176 K  |     176 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      86    |     170    |   15833 K  |   15833 K  |\n","|       from large pool |      27    |      80    |   10784 K  |   10784 K  |\n","|       from small pool |      59    |     107    |    5049 K  |    5049 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:267/7698 batch_size:250\n","Next token prediction. step:83/110 batch:267/7698 epoch:2/10\n","full seq: Cedomir Jovanovic, president of the Liberal Democratic Party, is concerned by the new developments.Ģġġġġġġġġġġ\n","pref seq: Cedomir Jovanovic, president of the Liberal Democratic Party, is concerned by the n\n","next tok:                                                                                   e\n","pred tok:                                                                                   w\n","Completed batch.\n","epoch:2/10 batch:267/7698 batch_size:250 loss:0.9410132765769958 time_for_batch_instance:115.82450532913208 total_batch_time:26268.594803094864 running_batch_average:98.38425019885717\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 649448 KiB |   9656 MiB |    961 TiB |    961 TiB |\n","|       from large pool | 191998 KiB |   9205 MiB |    958 TiB |    958 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 649448 KiB |   9656 MiB |    961 TiB |    961 TiB |\n","|       from large pool | 191998 KiB |   9205 MiB |    958 TiB |    958 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |   9645 MiB |    958 TiB |    958 TiB |\n","|       from large pool | 189056 KiB |   9197 MiB |    956 TiB |    956 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2370 MiB |  10248 MiB | 202620 GiB | 202618 GiB |\n","|       from large pool |   1918 MiB |   9782 MiB | 202273 GiB | 202271 GiB |\n","|       from small pool |    452 MiB |    486 MiB |    346 GiB |    346 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1735 MiB |   2864 MiB | 351909 GiB | 351908 GiB |\n","|       from large pool |   1730 MiB |   2857 MiB | 349186 GiB | 349185 GiB |\n","|       from small pool |      5 MiB |     19 MiB |   2722 GiB |   2722 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   32063 K  |   32047 K  |\n","|       from large pool |      98    |     248    |   19111 K  |   19111 K  |\n","|       from small pool |   16251    |   16398    |   12952 K  |   12936 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   32063 K  |   32047 K  |\n","|       from large pool |      98    |     248    |   19111 K  |   19111 K  |\n","|       from small pool |   16251    |   16398    |   12952 K  |   12936 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     243    |     329    |    1803 K  |    1803 K  |\n","|       from large pool |      17    |      96    |    1626 K  |    1626 K  |\n","|       from small pool |     226    |     243    |     177 K  |     177 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      77    |     179    |   15911 K  |   15911 K  |\n","|       from large pool |      22    |      90    |   10838 K  |   10838 K  |\n","|       from small pool |      55    |     108    |    5072 K  |    5072 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:268/7698 batch_size:250\n","Next token prediction. step:48/110 batch:268/7698 epoch:2/10\n","full seq: Albania and Bosnia and Herzegovina agreed on March 24th to liberalise movement of citizens and goods.Ģġġġġġġġġ\n","pref seq: Albania and Bosnia and Herzegovina agreed on Mar\n","next tok:                                                c\n","pred tok:                                                %\n","Completed batch.\n","epoch:2/10 batch:268/7698 batch_size:250 loss:0.9953133463859558 time_for_batch_instance:115.90696024894714 total_batch_time:26384.50176334381 running_batch_average:98.44963344531273\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 650971 KiB |   9656 MiB |    964 TiB |    964 TiB |\n","|       from large pool | 193521 KiB |   9204 MiB |    962 TiB |    962 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 650971 KiB |   9656 MiB |    964 TiB |    964 TiB |\n","|       from large pool | 193521 KiB |   9204 MiB |    962 TiB |    962 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |   9645 MiB |    962 TiB |    962 TiB |\n","|       from large pool | 189056 KiB |   9197 MiB |    959 TiB |    959 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2378 MiB |  10258 MiB | 203288 GiB | 203286 GiB |\n","|       from large pool |   1926 MiB |   9792 MiB | 202940 GiB | 202938 GiB |\n","|       from small pool |    452 MiB |    486 MiB |    348 GiB |    347 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1742 MiB |   2726 MiB | 353070 GiB | 353069 GiB |\n","|       from large pool |   1737 MiB |   2720 MiB | 350334 GiB | 350332 GiB |\n","|       from small pool |      5 MiB |     19 MiB |   2736 GiB |   2736 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   32205 K  |   32188 K  |\n","|       from large pool |      98    |     248    |   19193 K  |   19193 K  |\n","|       from small pool |   16251    |   16398    |   13011 K  |   12995 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   32205 K  |   32188 K  |\n","|       from large pool |      98    |     248    |   19193 K  |   19193 K  |\n","|       from small pool |   16251    |   16398    |   13011 K  |   12995 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     244    |     331    |    1811 K  |    1811 K  |\n","|       from large pool |      18    |      98    |    1632 K  |    1632 K  |\n","|       from small pool |     226    |     243    |     178 K  |     178 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      75    |     179    |   15989 K  |   15989 K  |\n","|       from large pool |      20    |      90    |   10893 K  |   10893 K  |\n","|       from small pool |      55    |     108    |    5095 K  |    5095 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:269/7698 batch_size:250\n","Next token prediction. step:31/110 batch:269/7698 epoch:2/10\n","full seq: He explained that to arrest Stankovic, co-operation of other states in the region is necessary.Ģġġġġġġġġġġġġġġ\n","pref seq: He explained that to arrest Sta\n","next tok:                               n\n","pred tok:                               w\n","Completed batch.\n","epoch:2/10 batch:269/7698 batch_size:250 loss:1.1249276399612427 time_for_batch_instance:116.11017966270447 total_batch_time:26500.611943006516 running_batch_average:98.51528603348147\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 649786 KiB |   9656 MiB |    968 TiB |    968 TiB |\n","|       from large pool | 192336 KiB |   9205 MiB |    965 TiB |    965 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 649786 KiB |   9656 MiB |    968 TiB |    968 TiB |\n","|       from large pool | 192336 KiB |   9205 MiB |    965 TiB |    965 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |   9645 MiB |    965 TiB |    965 TiB |\n","|       from large pool | 189056 KiB |   9197 MiB |    963 TiB |    963 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2342 MiB |  10248 MiB | 203956 GiB | 203953 GiB |\n","|       from large pool |   1890 MiB |   9782 MiB | 203606 GiB | 203604 GiB |\n","|       from small pool |    452 MiB |    486 MiB |    349 GiB |    349 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1707 MiB |   2822 MiB | 354237 GiB | 354235 GiB |\n","|       from large pool |   1702 MiB |   2817 MiB | 351487 GiB | 351485 GiB |\n","|       from small pool |      5 MiB |     19 MiB |   2750 GiB |   2750 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   32347 K  |   32330 K  |\n","|       from large pool |      98    |     248    |   19276 K  |   19276 K  |\n","|       from small pool |   16251    |   16398    |   13070 K  |   13054 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   32347 K  |   32330 K  |\n","|       from large pool |      98    |     248    |   19276 K  |   19276 K  |\n","|       from small pool |   16251    |   16398    |   13070 K  |   13054 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     243    |     330    |    1818 K  |    1818 K  |\n","|       from large pool |      17    |      97    |    1639 K  |    1639 K  |\n","|       from small pool |     226    |     243    |     179 K  |     178 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      73    |     178    |   16067 K  |   16066 K  |\n","|       from large pool |      18    |      89    |   10948 K  |   10948 K  |\n","|       from small pool |      55    |     108    |    5118 K  |    5118 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:270/7698 batch_size:250\n","Completed batch.\n","epoch:2/10 batch:270/7698 batch_size:250 loss:0.9760987162590027 time_for_batch_instance:115.7700526714325 total_batch_time:26616.381995677948 running_batch_average:98.57919257658499\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 649786 KiB |   9656 MiB |    971 TiB |    971 TiB |\n","|       from large pool | 192336 KiB |   9205 MiB |    969 TiB |    969 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 649786 KiB |   9656 MiB |    971 TiB |    971 TiB |\n","|       from large pool | 192336 KiB |   9205 MiB |    969 TiB |    969 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |   9645 MiB |    969 TiB |    969 TiB |\n","|       from large pool | 189056 KiB |   9197 MiB |    966 TiB |    966 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2342 MiB |  10248 MiB | 204624 GiB | 204622 GiB |\n","|       from large pool |   1890 MiB |   9782 MiB | 204273 GiB | 204271 GiB |\n","|       from small pool |    452 MiB |    486 MiB |    351 GiB |    350 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1707 MiB |   2822 MiB | 355406 GiB | 355404 GiB |\n","|       from large pool |   1702 MiB |   2817 MiB | 352642 GiB | 352640 GiB |\n","|       from small pool |      5 MiB |     19 MiB |   2763 GiB |   2763 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   32488 K  |   32472 K  |\n","|       from large pool |      98    |     248    |   19358 K  |   19358 K  |\n","|       from small pool |   16251    |   16398    |   13130 K  |   13113 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   32488 K  |   32472 K  |\n","|       from large pool |      98    |     248    |   19358 K  |   19358 K  |\n","|       from small pool |   16251    |   16398    |   13130 K  |   13113 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     243    |     330    |    1826 K  |    1826 K  |\n","|       from large pool |      17    |      97    |    1646 K  |    1646 K  |\n","|       from small pool |     226    |     243    |     179 K  |     179 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      73    |     178    |   16144 K  |   16144 K  |\n","|       from large pool |      18    |      89    |   11003 K  |   11003 K  |\n","|       from small pool |      55    |     108    |    5141 K  |    5141 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:271/7698 batch_size:250\n","Next token prediction. step:74/110 batch:271/7698 epoch:2/10\n","full seq: Serbian Minister for Kosovo Goran Bogdanovic unveiled \"incentives\" to local businesses there on June 3rd.Ģġġġġ\n","pref seq: Serbian Minister for Kosovo Goran Bogdanovic unveiled \"incentives\" to loca\n","next tok:                                                                          l\n","pred tok:                                                                          ;\n","Completed batch.\n","epoch:2/10 batch:271/7698 batch_size:250 loss:1.74180006980896 time_for_batch_instance:115.88883805274963 total_batch_time:26732.270833730698 running_batch_average:98.64306580712434\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 649786 KiB |   9656 MiB |    975 TiB |    975 TiB |\n","|       from large pool | 192336 KiB |   9205 MiB |    972 TiB |    972 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 649786 KiB |   9656 MiB |    975 TiB |    975 TiB |\n","|       from large pool | 192336 KiB |   9205 MiB |    972 TiB |    972 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |   9645 MiB |    972 TiB |    972 TiB |\n","|       from large pool | 189056 KiB |   9197 MiB |    970 TiB |    970 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2342 MiB |  10248 MiB | 205292 GiB | 205289 GiB |\n","|       from large pool |   1890 MiB |   9782 MiB | 204939 GiB | 204937 GiB |\n","|       from small pool |    452 MiB |    486 MiB |    352 GiB |    352 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1707 MiB |   2822 MiB | 356574 GiB | 356572 GiB |\n","|       from large pool |   1702 MiB |   2817 MiB | 353797 GiB | 353795 GiB |\n","|       from small pool |      5 MiB |     19 MiB |   2777 GiB |   2777 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   32630 K  |   32614 K  |\n","|       from large pool |      98    |     248    |   19441 K  |   19441 K  |\n","|       from small pool |   16251    |   16398    |   13189 K  |   13173 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   32630 K  |   32614 K  |\n","|       from large pool |      98    |     248    |   19441 K  |   19441 K  |\n","|       from small pool |   16251    |   16398    |   13189 K  |   13173 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     243    |     330    |    1834 K  |    1833 K  |\n","|       from large pool |      17    |      97    |    1653 K  |    1653 K  |\n","|       from small pool |     226    |     243    |     180 K  |     180 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      73    |     180    |   16222 K  |   16222 K  |\n","|       from large pool |      18    |      91    |   11058 K  |   11058 K  |\n","|       from small pool |      55    |     108    |    5164 K  |    5163 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:272/7698 batch_size:250\n","Next token prediction. step:104/109 batch:272/7698 epoch:2/10\n","full seq: Later, the black-robed judge considered the witnesses' credibility and found the defendant not guilty.Ģġġġġġġ\n","pref seq: Later, the black-robed judge considered the witnesses' credibility and found the defendant not guilty.Ģġ\n","next tok:                                                                                                        ġ\n","pred tok:                                                                                                        Ģ\n","Completed batch.\n","epoch:2/10 batch:272/7698 batch_size:250 loss:1.1122034788131714 time_for_batch_instance:115.07844400405884 total_batch_time:26847.349277734756 running_batch_average:98.7034899916719\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 650242 KiB |   9577 MiB |    978 TiB |    978 TiB |\n","|       from large pool | 192792 KiB |   9125 MiB |    975 TiB |    975 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 650242 KiB |   9577 MiB |    978 TiB |    978 TiB |\n","|       from large pool | 192792 KiB |   9125 MiB |    975 TiB |    975 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |   9562 MiB |    975 TiB |    975 TiB |\n","|       from large pool | 189056 KiB |   9114 MiB |    973 TiB |    973 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2348 MiB |  10152 MiB | 205997 GiB | 205994 GiB |\n","|       from large pool |   1896 MiB |   9686 MiB | 205643 GiB | 205641 GiB |\n","|       from small pool |    452 MiB |    486 MiB |    354 GiB |    353 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1712 MiB |   2459 MiB | 357832 GiB | 357830 GiB |\n","|       from large pool |   1707 MiB |   2453 MiB | 355041 GiB | 355039 GiB |\n","|       from small pool |      5 MiB |     19 MiB |   2790 GiB |   2790 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   32771 K  |   32754 K  |\n","|       from large pool |      98    |     248    |   19523 K  |   19522 K  |\n","|       from small pool |   16251    |   16398    |   13248 K  |   13231 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   32771 K  |   32754 K  |\n","|       from large pool |      98    |     248    |   19523 K  |   19522 K  |\n","|       from small pool |   16251    |   16398    |   13248 K  |   13231 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     248    |     328    |    1842 K  |    1841 K  |\n","|       from large pool |      22    |      95    |    1660 K  |    1660 K  |\n","|       from small pool |     226    |     243    |     181 K  |     181 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      87    |     172    |   16296 K  |   16296 K  |\n","|       from large pool |      28    |      83    |   11109 K  |   11109 K  |\n","|       from small pool |      59    |     108    |    5186 K  |    5186 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:273/7698 batch_size:250\n","Next token prediction. step:84/109 batch:273/7698 epoch:2/10\n","full seq: The main goal of the project is to disperse the government's power from Ankara to the regions, he said.Ģġġġġġ\n","pref seq: The main goal of the project is to disperse the government's power from Ankara to th\n","next tok:                                                                                    e\n","pred tok:                                                                                    w\n","Completed batch.\n","epoch:2/10 batch:273/7698 batch_size:250 loss:0.9436562657356262 time_for_batch_instance:115.65312147140503 total_batch_time:26963.00239920616 running_batch_average:98.76557655386873\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 650322 KiB |   9576 MiB |    981 TiB |    981 TiB |\n","|       from large pool | 192872 KiB |   9125 MiB |    979 TiB |    979 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 650322 KiB |   9576 MiB |    981 TiB |    981 TiB |\n","|       from large pool | 192872 KiB |   9125 MiB |    979 TiB |    979 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |   9562 MiB |    979 TiB |    979 TiB |\n","|       from large pool | 189056 KiB |   9114 MiB |    976 TiB |    976 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1928 MiB |  10150 MiB | 206740 GiB | 206738 GiB |\n","|       from large pool |   1476 MiB |   9684 MiB | 206385 GiB | 206383 GiB |\n","|       from small pool |    452 MiB |    486 MiB |    355 GiB |    355 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1292 MiB |   2196 MiB | 359006 GiB | 359005 GiB |\n","|       from large pool |   1287 MiB |   2191 MiB | 356202 GiB | 356200 GiB |\n","|       from small pool |      5 MiB |     19 MiB |   2804 GiB |   2804 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   32911 K  |   32895 K  |\n","|       from large pool |      98    |     248    |   19604 K  |   19604 K  |\n","|       from small pool |   16251    |   16398    |   13306 K  |   13290 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   32911 K  |   32895 K  |\n","|       from large pool |      98    |     248    |   19604 K  |   19604 K  |\n","|       from small pool |   16251    |   16398    |   13306 K  |   13290 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     246    |     329    |    1850 K  |    1849 K  |\n","|       from large pool |      20    |      96    |    1668 K  |    1668 K  |\n","|       from small pool |     226    |     243    |     182 K  |     181 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      83    |     172    |   16369 K  |   16369 K  |\n","|       from large pool |      24    |      83    |   11160 K  |   11160 K  |\n","|       from small pool |      59    |     108    |    5209 K  |    5209 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:274/7698 batch_size:250\n","Next token prediction. step:12/109 batch:274/7698 epoch:2/10\n","full seq: The Srebrenica massacre has been described as the worst atrocity in European history since World War II.Ģġġġġ\n","pref seq: The Srebreni\n","next tok:            c\n","pred tok:            w\n","Completed batch.\n","epoch:2/10 batch:274/7698 batch_size:250 loss:1.2404230833053589 time_for_batch_instance:115.42752742767334 total_batch_time:27078.429926633835 running_batch_average:98.82638659355415\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 649475 KiB |   9578 MiB |    985 TiB |    985 TiB |\n","|       from large pool | 192025 KiB |   9126 MiB |    982 TiB |    982 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 649475 KiB |   9578 MiB |    985 TiB |    985 TiB |\n","|       from large pool | 192025 KiB |   9126 MiB |    982 TiB |    982 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |   9562 MiB |    982 TiB |    982 TiB |\n","|       from large pool | 189056 KiB |   9114 MiB |    980 TiB |    980 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1824 MiB |  10150 MiB | 207484 GiB | 207482 GiB |\n","|       from large pool |   1372 MiB |   9684 MiB | 207127 GiB | 207126 GiB |\n","|       from small pool |    452 MiB |    486 MiB |    356 GiB |    356 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1189 MiB |   1901 MiB | 360162 GiB | 360161 GiB |\n","|       from large pool |   1184 MiB |   1895 MiB | 357344 GiB | 357343 GiB |\n","|       from small pool |      5 MiB |     20 MiB |   2817 GiB |   2817 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   33051 K  |   33035 K  |\n","|       from large pool |      98    |     248    |   19686 K  |   19686 K  |\n","|       from small pool |   16251    |   16398    |   13365 K  |   13349 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   33051 K  |   33035 K  |\n","|       from large pool |      98    |     248    |   19686 K  |   19686 K  |\n","|       from small pool |   16251    |   16398    |   13365 K  |   13349 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     245    |     332    |    1858 K  |    1857 K  |\n","|       from large pool |      19    |      98    |    1675 K  |    1675 K  |\n","|       from small pool |     226    |     243    |     182 K  |     182 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      83    |     175    |   16443 K  |   16443 K  |\n","|       from large pool |      24    |      85    |   11211 K  |   11211 K  |\n","|       from small pool |      59    |     108    |    5231 K  |    5231 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:275/7698 batch_size:250\n","Next token prediction. step:70/108 batch:275/7698 epoch:2/10\n","full seq: Bosnia and Herzegovina (BiH) and Pakistan have signed an agreement on avoidance of double taxation.Ģġġġġġġġġ\n","pref seq: Bosnia and Herzegovina (BiH) and Pakistan have signed an agreement on \n","next tok:                                                                      a\n","pred tok:                                                                      b\n","Completed batch.\n","epoch:2/10 batch:275/7698 batch_size:250 loss:2.030958414077759 time_for_batch_instance:114.46308183670044 total_batch_time:27192.893008470535 running_batch_average:98.88324730352922\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 649239 KiB |   9498 MiB |    988 TiB |    988 TiB |\n","|       from large pool | 191789 KiB |   9046 MiB |    986 TiB |    986 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 649239 KiB |   9498 MiB |    988 TiB |    988 TiB |\n","|       from large pool | 191789 KiB |   9046 MiB |    986 TiB |    986 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |   9479 MiB |    986 TiB |    986 TiB |\n","|       from large pool | 189056 KiB |   9031 MiB |    983 TiB |    983 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2290 MiB |  10026 MiB | 208236 GiB | 208234 GiB |\n","|       from large pool |   1838 MiB |   9560 MiB | 207878 GiB | 207876 GiB |\n","|       from small pool |    452 MiB |    486 MiB |    358 GiB |    357 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1655 MiB |   1820 MiB | 361345 GiB | 361343 GiB |\n","|       from large pool |   1650 MiB |   1809 MiB | 358514 GiB | 358512 GiB |\n","|       from small pool |      5 MiB |     20 MiB |   2831 GiB |   2831 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   33191 K  |   33174 K  |\n","|       from large pool |      98    |     248    |   19767 K  |   19767 K  |\n","|       from small pool |   16251    |   16398    |   13423 K  |   13407 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   33191 K  |   33174 K  |\n","|       from large pool |      98    |     248    |   19767 K  |   19767 K  |\n","|       from small pool |   16251    |   16398    |   13423 K  |   13407 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     244    |     331    |    1866 K  |    1866 K  |\n","|       from large pool |      18    |      98    |    1682 K  |    1682 K  |\n","|       from small pool |     226    |     243    |     183 K  |     183 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      86    |     175    |   16518 K  |   16518 K  |\n","|       from large pool |      27    |      85    |   11264 K  |   11264 K  |\n","|       from small pool |      59    |     107    |    5253 K  |    5253 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:276/7698 batch_size:250\n","Next token prediction. step:65/108 batch:276/7698 epoch:2/10\n","full seq: By Muhamet Brajshori and Linda Karadaku for Southeast European Times in Pristina -- 05/10/11Ģġġġġġġġġġġġġġġġ\n","pref seq: By Muhamet Brajshori and Linda Karadaku for Southeast European Ti\n","next tok:                                                                 m\n","pred tok:                                                                 w\n","Completed batch.\n","epoch:2/10 batch:276/7698 batch_size:250 loss:1.1850454807281494 time_for_batch_instance:113.91895413398743 total_batch_time:27306.811962604523 running_batch_average:98.9377245021903\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 649239 KiB |   9498 MiB |    991 TiB |    991 TiB |\n","|       from large pool | 191789 KiB |   9046 MiB |    989 TiB |    989 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 649239 KiB |   9498 MiB |    991 TiB |    991 TiB |\n","|       from large pool | 191789 KiB |   9046 MiB |    989 TiB |    989 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |   9479 MiB |    989 TiB |    989 TiB |\n","|       from large pool | 189056 KiB |   9031 MiB |    986 TiB |    986 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2290 MiB |  10026 MiB | 208969 GiB | 208967 GiB |\n","|       from large pool |   1838 MiB |   9560 MiB | 208609 GiB | 208608 GiB |\n","|       from small pool |    452 MiB |    486 MiB |    359 GiB |    359 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1655 MiB |   1860 MiB | 362542 GiB | 362540 GiB |\n","|       from large pool |   1650 MiB |   1850 MiB | 359698 GiB | 359696 GiB |\n","|       from small pool |      5 MiB |     19 MiB |   2844 GiB |   2844 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   33330 K  |   33313 K  |\n","|       from large pool |      98    |     248    |   19848 K  |   19848 K  |\n","|       from small pool |   16251    |   16398    |   13481 K  |   13465 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   33330 K  |   33313 K  |\n","|       from large pool |      98    |     248    |   19848 K  |   19848 K  |\n","|       from small pool |   16251    |   16398    |   13481 K  |   13465 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     244    |     328    |    1874 K  |    1874 K  |\n","|       from large pool |      18    |      95    |    1690 K  |    1690 K  |\n","|       from small pool |     226    |     243    |     184 K  |     184 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      86    |     173    |   16593 K  |   16593 K  |\n","|       from large pool |      27    |      84    |   11317 K  |   11317 K  |\n","|       from small pool |      59    |     107    |    5276 K  |    5276 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:277/7698 batch_size:250\n","Next token prediction. step:18/108 batch:277/7698 epoch:2/10\n","full seq: Tadic also assured the 15-nation body that his country \"will not resort to violence and war\".Ģġġġġġġġġġġġġġġ\n","pref seq: Tadic also assured\n","next tok:                   \n","pred tok:                  w\n","Completed batch.\n","epoch:2/10 batch:277/7698 batch_size:250 loss:0.7638937830924988 time_for_batch_instance:113.78482747077942 total_batch_time:27420.596790075302 running_batch_average:98.99132415189639\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 649239 KiB |   9498 MiB |    995 TiB |    995 TiB |\n","|       from large pool | 191789 KiB |   9046 MiB |    992 TiB |    992 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 649239 KiB |   9498 MiB |    995 TiB |    995 TiB |\n","|       from large pool | 191789 KiB |   9046 MiB |    992 TiB |    992 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |   9479 MiB |    992 TiB |    992 TiB |\n","|       from large pool | 189056 KiB |   9031 MiB |    990 TiB |    990 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2290 MiB |  10026 MiB | 209702 GiB | 209700 GiB |\n","|       from large pool |   1838 MiB |   9560 MiB | 209341 GiB | 209339 GiB |\n","|       from small pool |    452 MiB |    486 MiB |    361 GiB |    360 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1655 MiB |   1860 MiB | 363739 GiB | 363737 GiB |\n","|       from large pool |   1650 MiB |   1850 MiB | 360881 GiB | 360880 GiB |\n","|       from small pool |      5 MiB |     19 MiB |   2857 GiB |   2857 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   33469 K  |   33453 K  |\n","|       from large pool |      98    |     248    |   19929 K  |   19929 K  |\n","|       from small pool |   16251    |   16398    |   13540 K  |   13523 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   33469 K  |   33453 K  |\n","|       from large pool |      98    |     248    |   19929 K  |   19929 K  |\n","|       from small pool |   16251    |   16398    |   13540 K  |   13523 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     244    |     328    |    1882 K  |    1881 K  |\n","|       from large pool |      18    |      95    |    1697 K  |    1697 K  |\n","|       from small pool |     226    |     243    |     184 K  |     184 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      86    |     173    |   16668 K  |   16668 K  |\n","|       from large pool |      27    |      84    |   11370 K  |   11370 K  |\n","|       from small pool |      59    |     107    |    5298 K  |    5298 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:278/7698 batch_size:250\n","Next token prediction. step:80/108 batch:278/7698 epoch:2/10\n","full seq: Culture Minister Theodor Paleologu said the cost of this year's edition totals approximately 7m euros.Ģġġġġġ\n","pref seq: Culture Minister Theodor Paleologu said the cost of this year's edition totals a\n","next tok:                                                                                p\n","pred tok:                                                                                Q\n","Completed batch.\n","epoch:2/10 batch:278/7698 batch_size:250 loss:0.7735961079597473 time_for_batch_instance:114.17865085601807 total_batch_time:27534.77544093132 running_batch_average:99.04595482349396\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 649239 KiB |   9498 MiB |    998 TiB |    998 TiB |\n","|       from large pool | 191789 KiB |   9046 MiB |    996 TiB |    996 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 649239 KiB |   9498 MiB |    998 TiB |    998 TiB |\n","|       from large pool | 191789 KiB |   9046 MiB |    996 TiB |    996 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |   9479 MiB |    996 TiB |    996 TiB |\n","|       from large pool | 189056 KiB |   9031 MiB |    993 TiB |    993 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2290 MiB |  10026 MiB | 210435 GiB | 210433 GiB |\n","|       from large pool |   1838 MiB |   9560 MiB | 210072 GiB | 210070 GiB |\n","|       from small pool |    452 MiB |    486 MiB |    362 GiB |    362 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1655 MiB |   1860 MiB | 364936 GiB | 364934 GiB |\n","|       from large pool |   1650 MiB |   1850 MiB | 362065 GiB | 362063 GiB |\n","|       from small pool |      5 MiB |     19 MiB |   2870 GiB |   2870 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   33608 K  |   33592 K  |\n","|       from large pool |      98    |     248    |   20010 K  |   20010 K  |\n","|       from small pool |   16251    |   16398    |   13598 K  |   13581 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   33608 K  |   33592 K  |\n","|       from large pool |      98    |     248    |   20010 K  |   20010 K  |\n","|       from small pool |   16251    |   16398    |   13598 K  |   13581 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     244    |     328    |    1890 K  |    1889 K  |\n","|       from large pool |      18    |      95    |    1704 K  |    1704 K  |\n","|       from small pool |     226    |     243    |     185 K  |     185 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      86    |     173    |   16743 K  |   16743 K  |\n","|       from large pool |      27    |      84    |   11422 K  |   11422 K  |\n","|       from small pool |      59    |     107    |    5320 K  |    5320 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:279/7698 batch_size:250\n","Next token prediction. step:104/108 batch:279/7698 epoch:2/10\n","full seq: Greek art director Vassilis Fotopoulos passed away at the age of 72 in Athens on Sunday (January 14th).Ģġġġġ\n","pref seq: Greek art director Vassilis Fotopoulos passed away at the age of 72 in Athens on Sunday (January 14th).Ģ\n","next tok:                                                                                                        ġ\n","pred tok:                                                                                                        Ģ\n","Completed batch.\n","epoch:2/10 batch:279/7698 batch_size:250 loss:1.5573288202285767 time_for_batch_instance:113.85029602050781 total_batch_time:27648.625736951828 running_batch_average:99.09901697832197\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 649239 KiB |   9498 MiB |   1001 TiB |   1001 TiB |\n","|       from large pool | 191789 KiB |   9046 MiB |    999 TiB |    999 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 649239 KiB |   9498 MiB |   1001 TiB |   1001 TiB |\n","|       from large pool | 191789 KiB |   9046 MiB |    999 TiB |    999 TiB |\n","|       from small pool | 457450 KiB |    484 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |   9479 MiB |    999 TiB |    999 TiB |\n","|       from large pool | 189056 KiB |   9031 MiB |    996 TiB |    996 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2290 MiB |  10026 MiB | 211168 GiB | 211165 GiB |\n","|       from large pool |   1838 MiB |   9560 MiB | 210803 GiB | 210802 GiB |\n","|       from small pool |    452 MiB |    486 MiB |    364 GiB |    363 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1655 MiB |   1860 MiB | 366132 GiB | 366131 GiB |\n","|       from large pool |   1650 MiB |   1850 MiB | 363248 GiB | 363247 GiB |\n","|       from small pool |      5 MiB |     19 MiB |   2884 GiB |   2884 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   33747 K  |   33731 K  |\n","|       from large pool |      98    |     248    |   20091 K  |   20091 K  |\n","|       from small pool |   16251    |   16398    |   13656 K  |   13640 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   33747 K  |   33731 K  |\n","|       from large pool |      98    |     248    |   20091 K  |   20091 K  |\n","|       from small pool |   16251    |   16398    |   13656 K  |   13640 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     244    |     328    |    1898 K  |    1897 K  |\n","|       from large pool |      18    |      95    |    1711 K  |    1711 K  |\n","|       from small pool |     226    |     243    |     186 K  |     186 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      86    |     173    |   16818 K  |   16818 K  |\n","|       from large pool |      27    |      84    |   11475 K  |   11475 K  |\n","|       from small pool |      59    |     107    |    5342 K  |    5342 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:280/7698 batch_size:250\n","Next token prediction. step:61/107 batch:280/7698 epoch:2/10\n","full seq: Selling the state-owned shipyards was among the conditions set by the European Commission.Ģġġġġġġġġġġġġġġġġ\n","pref seq: Selling the state-owned shipyards was among the conditions se\n","next tok:                                                             t\n","pred tok:                                                             w\n","Completed batch.\n","epoch:2/10 batch:280/7698 batch_size:250 loss:1.7371662855148315 time_for_batch_instance:113.27223443984985 total_batch_time:27761.897971391678 running_batch_average:99.14963561211313\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 650166 KiB |   9423 MiB |   1005 TiB |   1005 TiB |\n","|       from large pool | 192716 KiB |   8971 MiB |   1002 TiB |   1002 TiB |\n","|       from small pool | 457450 KiB |    483 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 650166 KiB |   9423 MiB |   1005 TiB |   1005 TiB |\n","|       from large pool | 192716 KiB |   8971 MiB |   1002 TiB |   1002 TiB |\n","|       from small pool | 457450 KiB |    483 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |   9396 MiB |   1002 TiB |   1002 TiB |\n","|       from large pool | 189056 KiB |   8948 MiB |   1000 TiB |   1000 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1350 MiB |   9968 MiB | 211924 GiB | 211923 GiB |\n","|       from large pool |    896 MiB |   9502 MiB | 211559 GiB | 211558 GiB |\n","|       from small pool |    454 MiB |    486 MiB |    365 GiB |    365 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 732234 KiB |   1681 MiB | 367283 GiB | 367282 GiB |\n","|       from large pool | 724788 KiB |   1669 MiB | 364386 GiB | 364385 GiB |\n","|       from small pool |   7446 KiB |     20 MiB |   2897 GiB |   2897 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   33885 K  |   33869 K  |\n","|       from large pool |      98    |     248    |   20171 K  |   20171 K  |\n","|       from small pool |   16251    |   16398    |   13714 K  |   13697 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   33885 K  |   33869 K  |\n","|       from large pool |      98    |     248    |   20171 K  |   20171 K  |\n","|       from small pool |   16251    |   16398    |   13714 K  |   13697 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     254    |     343    |    1906 K  |    1906 K  |\n","|       from large pool |      27    |     110    |    1719 K  |    1719 K  |\n","|       from small pool |     227    |     243    |     187 K  |     186 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      83    |     177    |   16895 K  |   16894 K  |\n","|       from large pool |      26    |      87    |   11529 K  |   11529 K  |\n","|       from small pool |      57    |     107    |    5365 K  |    5365 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:281/7698 batch_size:250\n","Next token prediction. step:8/107 batch:281/7698 epoch:2/10\n","full seq: The event attracted over 30 competitors, including representatives of the Serbian and Albanian armies.Ģġġġġ\n","pref seq: The even\n","next tok:        t\n","pred tok:        w\n","Completed batch.\n","epoch:2/10 batch:281/7698 batch_size:250 loss:1.1894011497497559 time_for_batch_instance:113.15678715705872 total_batch_time:27875.054758548737 running_batch_average:99.19948312650796\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 650353 KiB |   9422 MiB |   1008 TiB |   1008 TiB |\n","|       from large pool | 192903 KiB |   8971 MiB |   1005 TiB |   1005 TiB |\n","|       from small pool | 457450 KiB |    483 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 650353 KiB |   9422 MiB |   1008 TiB |   1008 TiB |\n","|       from large pool | 192903 KiB |   8971 MiB |   1005 TiB |   1005 TiB |\n","|       from small pool | 457450 KiB |    483 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |   9396 MiB |   1005 TiB |   1005 TiB |\n","|       from large pool | 189056 KiB |   8948 MiB |   1003 TiB |   1003 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1288 MiB |   9966 MiB | 212680 GiB | 212679 GiB |\n","|       from large pool |    834 MiB |   9500 MiB | 212314 GiB | 212313 GiB |\n","|       from small pool |    454 MiB |    486 MiB |    366 GiB |    366 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 668559 KiB |    879 MiB | 368423 GiB | 368423 GiB |\n","|       from large pool | 661113 KiB |    873 MiB | 365513 GiB | 365512 GiB |\n","|       from small pool |   7446 KiB |     21 MiB |   2910 GiB |   2910 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   34023 K  |   34006 K  |\n","|       from large pool |      98    |     248    |   20251 K  |   20251 K  |\n","|       from small pool |   16251    |   16398    |   13771 K  |   13755 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   34023 K  |   34006 K  |\n","|       from large pool |      98    |     248    |   20251 K  |   20251 K  |\n","|       from small pool |   16251    |   16398    |   13771 K  |   13755 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     252    |     343    |    1914 K  |    1914 K  |\n","|       from large pool |      25    |     109    |    1726 K  |    1726 K  |\n","|       from small pool |     227    |     243    |     187 K  |     187 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      82    |     176    |   16971 K  |   16971 K  |\n","|       from large pool |      25    |      86    |   11584 K  |   11584 K  |\n","|       from small pool |      57    |     107    |    5387 K  |    5387 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:282/7698 batch_size:250\n","Next token prediction. step:6/107 batch:282/7698 epoch:2/10\n","full seq: Implementation may begin as early as November 1st and will be monitored by the EU, Serbia, and Kosovo.Ģġġġġ\n","pref seq: Implem\n","next tok:      e\n","pred tok:      w\n","Completed batch.\n","epoch:2/10 batch:282/7698 batch_size:250 loss:1.343017578125 time_for_batch_instance:113.23293399810791 total_batch_time:27988.287692546844 running_batch_average:99.24924713669094\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 650479 KiB |   9423 MiB |   1011 TiB |   1011 TiB |\n","|       from large pool | 193029 KiB |   8972 MiB |   1009 TiB |   1009 TiB |\n","|       from small pool | 457450 KiB |    483 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 650479 KiB |   9423 MiB |   1011 TiB |   1011 TiB |\n","|       from large pool | 193029 KiB |   8972 MiB |   1009 TiB |   1009 TiB |\n","|       from small pool | 457450 KiB |    483 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |   9396 MiB |   1009 TiB |   1009 TiB |\n","|       from large pool | 189056 KiB |   8948 MiB |   1006 TiB |   1006 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1262 MiB |   9974 MiB | 213436 GiB | 213435 GiB |\n","|       from large pool |    808 MiB |   9508 MiB | 213068 GiB | 213067 GiB |\n","|       from small pool |    454 MiB |    486 MiB |    368 GiB |    367 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 641809 KiB |    890 MiB | 369565 GiB | 369565 GiB |\n","|       from large pool | 634363 KiB |    884 MiB | 366642 GiB | 366641 GiB |\n","|       from small pool |   7446 KiB |     21 MiB |   2923 GiB |   2923 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   34161 K  |   34144 K  |\n","|       from large pool |      98    |     248    |   20331 K  |   20331 K  |\n","|       from small pool |   16251    |   16398    |   13829 K  |   13813 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   34161 K  |   34144 K  |\n","|       from large pool |      98    |     248    |   20331 K  |   20331 K  |\n","|       from small pool |   16251    |   16398    |   13829 K  |   13813 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     252    |     343    |    1922 K  |    1922 K  |\n","|       from large pool |      25    |     109    |    1734 K  |    1734 K  |\n","|       from small pool |     227    |     243    |     188 K  |     188 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      82    |     176    |   17048 K  |   17048 K  |\n","|       from large pool |      25    |      87    |   11639 K  |   11639 K  |\n","|       from small pool |      57    |     107    |    5409 K  |    5409 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:283/7698 batch_size:250\n","Next token prediction. step:59/106 batch:283/7698 epoch:2/10\n","full seq: Since 1971, COST has launched hundreds of initiatives, many of which have already been completed.Ģġġġġġġġġ\n","pref seq: Since 1971, COST has launched hundreds of initiatives, many\n","next tok:                                                            \n","pred tok:                                                           ;\n","Completed batch.\n","epoch:2/10 batch:283/7698 batch_size:250 loss:1.0879218578338623 time_for_batch_instance:112.27607035636902 total_batch_time:28100.563762903214 running_batch_average:99.29527831414563\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 654377 KiB |   9343 MiB |   1015 TiB |   1015 TiB |\n","|       from large pool | 196927 KiB |   8891 MiB |   1012 TiB |   1012 TiB |\n","|       from small pool | 457450 KiB |    483 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 654377 KiB |   9343 MiB |   1015 TiB |   1015 TiB |\n","|       from large pool | 196927 KiB |   8891 MiB |   1012 TiB |   1012 TiB |\n","|       from small pool | 457450 KiB |    483 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 642727 KiB |   9314 MiB |   1012 TiB |   1012 TiB |\n","|       from large pool | 189056 KiB |   8866 MiB |   1009 TiB |   1009 TiB |\n","|       from small pool | 453671 KiB |    480 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2304 MiB |   9846 MiB | 214169 GiB | 214167 GiB |\n","|       from large pool |   1850 MiB |   9380 MiB | 213799 GiB | 213798 GiB |\n","|       from small pool |    454 MiB |    486 MiB |    369 GiB |    369 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1664 MiB |   1914 MiB | 370614 GiB | 370612 GiB |\n","|       from large pool |   1657 MiB |   1907 MiB | 367678 GiB | 367676 GiB |\n","|       from small pool |      7 MiB |     19 MiB |   2936 GiB |   2936 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   16349    |   16520    |   34297 K  |   34281 K  |\n","|       from large pool |      98    |     248    |   20411 K  |   20411 K  |\n","|       from small pool |   16251    |   16398    |   13886 K  |   13870 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   16349    |   16520    |   34297 K  |   34281 K  |\n","|       from large pool |      98    |     248    |   20411 K  |   20411 K  |\n","|       from small pool |   16251    |   16398    |   13886 K  |   13870 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     248    |     330    |    1930 K  |    1930 K  |\n","|       from large pool |      21    |      97    |    1741 K  |    1741 K  |\n","|       from small pool |     227    |     243    |     189 K  |     189 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      79    |     142    |   17101 K  |   17101 K  |\n","|       from large pool |      22    |      53    |   11669 K  |   11669 K  |\n","|       from small pool |      57    |     106    |    5431 K  |    5431 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:284/7698 batch_size:250\n","Next token prediction. step:4/106 batch:284/7698 epoch:2/10\n","full seq: Deputy Prime Minister Dan Nica took over the ministry after Dragnea's resignation. [Gabriel Petrescu]Ģġġġġ\n","pref seq: Depu\n","next tok:    t\n","pred tok:    w\n"]}],"source":["runner = Runner(runner_hyperparameters_name=\"SETimesByT5Vaswani2017Kocmi2018_1\")\n","\n","runner.load_dataset()\n","runner.load_model()\n","runner.load_trainer()\n","runner.run_trainer()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyNflm1BE4ZCnLYeuXLrMyaW"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}