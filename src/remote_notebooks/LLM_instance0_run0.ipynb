{"cells":[{"cell_type":"markdown","metadata":{"id":"XxChZLAKliXg"},"source":["Content taken from GitHub repository hosting the code:\n","\n","https://github.com/matthewjohnson42/umass-cs685-finalproject\n","\n","Substantial modifications made to adapt to Colab training environment."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3574,"status":"ok","timestamp":1715586107128,"user":{"displayName":"Matthew Johnson","userId":"09672185346885346735"},"user_tz":240},"id":"U0NG9bOzleFZ","outputId":"1de40ed9-8075-4077-d7da-4a7299c204d7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]},{"data":{"text/plain":["device(type='cuda')"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["from google.colab import drive\n","\n","import torch\n","import numpy as np\n","\n","import random\n","from typing import Optional\n","import time\n","import os\n","import gc\n","\n","\n","drive.mount('/content/drive', force_remount=True)\n","root_filepath = '/content/drive/MyDrive/CS685-NLP-GroupProject/Code/singleNotebookFromPythonFilesStructure/'\n","is_remote_execution = True\n","\n","torch.device(\"cuda\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sllajv_0n2Vu"},"outputs":[],"source":["SETimesByT5Vaswani2017Kocmi2018_0 = {\n","    'dataset_transformer_name': 'dataset_transformer_setimesbyt5',\n","    'model_name': 'transformer_vaswani2017',\n","    'trainer_name': 'model_trainer_kocmi2018',\n","    'latest_param_filename_tag': '1715672129',\n","    # corresponds to dictionary 'get' calls in the dataset_loader constructor\n","    'dataset_transformer_hyperparameters': {\n","        'sentence_length_min_percentile': 5,\n","        'sentence_length_max_percentile': 95,\n","        'parsed_dataset_filename': 'setimes_parsed-1715586974'\n","    },\n","    # corresponds to dictionary 'get' calls in the model constructor\n","    'model_hyperparameters': {\n","        'd_model': 256,\n","        'nhead': 8,\n","        # number of encoders is 3 times that of decoders, following Xue 2021 - ByT5 - Sec 3.1\n","        'num_encoder_layers': 9,\n","        'num_decoder_layers': 3,\n","        'dim_feedforward': 2048,\n","        'dropout': 0.1,\n","        'activation': torch.nn.functional.relu,\n","        'custom_encoder': None,\n","        'custom_decoder': None,\n","        'layer_norm_eps': 1e-5,\n","        'batch_first': True,\n","        'norm_first': False,\n","        'bias': True,\n","        'device': None,\n","        'dtype': None\n","    },\n","    # corresponds to dictionary 'get' calls in the trainer constructor\n","    'trainer_hyperparameters': {\n","        # optimization and lr schedule following Kocmi 2018 - Trivial TL - Sec 3\n","        'optimizer_name': 'Adam',\n","        'lr_scheduler_name': 'ExponentialLR',\n","        'initial_lr': 0.001,\n","        'exp_decay': 0.5,\n","        'epochs': 10,\n","        'epoch_starting_index': 1,\n","        'batch_size_limit': 175,\n","        'element_difference_limit': 19,\n","        'batch_starting_index': 766\n","    }\n","}\n","\n","SETimesByT5Vaswani2017Kocmi2018_1 = {\n","    'dataset_transformer_name': 'dataset_transformer_setimesbyt5',\n","    'model_name': 'transformer_vaswani2017',\n","    'trainer_name': 'model_trainer_kocmi2018',\n","    'latest_param_filename_tag': '1715672186',\n","    # corresponds to dictionary 'get' calls in the dataset_loader constructor\n","    'dataset_transformer_hyperparameters': {\n","        'sentence_length_min_percentile': 5,\n","        'sentence_length_max_percentile': 95,\n","        'parsed_dataset_filename': 'setimes_parsed-1715586974'\n","    },\n","    # corresponds to dictionary 'get' calls in the model constructor\n","    'model_hyperparameters': {\n","        'd_model': 256,\n","        'nhead': 8,\n","        # number of encoders is 3 times that of decoders, following Xue 2021 - ByT5 - Sec 3.1\n","        'num_encoder_layers': 9,\n","        'num_decoder_layers': 3,\n","        'dim_feedforward': 1796,\n","        'dropout': 0.1,\n","        'activation': torch.nn.functional.relu,\n","        'custom_encoder': None,\n","        'custom_decoder': None,\n","        'layer_norm_eps': 1e-5,\n","        'batch_first': True,\n","        'norm_first': False,\n","        'bias': True,\n","        'device': None,\n","        'dtype': None\n","    },\n","    # corresponds to dictionary 'get' calls in the trainer constructor\n","    'trainer_hyperparameters': {\n","        # optimization and lr schedule following Kocmi 2018 - Trivial TL - Sec 3\n","        'optimizer_name': 'Adam',\n","        'lr_scheduler_name': 'ExponentialLR',\n","        'initial_lr': 0.001,\n","        'exp_decay': 0.5,\n","        'epochs': 10,\n","        'epoch_starting_index': 2,\n","        'batch_size_limit': 250,\n","        'element_difference_limit': 19,\n","        'batch_starting_index': 0\n","    }\n","}\n","\n","SETimesByT5Vaswani2017Kocmi2018_2 = {\n","    'dataset_transformer_name': 'dataset_transformer_setimesbyt5',\n","    'model_name': 'transformer_vaswani2017',\n","    'trainer_name': 'model_trainer_kocmi2018',\n","    'latest_param_filename_tag': '1715672061',\n","    # corresponds to dictionary 'get' calls in the dataset_loader constructor\n","    'dataset_transformer_hyperparameters': {\n","        'sentence_length_min_percentile': 5,\n","        'sentence_length_max_percentile': 95,\n","        'parsed_dataset_filename': 'setimes_parsed-1715586293'\n","    },\n","    # corresponds to dictionary 'get' calls in the model constructor\n","    'model_hyperparameters': {\n","        'd_model': 128,\n","        'nhead': 8,\n","        # number of encoders is 3 times that of decoders, following Xue 2021 - ByT5 - Sec 3.1\n","        'num_encoder_layers': 9,\n","        'num_decoder_layers': 3,\n","        'dim_feedforward': 1024,\n","        'dropout': 0.1,\n","        'activation': torch.nn.functional.relu,\n","        'custom_encoder': None,\n","        'custom_decoder': None,\n","        'layer_norm_eps': 1e-5,\n","        'batch_first': True,\n","        'norm_first': False,\n","        'bias': True,\n","        'device': None,\n","        'dtype': None\n","    },\n","    # corresponds to dictionary 'get' calls in the trainer constructor\n","    'trainer_hyperparameters': {\n","        # optimization and lr schedule following Kocmi 2018 - Trivial TL - Sec 3\n","        'optimizer_name': 'Adam',\n","        'lr_scheduler_name': 'ExponentialLR',\n","        'initial_lr': 0.001,\n","        'exp_decay': 0.5,\n","        'epochs': 10,\n","        'epoch_starting_index': 2,\n","        'batch_size_limit': 400,\n","        'element_difference_limit': 19,\n","        'batch_starting_index': 0\n","    }\n","}\n","\n","loss_weights_0 = torch.tensor([0, 0, 0.244293498, 0.354252208, 0.119055746, 0.129490827, 0.234447, 0.331966255, 0.062493498, 0.200436672, 0.128134531, 0.115730135, 0.114789455, 0.111928721, 0.120232896, 0.172708905, 0.091552235, 0.18382728, 0.167772254, 0.221570123, 0.26933557, 0.207267199, 0.161156936, 0.163208063, 0.206129376, 0.1923278, 0.246448966, 0.309805116, 0.312319847, 0.341492611, 0.287077958, 0.317765776, 0.282694925, 0.328107375, 0.305618951, 0.342956521, 0.33013427, 0.36810305, 0.29995848, 0.39787945, 0.36195021, 0.231575726, 0.238716465, 0.228047462, 0.589442629, 0.428540415, 0.349514641, 0.428583838, 0.372321337, 0.35910363, 0.314836573, 0.359830778, 0.329628544, 0.358553271, 0.38731315, 0.301171514, 0.414866271, 0.454463773, 0.410552656, 0.418645272, 0.489374491, 0.60674051, 0.415410876, 0.387694004, 0.469862412, 0.387466491, 0.404244134, 0.410692024, 0.3650963, 0.328332631, 0.362047807, 0.390990331, 0.407611852, 0.353090879, 0.519082435, 0.465516001, 0.382984849, 0.382904558, 0.417591599, 0.47406963, 0.513595183, 0.561900207, 0.600687916, 0.552947486, 0.672534847, 0.775971182, 0.728910416, 0.783069437, 0.726598021, 0.870987145, 0.761128877, 0.716818395, 0.708372474, 0.70507743, 0.731312344, 0.718124592, 0.931839821, 0.675783865, 0.863679642, 0.79786095, 0.870987145, 0.888835536, 0.845831251, 0.845831251, 0.870987145, 0.831986963, 0.817320914, 0.888835536, 0.82798286, 0.931839821, 0.900147142, 0.91399143, 0.91399143, 0.956995715, 0.931839821, 1, 0.900147142, 0.870987145, 0.870987145, 1, 0.900147142, 0.888835536, 0.956995715, 0.824221583, 1, 1, 0.956995715, 1, 0.931839821, 0.931839821, 0.956995715, 0.956995715, 0.956995715, 0.888835536, 0.931839821, 1, 0.900147142, 0.91399143, 0.956995715, 0.956995715, 0.956995715, 1, 1, 1, 0.900147142, 0.931839821, 0.900147142, 0.931839821, 0.956995715, 0.91399143, 1, 0.956995715, 1, 1, 1, 1, 1, 0.956995715, 1, 1, 1, 1, 1, 1, 1, 0.931839821, 1, 0.956995715, 1, 1, 0.956995715])\n","loss_weights_1 = torch.tensor([0, 0, 0.283786926, 0.387999164, 0.165094134, 0.174983875, 0.274455009, 0.366877881, 0.111487844, 0.242222071, 0.173698459, 0.16194232, 0.1610508, 0.158339569, 0.166209765, 0.215943364, 0.139027964, 0.226480689, 0.211264704, 0.262251081, 0.307520293, 0.248695632, 0.204995104, 0.206939038, 0.247617272, 0.23453697, 0.285829749, 0.345874889, 0.3482582, 0.375906387, 0.324335459, 0.353419523, 0.320181484, 0.363220667, 0.341907494, 0.377293793, 0.365141636, 0.401126157, 0.336542841, 0.429346435, 0.395294867, 0.271733788, 0.27850135, 0.268389913, 0.610898469, 0.458405049, 0.383509184, 0.458446203, 0.405123996, 0.39259705, 0.350643401, 0.393286196, 0.36466234, 0.392075452, 0.419332333, 0.337692481, 0.44544552, 0.482973645, 0.441357336, 0.449027029, 0.51605992, 0.627292358, 0.445961663, 0.419693282, 0.497567547, 0.419477659, 0.435378499, 0.44148942, 0.398276541, 0.363434152, 0.395387363, 0.422817343, 0.438570219, 0.386898527, 0.544215318, 0.493448281, 0.415230229, 0.415154135, 0.448028421, 0.501554895, 0.539014832, 0.584795422, 0.621556075, 0.576310573, 0.689648265, 0.78767899, 0.743077631, 0.794406288, 0.740886083, 0.877729392, 0.773612348, 0.731617543, 0.723613008, 0.720490164, 0.745354034, 0.732855478, 0.93540189, 0.692727489, 0.870803781, 0.808424792, 0.877729392, 0.894645021, 0.853888152, 0.853888152, 0.877729392, 0.84076737, 0.826867773, 0.894645021, 0.836972522, 0.93540189, 0.90536548, 0.918486261, 0.918486261, 0.959243131, 0.93540189, 1, 0.90536548, 0.877729392, 0.877729392, 1, 0.90536548, 0.894645021, 0.959243131, 0.833407811, 1, 1, 0.959243131, 1, 0.93540189, 0.93540189, 0.959243131, 0.959243131, 0.959243131, 0.894645021, 0.93540189, 1, 0.90536548, 0.918486261, 0.959243131, 0.959243131, 0.959243131, 1, 1, 1, 0.90536548, 0.93540189, 0.90536548, 0.93540189, 0.959243131, 0.918486261, 1, 0.959243131, 1, 1, 1, 1, 1, 0.959243131, 1, 1, 1, 1, 1, 1, 1, 0.93540189, 1, 0.959243131, 1, 1, 0.959243131])\n","\n","english_char_mappings = {\n","    ord(\" \"): ord(\" \"),\n","    ord(\"e\"): ord(\"e\"),\n","    ord(\"t\"): ord(\"t\"),\n","    ord(\"a\"): ord(\"a\"),\n","    ord(\"i\"): ord(\"i\"),\n","    ord(\"o\"): ord(\"o\"),\n","    ord(\"n\"): ord(\"n\"),\n","    ord(\"r\"): ord(\"r\"),\n","    ord(\"s\"): ord(\"s\"),\n","    ord(\"h\"): ord(\"h\"),\n","    ord(\"l\"): ord(\"l\"),\n","    ord(\"d\"): ord(\"d\"),\n","    ord(\"c\"): ord(\"c\"),\n","    ord(\"u\"): ord(\"u\"),\n","    ord(\"m\"): ord(\"m\"),\n","    ord(\"p\"): ord(\"p\"),\n","    ord(\"f\"): ord(\"f\"),\n","    ord(\"g\"): ord(\"g\"),\n","    ord(\"y\"): ord(\"y\"),\n","    ord(\"b\"): ord(\"b\"),\n","    ord(\"w\"): ord(\"w\"),\n","    ord(\"v\"): ord(\"v\"),\n","    ord(\",\"): ord(\",\"),\n","    ord(\".\"): ord(\".\"),\n","    ord(\"k\"): ord(\"k\"),\n","    ord(\"T\"): ord(\"T\"),\n","    ord(\"S\"): ord(\"S\"),\n","    ord(\"0\"): ord(\"0\"),\n","    ord(\"A\"): ord(\"A\"),\n","    ord(\"-\"): ord(\"-\"),\n","    ord(\"B\"): ord(\"B\"),\n","    ord(\"M\"): ord(\"M\"),\n","    ord(\"\\\"\"): ord(\"\\\"\"),\n","    ord(\"E\"): ord(\"E\"),\n","    ord(\"P\"): ord(\"P\"),\n","    ord(\"C\"): ord(\"C\"),\n","    ord(\"I\"): ord(\"I\"),\n","    ord(\"1\"): ord(\"1\"),\n","    ord(\"'\"): ord(\"'\"),\n","    ord(\"j\"): ord(\"j\"),\n","    ord(\"2\"): ord(\"2\"),\n","    ord(\"R\"): ord(\"R\"),\n","    ord(\"U\"): ord(\"U\"),\n","    ord(\"K\"): ord(\"K\"),\n","    ord(\"D\"): ord(\"D\"),\n","    ord(\"x\"): ord(\"x\"),\n","    ord(\"H\"): ord(\"H\"),\n","    ord(\"F\"): ord(\"F\"),\n","    ord(\"N\"): ord(\"N\"),\n","    ord(\"G\"): ord(\"G\"),\n","    ord(\"/\"): ord(\"/\"),\n","    ord(\"O\"): ord(\"O\"),\n","    ord(\")\"): ord(\")\"),\n","    ord(\"(\"): ord(\"(\"),\n","    ord(\"9\"): ord(\"9\"),\n","    ord(\"W\"): ord(\"W\"),\n","    ord(\"z\"): ord(\"z\"),\n","    ord(\"5\"): ord(\"5\"),\n","    ord(\"3\"): ord(\"3\"),\n","    ord(\"J\"): ord(\"J\"),\n","    ord(\"4\"): ord(\"4\"),\n","    ord(\"q\"): ord(\"q\"),\n","    ord(\"L\"): ord(\"L\"),\n","    ord(\"6\"): ord(\"6\"),\n","    ord(\"7\"): ord(\"7\"),\n","    ord(\"8\"): ord(\"8\"),\n","    ord(\"V\"): ord(\"V\"),\n","    ord(\"[\"): ord(\"[\"),\n","    ord(\"]\"): ord(\"]\"),\n","    ord(\":\"): ord(\":\"),\n","    ord(\"Z\"): ord(\"Z\"),\n","    ord(\"%\"): ord(\"%\"),\n","    ord(\"Y\"): ord(\"Y\"),\n","    ord(\";\"): ord(\";\"),\n","    ord(\"–\"): ord(\"-\"),\n","    ord(\"?\"): ord(\"?\"),\n","    ord(\"X\"): ord(\"X\"),\n","    ord(\"$\"): ord(\"$\"),\n","    ord(\"’\"): ord(\"'\"),\n","    ord(\"Q\"): ord(\"Q\"),\n","    ord(\"…\"): ord(\"\\u0120\"),\n","    ord(\"!\"): ord(\"\\u0120\"),\n","    ord(\"&\"): ord(\"\\u0120\"),\n","    ord(\"ć\"): ord(\"\\u0120\"),\n","    ord(\"”\"): ord(\"\\\"\"),\n","    ord(\"é\"): ord(\"\\u0120\"),\n","    ord(\"“\"): ord(\"\\\"\"),\n","    ord(\"ı\"): ord(\"\\u0120\"),\n","    ord(\"ü\"): ord(\"\\u0120\"),\n","    ord(\"+\"): ord(\"\\u0120\"),\n","    ord(\"ç\"): ord(\"\\u0120\"),\n","    ord(\"ˈ\"): ord(\"'\"),\n","    ord(\"ö\"): ord(\"\\u0120\"),\n","    ord(\"ë\"): ord(\"\\u0120\"),\n","    ord(\"Ç\"): ord(\"\\u0120\"),\n","    ord(\"ğ\"): ord(\"\\u0120\"),\n","    ord(\"č\"): ord(\"\\u0120\"),\n","    ord(\"š\"): ord(\"\\u0120\"),\n","    ord(\"‘\"): ord(\"'\"),\n","    ord(\"ž\"): ord(\"\\u0120\"),\n","    ord(\"*\"): ord(\"\\u0120\"),\n","    ord(\"ş\"): ord(\"\\u0120\"),\n","    ord(\"б\"): ord(\"\\u0120\"),\n","    ord(\"Š\"): ord(\"\\u0120\"),\n","    ord(\"İ\"): ord(\"\\u0120\"),\n","    ord(\"à\"): ord(\"\\u0120\"),\n","    ord(\"г\"): ord(\"\\u0120\"),\n","    ord(\"ï\"): ord(\"\\u0120\"),\n","    ord(\"Ü\"): ord(\"\\u0120\"),\n","    ord(\"—\"): ord(\"-\"),\n","    ord(\"€\"): ord(\"\\u0120\"),\n","    ord(\"Ö\"): ord(\"\\u0120\"),\n","    ord(\"đ\"): ord(\"\\u0120\"),\n","    ord(\"\\\\\"): ord(\"\\u0120\"),\n","    ord(\"Ι\"): ord(\"\\u0120\"),\n","    ord(\"Α\"): ord(\"A\"),\n","    ord(\"`\"): ord(\"'\"),\n","    ord(\"_\"): ord(\"\\u0120\"),\n","    ord(\"=\"): ord(\"\\u0120\"),\n","    ord(\"@\"): ord(\"\\u0120\"),\n","    ord(\"А\"): ord(\"A\"),\n","    ord(\"ó\"): ord(\"\\u0120\"),\n","    ord(\"í\"): ord(\"\\u0120\"),\n","    ord(\"â\"): ord(\"\\u0120\"),\n","    ord(\"\\x80\"): ord(\"\\u0120\"),\n","    ord(\"Ž\"): ord(\"\\u0120\"),\n","    ord(\"Κ\"): ord(\"K\"),\n","    ord(\"Ο\"): ord(\"O\"),\n","    ord(\"р\"): ord(\"p\"),\n","    ord(\"Ş\"): ord(\"\\u0120\"),\n","    ord(\"á\"): ord(\"\\u0120\"),\n","    ord(\"у\"): ord(\"y\"),\n","    ord(\"\\x93\"): ord(\"\\u0120\"),\n","    ord(\"°\"): ord(\"\\u0120\"),\n","    ord(\"<\"): ord(\"\\u0120\"),\n","    ord(\"½\"): ord(\"\\u0120\"),\n","    ord(\"Т\"): ord(\"T\"),\n","    ord(\"ø\"): ord(\"\\u0120\"),\n","    ord(\"Ε\"): ord(\"E\"),\n","    ord(\"#\"): ord(\"\\u0120\"),\n","    ord(\"ý\"): ord(\"\\u0120\"),\n","    ord(\"л\"): ord(\"\\u0120\"),\n","    ord(\"я\"): ord(\"\\u0120\"),\n","    ord(\"�\"): ord(\"\\u0120\"),\n","    ord(\"º\"): ord(\"\\u0120\"),\n","    ord(\"ä\"): ord(\"\\u0120\"),\n","    ord(\"е\"): ord(\"e\"),\n","    ord(\"о\"): ord(\"o\"),\n","    ord(\"Đ\"): ord(\"\\u0120\"),\n","    ord(\"è\"): ord(\"\\u0120\"),\n","    ord(\"¾\"): ord(\"\\u0120\"),\n","    ord(\"\\x96\"): ord(\"\\u0120\"),\n","    ord(\"æ\"): ord(\"\\u0120\"),\n","    ord(\">\"): ord(\"\\u0120\"),\n","    ord(\"¦\"): ord(\"\\u0120\"),\n","    ord(\"μ\"): ord(\"\\u0120\"),\n","    ord(\"Č\"): ord(\"\\u0120\"),\n","    ord(\"ñ\"): ord(\"\\u0120\"),\n","    ord(\"х\"): ord(\"x\"),\n","    ord(\"М\"): ord(\"M\"),\n","    ord(\"É\"): ord(\"\\u0120\"),\n","    ord(\"±\"): ord(\"\\u0120\"),\n","    ord(\"£\"): ord(\"\\u0120\"),\n","    ord(\"{\"): ord(\"\\u0120\"),\n","    ord(\"}\"): ord(\"\\u0120\"),\n","    ord(\"ъ\"): ord(\"\\u0120\"),\n","    ord(\"а\"): ord(\"\\u0120\"),\n","    ord(\"и\"): ord(\"\\u0120\")\n","}\n","\n","turkish_char_mappings = {\n","    ord(\" \"): ord(\" \"),\n","    ord(\"a\"): ord(\"a\"),\n","    ord(\"e\"): ord(\"e\"),\n","    ord(\"i\"): ord(\"i\"),\n","    ord(\"n\"): ord(\"n\"),\n","    ord(\"r\"): ord(\"r\"),\n","    ord(\"l\"): ord(\"l\"),\n","    ord(\"ı\"): ord(\"ı\"),\n","    ord(\"k\"): ord(\"k\"),\n","    ord(\"d\"): ord(\"d\"),\n","    ord(\"t\"): ord(\"t\"),\n","    ord(\"s\"): ord(\"s\"),\n","    ord(\"u\"): ord(\"u\"),\n","    ord(\"m\"): ord(\"m\"),\n","    ord(\"y\"): ord(\"y\"),\n","    ord(\"o\"): ord(\"o\"),\n","    ord(\"ü\"): ord(\"ü\"),\n","    ord(\"b\"): ord(\"b\"),\n","    ord(\"ş\"): ord(\"ş\"),\n","    ord(\"v\"): ord(\"v\"),\n","    ord(\"g\"): ord(\"g\"),\n","    ord(\"z\"): ord(\"z\"),\n","    ord(\"ç\"): ord(\"ç\"),\n","    ord(\"ğ\"): ord(\"ğ\"),\n","    ord(\".\"): ord(\".\"),\n","    ord(\",\"): ord(\",\"),\n","    ord(\"c\"): ord(\"c\"),\n","    ord(\"h\"): ord(\"h\"),\n","    ord(\"p\"): ord(\"p\"),\n","    ord(\"ö\"): ord(\"ö\"),\n","    ord(\"'\"): ord(\"'\"),\n","    ord(\"B\"): ord(\"B\"),\n","    ord(\"A\"): ord(\"A\"),\n","    ord(\"f\"): ord(\"f\"),\n","    ord(\"S\"): ord(\"S\"),\n","    ord(\"K\"): ord(\"K\"),\n","    ord(\"0\"): ord(\"0\"),\n","    ord(\"\\\"\"): ord(\"\\\"\"),\n","    ord(\"T\"): ord(\"T\"),\n","    ord(\"M\"): ord(\"M\"),\n","    ord(\"1\"): ord(\"1\"),\n","    ord(\"P\"): ord(\"P\"),\n","    ord(\"D\"): ord(\"D\"),\n","    ord(\"H\"): ord(\"H\"),\n","    ord(\"2\"): ord(\"2\"),\n","    ord(\"E\"): ord(\"E\"),\n","    ord(\"R\"): ord(\"R\"),\n","    ord(\"-\"): ord(\"-\"),\n","    ord(\"G\"): ord(\"G\"),\n","    ord(\"j\"): ord(\"j\"),\n","    ord(\"Y\"): ord(\"Y\"),\n","    ord(\"C\"): ord(\"C\"),\n","    ord(\"İ\"): ord(\"İ\"),\n","    ord(\"O\"): ord(\"O\"),\n","    ord(\"/\"): ord(\"/\"),\n","    ord(\"F\"): ord(\"F\"),\n","    ord(\"N\"): ord(\"N\"),\n","    ord(\"9\"): ord(\"9\"),\n","    ord(\"5\"): ord(\"5\"),\n","    ord(\"3\"): ord(\"3\"),\n","    ord(\"I\"): ord(\"I\"),\n","    ord(\"4\"): ord(\"4\"),\n","    ord(\"L\"): ord(\"L\"),\n","    ord(\"6\"): ord(\"6\"),\n","    ord(\")\"): ord(\")\"),\n","    ord(\"(\"): ord(\"(\"),\n","    ord(\"7\"): ord(\"7\"),\n","    ord(\"8\"): ord(\"8\"),\n","    ord(\"U\"): ord(\"U\"),\n","    ord(\"V\"): ord(\"V\"),\n","    ord(\":\"): ord(\":\"),\n","    ord(\"[\"): ord(\"[\"),\n","    ord(\"]\"): ord(\"]\"),\n","    ord(\"’\"): ord(\"'\"),\n","    ord(\"Z\"): ord(\"Z\"),\n","    ord(\"Ç\"): ord(\"Ç\"),\n","    ord(\"J\"): ord(\"J\"),\n","    ord(\"Ü\"): ord(\"Ü\"),\n","    ord(\"Ş\"): ord(\"Ş\"),\n","    ord(\"Ö\"): ord(\"Ö\"),\n","    ord(\"%\"): ord(\"%\"),\n","    ord(\";\"): ord(\";\"),\n","    ord(\"w\"): ord(\"w\"),\n","    ord(\"W\"): ord(\"W\"),\n","    ord(\"â\"): ord(\"â\"),\n","    ord(\"–\"): ord(\"-\"),\n","    ord(\"?\"): ord(\"?\"),\n","    ord(\"x\"): ord(\"x\"),\n","    ord(\"“\"): ord(\"\\\"\"),\n","    ord(\"”\"): ord(\"\\\"\"),\n","    ord(\"X\"): ord(\"X\"),\n","    ord(\"q\"): ord(\"q\"),\n","    ord(\"î\"): ord(\"\\u0120\"),\n","    ord(\"&\"): ord(\"\\u0120\"),\n","    ord(\"!\"): ord(\"\\u0120\"),\n","    ord(\"ð\"): ord(\"\\u0120\"),\n","    ord(\"Q\"): ord(\"\\u0120\"),\n","    ord(\"+\"): ord(\"\\u0120\"),\n","    ord(\"þ\"): ord(\"\\u0120\"),\n","    ord(\"‘\"): ord(\"'\"),\n","    ord(\"é\"): ord(\"\\u0120\"),\n","    ord(\"º\"): ord(\"\\u0120\"),\n","    ord(\"ë\"): ord(\"\\u0120\"),\n","    ord(\"…\"): ord(\"\\u0120\"),\n","    ord(\"б\"): ord(\"\\u0120\"),\n","    ord(\"*\"): ord(\"\\u0120\"),\n","    ord(\"=\"): ord(\"\\u0120\"),\n","    ord(\"`\"): ord(\"'\"),\n","    ord(\"ć\"): ord(\"\\u0120\"),\n","    ord(\"û\"): ord(\"\\u0120\"),\n","    ord(\"Ý\"): ord(\"\\u0120\"),\n","    ord(\"г\"): ord(\"\\u0120\"),\n","    ord(\"—\"): ord(\"\\u0120\"),\n","    ord(\"\\\\\"): ord(\"\\u0120\"),\n","    ord(\"°\"): ord(\"\\u0120\"),\n","    ord(\"@\"): ord(\"\\u0120\"),\n","    ord(\"č\"): ord(\"\\u0120\"),\n","    ord(\"ó\"): ord(\"\\u0120\"),\n","    ord(\"š\"): ord(\"\\u0120\"),\n","    ord(\"р\"): ord(\"\\u0120\"),\n","    ord(\"_\"): ord(\"\\u0120\"),\n","    ord(\"{\"): ord(\"\\u0120\"),\n","    ord(\"#\"): ord(\"\\u0120\"),\n","    ord(\"^\"): ord(\"\\u0120\"),\n","    ord(\">\"): ord(\"\\u0120\"),\n","    ord(\"$\"): ord(\"\\u0120\"),\n","    ord(\"đ\"): ord(\"\\u0120\"),\n","    ord(\"í\"): ord(\"\\u0120\"),\n","    ord(\"ø\"): ord(\"\\u0120\"),\n","    ord(\"Š\"): ord(\"\\u0120\"),\n","    ord(\"ž\"): ord(\"\\u0120\"),\n","    ord(\"Þ\"): ord(\"\\u0120\"),\n","    ord(\"л\"): ord(\"\\u0120\"),\n","    ord(\"я\"): ord(\"\\u0120\"),\n","    ord(\"}\"): ord(\"\\u0120\"),\n","    ord(\"±\"): ord(\"\\u0120\"),\n","    ord(\"½\"): ord(\"\\u0120\"),\n","    ord(\"¾\"): ord(\"\\u0120\"),\n","    ord(\"ª\"): ord(\"\\u0120\"),\n","    ord(\"á\"): ord(\"\\u0120\"),\n","    ord(\"É\"): ord(\"\\u0120\"),\n","    ord(\"è\"): ord(\"\\u0120\"),\n","    ord(\"Ğ\"): ord(\"\\u0120\"),\n","    ord(\"ï\"): ord(\"\\u0120\"),\n","    ord(\"ñ\"): ord(\"\\u0120\"),\n","    ord(\"ý\"): ord(\"\\u0120\"),\n","    ord(\"Ž\"): ord(\"\\u0120\"),\n","    ord(\"μ\"): ord(\"\\u0120\"),\n","    ord(\"а\"): ord(\"\\u0120\"),\n","    ord(\"и\"): ord(\"\\u0120\"),\n","    ord(\"у\"): ord(\"\\u0120\"),\n","    ord(\"х\"): ord(\"\\u0120\"),\n","    ord(\"ъ\"): ord(\"\\u0120\"),\n","}\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RJAevV6XnuW1"},"outputs":[],"source":["class DatasetHolder:\n","\n","    def __init__(self):\n","        self.unknown_vocabulary_type = None\n","        self.padding_vocabulary_type = None\n","        self.end_of_sequence_type = None\n","        self.target_vocab = None\n","        self.target_vocab_array = None\n","        self.target_vocab_counts = None\n","        self.source_vocab = None\n","        self.source_vocab_array = None\n","        self.source_vocab_counts = None\n","        self.target_encodings = None\n","        self.target_encodings_train = None\n","        self.target_encodings_test = None\n","        self.source_encodings = None\n","        self.source_encodings_train = None\n","        self.source_encodings_test = None\n","        self.max_src_seq_obs = 0\n","        self.max_tgt_seq_obs = 0\n","\n","    def get_unknown_vocabulary_type(self):\n","        return self.unknown_vocabulary_type\n","\n","    def set_unknown_vocabulary_type(self, unknown_vocabulary_type):\n","        self.unknown_vocabulary_type = unknown_vocabulary_type\n","\n","    def get_padding_vocabulary_type(self):\n","        return self.padding_vocabulary_type\n","\n","    def set_padding_vocabulary_type(self, padding_vocabulary_type):\n","        self.padding_vocabulary_type = padding_vocabulary_type\n","\n","    def get_end_of_sequence_vocabulary_type(self):\n","        return self.end_of_sequence_type\n","\n","    def set_end_of_sequence_vocabulary_type(self, end_of_sequence_type):\n","        self.end_of_sequence_type = end_of_sequence_type\n","\n","    def get_target_vocab(self):\n","        return self.target_vocab\n","\n","    def set_target_vocab(self, target_vocab):\n","        self.target_vocab = target_vocab\n","\n","    def get_target_vocab_numpy(self):\n","        if self.target_vocab_array is None:\n","            self.target_vocab_array = np.array(self.target_vocab)\n","        return self.target_vocab_array\n","\n","    def get_target_vocab_counts(self):\n","        return self.target_vocab_counts\n","\n","    def set_target_vocab_counts(self, target_vocab_counts):\n","        self.target_vocab_counts = target_vocab_counts\n","\n","    def get_source_vocab(self):\n","        return self.source_vocab\n","\n","    def set_source_vocab(self, source_vocab):\n","        self.source_vocab = source_vocab\n","\n","    def get_source_vocab_numpy(self):\n","        if self.source_vocab_array is None:\n","            self.source_vocab_array = np.array(self.source_vocab)\n","        return self.source_vocab_array\n","\n","    def get_source_vocab_counts(self):\n","        return self.source_vocab_counts\n","\n","    def set_source_vocab_counts(self, source_vocab_counts):\n","        self.source_vocab_counts = source_vocab_counts\n","\n","    def get_target_encodings(self):\n","        return self.target_encodings\n","\n","    def set_target_encodings(self, target_encodings):\n","        del self.target_encodings\n","        self.target_encodings = target_encodings\n","        if is_remote_execution:\n","            torch.cuda.empty_cache()\n","\n","    def get_source_encodings(self):\n","        return self.source_encodings\n","\n","    def set_source_encodings(self, source_encodings):\n","        del self.source_encodings\n","        self.source_encodings = source_encodings\n","        if is_remote_execution:\n","            torch.cuda.empty_cache()\n","\n","    def get_target_encodings_train(self):\n","        return self.target_encodings_train\n","\n","    def set_target_encodings_train(self, target_encodings_train):\n","        del self.target_encodings_train\n","        self.target_encodings_train = target_encodings_train\n","        if is_remote_execution:\n","            torch.cuda.empty_cache()\n","\n","    def get_source_encodings_train(self):\n","        return self.source_encodings_train\n","\n","    def set_source_encodings_train(self, source_encodings_train):\n","        del self.source_encodings_train\n","        self.source_encodings_train = source_encodings_train\n","        if is_remote_execution:\n","            torch.cuda.empty_cache()\n","\n","    def get_target_encodings_test(self):\n","        return self.target_encodings_test\n","\n","    def set_target_encodings_test(self, target_encodings_test):\n","        del self.target_encodings_test\n","        self.target_encodings_test = target_encodings_test\n","        if is_remote_execution:\n","            torch.cuda.empty_cache()\n","\n","    def get_source_encodings_test(self):\n","        return self.source_encodings_test\n","\n","    def set_source_encodings_test(self, source_encodings_test):\n","        del self.source_encodings_test\n","        self.source_encodings_test = source_encodings_test\n","        if is_remote_execution:\n","            torch.cuda.empty_cache()\n","\n","    def get_max_src_seq_obs(self):\n","        return self.max_src_seq_obs\n","\n","    def set_max_src_seq_obs(self, max_src_seq_obs):\n","        self.max_src_seq_obs = max_src_seq_obs\n","\n","    def get_max_tgt_seq_obs(self):\n","        return self.max_tgt_seq_obs\n","\n","    def set_max_tgt_seq_obs(self, max_tgt_seq_obs):\n","        self.max_tgt_seq_obs = max_tgt_seq_obs\n","\n","\n","# class name matches file name\n","class dataset_transformer_setimesbyt5():\n","\n","    def __init__(self,\n","                 datasets_directory=root_filepath+\"resources\",\n","                 raw_dataset_directory=\"raw_datasets/setimes\",\n","                 parsed_dataset_directory=\"parsed_datasets/setimes\",\n","                 ids_filename='SETIMES.en-tr.ids',\n","                 en_filename='SETIMES.en-tr.en',\n","                 tr_filename='SETIMES.en-tr.tr',\n","                 dataset_hyperparameters=None):\n","        self.datasets_directory = datasets_directory\n","        self.raw_dataset_directory = raw_dataset_directory\n","        self.parsed_dataset_directory = parsed_dataset_directory\n","        self.ids_filename = ids_filename\n","        self.en_filename = en_filename\n","        self.tr_filename = tr_filename\n","        self.parsed_dataset_filename = None\n","        if 'parsed_dataset_filename' in dataset_hyperparameters:\n","            self.parsed_dataset_filename = dataset_hyperparameters['parsed_dataset_filename']\n","        self.sentence_length_min_percentile = None\n","        if 'sentence_length_min_percentile' in dataset_hyperparameters:\n","            self.sentence_length_min_percentile = dataset_hyperparameters['sentence_length_min_percentile']\n","        self.sentence_length_max_percentile = None\n","        if 'sentence_length_max_percentile' in dataset_hyperparameters:\n","            self.sentence_length_max_percentile = dataset_hyperparameters['sentence_length_max_percentile']\n","\n","\n","    def read_dataset(self):\n","        dataset_holder = None\n","        if self.parsed_dataset_filename is not None:\n","            dataset_holder = torch.load(self.datasets_directory + \"/\"\n","                                        + self.parsed_dataset_directory + \"/\"\n","                                        + self.parsed_dataset_filename)\n","        else:\n","            target_sentences = list()\n","            source_sentences = list()\n","            index_file = open(self.datasets_directory + \"/\" + self.raw_dataset_directory + \"/\" + self.ids_filename)\n","            en_file = open(self.datasets_directory + \"/\" + self.raw_dataset_directory + \"/\" + self.en_filename)\n","            tr_file = open(self.datasets_directory + \"/\" + self.raw_dataset_directory + \"/\" + self.tr_filename)\n","            indices = list()\n","            en_sentences = list()\n","            tr_sentences = list()\n","            line_number = 1\n","            for line in index_file:\n","                line_segments = line.strip().split()\n","                if len(line_segments) != 4:\n","                    print(\"Line segmentation error on line \" + str(line_number))\n","                    print(\"Content: \" + line)\n","                    continue\n","                if line_segments[0].startswith(\"en\") and line_segments[1].startswith(\"tr\"):\n","                    indices.append((int(line_segments[2]), int(line_segments[3])))\n","                elif line_segments[0].startswith(\"tr\") and line_segments[1].startswith(\"en\"):\n","                    indices.append((int(line_segments[3]), int(line_segments[2])))\n","                else:\n","                    print(\"Index parsing error on line \" + str(line_number))\n","                    print(\"Content: \" + line)\n","                    continue\n","                line_number = line_number + 1\n","            for line in en_file:\n","                en_sentences.append(line.strip())\n","            for line in tr_file:\n","                tr_sentences.append(line.strip())\n","            for index in indices:\n","                target_sentences.append(en_sentences[index[0] - 1])\n","                source_sentences.append(tr_sentences[index[1] - 1])\n","            target_sentence_lengths = list()\n","            for sentence in target_sentences:\n","                target_sentence_lengths.append(len(sentence))\n","            source_sentence_lengths = list()\n","            for sentence in source_sentences:\n","                source_sentence_lengths.append(len(sentence))\n","            target_sentences_length_limited = list()\n","            source_sentences_length_limited = list()\n","            target_min_len = int(np.percentile(sorted(target_sentence_lengths), self.sentence_length_min_percentile))\n","            target_max_len = int(np.percentile(sorted(target_sentence_lengths), self.sentence_length_max_percentile))\n","            source_min_len = int(np.percentile(sorted(source_sentence_lengths), self.sentence_length_min_percentile))\n","            source_max_len = int(np.percentile(sorted(source_sentence_lengths), self.sentence_length_max_percentile))\n","            max_src_seq_obs = 0\n","            max_tgt_seq_obs = 0\n","            for i in range(0, len(target_sentences)):\n","                if (len(target_sentences[i]) > target_min_len and len(target_sentences[i]) <= target_max_len\n","                        and len(source_sentences[i]) > source_min_len and len(source_sentences[i]) <= source_max_len):\n","                    if len(source_sentences[i]) > max_src_seq_obs:\n","                        max_src_seq_obs = len(source_sentences[i])\n","                    if len(target_sentences[i]) > max_tgt_seq_obs:\n","                        max_tgt_seq_obs = len(target_sentences[i])\n","                    target_sentences_length_limited.append(target_sentences[i].translate(english_char_mappings))\n","                    source_sentences_length_limited.append(source_sentences[i].translate(turkish_char_mappings))\n","            dataset_holder = DatasetHolder()\n","            dataset_holder.set_max_src_seq_obs(max_src_seq_obs)\n","            dataset_holder.set_max_tgt_seq_obs(max_tgt_seq_obs)\n","            # encode to Pytorch tensors as raw UTF-8 character vocabulary\n","            # method replicated from Xue 2021 - ByT5 - Introduction, sec 3.1\n","            unknown_vocabulary_type = \"\\u0120\".encode('utf-8').decode('utf-8')\n","            padding_vocabulary_type = \"\\u0121\".encode('utf-8').decode('utf-8')\n","            end_of_sequence_vocabulary_type = \"\\u0122\".encode('utf-8').decode('utf-8')\n","            dataset_holder.set_unknown_vocabulary_type(unknown_vocabulary_type)\n","            dataset_holder.set_padding_vocabulary_type(padding_vocabulary_type)\n","            dataset_holder.set_end_of_sequence_vocabulary_type(end_of_sequence_vocabulary_type)\n","            target_vocab = list([unknown_vocabulary_type, padding_vocabulary_type, end_of_sequence_vocabulary_type])\n","            source_vocab = list([unknown_vocabulary_type, padding_vocabulary_type, end_of_sequence_vocabulary_type])\n","            target_encodings = list()\n","            source_encodings = list()\n","            for entry in target_sentences_length_limited:\n","                encoding = list()\n","                for character in entry:\n","                    if character not in target_vocab:\n","                        target_vocab.append(character)\n","                    encoding.append(target_vocab.index(character))\n","                encoding.append(target_vocab.index(end_of_sequence_vocabulary_type))\n","                target_encodings.append(torch.tensor(encoding))\n","            for entry in source_sentences_length_limited:\n","                encoding = list()\n","                for character in entry:\n","                    if character not in source_vocab:\n","                        source_vocab.append(character)\n","                    encoding.append(source_vocab.index(character))\n","                encoding.append(target_vocab.index(end_of_sequence_vocabulary_type))\n","                source_encodings.append(torch.tensor(encoding))\n","            # fix vocabulary indices using tuple type\n","            dataset_holder.set_target_vocab(tuple(target_vocab))\n","            dataset_holder.set_target_encodings(target_encodings)\n","            dataset_holder.set_source_vocab(tuple(source_vocab))\n","            dataset_holder.set_source_encodings(source_encodings)\n","            dataset_holder = DatasetUtils.create_dataset_segments(dataset_holder)\n","            torch.save(dataset_holder,\n","                       self.datasets_directory + \"/\" +\n","                       self.parsed_dataset_directory + \"/\" +\n","                       \"setimes_parsed-\" + str(int(time.time())))\n","        return dataset_holder\n","\n","\n","class Utils:\n","\n","    def __init__(self):\n","        pass\n","\n","    @staticmethod\n","    def load_python_object(object_path: str, object_attribute: str):\n","        path_segments = object_path.split('.')\n","        module = __import__(object_path)\n","        for segment in path_segments[1:]:\n","            module = getattr(module, segment)\n","        return getattr(module, object_attribute)\n","\n","\n","class DatasetUtils:\n","\n","    @staticmethod\n","    def shuffle_dataset(dataset_holder: DatasetHolder):\n","        new_source_encodings, new_target_encodings = (\n","            DatasetUtils.shuffle_lists(\n","                dataset_holder.get_source_encodings(),\n","                dataset_holder.get_target_encodings()\n","            )\n","        )\n","        dataset_holder.set_source_encodings(new_source_encodings)\n","        dataset_holder.set_target_encodings(new_target_encodings)\n","        return dataset_holder\n","\n","    @staticmethod\n","    def shuffle_training_dataset(dataset_holder: DatasetHolder):\n","        new_source_encodings, new_target_encodings = (\n","            DatasetUtils.shuffle_lists(\n","                dataset_holder.get_source_encodings_train(),\n","                dataset_holder.get_target_encodings_train()\n","            )\n","        )\n","        dataset_holder.set_source_encodings(new_source_encodings)\n","        dataset_holder.set_target_encodings(new_target_encodings)\n","        return dataset_holder\n","\n","    @staticmethod\n","    def shuffle_test_dataset(dataset_holder: DatasetHolder):\n","        new_source_encodings, new_target_encodings = (\n","            DatasetUtils.shuffle_lists(\n","                dataset_holder.get_source_encodings_test(),\n","                dataset_holder.get_target_encodings_test()\n","            )\n","        )\n","        dataset_holder.set_source_encodings(new_source_encodings)\n","        dataset_holder.set_target_encodings(new_target_encodings)\n","        return dataset_holder\n","\n","    @staticmethod\n","    def shuffle_lists(source_list, target_list):\n","        assert len(source_list) == len(target_list)\n","        list_element_shuffle_indices = list(range(0, len(source_list)))\n","        random.shuffle(list_element_shuffle_indices)\n","        new_source_list = list()\n","        new_target_list = list()\n","        for i in list_element_shuffle_indices:\n","            new_source_list.append(source_list[i])\n","            new_target_list.append(target_list[i])\n","        assert (len(new_source_list) == len(new_target_list)\n","                == len(source_list) == len(target_list))\n","        return new_source_list, new_target_list\n","\n","    @staticmethod\n","    def create_dataset_segments(dataset_holder: DatasetHolder):\n","        split_with_even_target_distribution = False\n","        iteration = 1\n","        best_split_target_encodings = None\n","        best_split_source_encodings = None\n","        best_split_deviation_from_desired = 1\n","        segments = 20\n","        split_size = len(dataset_holder.get_target_encodings()) // segments\n","        train_size = split_size * (segments - 1)\n","        while not split_with_even_target_distribution and iteration <= 100:\n","            segment_attempt_start = time.time()\n","            dataset_holder = DatasetUtils.shuffle_dataset(dataset_holder)\n","            target_encodings = dataset_holder.get_target_encodings()\n","            source_encodings = dataset_holder.get_source_encodings()\n","            train_set_target_enc = target_encodings[0:train_size]\n","            test_set_target_enc = target_encodings[train_size:]\n","            numpy_encodings = list()\n","            for encoding in train_set_target_enc:\n","                numpy_encodings.append(encoding.flatten().numpy())\n","            train_set_target_enc_cts = np.bincount(\n","                np.concatenate([\n","                    np.concatenate(numpy_encodings),\n","                    np.arange(0, 170)\n","                ])\n","            )\n","            numpy_encodings = list()\n","            for encoding in test_set_target_enc:\n","                numpy_encodings.append(encoding.flatten().numpy())\n","            test_set_target_enc_cts = np.bincount(\n","                np.concatenate([\n","                    np.concatenate(numpy_encodings),\n","                    np.arange(0, 170)\n","                ])\n","            )\n","            # terms with probability ~ 1%\n","            total_5 = train_set_target_enc_cts[5] + test_set_target_enc_cts[5]\n","            total_40 = train_set_target_enc_cts[40] + test_set_target_enc_cts[40]\n","            total_42 = train_set_target_enc_cts[42] + test_set_target_enc_cts[42]\n","            # top 3 terms\n","            total_7 = train_set_target_enc_cts[7] + test_set_target_enc_cts[7]\n","            total_15 = train_set_target_enc_cts[15] + test_set_target_enc_cts[15]\n","            total_12 = train_set_target_enc_cts[12] + test_set_target_enc_cts[12]\n","            train_dist_goal = (segments - 1)/segments\n","            test_dist_goal = (1 / segments)\n","            deviation_from_desired = (\n","                    np.abs(((segments - 2)/segments) - (train_set_target_enc_cts[5] / total_5)) +\n","                    np.abs(train_dist_goal - (train_set_target_enc_cts[40] / total_40)) +\n","                    np.abs(train_dist_goal - (train_set_target_enc_cts[42] / total_42)) +\n","                    np.abs(train_dist_goal - (train_set_target_enc_cts[7] / total_7)) +\n","                    np.abs(train_dist_goal - (train_set_target_enc_cts[15] / total_15)) +\n","                    np.abs(train_dist_goal - (train_set_target_enc_cts[12] / total_12)) +\n","                    np.abs(test_dist_goal - (test_set_target_enc_cts[5] / total_5)) +\n","                    np.abs(test_dist_goal - (test_set_target_enc_cts[40] / total_40)) +\n","                    np.abs(test_dist_goal - (test_set_target_enc_cts[42] / total_42)) +\n","                    np.abs(test_dist_goal - (test_set_target_enc_cts[7] / total_7)) +\n","                    np.abs(test_dist_goal - (test_set_target_enc_cts[15] / total_15)) +\n","                    np.abs(test_dist_goal - (test_set_target_enc_cts[12] / total_12))\n","            )\n","            if deviation_from_desired <= 12 * 0.0001:\n","                split_with_even_target_distribution = True\n","                best_split_target_encodings = target_encodings\n","                best_split_source_encodings = source_encodings\n","                print(f\"Found dataset split within tolerance for deviation from uniform distribution over characters\")\n","            if deviation_from_desired < best_split_deviation_from_desired:\n","                best_split_target_encodings = target_encodings\n","                best_split_source_encodings = source_encodings\n","                best_split_deviation_from_desired = deviation_from_desired\n","            segment_attempt_end = time.time()\n","            print(f\"Completed data split attempt. \"\n","                  f\"iteration:{iteration} \"\n","                  f\"best_split_deviation_from_desired:{best_split_deviation_from_desired} \"\n","                  f\"time_to_complete_attempt:{segment_attempt_end-segment_attempt_start}\")\n","            iteration = iteration + 1\n","        best_split_source_encodings_train = best_split_source_encodings[0:train_size]\n","        best_split_target_encodings_train = best_split_target_encodings[0:train_size]\n","        assert len(best_split_source_encodings_train) == len(best_split_target_encodings_train)\n","        train_split_encoding_length_sum_and_encoding_index_pairs = list()\n","        for i in range(0, len(best_split_source_encodings_train)):\n","            train_split_encoding_length_sum_and_encoding_index_pairs.append(\n","                list([\n","                    best_split_source_encodings_train[i].shape[0] + best_split_target_encodings_train[i].shape[0],\n","                    np.abs(best_split_source_encodings_train[i].shape[0] - best_split_target_encodings_train[i].shape[0]),\n","                    i\n","                ])\n","            )\n","        train_split_encoding_length_sum_and_encoding_index_pairs = sorted(\n","            train_split_encoding_length_sum_and_encoding_index_pairs,\n","            key=lambda pair: (pair[0], pair[1])\n","        )\n","        train_source_encs_length_sorted = list()\n","        train_target_encs_length_sorted = list()\n","        for encoding_length_sum_and_encoding_index_pair in train_split_encoding_length_sum_and_encoding_index_pairs:\n","            train_source_encs_length_sorted.append(best_split_source_encodings_train[encoding_length_sum_and_encoding_index_pair[2]])\n","            train_target_encs_length_sorted.append(best_split_target_encodings_train[encoding_length_sum_and_encoding_index_pair[2]])\n","        best_split_source_encodings_test = best_split_source_encodings[train_size:]\n","        best_split_target_encodings_test = best_split_target_encodings[train_size:]\n","        assert len(best_split_source_encodings_test) == len(best_split_target_encodings_test)\n","        test_split_encoding_length_sum_and_encoding_index_pairs = list()\n","        for i in range(0, len(best_split_source_encodings_test)):\n","            test_split_encoding_length_sum_and_encoding_index_pairs.append(\n","                list([\n","                    best_split_source_encodings_test[i].shape[0] + best_split_target_encodings_test[i].shape[0],\n","                    np.abs(best_split_source_encodings_test[i].shape[0] - best_split_target_encodings_test[i].shape[0]),\n","                    i\n","                ])\n","            )\n","        test_split_encoding_length_sum_and_encoding_index_pairs = sorted(\n","            test_split_encoding_length_sum_and_encoding_index_pairs,\n","            key=lambda pair: (pair[0], pair[1])\n","        )\n","        test_source_encs_length_sorted = list()\n","        test_target_encs_length_sorted = list()\n","        for encoding_length_sum_and_encoding_index_pair in test_split_encoding_length_sum_and_encoding_index_pairs:\n","            test_source_encs_length_sorted.append(best_split_source_encodings_test[encoding_length_sum_and_encoding_index_pair[2]])\n","            test_target_encs_length_sorted.append(best_split_target_encodings_test[encoding_length_sum_and_encoding_index_pair[2]])\n","        dataset_holder.set_source_encodings(best_split_source_encodings)\n","        dataset_holder.set_target_encodings(best_split_target_encodings)\n","        dataset_holder.set_source_encodings_train(train_source_encs_length_sorted)\n","        dataset_holder.set_target_encodings_train(train_target_encs_length_sorted)\n","        dataset_holder.set_source_encodings_test(test_source_encs_length_sorted)\n","        dataset_holder.set_target_encodings_test(test_target_encs_length_sorted)\n","        return dataset_holder\n","\n","    # use a dedicated padding token to pad batches as in Xue 2021 - ByT5 - Sec 3.1\n","    @staticmethod\n","    def prepare_batches(\n","            source_encodings,\n","            target_encodings,\n","            source_vocab,\n","            target_vocab,\n","            batch_size_limit: int,\n","            element_difference_limit: int,\n","            padding_value):\n","        assert len(source_encodings) == len(target_encodings)\n","        total_elements = len(source_encodings)\n","        source_encodings_batches = list()\n","        target_encodings_batches = list()\n","        source_encodings_tensors = list()\n","        target_encodings_tensors = list()\n","        encodings_index = 0\n","        while encodings_index < total_elements - 1:\n","            batch_size = 0\n","            batch_end_reached = False\n","            min_source_enc_len = source_encodings[encodings_index+batch_size].shape[0]\n","            max_source_enc_len = source_encodings[encodings_index+batch_size].shape[0]\n","            min_target_enc_len = target_encodings[encodings_index+batch_size].shape[0]\n","            max_target_enc_len = target_encodings[encodings_index+batch_size].shape[0]\n","            while not batch_end_reached:\n","                if (max(abs(source_encodings[encodings_index+batch_size].shape[0] - min_source_enc_len),\n","                        abs(source_encodings[encodings_index+batch_size].shape[0] - max_source_enc_len)) > element_difference_limit\n","                        or max(abs(target_encodings[encodings_index+batch_size].shape[0] - min_target_enc_len),\n","                               abs(target_encodings[encodings_index+batch_size].shape[0] - max_target_enc_len)) > element_difference_limit):\n","                    batch_end_reached = True\n","                if batch_size == batch_size_limit - 1:\n","                    batch_end_reached = True\n","                if encodings_index + batch_size + 1 < total_elements:\n","                    batch_size = batch_size + 1\n","                else:\n","                    batch_end_reached = True\n","            max_src_len_for_batch = 0\n","            max_tgt_len_for_batch = 0\n","            for batch_index in range(0, batch_size):\n","                if len(source_encodings[encodings_index+batch_index]) > max_src_len_for_batch:\n","                    max_src_len_for_batch = len(source_encodings[encodings_index+batch_index])\n","                if len(target_encodings[encodings_index+batch_index]) > max_tgt_len_for_batch:\n","                    max_tgt_len_for_batch = len(target_encodings[encodings_index+batch_index])\n","            for batch_index in range(0, batch_size):\n","                source_encoding = source_encodings[encodings_index]\n","                target_encoding = target_encodings[encodings_index]\n","                source_encodings_tensors.append(\n","                    torch.nn.functional.pad(\n","                        source_encoding,\n","                        (0, max_src_len_for_batch - len(source_encoding)),\n","                        value=source_vocab.index(padding_value)\n","                    )\n","                )\n","                target_encodings_tensors.append(\n","                    torch.nn.functional.pad(\n","                        target_encoding,\n","                        (0, max_tgt_len_for_batch - len(target_encoding)),\n","                        value=target_vocab.index(padding_value)\n","                    )\n","                )\n","                encodings_index = encodings_index + 1\n","            if batch_size > 0:\n","                source_batch = torch.stack(source_encodings_tensors)\n","                target_batch = torch.stack(target_encodings_tensors)\n","                source_encodings_batches.append(source_batch)\n","                target_encodings_batches.append(target_batch)\n","            source_encodings_tensors = list()\n","            target_encodings_tensors = list()\n","        target_encodings_batches_with_index = list()\n","        for i in range(0, len(target_encodings_batches)):\n","            target_encodings_batches_with_index.append(list([target_encodings_batches[i], i]))\n","        assert len(target_encodings_batches_with_index) == len(target_encodings_batches)\n","        target_encodings_batches_with_index_sorted = sorted(\n","            target_encodings_batches_with_index,\n","            key=lambda batch_pair: (-batch_pair[0].shape[0], -batch_pair[0].shape[1])\n","        )\n","        source_encodings_batches_sorted = list()\n","        target_encodings_batches_sorted = list()\n","        for i in range(0, len(target_encodings_batches_with_index_sorted)):\n","            source_encodings_batches_sorted.append(\n","                source_encodings_batches[target_encodings_batches_with_index_sorted[i][1]]\n","            )\n","            target_encodings_batches_sorted.append(\n","                target_encodings_batches[target_encodings_batches_with_index_sorted[i][1]]\n","            )\n","        del source_encodings_tensors\n","        del target_encodings_tensors\n","        del source_encodings_batches\n","        del target_encodings_batches\n","        del target_encodings_batches_with_index_sorted\n","        return source_encodings_batches_sorted, target_encodings_batches_sorted\n","\n","    @staticmethod\n","    def prepare_training_batches(\n","            dataset_holder: DatasetHolder,\n","            batch_size_limit: int,\n","            element_difference_limit: int):\n","        source_encodings_batches, target_encodings_batches = DatasetUtils.prepare_batches(\n","            dataset_holder.get_source_encodings_train(),\n","            dataset_holder.get_target_encodings_train(),\n","            dataset_holder.get_source_vocab(),\n","            dataset_holder.get_target_vocab(),\n","            batch_size_limit,\n","            element_difference_limit,\n","            dataset_holder.get_padding_vocabulary_type()\n","        )\n","\n","        source_vocab_counts = {}\n","        for source_encoding_batch in source_encodings_batches:\n","            for source_encoding in source_encoding_batch:\n","                for character in source_encoding:\n","                    if character.item() not in source_vocab_counts:\n","                        source_vocab_counts[character.item()] = 0\n","                    source_vocab_counts[character.item()] = source_vocab_counts[character.item()] + 1\n","        target_vocab_counts = {}\n","        for target_vocab_batch in target_encodings_batches:\n","            for target_encoding in target_vocab_batch:\n","                for character in target_encoding:\n","                    if character.item() not in target_vocab_counts:\n","                        target_vocab_counts[character.item()] = 0\n","                    target_vocab_counts[character.item()] = target_vocab_counts[character.item()] + 1\n","        dataset_holder.set_source_vocab_counts(source_vocab_counts)\n","        dataset_holder.set_target_vocab_counts(target_vocab_counts)\n","        return source_encodings_batches, target_encodings_batches\n","\n","    @staticmethod\n","    def decode_target_tensor(dataset_holder: DatasetHolder, tensor_to_decode):\n","        vocab = dataset_holder.get_target_vocab_numpy()\n","        decoded_tensor = np.take(vocab, tensor_to_decode.detach().to(device=\"cpu\").flatten().numpy())\n","        return \"\".join(decoded_tensor.tolist())\n","\n","    @staticmethod\n","    def decode_source_tensor(dataset_holder: DatasetHolder, tensor_to_decode):\n","        vocab = dataset_holder.get_source_vocab_numpy()\n","        decoded_tensor = np.take(vocab, tensor_to_decode.detach().to(device=\"cpu\").flatten().numpy())\n","        return \"\".join(decoded_tensor.tolist())\n","\n","\n","# class name matches file name\n","class transformer_vaswani2017(torch.nn.Transformer):\n","\n","    def __init__(self,\n","                 model_hyperparameters):\n","        super().__init__(\n","            d_model=model_hyperparameters['d_model'],\n","            nhead=model_hyperparameters['nhead'],\n","            num_encoder_layers=model_hyperparameters['num_encoder_layers'],\n","            num_decoder_layers=model_hyperparameters['num_decoder_layers'],\n","            dim_feedforward=model_hyperparameters['dim_feedforward'],\n","            dropout=model_hyperparameters['dropout'],\n","            activation=model_hyperparameters['activation'],\n","            custom_encoder=model_hyperparameters['custom_encoder'],\n","            custom_decoder=model_hyperparameters['custom_decoder'],\n","            layer_norm_eps=model_hyperparameters['layer_norm_eps'],\n","            batch_first=model_hyperparameters['batch_first'],\n","            norm_first=model_hyperparameters['norm_first'],\n","            bias=model_hyperparameters['bias'],\n","            device=model_hyperparameters['device'],\n","            dtype=model_hyperparameters['dtype']\n","        )\n","        # add one for the end of sequence token\n","        self.max_src_seq_len = model_hyperparameters['max_src_seq_len'] + 1\n","        self.max_tgt_seq_len = model_hyperparameters['max_tgt_seq_len'] + 1\n","        self.src_embeddings = torch.nn.Embedding(\n","            model_hyperparameters['src_vocab_size'],\n","            model_hyperparameters['d_model']\n","        )\n","        self.tgt_embeddings = torch.nn.Embedding(\n","            model_hyperparameters['tgt_vocab_size'],\n","            model_hyperparameters['d_model']\n","        )\n","        self.src_pos_enc = torch.nn.Embedding(\n","            self.max_src_seq_len,\n","            model_hyperparameters['d_model']\n","        ).requires_grad_(False)\n","        self.tgt_pos_enc = torch.nn.Embedding(\n","            self.max_tgt_seq_len,\n","            model_hyperparameters['d_model']\n","        ).requires_grad_(False)\n","        self.linear_output_projection_1 = torch.nn.Linear(\n","            self.max_tgt_seq_len,\n","            1,\n","            bias=False\n","        )\n","        self.linear_output_projection_2 = torch.nn.Linear(\n","            model_hyperparameters['d_model'],\n","            model_hyperparameters['tgt_vocab_size'],\n","            bias=False\n","        )\n","        self.logsoftmax_output = torch.nn.LogSoftmax(dim=1)\n","        self.model_hyperparameters = model_hyperparameters\n","        self.tgt_mask_cache = {}\n","        for i in range(1, self.max_tgt_seq_len + 1):\n","            tgt_mask = self.generate_square_subsequent_mask(i)\n","            if is_remote_execution:\n","                self.tgt_mask_cache[i] = tgt_mask.to(device=\"cuda\")\n","            self.tgt_mask_cache[i] = tgt_mask\n","        self.indices_cache = {}\n","        for i in range(1, max([self.max_src_seq_len, self.max_tgt_seq_len]) + 1):\n","            indices = torch.tensor(np.arange(0, i), dtype=torch.long)\n","            if is_remote_execution:\n","                indices = indices.to(device=\"cuda\")\n","            self.indices_cache[i] = indices\n","\n","    def forward(self,\n","                src: torch.Tensor,\n","                tgt: torch.Tensor,\n","                src_mask: Optional[torch.Tensor] = None,\n","                tgt_mask: Optional[torch.Tensor] = None,\n","                memory_mask: Optional[torch.Tensor] = None,\n","                src_key_padding_mask: Optional[torch.Tensor] = None,\n","                tgt_key_padding_mask: Optional[torch.Tensor] = None,\n","                memory_key_padding_mask: Optional[torch.Tensor] = None,\n","                src_is_causal: Optional[bool] = None,\n","                tgt_is_causal: Optional[bool] = True,\n","                memory_is_causal: bool = False) -> torch.Tensor:\n","        src_embedding_pos_enc = self.src_embeddings(src) + self.src_pos_enc(self.indices_cache[src.shape[1]])\n","        tgt_embedding_pos_enc = self.tgt_embeddings(tgt) + self.tgt_pos_enc(self.indices_cache[tgt.shape[1]])\n","        tgt_mask = self.tgt_mask_cache[tgt.shape[1]]\n","        transformer_output = super().forward(src_embedding_pos_enc, tgt_embedding_pos_enc, src_mask,\n","                                             tgt_mask, memory_mask, src_key_padding_mask,\n","                                             tgt_key_padding_mask, memory_key_padding_mask,\n","                                             src_is_causal, tgt_is_causal, memory_is_causal)\n","        transformer_output = torch.swapaxes(transformer_output, -1, -2)\n","        transformer_output = torch.nn.functional.pad(\n","            transformer_output,\n","            (0, self.max_tgt_seq_len - transformer_output.shape[2]),\n","            value=0\n","        )\n","        output = self.logsoftmax_output(\n","            self.linear_output_projection_2(\n","                torch.squeeze(\n","                    self.linear_output_projection_1(\n","                        transformer_output\n","                    ),\n","                    dim=2\n","                )\n","            )\n","        )\n","        del src_embedding_pos_enc\n","        del tgt_embedding_pos_enc\n","        del transformer_output\n","        return output\n","\n","\n","class model_trainer_kocmi2018():\n","\n","    def __init__(self,\n","                 trainer_hyperparameters=None,\n","                 model_parameter_directory=None,\n","                 trainer_parameter_directory=None,\n","                 runner_hyperparameters_name=None,\n","                 latest_param_filename_tag=None):\n","        self.trainer_hyperparameters = trainer_hyperparameters\n","        self.optimizer_name = self.trainer_hyperparameters['optimizer_name']\n","        self.initial_lr = self.trainer_hyperparameters['initial_lr']\n","        self.exp_decay = self.trainer_hyperparameters['exp_decay']\n","        self.lr_scheduler_name = self.trainer_hyperparameters['lr_scheduler_name']\n","        self.epochs = self.trainer_hyperparameters['epochs']\n","        self.epoch_starting_index = self.trainer_hyperparameters['epoch_starting_index']\n","        self.batch_size_limit = self.trainer_hyperparameters['batch_size_limit']\n","        self.element_difference_limit = self.trainer_hyperparameters['element_difference_limit']\n","        self.batch_starting_index = self.trainer_hyperparameters['batch_starting_index']\n","        self.model_parameter_directory = model_parameter_directory\n","        self.trainer_parameter_directory = trainer_parameter_directory\n","        self.runner_hyperparameters_name = runner_hyperparameters_name\n","        self.latest_param_filename_tag = latest_param_filename_tag\n","        self.dataset_holder = None\n","        self.model = None\n","        self.source_encoding_batches = None\n","        self.target_encoding_batches = None\n","        self.optimizer = None\n","        self.lr_scheduler = None\n","        self.loss_fcn = None\n","\n","    def init_trainer(self):\n","        self.source_encoding_batches, self.target_encoding_batches = (\n","            DatasetUtils.prepare_training_batches(\n","                self.dataset_holder,\n","                self.batch_size_limit,\n","                self.element_difference_limit\n","            )\n","        )\n","        # get_target_vocab_counts requires that training batches have been prepared\n","        # this ensures that vocab counts include padding and eos tokens\n","        loss_weights = list()\n","        for vocab_term in self.dataset_holder.get_target_vocab():\n","            loss_weights.append(\n","                1 / self.dataset_holder.get_target_vocab_counts()[\n","                    self.dataset_holder.get_target_vocab().index(vocab_term)\n","                ]\n","            )\n","        # set padding to have 0 weight\n","        loss_weights[\n","            self.dataset_holder.get_target_vocab().index(self.dataset_holder.get_padding_vocabulary_type())] = 0\n","        loss_weights = torch.tensor(loss_weights, dtype=torch.float)\n","        if is_remote_execution:\n","            torch.cuda.empty_cache()\n","            self.model.cuda()\n","            loss_weights = loss_weights.to(device=\"cuda\")\n","        self.loss_fcn = torch.nn.NLLLoss(weight=loss_weights)\n","        _optimizer_class_ = Utils.load_python_object('torch.optim', self.optimizer_name)\n","        self.optimizer = _optimizer_class_(self.model.parameters(), lr=self.initial_lr)\n","        _lr_scheduler_class_ = Utils.load_python_object('torch.optim.lr_scheduler', self.lr_scheduler_name)\n","        # constructor call assumes that the scheduler is the ExponentialLR scheduler\n","        self.lr_scheduler = _lr_scheduler_class_(self.optimizer, self.exp_decay)\n","        scheduler_parameter_filepath = self.trainer_parameter_directory + \"/\" + self.runner_hyperparameters_name + \"-\" + self.latest_param_filename_tag + \"-scheduler.params\"\n","        if os.path.exists(scheduler_parameter_filepath):\n","            scheduler_parameters = torch.load(scheduler_parameter_filepath)\n","            self.lr_scheduler.load_state_dict(scheduler_parameters)\n","        parameter_count = 0\n","        bytes_consumed = 0\n","        for parameter in self.model.parameters():\n","            if parameter.requires_grad:\n","                parameter_count = parameter_count + np.prod(parameter.data.shape)\n","                bytes_consumed = bytes_consumed + parameter.data.nbytes\n","        gb_consumed = bytes_consumed / 1024 / 1024 / 1024\n","        print(f\"Model trainer initialization complete.\"\n","              f\"Trainer will run on model with parameter count {parameter_count} \"\n","              f\"and parameter memory use {gb_consumed} GB\")\n","\n","    # pretraining is not used for monolingual english as described in Xue 2021 - ByT5 - Sec 3.1\n","    def run_trainer(self):\n","        assert self.epoch_starting_index < self.epochs\n","        for i in range(self.epoch_starting_index, self.epochs):\n","            epoch_start = time.time()\n","            print(f\"Beginning epoch {i+1} of {self.epochs}\")\n","            if i > 0:\n","                source_encoding_batches, target_encoding_batches = DatasetUtils.shuffle_lists(\n","                    source_encoding_batches, target_encoding_batches\n","                )\n","            source_batches = None\n","            target_batches = None\n","            if is_remote_execution:\n","                source_batches = list()\n","                target_batches = list()\n","                for batch in self.source_encoding_batches:\n","                    source_batches.append(batch.to(device=\"cuda\"))\n","                    del batch\n","                for batch in self.target_encoding_batches:\n","                    target_batches.append(batch.to(device=\"cuda\"))\n","                    del batch\n","                torch.cuda.empty_cache()\n","            else:\n","                source_batches = self.source_encoding_batches\n","                target_batches = self.target_encoding_batches\n","            assert len(source_batches) == len(target_batches)\n","            batch_ct = len(source_batches)\n","            batch_size = source_batches[0].shape[0]\n","            samples_passed = 0\n","            last_log = 0\n","            last_loss = 0\n","            note_step_prediction = False\n","            step_prediction_at_percentage_of_sample = 0\n","            total_batch_time = 0\n","            assert self.batch_starting_index < batch_ct\n","            for j in range(self.batch_starting_index, batch_ct):\n","                batch_start = time.time()\n","                batch_sequence_length = target_batches[j].shape[1]\n","                step_prediction_step_number = int(batch_sequence_length * step_prediction_at_percentage_of_sample)\n","                for k in range(1, batch_sequence_length-1):\n","                    target_batch_slices = torch.tensor_split(target_batches[j], [k], dim=1)\n","                    self.model.zero_grad()\n","                    output_logits = self.model.forward(\n","                        source_batches[j],\n","                        target_batch_slices[0]\n","                    )\n","                    next_word_indices = target_batch_slices[1][:, 0]\n","                    last_loss = self.loss_fcn(output_logits, next_word_indices)\n","                    last_loss.backward()\n","                    self.optimizer.step()\n","                    if note_step_prediction and k == step_prediction_step_number:\n","                        note_step_prediction = False\n","                        full_sequence = DatasetUtils.decode_target_tensor(self.dataset_holder, target_batches[j][0])\n","                        prefix_sequence = DatasetUtils.decode_target_tensor(\n","                            self.dataset_holder,\n","                            target_batch_slices[0][0]\n","                        )\n","                        next_token = DatasetUtils.decode_target_tensor(\n","                            self.dataset_holder,\n","                            next_word_indices[0]\n","                        )\n","                        predicted_token = DatasetUtils.decode_target_tensor(\n","                            self.dataset_holder,\n","                            torch.argmax(output_logits[0])\n","                        )\n","                        print(f\"Next token prediction. step:{k}/{batch_sequence_length} \"\n","                              f\"batch:{j+1}/{batch_ct} epoch:{i+1}/{self.epochs}\")\n","                        print(f\"full seq: {full_sequence}\")\n","                        print(f\"pref seq: {prefix_sequence}\")\n","                        print(f\"next tok: {next_token.rjust(k, ' ')}\")\n","                        print(f\"pred tok: {predicted_token.rjust(k, ' ')}\")\n","                        del full_sequence\n","                        del prefix_sequence\n","                        del next_token\n","                        del predicted_token\n","                    del target_batch_slices\n","                    del output_logits\n","                    del next_word_indices\n","                    last_loss = last_loss.detach()\n","                    gc.collect()\n","                    if is_remote_execution:\n","                        torch.cuda.empty_cache()\n","                batch_end = time.time()\n","                batch_time = batch_end - batch_start\n","                total_batch_time = total_batch_time + batch_time\n","                print(f\"Completed batch.\")\n","                print(f\"epoch:{i+1}/{self.epochs} batch:{j+1}/{batch_ct} batch_size:{target_batches[j].shape[0]} loss:{last_loss} \"\n","                      f\"time_for_batch_instance:{batch_time} total_batch_time:{total_batch_time} running_batch_average:{total_batch_time/(j+1)}\")\n","                samples_passed = samples_passed + batch_size\n","                if samples_passed - last_log > 100:\n","                    last_log = samples_passed\n","                    note_step_prediction = True\n","                    step_prediction_at_percentage_of_sample = random.random()\n","                    if is_remote_execution:\n","                        print(f\"Memory usage summary:\")\n","                        print(f\"{torch.cuda.memory_summary()}\")\n","                        torch.cuda.reset_max_memory_allocated()\n","                        torch.cuda.reset_max_memory_cached()\n","                        torch.cuda.reset_peak_memory_stats()\n","                    param_filename_tag = str(int(time.time()))\n","                    torch.save(\n","                        self.model.state_dict(),\n","                        self.model_parameter_directory + \"/\" + self.runner_hyperparameters_name + \"-\" + param_filename_tag + \"-model.params\"\n","                    )\n","                    torch.save(\n","                        lr_scheduler.state_dict(),\n","                        self.trainer_parameter_directory + \"/\" + self.runner_hyperparameters_name + \"-\" + param_filename_tag + \"-scheduler.params\"\n","                    )\n","                    torch.save(\n","                        f\"epoch:{i+1}/{self.epochs} batch:{j+1}/{batch_ct}\",\n","                        self.trainer_parameter_directory + \"/\" + self.runner_hyperparameters_name + \"-\" + param_filename_tag + \"-trainer.params\"\n","                    )\n","            del source_batches\n","            del target_batches\n","            gc.collect()\n","            if is_remote_execution:\n","                torch.cuda.empty_cache()\n","            self.lr_scheduler.step()\n","            epoch_end = time.time()\n","            print(f\"Completed epoch {i+1}/{self.epochs} in {(epoch_end - epoch_start) / 60 }m\")\n","            print(f\"epoch:{i+1}, batch:{j+1}/{batch_ct}, loss:{last_loss}\")\n","\n","    def get_dataset_holder(self):\n","        return self.dataset_holder\n","\n","    def set_dataset_holder(self, dataset_holder):\n","        self.dataset_holder = dataset_holder\n","\n","    def get_model(self):\n","        return self.model\n","\n","    def set_model(self, model):\n","        self.model = model\n","\n","\n","class Runner:\n","\n","    def __init__(self,\n","                 model_parameter_directory=root_filepath+\"resources/model_parameters\",\n","                 trainer_parameter_directory=root_filepath+\"resources/trainer_parameters\",\n","                 runner_hyperparameters_name=\"SETimesByT5Vaswani2017Kocmi2018_0\"):\n","        self.model_parameter_directory = model_parameter_directory\n","        self.trainer_parameter_directory = trainer_parameter_directory\n","        self.runner_hyperparameters_name = runner_hyperparameters_name\n","        self.runner_hyperparameters = SETimesByT5Vaswani2017Kocmi2018_0\n","        self.dataset_holder: DatasetHolder = None\n","        self.model = None\n","        self.trainer = None\n","        self.latest_param_filename_tag = None\n","        if 'latest_param_filename_tag' in self.runner_hyperparameters:\n","            self.latest_param_filename_tag = self.runner_hyperparameters['latest_param_filename_tag']\n","        print(f\"Initialized runner {runner_hyperparameters_name} with parameters {self.runner_hyperparameters}\")\n","\n","    def load_dataset(self):\n","        dataset_transformer_name = self.runner_hyperparameters.get('dataset_transformer_name')\n","        dataset_hyperparameters = self.runner_hyperparameters.get('dataset_transformer_hyperparameters')\n","        dataset_transformer = dataset_transformer_setimesbyt5(dataset_hyperparameters=dataset_hyperparameters)\n","        self.dataset_holder = dataset_transformer.read_dataset()\n","\n","    def load_model(self):\n","        model_hyperparameters = self.runner_hyperparameters.get('model_hyperparameters')\n","        model_hyperparameters['src_vocab_size'] = len(self.dataset_holder.get_source_vocab())\n","        model_hyperparameters['tgt_vocab_size'] = len(self.dataset_holder.get_target_vocab())\n","        model_hyperparameters['max_src_seq_len'] = self.dataset_holder.get_max_src_seq_obs()\n","        model_hyperparameters['max_tgt_seq_len'] = self.dataset_holder.get_max_tgt_seq_obs()\n","        model_parameter_filepath = self.model_parameter_directory + \"/\" + self.runner_hyperparameters_name + \"-\" + self.latest_param_filename_tag + \"-model.params\"\n","        self.model = transformer_vaswani2017(model_hyperparameters=model_hyperparameters)\n","        if os.path.exists(model_parameter_filepath):\n","            model_parameters = torch.load(model_parameter_filepath)\n","            self.model.load_state_dict(model_parameters)\n","\n","    def load_trainer(self):\n","        trainer_hyperparameters = self.runner_hyperparameters.get('trainer_hyperparameters')\n","        self.trainer = model_trainer_kocmi2018(\n","            trainer_hyperparameters=trainer_hyperparameters,\n","            model_parameter_directory=self.model_parameter_directory,\n","            trainer_parameter_directory=self.trainer_parameter_directory,\n","            runner_hyperparameters_name=self.runner_hyperparameters_name,\n","            latest_param_filename_tag=self.latest_param_filename_tag\n","        )\n","\n","    def run_trainer(self):\n","        self.trainer.set_dataset_holder(self.dataset_holder)\n","        self.trainer.set_model(self.model)\n","        self.trainer.run_trainer()\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"1qcv-CZAnpo1","outputId":"97ef3779-7559-4cb2-a26c-55418e1bbad0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Initialized runner SETimesByT5Vaswani2017Kocmi2018_0 with parameters {'dataset_transformer_name': 'dataset_transformer_setimesbyt5', 'model_name': 'transformer_vaswani2017', 'trainer_name': 'model_trainer_kocmi2018', 'dataset_transformer_hyperparameters': {'sentence_length_min_percentile': 5, 'sentence_length_max_percentile': 95}, 'model_hyperparameters': {'d_model': 256, 'nhead': 8, 'num_encoder_layers': 9, 'num_decoder_layers': 3, 'dim_feedforward': 2048, 'dropout': 0.1, 'activation': <function relu at 0x7e2fd08929e0>, 'custom_encoder': None, 'custom_decoder': None, 'layer_norm_eps': 1e-05, 'batch_first': True, 'norm_first': False, 'bias': True, 'device': None, 'dtype': None}, 'trainer_hyperparameters': {'optimizer_name': 'Adam', 'lr_scheduler_name': 'ExponentialLR', 'initial_lr': 0.001, 'exp_decay': 0.5, 'epochs': 10, 'batch_size_limit': 175, 'element_difference_limit': 19}}\n","Completed data split attempt. iteration:1 best_split_deviation_from_desired:0.052352723871284264 time_to_complete_attempt:1.5492889881134033\n","Completed data split attempt. iteration:2 best_split_deviation_from_desired:0.052352723871284264 time_to_complete_attempt:1.1315522193908691\n","Completed data split attempt. iteration:3 best_split_deviation_from_desired:0.052352723871284264 time_to_complete_attempt:1.5958631038665771\n","Completed data split attempt. iteration:4 best_split_deviation_from_desired:0.051809667139066595 time_to_complete_attempt:1.1535003185272217\n","Completed data split attempt. iteration:5 best_split_deviation_from_desired:0.051809667139066595 time_to_complete_attempt:1.605686902999878\n","Completed data split attempt. iteration:6 best_split_deviation_from_desired:0.051809667139066595 time_to_complete_attempt:1.1249520778656006\n","Completed data split attempt. iteration:7 best_split_deviation_from_desired:0.051809667139066595 time_to_complete_attempt:1.5809223651885986\n","Completed data split attempt. iteration:8 best_split_deviation_from_desired:0.051809667139066595 time_to_complete_attempt:1.5934765338897705\n","Completed data split attempt. iteration:9 best_split_deviation_from_desired:0.051809667139066595 time_to_complete_attempt:1.135244369506836\n","Completed data split attempt. iteration:10 best_split_deviation_from_desired:0.051809667139066595 time_to_complete_attempt:1.591933250427246\n","Completed data split attempt. iteration:11 best_split_deviation_from_desired:0.051809667139066595 time_to_complete_attempt:1.1366934776306152\n","Completed data split attempt. iteration:12 best_split_deviation_from_desired:0.05127750025973492 time_to_complete_attempt:1.6078643798828125\n","Completed data split attempt. iteration:13 best_split_deviation_from_desired:0.05127750025973492 time_to_complete_attempt:1.1341216564178467\n","Completed data split attempt. iteration:14 best_split_deviation_from_desired:0.05127750025973492 time_to_complete_attempt:1.5660905838012695\n","Completed data split attempt. iteration:15 best_split_deviation_from_desired:0.05127750025973492 time_to_complete_attempt:1.595611333847046\n","Completed data split attempt. iteration:16 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.1641440391540527\n","Completed data split attempt. iteration:17 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.6072983741760254\n","Completed data split attempt. iteration:18 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.151867151260376\n","Completed data split attempt. iteration:19 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.590040683746338\n","Completed data split attempt. iteration:20 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.155590534210205\n","Completed data split attempt. iteration:21 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.6207671165466309\n","Completed data split attempt. iteration:22 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.14564847946167\n","Completed data split attempt. iteration:23 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.5732252597808838\n","Completed data split attempt. iteration:24 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.595259428024292\n","Completed data split attempt. iteration:25 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.14349365234375\n","Completed data split attempt. iteration:26 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.5888385772705078\n","Completed data split attempt. iteration:27 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.1388413906097412\n","Completed data split attempt. iteration:28 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.592179536819458\n","Completed data split attempt. iteration:29 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.1403052806854248\n","Completed data split attempt. iteration:30 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.5848252773284912\n","Completed data split attempt. iteration:31 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.129493236541748\n","Completed data split attempt. iteration:32 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.5838472843170166\n","Completed data split attempt. iteration:33 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.5924839973449707\n","Completed data split attempt. iteration:34 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.1565403938293457\n","Completed data split attempt. iteration:35 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.5841403007507324\n","Completed data split attempt. iteration:36 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.1455729007720947\n","Completed data split attempt. iteration:37 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.584599494934082\n","Completed data split attempt. iteration:38 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.1447012424468994\n","Completed data split attempt. iteration:39 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.6100776195526123\n","Completed data split attempt. iteration:40 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.563469648361206\n","Completed data split attempt. iteration:41 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.1284263134002686\n","Completed data split attempt. iteration:42 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.6046199798583984\n","Completed data split attempt. iteration:43 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.1356561183929443\n","Completed data split attempt. iteration:44 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.5802857875823975\n","Completed data split attempt. iteration:45 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.1215472221374512\n","Completed data split attempt. iteration:46 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.5786867141723633\n","Completed data split attempt. iteration:47 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.5871188640594482\n","Completed data split attempt. iteration:48 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.148866891860962\n","Completed data split attempt. iteration:49 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.587942123413086\n","Completed data split attempt. iteration:50 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.1497018337249756\n","Completed data split attempt. iteration:51 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.5883915424346924\n","Completed data split attempt. iteration:52 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.1392924785614014\n","Completed data split attempt. iteration:53 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.582878589630127\n","Completed data split attempt. iteration:54 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.5962300300598145\n","Completed data split attempt. iteration:55 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.1373693943023682\n","Completed data split attempt. iteration:56 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.6250121593475342\n","Completed data split attempt. iteration:57 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.1463565826416016\n","Completed data split attempt. iteration:58 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.5861785411834717\n","Completed data split attempt. iteration:59 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.1303367614746094\n","Completed data split attempt. iteration:60 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.5828397274017334\n","Completed data split attempt. iteration:61 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.594296932220459\n","Completed data split attempt. iteration:62 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.1341097354888916\n","Completed data split attempt. iteration:63 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.5759222507476807\n","Completed data split attempt. iteration:64 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.1320159435272217\n","Completed data split attempt. iteration:65 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.6275882720947266\n","Completed data split attempt. iteration:66 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.1287643909454346\n","Completed data split attempt. iteration:67 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.5652916431427002\n","Completed data split attempt. iteration:68 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.1313488483428955\n","Completed data split attempt. iteration:69 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.5692598819732666\n","Completed data split attempt. iteration:70 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.6077172756195068\n","Completed data split attempt. iteration:71 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.1480858325958252\n","Completed data split attempt. iteration:72 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.582533836364746\n","Completed data split attempt. iteration:73 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.158613681793213\n","Completed data split attempt. iteration:74 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.6062912940979004\n","Completed data split attempt. iteration:75 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.6110198497772217\n","Completed data split attempt. iteration:76 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.1350688934326172\n","Completed data split attempt. iteration:77 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.603306770324707\n","Completed data split attempt. iteration:78 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.1252050399780273\n","Completed data split attempt. iteration:79 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.5928826332092285\n","Completed data split attempt. iteration:80 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.1275968551635742\n","Completed data split attempt. iteration:81 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.5832250118255615\n","Completed data split attempt. iteration:82 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.1390562057495117\n","Completed data split attempt. iteration:83 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.6028356552124023\n","Completed data split attempt. iteration:84 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.5928516387939453\n","Completed data split attempt. iteration:85 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.1233198642730713\n","Completed data split attempt. iteration:86 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.603217363357544\n","Completed data split attempt. iteration:87 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.1452867984771729\n","Completed data split attempt. iteration:88 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.572850227355957\n","Completed data split attempt. iteration:89 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.1394097805023193\n","Completed data split attempt. iteration:90 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.5895113945007324\n","Completed data split attempt. iteration:91 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.6110737323760986\n","Completed data split attempt. iteration:92 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.1505820751190186\n","Completed data split attempt. iteration:93 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.5992624759674072\n","Completed data split attempt. iteration:94 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.1318366527557373\n","Completed data split attempt. iteration:95 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.5863773822784424\n","Completed data split attempt. iteration:96 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.1376380920410156\n","Completed data split attempt. iteration:97 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.5652518272399902\n","Completed data split attempt. iteration:98 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.5791850090026855\n","Completed data split attempt. iteration:99 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.1373491287231445\n","Completed data split attempt. iteration:100 best_split_deviation_from_desired:0.05029769270251422 time_to_complete_attempt:1.6095223426818848\n","Beginning training of model with parameter count 16637953 and parameter memory use 0.0619812048971653 GB\n","Beginning epoch 1 of 10\n","Completed batch.\n","epoch:1/10 batch:1/8961 batch_size:175 loss:3.511655569076538 time_for_batch_instance:220.1015202999115 total_batch_time:220.1015202999115 running_batch_average:220.1015202999115\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 671605 KiB |  17099 MiB |  14343 GiB |  14342 GiB |\n","|       from large pool | 216999 KiB |  16661 MiB |  14319 GiB |  14318 GiB |\n","|       from small pool | 454606 KiB |    470 MiB |     23 GiB |     23 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 671605 KiB |  17099 MiB |  14343 GiB |  14342 GiB |\n","|       from large pool | 216999 KiB |  16661 MiB |  14319 GiB |  14318 GiB |\n","|       from small pool | 454606 KiB |    470 MiB |     23 GiB |     23 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  17073 MiB |  14307 GiB |  14306 GiB |\n","|       from large pool | 213248 KiB |  16640 MiB |  14283 GiB |  14282 GiB |\n","|       from small pool | 450193 KiB |    465 MiB |     23 GiB |     23 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1406 MiB |  17890 MiB |   3427 GiB |   3426 GiB |\n","|       from large pool |    958 MiB |  17426 MiB |   3423 GiB |   3422 GiB |\n","|       from small pool |    448 MiB |    474 MiB |      4 GiB |      3 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 768139 KiB |   1888 MiB |   4575 GiB |   4575 GiB |\n","|       from large pool | 763993 KiB |   1880 MiB |   4549 GiB |   4549 GiB |\n","|       from small pool |   4146 KiB |     24 MiB |     26 GiB |     26 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  354073    |  335198    |\n","|       from large pool |      98    |     263    |  204081    |  203983    |\n","|       from small pool |   18777    |   18924    |  149992    |  131215    |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  354073    |  335198    |\n","|       from large pool |      98    |     263    |  204081    |  203983    |\n","|       from small pool |   18777    |   18924    |  149992    |  131215    |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     236    |     321    |   18616    |   18380    |\n","|       from large pool |      12    |      89    |   16510    |   16498    |\n","|       from small pool |     224    |     237    |    2106    |    1882    |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      79    |     143    |  144817    |  144738    |\n","|       from large pool |      12    |      40    |   92230    |   92218    |\n","|       from small pool |      67    |     119    |   52587    |   52520    |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/cuda/memory.py:330: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/cuda/memory.py:356: FutureWarning: torch.cuda.reset_max_memory_cached now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","| Allocations           |   18875    |   19046    |  115292 K  |  115273 K  |\n","|       from large pool |      98    |     248    |   67869 K  |   67869 K  |\n","|       from small pool |   18777    |   18924    |   47423 K  |   47404 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  115292 K  |  115273 K  |\n","|       from large pool |      98    |     248    |   67869 K  |   67869 K  |\n","|       from small pool |   18777    |   18924    |   47423 K  |   47404 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     239    |     316    |    5972 K  |    5972 K  |\n","|       from large pool |      13    |      83    |    5320 K  |    5320 K  |\n","|       from small pool |     226    |     240    |     651 K  |     651 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      95    |     157    |   55158 K  |   55158 K  |\n","|       from large pool |      18    |      54    |   36634 K  |   36634 K  |\n","|       from small pool |      77    |     122    |   18524 K  |   18524 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:2/125 batch:676/8961 epoch:1/10\n","full seq: A lack of a common position and unsound proposals have weakened the role of civil society in Kosovo's election reform.Ģġġġġġġ\n","pref seq: A \n","next tok:  l\n","pred tok:  Ģ\n","Completed batch.\n","epoch:1/10 batch:676/8961 batch_size:166 loss:2.8428657054901123 time_for_batch_instance:102.13738703727722 total_batch_time:73480.44233822823 running_batch_average:108.69887919856247\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 670498 KiB |   8002 MiB |   2870 TiB |   2870 TiB |\n","|       from large pool | 215892 KiB |   7559 MiB |   2861 TiB |   2861 TiB |\n","|       from small pool | 454606 KiB |    476 MiB |      8 TiB |      8 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 670498 KiB |   8002 MiB |   2870 TiB |   2870 TiB |\n","|       from large pool | 215892 KiB |   7559 MiB |   2861 TiB |   2861 TiB |\n","|       from small pool | 454606 KiB |    476 MiB |      8 TiB |      8 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |   7991 MiB |   2862 TiB |   2862 TiB |\n","|       from large pool | 213248 KiB |   7553 MiB |   2853 TiB |   2853 TiB |\n","|       from small pool | 450193 KiB |    472 MiB |      8 TiB |      8 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1830 MiB |   8430 MiB | 649047 GiB | 649045 GiB |\n","|       from large pool |   1378 MiB |   7964 MiB | 647772 GiB | 647771 GiB |\n","|       from small pool |    452 MiB |    480 MiB |   1274 GiB |   1274 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1175 MiB |   1407 MiB |   1003 TiB |   1003 TiB |\n","|       from large pool |   1167 MiB |   1396 MiB |    994 TiB |    994 TiB |\n","|       from small pool |      8 MiB |     23 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  115454 K  |  115435 K  |\n","|       from large pool |      98    |     248    |   67963 K  |   67963 K  |\n","|       from small pool |   18777    |   18924    |   47490 K  |   47472 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  115454 K  |  115435 K  |\n","|       from large pool |      98    |     248    |   67963 K  |   67963 K  |\n","|       from small pool |   18777    |   18924    |   47490 K  |   47472 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     241    |     315    |    5980 K  |    5980 K  |\n","|       from large pool |      15    |      82    |    5328 K  |    5328 K  |\n","|       from small pool |     226    |     240    |     652 K  |     652 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      95    |     186    |   55247 K  |   55247 K  |\n","|       from large pool |      17    |      83    |   36697 K  |   36697 K  |\n","|       from small pool |      78    |     122    |   18549 K  |   18549 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:74/102 batch:677/8961 epoch:1/10\n","full seq: It is of exceptional importance that the country becomes a NATO member, de Hoop Scheffer said.Ģġġġġġġġ\n","pref seq: It is of exceptional importance that the country becomes a NATO member, de\n","next tok:                                                                           \n","pred tok:                                                                          Ģ\n","Completed batch.\n","epoch:1/10 batch:677/8961 batch_size:166 loss:2.098318338394165 time_for_batch_instance:82.68212246894836 total_batch_time:73563.12446069717 running_batch_average:108.66044972037987\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 671123 KiB |   6685 MiB |   2872 TiB |   2872 TiB |\n","|       from large pool | 216517 KiB |   6243 MiB |   2864 TiB |   2864 TiB |\n","|       from small pool | 454606 KiB |    476 MiB |      8 TiB |      8 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 671123 KiB |   6685 MiB |   2872 TiB |   2872 TiB |\n","|       from large pool | 216517 KiB |   6243 MiB |   2864 TiB |   2864 TiB |\n","|       from small pool | 454606 KiB |    476 MiB |      8 TiB |      8 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |   6666 MiB |   2864 TiB |   2864 TiB |\n","|       from large pool | 213248 KiB |   6228 MiB |   2855 TiB |   2855 TiB |\n","|       from small pool | 450193 KiB |    471 MiB |      8 TiB |      8 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1640 MiB |   7094 MiB | 649497 GiB | 649495 GiB |\n","|       from large pool |   1188 MiB |   6626 MiB | 648221 GiB | 648219 GiB |\n","|       from small pool |    452 MiB |    478 MiB |   1276 GiB |   1275 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |    984 MiB |   1358 MiB |   1004 TiB |   1004 TiB |\n","|       from large pool |    976 MiB |   1351 MiB |    994 TiB |    994 TiB |\n","|       from small pool |      8 MiB |     23 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  115585 K  |  115566 K  |\n","|       from large pool |      98    |     248    |   68039 K  |   68038 K  |\n","|       from small pool |   18777    |   18924    |   47546 K  |   47527 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  115585 K  |  115566 K  |\n","|       from large pool |      98    |     248    |   68039 K  |   68038 K  |\n","|       from small pool |   18777    |   18924    |   47546 K  |   47527 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     238    |     318    |    5987 K  |    5987 K  |\n","|       from large pool |      12    |      85    |    5334 K  |    5334 K  |\n","|       from small pool |     226    |     239    |     653 K  |     653 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      90    |     158    |   55314 K  |   55314 K  |\n","|       from large pool |      12    |      56    |   36743 K  |   36743 K  |\n","|       from small pool |      78    |     120    |   18570 K  |   18570 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:6/252 batch:678/8961 epoch:1/10\n","full seq: The European Council made that decision on November 8th, saying any Albanian who holds a biometric passport will be able to visit the EU member states for up to 90 days over six months, though there is no right to residence or work.Ģġġġġġġġġġġġġġġġġġġġ\n","pref seq: The Eu\n","next tok:      r\n","pred tok:      Ģ\n","Completed batch.\n","epoch:1/10 batch:678/8961 batch_size:165 loss:1.2047607898712158 time_for_batch_instance:213.08817338943481 total_batch_time:73776.21263408661 running_batch_average:108.81447291163217\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 668532 KiB |  15515 MiB |   2885 TiB |   2885 TiB |\n","|       from large pool | 213926 KiB |  15077 MiB |   2876 TiB |   2876 TiB |\n","|       from small pool | 454606 KiB |    473 MiB |      8 TiB |      8 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 668532 KiB |  15515 MiB |   2885 TiB |   2885 TiB |\n","|       from large pool | 213926 KiB |  15077 MiB |   2876 TiB |   2876 TiB |\n","|       from small pool | 454606 KiB |    473 MiB |      8 TiB |      8 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  15502 MiB |   2877 TiB |   2877 TiB |\n","|       from large pool | 213248 KiB |  15069 MiB |   2868 TiB |   2868 TiB |\n","|       from small pool | 450193 KiB |    469 MiB |      8 TiB |      8 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1778 MiB |  16316 MiB | 652511 GiB | 652509 GiB |\n","|       from large pool |   1330 MiB |  15852 MiB | 651231 GiB | 651230 GiB |\n","|       from small pool |    448 MiB |    478 MiB |   1279 GiB |   1279 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1125 MiB |   2055 MiB |   1008 TiB |   1008 TiB |\n","|       from large pool |   1121 MiB |   2052 MiB |    999 TiB |    999 TiB |\n","|       from small pool |      4 MiB |     25 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  115913 K  |  115894 K  |\n","|       from large pool |      98    |     263    |   68238 K  |   68238 K  |\n","|       from small pool |   18777    |   18924    |   47675 K  |   47656 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  115913 K  |  115894 K  |\n","|       from large pool |      98    |     263    |   68238 K  |   68238 K  |\n","|       from small pool |   18777    |   18924    |   47675 K  |   47656 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     240    |     323    |    6005 K  |    6005 K  |\n","|       from large pool |      16    |      91    |    5350 K  |    5350 K  |\n","|       from small pool |     224    |     239    |     655 K  |     655 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      90    |     177    |   55495 K  |   55495 K  |\n","|       from large pool |      22    |      75    |   36874 K  |   36874 K  |\n","|       from small pool |      68    |     120    |   18621 K  |   18621 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:182/249 batch:679/8961 epoch:1/10\n","full seq: Under the term of the return, the family pledged to keep the castle open to the public as a museum until 2009. Von Habsburg, 69, last year offered to sell the castle to local authorities for 60m euros, but the offer was rejected.Ģġġġġġġġġġġġġġġġġġġġ\n","pref seq: Under the term of the return, the family pledged to keep the castle open to the public as a museum until 2009. Von Habsburg, 69, last year offered to sell the castle to local authori\n","next tok:                                                                                                                                                                                      t\n","pred tok:                                                                                                                                                                                      P\n","Completed batch.\n","epoch:1/10 batch:679/8961 batch_size:165 loss:2.826570510864258 time_for_batch_instance:209.33119440078735 total_batch_time:73985.5438284874 running_batch_average:108.96250932030544\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 669559 KiB |  15339 MiB |   2897 TiB |   2897 TiB |\n","|       from large pool | 214953 KiB |  14902 MiB |   2888 TiB |   2888 TiB |\n","|       from small pool | 454606 KiB |    473 MiB |      8 TiB |      8 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 669559 KiB |  15339 MiB |   2897 TiB |   2897 TiB |\n","|       from large pool | 214953 KiB |  14902 MiB |   2888 TiB |   2888 TiB |\n","|       from small pool | 454606 KiB |    473 MiB |      8 TiB |      8 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  15325 MiB |   2889 TiB |   2889 TiB |\n","|       from large pool | 213248 KiB |  14892 MiB |   2880 TiB |   2880 TiB |\n","|       from small pool | 450193 KiB |    469 MiB |      8 TiB |      8 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2320 MiB |  16114 MiB | 655381 GiB | 655379 GiB |\n","|       from large pool |   1870 MiB |  15650 MiB | 654098 GiB | 654096 GiB |\n","|       from small pool |    450 MiB |    476 MiB |   1283 GiB |   1283 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1666 MiB |   2140 MiB |   1012 TiB |   1012 TiB |\n","|       from large pool |   1660 MiB |   2136 MiB |   1003 TiB |   1003 TiB |\n","|       from small pool |      6 MiB |     22 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  116238 K  |  116219 K  |\n","|       from large pool |      98    |     263    |   68435 K  |   68435 K  |\n","|       from small pool |   18777    |   18924    |   47802 K  |   47784 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  116238 K  |  116219 K  |\n","|       from large pool |      98    |     263    |   68435 K  |   68435 K  |\n","|       from small pool |   18777    |   18924    |   47802 K  |   47784 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     243    |     323    |    6022 K  |    6022 K  |\n","|       from large pool |      18    |      91    |    5365 K  |    5365 K  |\n","|       from small pool |     225    |     238    |     657 K  |     656 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      98    |     179    |   55682 K  |   55682 K  |\n","|       from large pool |      25    |      77    |   37010 K  |   37010 K  |\n","|       from small pool |      73    |     120    |   18672 K  |   18672 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:36/145 batch:680/8961 epoch:1/10\n","full seq: Officials say both developments reflect the country's desire to become a key contributor to regional stability and security.Ģġġġġġġġġġġġġġġġġġġġġ\n","pref seq: Officials say both developments refl\n","next tok:                                    e\n","pred tok:                                    :\n","Completed batch.\n","epoch:1/10 batch:680/8961 batch_size:165 loss:2.32135272026062 time_for_batch_instance:119.38193988800049 total_batch_time:74104.9257683754 running_batch_average:108.97783201231675\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 670302 KiB |   9126 MiB |   2901 TiB |   2901 TiB |\n","|       from large pool | 215696 KiB |   8681 MiB |   2892 TiB |   2892 TiB |\n","|       from small pool | 454606 KiB |    478 MiB |      8 TiB |      8 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 670302 KiB |   9126 MiB |   2901 TiB |   2901 TiB |\n","|       from large pool | 215696 KiB |   8681 MiB |   2892 TiB |   2892 TiB |\n","|       from small pool | 454606 KiB |    478 MiB |      8 TiB |      8 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |   9089 MiB |   2893 TiB |   2893 TiB |\n","|       from large pool | 213248 KiB |   8648 MiB |   2884 TiB |   2884 TiB |\n","|       from small pool | 450193 KiB |    473 MiB |      8 TiB |      8 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1424 MiB |   9538 MiB | 656317 GiB | 656315 GiB |\n","|       from large pool |    976 MiB |   9076 MiB | 655031 GiB | 655030 GiB |\n","|       from small pool |    448 MiB |    482 MiB |   1285 GiB |   1285 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |    769 MiB |   1679 MiB |   1014 TiB |   1014 TiB |\n","|       from large pool |    765 MiB |   1672 MiB |   1004 TiB |   1004 TiB |\n","|       from small pool |      4 MiB |     24 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  116425 K  |  116407 K  |\n","|       from large pool |      98    |     248    |   68544 K  |   68544 K  |\n","|       from small pool |   18777    |   18924    |   47881 K  |   47862 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  116425 K  |  116407 K  |\n","|       from large pool |      98    |     248    |   68544 K  |   68544 K  |\n","|       from small pool |   18777    |   18924    |   47881 K  |   47862 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     237    |     318    |    6032 K  |    6032 K  |\n","|       from large pool |      13    |      87    |    5374 K  |    5374 K  |\n","|       from small pool |     224    |     241    |     658 K  |     657 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      87    |     152    |   55763 K  |   55763 K  |\n","|       from large pool |      15    |      47    |   37059 K  |   37059 K  |\n","|       from small pool |      72    |     123    |   18703 K  |   18703 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:18/88 batch:681/8961 epoch:1/10\n","full seq: Science and Technology: Facebook used to study literature in SerbiaĢġġġġġġġġġġġġġġġġġġġġ\n","pref seq: Science and Techno\n","next tok:                  l\n","pred tok:                  ġ\n","Completed batch.\n","epoch:1/10 batch:681/8961 batch_size:164 loss:4.672028064727783 time_for_batch_instance:71.46645998954773 total_batch_time:74176.39222836494 running_batch_average:108.92274923401607\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 673797 KiB |   5709 MiB |   2903 TiB |   2903 TiB |\n","|       from large pool | 219191 KiB |   5271 MiB |   2894 TiB |   2894 TiB |\n","|       from small pool | 454606 KiB |    473 MiB |      8 TiB |      8 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 673797 KiB |   5709 MiB |   2903 TiB |   2903 TiB |\n","|       from large pool | 219191 KiB |   5271 MiB |   2894 TiB |   2894 TiB |\n","|       from small pool | 454606 KiB |    473 MiB |      8 TiB |      8 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |   5685 MiB |   2894 TiB |   2894 TiB |\n","|       from large pool | 213248 KiB |   5251 MiB |   2886 TiB |   2886 TiB |\n","|       from small pool | 450193 KiB |    469 MiB |      8 TiB |      8 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1462 MiB |   6068 MiB | 656636 GiB | 656634 GiB |\n","|       from large pool |   1012 MiB |   5602 MiB | 655349 GiB | 655348 GiB |\n","|       from small pool |    450 MiB |    476 MiB |   1286 GiB |   1286 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |    803 MiB |   1109 MiB |   1014 TiB |   1014 TiB |\n","|       from large pool |    797 MiB |   1097 MiB |   1005 TiB |   1005 TiB |\n","|       from small pool |      6 MiB |     21 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  116538 K  |  116519 K  |\n","|       from large pool |      98    |     248    |   68609 K  |   68609 K  |\n","|       from small pool |   18777    |   18924    |   47929 K  |   47910 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  116538 K  |  116519 K  |\n","|       from large pool |      98    |     248    |   68609 K  |   68609 K  |\n","|       from small pool |   18777    |   18924    |   47929 K  |   47910 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     239    |     319    |    6038 K  |    6037 K  |\n","|       from large pool |      14    |      86    |    5379 K  |    5379 K  |\n","|       from small pool |     225    |     238    |     658 K  |     658 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      94    |     149    |   55809 K  |   55809 K  |\n","|       from large pool |      19    |      46    |   37087 K  |   37087 K  |\n","|       from small pool |      75    |     119    |   18721 K  |   18721 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:58/87 batch:682/8961 epoch:1/10\n","full seq: Ashdown Sets Deadline for Republika Srpska's Srebrenica CommissionĢġġġġġġġġġġġġġġġġġġġġ\n","pref seq: Ashdown Sets Deadline for Republika Srpska's Srebrenica Co\n","next tok:                                                          m\n","pred tok:                                                          ?\n","Completed batch.\n","epoch:1/10 batch:682/8961 batch_size:164 loss:2.4536454677581787 time_for_batch_instance:70.60124588012695 total_batch_time:74246.99347424507 running_batch_average:108.8665593464004\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 674909 KiB |   5693 MiB |   2904 TiB |   2904 TiB |\n","|       from large pool | 220303 KiB |   5254 MiB |   2895 TiB |   2895 TiB |\n","|       from small pool | 454606 KiB |    473 MiB |      8 TiB |      8 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 674909 KiB |   5693 MiB |   2904 TiB |   2904 TiB |\n","|       from large pool | 220303 KiB |   5254 MiB |   2895 TiB |   2895 TiB |\n","|       from small pool | 454606 KiB |    473 MiB |      8 TiB |      8 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |   5668 MiB |   2896 TiB |   2896 TiB |\n","|       from large pool | 213248 KiB |   5234 MiB |   2887 TiB |   2887 TiB |\n","|       from small pool | 450193 KiB |    469 MiB |      8 TiB |      8 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1574 MiB |   6068 MiB | 656951 GiB | 656950 GiB |\n","|       from large pool |   1124 MiB |   5602 MiB | 655663 GiB | 655662 GiB |\n","|       from small pool |    450 MiB |    476 MiB |   1288 GiB |   1287 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |    914 MiB |   1129 MiB |   1015 TiB |   1015 TiB |\n","|       from large pool |    908 MiB |   1123 MiB |   1005 TiB |   1005 TiB |\n","|       from small pool |      6 MiB |     21 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  116649 K  |  116631 K  |\n","|       from large pool |      98    |     248    |   68673 K  |   68673 K  |\n","|       from small pool |   18777    |   18924    |   47976 K  |   47957 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  116649 K  |  116631 K  |\n","|       from large pool |      98    |     248    |   68673 K  |   68673 K  |\n","|       from small pool |   18777    |   18924    |   47976 K  |   47957 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     240    |     319    |    6043 K  |    6043 K  |\n","|       from large pool |      15    |      86    |    5384 K  |    5384 K  |\n","|       from small pool |     225    |     238    |     659 K  |     659 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      94    |     149    |   55854 K  |   55854 K  |\n","|       from large pool |      18    |      46    |   37115 K  |   37115 K  |\n","|       from small pool |      76    |     119    |   18739 K  |   18738 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:16/247 batch:683/8961 epoch:1/10\n","full seq: ATHENS, Greece -- Prime Minister George Papandreou failed to convince the leaders of the opposition Friday (May 27th) to support his government's austerity measures necessary to help the country overcome its financial crisis.Ģġġġġġġġġġġġġġġġġġġġġġ\n","pref seq: ATHENS, Greece -\n","next tok:                -\n","pred tok:                Ģ\n","Completed batch.\n","epoch:1/10 batch:683/8961 batch_size:163 loss:1.233463168144226 time_for_batch_instance:209.19912195205688 total_batch_time:74456.19259619713 running_batch_average:109.01345914523738\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 670300 KiB |  14986 MiB |   2916 TiB |   2916 TiB |\n","|       from large pool | 215694 KiB |  14549 MiB |   2907 TiB |   2907 TiB |\n","|       from small pool | 454606 KiB |    472 MiB |      8 TiB |      8 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 670300 KiB |  14986 MiB |   2916 TiB |   2916 TiB |\n","|       from large pool | 215694 KiB |  14549 MiB |   2907 TiB |   2907 TiB |\n","|       from small pool | 454606 KiB |    472 MiB |      8 TiB |      8 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  14948 MiB |   2908 TiB |   2908 TiB |\n","|       from large pool | 213248 KiB |  14515 MiB |   2899 TiB |   2899 TiB |\n","|       from small pool | 450193 KiB |    468 MiB |      8 TiB |      8 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1644 MiB |  15658 MiB | 659761 GiB | 659759 GiB |\n","|       from large pool |   1196 MiB |  15194 MiB | 658469 GiB | 658468 GiB |\n","|       from small pool |    448 MiB |    476 MiB |   1291 GiB |   1291 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |    989 MiB |   2097 MiB |   1019 TiB |   1019 TiB |\n","|       from large pool |    985 MiB |   2092 MiB |   1009 TiB |   1009 TiB |\n","|       from small pool |      4 MiB |     22 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  116971 K  |  116952 K  |\n","|       from large pool |      98    |     263    |   68869 K  |   68869 K  |\n","|       from small pool |   18777    |   18924    |   48102 K  |   48083 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  116971 K  |  116952 K  |\n","|       from large pool |      98    |     263    |   68869 K  |   68869 K  |\n","|       from small pool |   18777    |   18924    |   48102 K  |   48083 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     240    |     324    |    6061 K  |    6061 K  |\n","|       from large pool |      16    |      92    |    5399 K  |    5399 K  |\n","|       from small pool |     224    |     238    |     661 K  |     661 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      89    |     143    |   55994 K  |   55994 K  |\n","|       from large pool |      17    |      41    |   37204 K  |   37204 K  |\n","|       from small pool |      72    |     119    |   18789 K  |   18789 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:102/186 batch:684/8961 epoch:1/10\n","full seq: \"It's the best we could do,\" Dimitri Sotiropoulos, an associate professor of political science at the University of Athens and a Senior Research Fellow at ELIAMEP, told SETimes.Ģġġġġġġġġ\n","pref seq: \"It's the best we could do,\" Dimitri Sotiropoulos, an associate professor of political science at the \n","next tok:                                                                                                      U\n","pred tok:                                                                                                      b\n","Completed batch.\n","epoch:1/10 batch:684/8961 batch_size:163 loss:2.6212217807769775 time_for_batch_instance:154.430180311203 total_batch_time:74610.62277650833 running_batch_average:109.0798578603923\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 671393 KiB |  11488 MiB |   2923 TiB |   2923 TiB |\n","|       from large pool | 216787 KiB |  11039 MiB |   2914 TiB |   2914 TiB |\n","|       from small pool | 454606 KiB |    480 MiB |      8 TiB |      8 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 671393 KiB |  11488 MiB |   2923 TiB |   2923 TiB |\n","|       from large pool | 216787 KiB |  11039 MiB |   2914 TiB |   2914 TiB |\n","|       from small pool | 454606 KiB |    480 MiB |      8 TiB |      8 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  11464 MiB |   2914 TiB |   2914 TiB |\n","|       from large pool | 213248 KiB |  11019 MiB |   2906 TiB |   2906 TiB |\n","|       from small pool | 450193 KiB |    475 MiB |      8 TiB |      8 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1896 MiB |  12084 MiB | 661364 GiB | 661362 GiB |\n","|       from large pool |   1446 MiB |  11620 MiB | 660070 GiB | 660069 GiB |\n","|       from small pool |    450 MiB |    484 MiB |   1294 GiB |   1293 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1240 MiB |   1521 MiB |   1021 TiB |   1021 TiB |\n","|       from large pool |   1234 MiB |   1514 MiB |   1011 TiB |   1011 TiB |\n","|       from small pool |      6 MiB |     25 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  117213 K  |  117194 K  |\n","|       from large pool |      98    |     248    |   69009 K  |   69009 K  |\n","|       from small pool |   18777    |   18924    |   48203 K  |   48184 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  117213 K  |  117194 K  |\n","|       from large pool |      98    |     248    |   69009 K  |   69009 K  |\n","|       from small pool |   18777    |   18924    |   48203 K  |   48184 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     240    |     320    |    6074 K  |    6073 K  |\n","|       from large pool |      15    |      88    |    5411 K  |    5411 K  |\n","|       from small pool |     225    |     242    |     662 K  |     662 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      92    |     178    |   56096 K  |   56096 K  |\n","|       from large pool |      17    |      73    |   37267 K  |   37267 K  |\n","|       from small pool |      75    |     122    |   18828 K  |   18828 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:77/126 batch:685/8961 epoch:1/10\n","full seq: The United States and EU stand behind this as the signatories of the Framework Agreement, so I do not expect problems.Ģġġġġġġġ\n","pref seq: The United States and EU stand behind this as the signatories of the Framewor\n","next tok:                                                                             k\n","pred tok:                                                                             ;\n","Completed batch.\n","epoch:1/10 batch:685/8961 batch_size:163 loss:4.002079963684082 time_for_batch_instance:103.12274479866028 total_batch_time:74713.74552130699 running_batch_average:109.07116134497372\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 670331 KiB |   7929 MiB |   2926 TiB |   2926 TiB |\n","|       from large pool | 215725 KiB |   7487 MiB |   2917 TiB |   2917 TiB |\n","|       from small pool | 454606 KiB |    475 MiB |      8 TiB |      8 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 670331 KiB |   7929 MiB |   2926 TiB |   2926 TiB |\n","|       from large pool | 215725 KiB |   7487 MiB |   2917 TiB |   2917 TiB |\n","|       from small pool | 454606 KiB |    475 MiB |      8 TiB |      8 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |   7916 MiB |   2918 TiB |   2918 TiB |\n","|       from large pool | 213248 KiB |   7478 MiB |   2909 TiB |   2909 TiB |\n","|       from small pool | 450193 KiB |    471 MiB |      8 TiB |      8 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1836 MiB |   8358 MiB | 662061 GiB | 662060 GiB |\n","|       from large pool |   1386 MiB |   7892 MiB | 660766 GiB | 660764 GiB |\n","|       from small pool |    450 MiB |    478 MiB |   1295 GiB |   1295 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1181 MiB |   1331 MiB |   1022 TiB |   1022 TiB |\n","|       from large pool |   1175 MiB |   1324 MiB |   1013 TiB |   1013 TiB |\n","|       from small pool |      6 MiB |     23 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  117376 K  |  117357 K  |\n","|       from large pool |      98    |     248    |   69104 K  |   69104 K  |\n","|       from small pool |   18777    |   18924    |   48271 K  |   48253 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  117376 K  |  117357 K  |\n","|       from large pool |      98    |     248    |   69104 K  |   69104 K  |\n","|       from small pool |   18777    |   18924    |   48271 K  |   48253 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     241    |     319    |    6082 K  |    6082 K  |\n","|       from large pool |      16    |      86    |    5418 K  |    5418 K  |\n","|       from small pool |     225    |     239    |     663 K  |     663 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      94    |     184    |   56186 K  |   56185 K  |\n","|       from large pool |      19    |      81    |   37331 K  |   37331 K  |\n","|       from small pool |      75    |     122    |   18854 K  |   18854 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:104/122 batch:686/8961 epoch:1/10\n","full seq: It later emerged, however, that Karic's company never invested in Mobtel to the extent stipulated by the contract.Ģġġġġġġġ\n","pref seq: It later emerged, however, that Karic's company never invested in Mobtel to the extent stipulated by the\n","next tok:                                                                                                         \n","pred tok:                                                                                                        Ģ\n","Completed batch.\n","epoch:1/10 batch:686/8961 batch_size:163 loss:3.276230812072754 time_for_batch_instance:99.72522187232971 total_batch_time:74813.47074317932 running_batch_average:109.05753752650047\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 670933 KiB |   7718 MiB |   2929 TiB |   2929 TiB |\n","|       from large pool | 216327 KiB |   7276 MiB |   2920 TiB |   2920 TiB |\n","|       from small pool | 454606 KiB |    475 MiB |      8 TiB |      8 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 670933 KiB |   7718 MiB |   2929 TiB |   2929 TiB |\n","|       from large pool | 216327 KiB |   7276 MiB |   2920 TiB |   2920 TiB |\n","|       from small pool | 454606 KiB |    475 MiB |      8 TiB |      8 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |   7682 MiB |   2921 TiB |   2921 TiB |\n","|       from large pool | 213248 KiB |   7244 MiB |   2912 TiB |   2912 TiB |\n","|       from small pool | 450193 KiB |    471 MiB |      8 TiB |      8 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1498 MiB |   8110 MiB | 662707 GiB | 662706 GiB |\n","|       from large pool |   1046 MiB |   7644 MiB | 661409 GiB | 661408 GiB |\n","|       from small pool |    452 MiB |    478 MiB |   1297 GiB |   1297 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |    842 MiB |   1427 MiB |   1023 TiB |   1023 TiB |\n","|       from large pool |    834 MiB |   1421 MiB |   1014 TiB |   1014 TiB |\n","|       from small pool |      8 MiB |     22 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  117533 K  |  117514 K  |\n","|       from large pool |      98    |     248    |   69195 K  |   69195 K  |\n","|       from small pool |   18777    |   18924    |   48337 K  |   48319 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  117533 K  |  117514 K  |\n","|       from large pool |      98    |     248    |   69195 K  |   69195 K  |\n","|       from small pool |   18777    |   18924    |   48337 K  |   48319 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     241    |     321    |    6090 K  |    6090 K  |\n","|       from large pool |      15    |      87    |    5426 K  |    5426 K  |\n","|       from small pool |     226    |     239    |     664 K  |     664 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      90    |     160    |   56255 K  |   56255 K  |\n","|       from large pool |      15    |      58    |   37376 K  |   37376 K  |\n","|       from small pool |      75    |     122    |   18879 K  |   18879 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:6/68 batch:687/8961 epoch:1/10\n","full seq: Besides, why bother if no one cares?\" he added.Ģġġġġġġġġġġġġġġġġġġġġ\n","pref seq: Beside\n","next tok:      s\n","pred tok:      Ģ\n","Completed batch.\n","epoch:1/10 batch:687/8961 batch_size:163 loss:4.028777599334717 time_for_batch_instance:54.23806357383728 total_batch_time:74867.70880675316 running_batch_average:108.9777420767877\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 673378 KiB |   5121 MiB |   2930 TiB |   2930 TiB |\n","|       from large pool | 218772 KiB |   4682 MiB |   2921 TiB |   2921 TiB |\n","|       from small pool | 454606 KiB |    473 MiB |      8 TiB |      8 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 673378 KiB |   5121 MiB |   2930 TiB |   2930 TiB |\n","|       from large pool | 218772 KiB |   4682 MiB |   2921 TiB |   2921 TiB |\n","|       from small pool | 454606 KiB |    473 MiB |      8 TiB |      8 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |   5102 MiB |   2922 TiB |   2922 TiB |\n","|       from large pool | 213248 KiB |   4668 MiB |   2913 TiB |   2913 TiB |\n","|       from small pool | 450193 KiB |    469 MiB |      8 TiB |      8 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1584 MiB |   5558 MiB | 662928 GiB | 662927 GiB |\n","|       from large pool |   1134 MiB |   5094 MiB | 661630 GiB | 661629 GiB |\n","|       from small pool |    450 MiB |    476 MiB |   1298 GiB |   1298 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |    926 MiB |   1070 MiB |   1024 TiB |   1024 TiB |\n","|       from large pool |    920 MiB |   1065 MiB |   1014 TiB |   1014 TiB |\n","|       from small pool |      6 MiB |     24 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  117619 K  |  117600 K  |\n","|       from large pool |      98    |     248    |   69245 K  |   69245 K  |\n","|       from small pool |   18777    |   18924    |   48374 K  |   48355 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  117619 K  |  117600 K  |\n","|       from large pool |      98    |     248    |   69245 K  |   69245 K  |\n","|       from small pool |   18777    |   18924    |   48374 K  |   48355 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     239    |     311    |    6094 K  |    6094 K  |\n","|       from large pool |      14    |      79    |    5429 K  |    5429 K  |\n","|       from small pool |     225    |     238    |     664 K  |     664 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      89    |     160    |   56295 K  |   56295 K  |\n","|       from large pool |      13    |      57    |   37402 K  |   37402 K  |\n","|       from small pool |      76    |     118    |   18892 K  |   18892 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:51/188 batch:688/8961 epoch:1/10\n","full seq: Since neither took the majority vote, one resident suggested that the two exchange daily duties in the mayor's office, providing the city with not one, but two mayors.Ģġġġġġġġġġġġġġġġġġġġġ\n","pref seq: Since neither took the majority vote, one resident \n","next tok:                                                   s\n","pred tok:                                                   Ģ\n","Completed batch.\n","epoch:1/10 batch:688/8961 batch_size:162 loss:1.1229493618011475 time_for_batch_instance:156.96419429779053 total_batch_time:75024.67300105095 running_batch_average:109.04748982710893\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 671866 KiB |  11454 MiB |   2937 TiB |   2937 TiB |\n","|       from large pool | 217260 KiB |  11005 MiB |   2928 TiB |   2928 TiB |\n","|       from small pool | 454606 KiB |    479 MiB |      8 TiB |      8 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 671866 KiB |  11454 MiB |   2937 TiB |   2937 TiB |\n","|       from large pool | 217260 KiB |  11005 MiB |   2928 TiB |   2928 TiB |\n","|       from small pool | 454606 KiB |    479 MiB |      8 TiB |      8 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  11432 MiB |   2929 TiB |   2929 TiB |\n","|       from large pool | 213248 KiB |  10987 MiB |   2920 TiB |   2920 TiB |\n","|       from small pool | 450193 KiB |    475 MiB |      8 TiB |      8 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1504 MiB |  12026 MiB | 664520 GiB | 664519 GiB |\n","|       from large pool |   1054 MiB |  11562 MiB | 663220 GiB | 663218 GiB |\n","|       from small pool |    450 MiB |    484 MiB |   1300 GiB |   1300 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |    847 MiB |   1591 MiB |   1026 TiB |   1026 TiB |\n","|       from large pool |    841 MiB |   1585 MiB |   1016 TiB |   1016 TiB |\n","|       from small pool |      6 MiB |     22 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  117864 K  |  117845 K  |\n","|       from large pool |      98    |     248    |   69387 K  |   69387 K  |\n","|       from small pool |   18777    |   18924    |   48476 K  |   48457 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  117864 K  |  117845 K  |\n","|       from large pool |      98    |     248    |   69387 K  |   69387 K  |\n","|       from small pool |   18777    |   18924    |   48476 K  |   48457 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     238    |     321    |    6107 K  |    6107 K  |\n","|       from large pool |      13    |      90    |    5441 K  |    5441 K  |\n","|       from small pool |     225    |     242    |     666 K  |     665 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      90    |     188    |   56405 K  |   56405 K  |\n","|       from large pool |      14    |      81    |   37472 K  |   37472 K  |\n","|       from small pool |      76    |     123    |   18933 K  |   18933 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:144/188 batch:689/8961 epoch:1/10\n","full seq: While sharply criticising the Finnish envoy and even calling for his replacement, Moscow has stopped short of a making a clear threat to use its Security Council veto.Ģġġġġġġġġġġġġġġġġġġġġ\n","pref seq: While sharply criticising the Finnish envoy and even calling for his replacement, Moscow has stopped short of a making a clear threat to use its\n","next tok:                                                                                                                                                 \n","pred tok:                                                                                                                                                Ģ\n","Completed batch.\n","epoch:1/10 batch:689/8961 batch_size:161 loss:1.6047236919403076 time_for_batch_instance:156.86151599884033 total_batch_time:75181.53451704979 running_batch_average:109.11688609150913\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 672032 KiB |  11428 MiB |   2944 TiB |   2944 TiB |\n","|       from large pool | 217426 KiB |  10979 MiB |   2935 TiB |   2935 TiB |\n","|       from small pool | 454606 KiB |    479 MiB |      8 TiB |      8 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 672032 KiB |  11428 MiB |   2944 TiB |   2944 TiB |\n","|       from large pool | 217426 KiB |  10979 MiB |   2935 TiB |   2935 TiB |\n","|       from small pool | 454606 KiB |    479 MiB |      8 TiB |      8 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  11405 MiB |   2935 TiB |   2935 TiB |\n","|       from large pool | 213248 KiB |  10961 MiB |   2927 TiB |   2927 TiB |\n","|       from small pool | 450193 KiB |    475 MiB |      8 TiB |      8 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1630 MiB |  11998 MiB | 666111 GiB | 666109 GiB |\n","|       from large pool |   1180 MiB |  11536 MiB | 664808 GiB | 664806 GiB |\n","|       from small pool |    450 MiB |    484 MiB |   1303 GiB |   1302 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |    973 MiB |   1662 MiB |   1028 TiB |   1028 TiB |\n","|       from large pool |    967 MiB |   1653 MiB |   1019 TiB |   1019 TiB |\n","|       from small pool |      6 MiB |     23 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  118108 K  |  118089 K  |\n","|       from large pool |      98    |     248    |   69529 K  |   69529 K  |\n","|       from small pool |   18777    |   18924    |   48578 K  |   48559 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  118108 K  |  118089 K  |\n","|       from large pool |      98    |     248    |   69529 K  |   69529 K  |\n","|       from small pool |   18777    |   18924    |   48578 K  |   48559 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     238    |     322    |    6120 K  |    6120 K  |\n","|       from large pool |      13    |      91    |    5453 K  |    5453 K  |\n","|       from small pool |     225    |     242    |     667 K  |     667 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      85    |     184    |   56514 K  |   56514 K  |\n","|       from large pool |      12    |      78    |   37541 K  |   37541 K  |\n","|       from small pool |      73    |     122    |   18972 K  |   18972 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:36/182 batch:690/8961 epoch:1/10\n","full seq: Now I see a democratic Romania, which is orienting itself towards a top position in Europe,\" Peres said on Thursday (August 12th) during a joint news conference with Basescu.Ģġġġġġġġ\n","pref seq: Now I see a democratic Romania, whic\n","next tok:                                    h\n","pred tok:                                    :\n","Completed batch.\n","epoch:1/10 batch:690/8961 batch_size:161 loss:1.5859631299972534 time_for_batch_instance:150.87470412254333 total_batch_time:75332.40922117233 running_batch_average:109.1774046683657\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 673410 KiB |  11106 MiB |   2950 TiB |   2950 TiB |\n","|       from large pool | 218804 KiB |  10657 MiB |   2941 TiB |   2941 TiB |\n","|       from small pool | 454606 KiB |    479 MiB |      8 TiB |      8 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 673410 KiB |  11106 MiB |   2950 TiB |   2950 TiB |\n","|       from large pool | 218804 KiB |  10657 MiB |   2941 TiB |   2941 TiB |\n","|       from small pool | 454606 KiB |    479 MiB |      8 TiB |      8 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  11100 MiB |   2942 TiB |   2942 TiB |\n","|       from large pool | 213248 KiB |  10655 MiB |   2933 TiB |   2933 TiB |\n","|       from small pool | 450193 KiB |    475 MiB |      8 TiB |      8 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1854 MiB |  11724 MiB | 667621 GiB | 667619 GiB |\n","|       from large pool |   1404 MiB |  11260 MiB | 666315 GiB | 666314 GiB |\n","|       from small pool |    450 MiB |    484 MiB |   1305 GiB |   1305 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1196 MiB |   1665 MiB |   1030 TiB |   1030 TiB |\n","|       from large pool |   1190 MiB |   1658 MiB |   1021 TiB |   1021 TiB |\n","|       from small pool |      6 MiB |     25 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  118344 K  |  118325 K  |\n","|       from large pool |      98    |     248    |   69667 K  |   69667 K  |\n","|       from small pool |   18777    |   18924    |   48677 K  |   48658 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  118344 K  |  118325 K  |\n","|       from large pool |      98    |     248    |   69667 K  |   69667 K  |\n","|       from small pool |   18777    |   18924    |   48677 K  |   48658 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     239    |     321    |    6133 K  |    6132 K  |\n","|       from large pool |      14    |      89    |    5464 K  |    5464 K  |\n","|       from small pool |     225    |     242    |     668 K  |     668 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      93    |     191    |   56641 K  |   56641 K  |\n","|       from large pool |      14    |      86    |   37630 K  |   37630 K  |\n","|       from small pool |      79    |     125    |   19010 K  |   19010 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:114/145 batch:691/8961 epoch:1/10\n","full seq: \"The international monitors and OSCE said that the elections were not conducted according to the criteria, and that is a basic requirement.Ģġġġġġ\n","pref seq: \"The international monitors and OSCE said that the elections were not conducted according to the criteria, and tha\n","next tok:                                                                                                                  t\n","pred tok:                                                                                                                  0\n","Completed batch.\n","epoch:1/10 batch:691/8961 batch_size:161 loss:2.3455076217651367 time_for_batch_instance:119.1958224773407 total_batch_time:75451.60504364967 running_batch_average:109.19190310224265\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 671048 KiB |   8982 MiB |   2954 TiB |   2954 TiB |\n","|       from large pool | 216442 KiB |   8537 MiB |   2946 TiB |   2946 TiB |\n","|       from small pool | 454606 KiB |    477 MiB |      8 TiB |      8 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 671048 KiB |   8982 MiB |   2954 TiB |   2954 TiB |\n","|       from large pool | 216442 KiB |   8537 MiB |   2946 TiB |   2946 TiB |\n","|       from small pool | 454606 KiB |    477 MiB |      8 TiB |      8 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |   8964 MiB |   2946 TiB |   2946 TiB |\n","|       from large pool | 213248 KiB |   8523 MiB |   2937 TiB |   2937 TiB |\n","|       from small pool | 450193 KiB |    472 MiB |      8 TiB |      8 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1602 MiB |   9414 MiB | 668506 GiB | 668504 GiB |\n","|       from large pool |   1154 MiB |   8952 MiB | 667198 GiB | 667197 GiB |\n","|       from small pool |    448 MiB |    480 MiB |   1307 GiB |   1307 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |    946 MiB |   2044 MiB |   1032 TiB |   1032 TiB |\n","|       from large pool |    942 MiB |   2035 MiB |   1022 TiB |   1022 TiB |\n","|       from small pool |      4 MiB |     23 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  118532 K  |  118513 K  |\n","|       from large pool |      98    |     248    |   69776 K  |   69776 K  |\n","|       from small pool |   18777    |   18924    |   48756 K  |   48737 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  118532 K  |  118513 K  |\n","|       from large pool |      98    |     248    |   69776 K  |   69776 K  |\n","|       from small pool |   18777    |   18924    |   48756 K  |   48737 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     238    |     318    |    6142 K  |    6142 K  |\n","|       from large pool |      14    |      87    |    5473 K  |    5473 K  |\n","|       from small pool |     224    |     240    |     669 K  |     669 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      88    |     164    |   56737 K  |   56737 K  |\n","|       from large pool |      14    |      59    |   37695 K  |   37695 K  |\n","|       from small pool |      74    |     122    |   19041 K  |   19041 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:97/122 batch:692/8961 epoch:1/10\n","full seq: Take the social networking site Facebook, a medium embraced by the middle-age generations as well as Kosovo's youth.Ģġġġġġ\n","pref seq: Take the social networking site Facebook, a medium embraced by the middle-age generations as well\n","next tok:                                                                                                  \n","pred tok:                                                                                                 2\n","Completed batch.\n","epoch:1/10 batch:692/8961 batch_size:161 loss:2.6514737606048584 time_for_batch_instance:99.6431794166565 total_batch_time:75551.24822306633 running_batch_average:109.17810436859297\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 670951 KiB |   7643 MiB |   2957 TiB |   2957 TiB |\n","|       from large pool | 216345 KiB |   7201 MiB |   2949 TiB |   2949 TiB |\n","|       from small pool | 454606 KiB |    475 MiB |      8 TiB |      8 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 670951 KiB |   7643 MiB |   2957 TiB |   2957 TiB |\n","|       from large pool | 216345 KiB |   7201 MiB |   2949 TiB |   2949 TiB |\n","|       from small pool | 454606 KiB |    475 MiB |      8 TiB |      8 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |   7636 MiB |   2949 TiB |   2949 TiB |\n","|       from large pool | 213248 KiB |   7198 MiB |   2940 TiB |   2940 TiB |\n","|       from small pool | 450193 KiB |    470 MiB |      8 TiB |      8 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1494 MiB |   8082 MiB | 669154 GiB | 669152 GiB |\n","|       from large pool |   1042 MiB |   7616 MiB | 667845 GiB | 667844 GiB |\n","|       from small pool |    452 MiB |    478 MiB |   1309 GiB |   1308 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |    838 MiB |   1364 MiB |   1033 TiB |   1033 TiB |\n","|       from large pool |    830 MiB |   1355 MiB |   1023 TiB |   1023 TiB |\n","|       from small pool |      8 MiB |     22 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  118689 K  |  118670 K  |\n","|       from large pool |      98    |     248    |   69867 K  |   69867 K  |\n","|       from small pool |   18777    |   18924    |   48822 K  |   48803 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  118689 K  |  118670 K  |\n","|       from large pool |      98    |     248    |   69867 K  |   69867 K  |\n","|       from small pool |   18777    |   18924    |   48822 K  |   48803 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     241    |     320    |    6150 K  |    6150 K  |\n","|       from large pool |      15    |      86    |    5480 K  |    5480 K  |\n","|       from small pool |     226    |     239    |     670 K  |     670 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      97    |     182    |   56809 K  |   56808 K  |\n","|       from large pool |      14    |      79    |   37742 K  |   37742 K  |\n","|       from small pool |      83    |     121    |   19066 K  |   19066 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:107/118 batch:693/8961 epoch:1/10\n","full seq: We have a wonderful document, very significant, from the historical, political, educational and artistic aspect.Ģġġġġġ\n","pref seq: We have a wonderful document, very significant, from the historical, political, educational and artistic as\n","next tok:                                                                                                           p\n","pred tok:                                                                                                           Ģ\n","Completed batch.\n","epoch:1/10 batch:693/8961 batch_size:161 loss:2.066344738006592 time_for_batch_instance:96.16237545013428 total_batch_time:75647.41059851646 running_batch_average:109.15932265298191\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 671400 KiB |   7420 MiB |   2960 TiB |   2960 TiB |\n","|       from large pool | 216794 KiB |   6978 MiB |   2951 TiB |   2951 TiB |\n","|       from small pool | 454606 KiB |    475 MiB |      8 TiB |      8 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 671400 KiB |   7420 MiB |   2960 TiB |   2960 TiB |\n","|       from large pool | 216794 KiB |   6978 MiB |   2951 TiB |   2951 TiB |\n","|       from small pool | 454606 KiB |    475 MiB |      8 TiB |      8 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |   7405 MiB |   2952 TiB |   2952 TiB |\n","|       from large pool | 213248 KiB |   6968 MiB |   2943 TiB |   2943 TiB |\n","|       from small pool | 450193 KiB |    470 MiB |      8 TiB |      8 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1570 MiB |   7810 MiB | 669748 GiB | 669747 GiB |\n","|       from large pool |   1116 MiB |   7342 MiB | 668437 GiB | 668436 GiB |\n","|       from small pool |    454 MiB |    478 MiB |   1311 GiB |   1310 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |    914 MiB |   1493 MiB |   1034 TiB |   1034 TiB |\n","|       from large pool |    904 MiB |   1484 MiB |   1024 TiB |   1024 TiB |\n","|       from small pool |     10 MiB |     22 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  118841 K  |  118823 K  |\n","|       from large pool |      98    |     248    |   69955 K  |   69955 K  |\n","|       from small pool |   18777    |   18924    |   48886 K  |   48867 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  118841 K  |  118823 K  |\n","|       from large pool |      98    |     248    |   69955 K  |   69955 K  |\n","|       from small pool |   18777    |   18924    |   48886 K  |   48867 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     241    |     319    |    6158 K  |    6158 K  |\n","|       from large pool |      14    |      85    |    5487 K  |    5487 K  |\n","|       from small pool |     227    |     239    |     671 K  |     671 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      91    |     161    |   56886 K  |   56886 K  |\n","|       from large pool |      12    |      58    |   37796 K  |   37796 K  |\n","|       from small pool |      79    |     120    |   19090 K  |   19090 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:92/111 batch:694/8961 epoch:1/10\n","full seq: \"I hope that the report is in the continuity of all the processes Kosovo has been through.Ģġġġġġġġġġġġġġġġġġġġġ\n","pref seq: \"I hope that the report is in the continuity of all the processes Kosovo has been through.Ģġ\n","next tok:                                                                                            ġ\n","pred tok:                                                                                            Ģ\n","Completed batch.\n","epoch:1/10 batch:694/8961 batch_size:161 loss:2.1184890270233154 time_for_batch_instance:89.97005772590637 total_batch_time:75737.38065624237 running_batch_average:109.13167241533483\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 670629 KiB |   6949 MiB |   2963 TiB |   2963 TiB |\n","|       from large pool | 216023 KiB |   6507 MiB |   2954 TiB |   2954 TiB |\n","|       from small pool | 454606 KiB |    474 MiB |      8 TiB |      8 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 670629 KiB |   6949 MiB |   2963 TiB |   2963 TiB |\n","|       from large pool | 216023 KiB |   6507 MiB |   2954 TiB |   2954 TiB |\n","|       from small pool | 454606 KiB |    474 MiB |      8 TiB |      8 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |   6921 MiB |   2954 TiB |   2954 TiB |\n","|       from large pool | 213248 KiB |   6483 MiB |   2945 TiB |   2945 TiB |\n","|       from small pool | 450193 KiB |    470 MiB |      8 TiB |      8 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1548 MiB |   7328 MiB | 670261 GiB | 670260 GiB |\n","|       from large pool |   1096 MiB |   6862 MiB | 668949 GiB | 668948 GiB |\n","|       from small pool |    452 MiB |    478 MiB |   1312 GiB |   1312 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |    893 MiB |   1443 MiB |   1035 TiB |   1035 TiB |\n","|       from large pool |    885 MiB |   1436 MiB |   1025 TiB |   1025 TiB |\n","|       from small pool |      8 MiB |     22 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  118984 K  |  118965 K  |\n","|       from large pool |      98    |     248    |   70038 K  |   70038 K  |\n","|       from small pool |   18777    |   18924    |   48946 K  |   48927 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  118984 K  |  118965 K  |\n","|       from large pool |      98    |     248    |   70038 K  |   70038 K  |\n","|       from small pool |   18777    |   18924    |   48946 K  |   48927 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     240    |     319    |    6165 K  |    6165 K  |\n","|       from large pool |      14    |      85    |    5493 K  |    5493 K  |\n","|       from small pool |     226    |     239    |     672 K  |     671 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      96    |     175    |   56952 K  |   56952 K  |\n","|       from large pool |      16    |      73    |   37839 K  |   37839 K  |\n","|       from small pool |      80    |     122    |   19113 K  |   19112 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:84/103 batch:695/8961 epoch:1/10\n","full seq: If this sale is successful, it will continue to do so,\" the statement quoted Ashdown as saying.Ģġġġġġġġ\n","pref seq: If this sale is successful, it will continue to do so,\" the statement quoted Ashdown\n","next tok:                                                                                     \n","pred tok:                                                                                    Ģ\n","Completed batch.\n","epoch:1/10 batch:695/8961 batch_size:161 loss:1.2361245155334473 time_for_batch_instance:83.2793939113617 total_batch_time:75820.66005015373 running_batch_average:109.09447489230753\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 670162 KiB |   6524 MiB |   2965 TiB |   2965 TiB |\n","|       from large pool | 215556 KiB |   6083 MiB |   2956 TiB |   2956 TiB |\n","|       from small pool | 454606 KiB |    474 MiB |      8 TiB |      8 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 670162 KiB |   6524 MiB |   2965 TiB |   2965 TiB |\n","|       from large pool | 215556 KiB |   6083 MiB |   2956 TiB |   2956 TiB |\n","|       from small pool | 454606 KiB |    474 MiB |      8 TiB |      8 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |   6500 MiB |   2956 TiB |   2956 TiB |\n","|       from large pool | 213248 KiB |   6063 MiB |   2947 TiB |   2947 TiB |\n","|       from small pool | 450193 KiB |    470 MiB |      8 TiB |      8 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1828 MiB |   6908 MiB | 670689 GiB | 670687 GiB |\n","|       from large pool |   1378 MiB |   6442 MiB | 669374 GiB | 669373 GiB |\n","|       from small pool |    450 MiB |    478 MiB |   1314 GiB |   1313 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1173 MiB |   1418 MiB |   1036 TiB |   1036 TiB |\n","|       from large pool |   1167 MiB |   1410 MiB |   1026 TiB |   1026 TiB |\n","|       from small pool |      6 MiB |     22 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  119117 K  |  119098 K  |\n","|       from large pool |      98    |     248    |   70115 K  |   70115 K  |\n","|       from small pool |   18777    |   18924    |   49001 K  |   48983 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  119117 K  |  119098 K  |\n","|       from large pool |      98    |     248    |   70115 K  |   70115 K  |\n","|       from small pool |   18777    |   18924    |   49001 K  |   48983 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     241    |     316    |    6172 K  |    6172 K  |\n","|       from large pool |      16    |      83    |    5499 K  |    5499 K  |\n","|       from small pool |     225    |     239    |     672 K  |     672 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      90    |     163    |   57023 K  |   57023 K  |\n","|       from large pool |      17    |      61    |   37889 K  |   37889 K  |\n","|       from small pool |      73    |     122    |   19133 K  |   19133 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:33/68 batch:696/8961 epoch:1/10\n","full seq: Balkan mercenaries in Libya risk lives for gainĢġġġġġġġġġġġġġġġġġġġġ\n","pref seq: Balkan mercenaries in Libya risk \n","next tok:                                 l\n","pred tok:                                 .\n","Completed batch.\n","epoch:1/10 batch:696/8961 batch_size:161 loss:3.072399139404297 time_for_batch_instance:54.26126289367676 total_batch_time:75874.92131304741 running_batch_average:109.01569154173478\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 671099 KiB |   5028 MiB |   2966 TiB |   2966 TiB |\n","|       from large pool | 216493 KiB |   4590 MiB |   2957 TiB |   2957 TiB |\n","|       from small pool | 454606 KiB |    472 MiB |      8 TiB |      8 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 671099 KiB |   5028 MiB |   2966 TiB |   2966 TiB |\n","|       from large pool | 216493 KiB |   4590 MiB |   2957 TiB |   2957 TiB |\n","|       from small pool | 454606 KiB |    472 MiB |      8 TiB |      8 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |   5006 MiB |   2958 TiB |   2958 TiB |\n","|       from large pool | 213248 KiB |   4572 MiB |   2949 TiB |   2949 TiB |\n","|       from small pool | 450193 KiB |    468 MiB |      8 TiB |      8 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1860 MiB |   5360 MiB | 670891 GiB | 670889 GiB |\n","|       from large pool |   1410 MiB |   4896 MiB | 669576 GiB | 669574 GiB |\n","|       from small pool |    450 MiB |    476 MiB |   1315 GiB |   1314 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1204 MiB |   1454 MiB |   1036 TiB |   1036 TiB |\n","|       from large pool |   1198 MiB |   1449 MiB |   1026 TiB |   1026 TiB |\n","|       from small pool |      6 MiB |     24 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  119203 K  |  119184 K  |\n","|       from large pool |      98    |     248    |   70164 K  |   70164 K  |\n","|       from small pool |   18777    |   18924    |   49038 K  |   49019 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  119203 K  |  119184 K  |\n","|       from large pool |      98    |     248    |   70164 K  |   70164 K  |\n","|       from small pool |   18777    |   18924    |   49038 K  |   49019 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     241    |     308    |    6176 K  |    6175 K  |\n","|       from large pool |      16    |      76    |    5502 K  |    5502 K  |\n","|       from small pool |     225    |     238    |     673 K  |     673 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      87    |     150    |   57067 K  |   57067 K  |\n","|       from large pool |      15    |      48    |   37920 K  |   37920 K  |\n","|       from small pool |      72    |     121    |   19147 K  |   19147 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:58/254 batch:697/8961 epoch:1/10\n","full seq: More than 200 unarmed monitors from 22 EU member nations have gone to Georgia to oversee the withdrawal of Russian forces from two buffer zones adjacent to the former Soviet republic's breakaway regions of South Ossetia and Abkhazia.Ģġġġġġġġġġġġġġġġġġġġġ\n","pref seq: More than 200 unarmed monitors from 22 EU member nations h\n","next tok:                                                          a\n","pred tok:                                                          Ģ\n","Completed batch.\n","epoch:1/10 batch:697/8961 batch_size:160 loss:1.057788610458374 time_for_batch_instance:214.45069408416748 total_batch_time:76089.37200713158 running_batch_average:109.16696127278561\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 669454 KiB |  15176 MiB |   2978 TiB |   2978 TiB |\n","|       from large pool | 214848 KiB |  14739 MiB |   2969 TiB |   2969 TiB |\n","|       from small pool | 454606 KiB |    472 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 669454 KiB |  15176 MiB |   2978 TiB |   2978 TiB |\n","|       from large pool | 214848 KiB |  14739 MiB |   2969 TiB |   2969 TiB |\n","|       from small pool | 454606 KiB |    472 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  15125 MiB |   2970 TiB |   2970 TiB |\n","|       from large pool | 213248 KiB |  14692 MiB |   2961 TiB |   2961 TiB |\n","|       from small pool | 450193 KiB |    468 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1408 MiB |  15850 MiB | 673817 GiB | 673816 GiB |\n","|       from large pool |    960 MiB |  15386 MiB | 672498 GiB | 672497 GiB |\n","|       from small pool |    448 MiB |    476 MiB |   1318 GiB |   1318 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 772337 KiB |   1986 MiB |   1040 TiB |   1040 TiB |\n","|       from large pool | 768191 KiB |   1983 MiB |   1030 TiB |   1030 TiB |\n","|       from small pool |   4146 KiB |     24 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  119534 K  |  119515 K  |\n","|       from large pool |      98    |     263    |   70365 K  |   70365 K  |\n","|       from small pool |   18777    |   18924    |   49168 K  |   49149 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  119534 K  |  119515 K  |\n","|       from large pool |      98    |     263    |   70365 K  |   70365 K  |\n","|       from small pool |   18777    |   18924    |   49168 K  |   49149 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     237    |     324    |    6194 K  |    6194 K  |\n","|       from large pool |      13    |      92    |    5518 K  |    5518 K  |\n","|       from small pool |     224    |     238    |     675 K  |     675 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      88    |     142    |   57203 K  |   57202 K  |\n","|       from large pool |      15    |      40    |   38002 K  |   38002 K  |\n","|       from small pool |      73    |     122    |   19200 K  |   19199 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:1/250 batch:698/8961 epoch:1/10\n","full seq: The meeting that has generated the greatest media interest is the one between Karamanlis and Erdogan on Thursday, which Turkish media have described as aimed at reviving confidence-building measures between the two NATO members.Ģġġġġġġġġġġġġġġġġġġġġġ\n","pref seq: T\n","next tok: h\n","pred tok: .\n","Completed batch.\n","epoch:1/10 batch:698/8961 batch_size:160 loss:1.1271427869796753 time_for_batch_instance:210.0269124507904 total_batch_time:76299.39891958237 running_batch_average:109.3114597701753\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 670731 KiB |  14883 MiB |   2990 TiB |   2990 TiB |\n","|       from large pool | 216125 KiB |  14446 MiB |   2981 TiB |   2981 TiB |\n","|       from small pool | 454606 KiB |    472 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 670731 KiB |  14883 MiB |   2990 TiB |   2990 TiB |\n","|       from large pool | 216125 KiB |  14446 MiB |   2981 TiB |   2981 TiB |\n","|       from small pool | 454606 KiB |    472 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  14855 MiB |   2981 TiB |   2981 TiB |\n","|       from large pool | 213248 KiB |  14423 MiB |   2972 TiB |   2972 TiB |\n","|       from small pool | 450193 KiB |    467 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1418 MiB |  15562 MiB | 676673 GiB | 676671 GiB |\n","|       from large pool |    970 MiB |  15098 MiB | 675350 GiB | 675349 GiB |\n","|       from small pool |    448 MiB |    476 MiB |   1322 GiB |   1322 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 781300 KiB |   1780 MiB |   1044 TiB |   1044 TiB |\n","|       from large pool | 777154 KiB |   1775 MiB |   1034 TiB |   1034 TiB |\n","|       from small pool |   4146 KiB |     21 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  119860 K  |  119841 K  |\n","|       from large pool |      98    |     263    |   70563 K  |   70563 K  |\n","|       from small pool |   18777    |   18924    |   49296 K  |   49278 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  119860 K  |  119841 K  |\n","|       from large pool |      98    |     263    |   70563 K  |   70563 K  |\n","|       from small pool |   18777    |   18924    |   49296 K  |   49278 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     238    |     323    |    6212 K  |    6211 K  |\n","|       from large pool |      14    |      92    |    5534 K  |    5534 K  |\n","|       from small pool |     224    |     238    |     677 K  |     676 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      85    |     150    |   57370 K  |   57370 K  |\n","|       from large pool |      13    |      47    |   38119 K  |   38119 K  |\n","|       from small pool |      72    |     120    |   19251 K  |   19250 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:61/250 batch:699/8961 epoch:1/10\n","full seq: \"No doubt, we are leaders in gymnastics, and we have some expectations in canoe/kayak, fencing, shooting -- sports where we are ranked quite well,\" said the president of the Romanian Olympic Committee, former tennis ace Ion Tiriac.Ģġġġġġġġġġġġġġġġġġġ\n","pref seq: \"No doubt, we are leaders in gymnastics, and we have some exp\n","next tok:                                                             e\n","pred tok:                                                             H\n","Completed batch.\n","epoch:1/10 batch:699/8961 batch_size:160 loss:0.9410943984985352 time_for_batch_instance:210.23659896850586 total_batch_time:76509.63551855087 running_batch_average:109.45584480479381\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 670227 KiB |  15014 MiB |   3002 TiB |   3002 TiB |\n","|       from large pool | 215621 KiB |  14577 MiB |   2993 TiB |   2993 TiB |\n","|       from small pool | 454606 KiB |    472 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 670227 KiB |  15014 MiB |   3002 TiB |   3002 TiB |\n","|       from large pool | 215621 KiB |  14577 MiB |   2993 TiB |   2993 TiB |\n","|       from small pool | 454606 KiB |    472 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  14976 MiB |   2993 TiB |   2993 TiB |\n","|       from large pool | 213248 KiB |  14543 MiB |   2984 TiB |   2984 TiB |\n","|       from small pool | 450193 KiB |    467 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1512 MiB |  15714 MiB | 679585 GiB | 679584 GiB |\n","|       from large pool |   1064 MiB |  15250 MiB | 678259 GiB | 678258 GiB |\n","|       from small pool |    448 MiB |    476 MiB |   1326 GiB |   1325 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |    857 MiB |   1721 MiB |   1048 TiB |   1048 TiB |\n","|       from large pool |    853 MiB |   1716 MiB |   1038 TiB |   1038 TiB |\n","|       from small pool |      4 MiB |     22 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  120186 K  |  120167 K  |\n","|       from large pool |      98    |     263    |   70761 K  |   70761 K  |\n","|       from small pool |   18777    |   18924    |   49425 K  |   49406 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  120186 K  |  120167 K  |\n","|       from large pool |      98    |     263    |   70761 K  |   70761 K  |\n","|       from small pool |   18777    |   18924    |   49425 K  |   49406 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     240    |     321    |    6229 K  |    6229 K  |\n","|       from large pool |      16    |      89    |    5550 K  |    5550 K  |\n","|       from small pool |     224    |     238    |     679 K  |     678 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      90    |     151    |   57516 K  |   57515 K  |\n","|       from large pool |      16    |      48    |   38214 K  |   38214 K  |\n","|       from small pool |      74    |     120    |   19301 K  |   19301 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:150/182 batch:700/8961 epoch:1/10\n","full seq: DPA member Imer Aliu said it is because the government failed to implement legislation derived from the Ohrid Framework Agreement, and is neglecting the rights of Albanians.Ģġġġġġġġġ\n","pref seq: DPA member Imer Aliu said it is because the government failed to implement legislation derived from the Ohrid Framework Agreement, and is neglecting t\n","next tok:                                                                                                                                                      h\n","pred tok:                                                                                                                                                      %\n","Completed batch.\n","epoch:1/10 batch:700/8961 batch_size:160 loss:3.0430808067321777 time_for_batch_instance:150.80474710464478 total_batch_time:76660.44026565552 running_batch_average:109.51491466522216\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 673019 KiB |  11053 MiB |   3008 TiB |   3008 TiB |\n","|       from large pool | 218413 KiB |  10604 MiB |   2999 TiB |   2999 TiB |\n","|       from small pool | 454606 KiB |    479 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 673019 KiB |  11053 MiB |   3008 TiB |   3008 TiB |\n","|       from large pool | 218413 KiB |  10604 MiB |   2999 TiB |   2999 TiB |\n","|       from small pool | 454606 KiB |    479 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  11035 MiB |   3000 TiB |   3000 TiB |\n","|       from large pool | 213248 KiB |  10590 MiB |   2991 TiB |   2991 TiB |\n","|       from small pool | 450193 KiB |    474 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1620 MiB |  11638 MiB | 681087 GiB | 681085 GiB |\n","|       from large pool |   1170 MiB |  11174 MiB | 679758 GiB | 679757 GiB |\n","|       from small pool |    450 MiB |    484 MiB |   1328 GiB |   1328 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |    962 MiB |   1599 MiB |   1050 TiB |   1050 TiB |\n","|       from large pool |    956 MiB |   1592 MiB |   1040 TiB |   1040 TiB |\n","|       from small pool |      6 MiB |     28 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  120422 K  |  120403 K  |\n","|       from large pool |      98    |     248    |   70898 K  |   70898 K  |\n","|       from small pool |   18777    |   18924    |   49523 K  |   49504 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  120422 K  |  120403 K  |\n","|       from large pool |      98    |     248    |   70898 K  |   70898 K  |\n","|       from small pool |   18777    |   18924    |   49523 K  |   49504 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     238    |     323    |    6242 K  |    6242 K  |\n","|       from large pool |      13    |      91    |    5562 K  |    5562 K  |\n","|       from small pool |     225    |     242    |     680 K  |     680 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      92    |     178    |   57637 K  |   57636 K  |\n","|       from large pool |      13    |      73    |   38296 K  |   38296 K  |\n","|       from small pool |      79    |     123    |   19340 K  |   19340 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:62/137 batch:701/8961 epoch:1/10\n","full seq: A spokesman for Serbia's special war crimes prosecutor's office said Zupljanin would be transferred to The Hague within 72 hours.Ģġġġġġġġ\n","pref seq: A spokesman for Serbia's special war crimes prosecutor's offic\n","next tok:                                                              e\n","pred tok:                                                              y\n","Completed batch.\n","epoch:1/10 batch:701/8961 batch_size:160 loss:3.9812145233154297 time_for_batch_instance:112.07034969329834 total_batch_time:76772.51061534882 running_batch_average:109.51856007895694\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 669182 KiB |   8453 MiB |   3012 TiB |   3012 TiB |\n","|       from large pool | 214576 KiB |   8008 MiB |   3003 TiB |   3003 TiB |\n","|       from small pool | 454606 KiB |    476 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 669182 KiB |   8453 MiB |   3012 TiB |   3012 TiB |\n","|       from large pool | 214576 KiB |   8008 MiB |   3003 TiB |   3003 TiB |\n","|       from small pool | 454606 KiB |    476 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |   8414 MiB |   3003 TiB |   3003 TiB |\n","|       from large pool | 213248 KiB |   7973 MiB |   2994 TiB |   2994 TiB |\n","|       from small pool | 450193 KiB |    472 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1732 MiB |   8870 MiB | 681888 GiB | 681886 GiB |\n","|       from large pool |   1284 MiB |   8408 MiB | 680557 GiB | 680556 GiB |\n","|       from small pool |    448 MiB |    480 MiB |   1330 GiB |   1330 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1078 MiB |   1563 MiB |   1052 TiB |   1052 TiB |\n","|       from large pool |   1074 MiB |   1558 MiB |   1042 TiB |   1042 TiB |\n","|       from small pool |      4 MiB |     24 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  120599 K  |  120580 K  |\n","|       from large pool |      98    |     248    |   71001 K  |   71001 K  |\n","|       from small pool |   18777    |   18924    |   49598 K  |   49579 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  120599 K  |  120580 K  |\n","|       from large pool |      98    |     248    |   71001 K  |   71001 K  |\n","|       from small pool |   18777    |   18924    |   49598 K  |   49579 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     238    |     317    |    6251 K  |    6251 K  |\n","|       from large pool |      14    |      85    |    5570 K  |    5570 K  |\n","|       from small pool |     224    |     240    |     681 K  |     681 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      90    |     162    |   57716 K  |   57715 K  |\n","|       from large pool |      20    |      58    |   38346 K  |   38346 K  |\n","|       from small pool |      70    |     122    |   19369 K  |   19369 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:107/114 batch:702/8961 epoch:1/10\n","full seq: Concerns have been raised following reports of possible vote buying and intimidation by political parties.Ģġġġġġġġ\n","pref seq: Concerns have been raised following reports of possible vote buying and intimidation by political parties.Ģ\n","next tok:                                                                                                           ġ\n","pred tok:                                                                                                           ġ\n","Completed batch.\n","epoch:1/10 batch:702/8961 batch_size:160 loss:3.2114243507385254 time_for_batch_instance:92.6089346408844 total_batch_time:76865.1195499897 running_batch_average:109.49447229343262\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 674701 KiB |   7112 MiB |   3015 TiB |   3015 TiB |\n","|       from large pool | 220095 KiB |   6671 MiB |   3006 TiB |   3006 TiB |\n","|       from small pool | 454606 KiB |    474 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 674701 KiB |   7112 MiB |   3015 TiB |   3015 TiB |\n","|       from large pool | 220095 KiB |   6671 MiB |   3006 TiB |   3006 TiB |\n","|       from small pool | 454606 KiB |    474 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |   7093 MiB |   3006 TiB |   3006 TiB |\n","|       from large pool | 213248 KiB |   6656 MiB |   2997 TiB |   2997 TiB |\n","|       from small pool | 450193 KiB |    470 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1898 MiB |   7474 MiB | 682399 GiB | 682397 GiB |\n","|       from large pool |   1448 MiB |   7008 MiB | 681067 GiB | 681065 GiB |\n","|       from small pool |    450 MiB |    478 MiB |   1332 GiB |   1331 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1239 MiB |   1732 MiB |   1052 TiB |   1052 TiB |\n","|       from large pool |   1233 MiB |   1726 MiB |   1043 TiB |   1043 TiB |\n","|       from small pool |      6 MiB |     24 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  120746 K  |  120727 K  |\n","|       from large pool |      98    |     248    |   71086 K  |   71086 K  |\n","|       from small pool |   18777    |   18924    |   49659 K  |   49640 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  120746 K  |  120727 K  |\n","|       from large pool |      98    |     248    |   71086 K  |   71086 K  |\n","|       from small pool |   18777    |   18924    |   49659 K  |   49640 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     240    |     315    |    6258 K  |    6258 K  |\n","|       from large pool |      15    |      82    |    5576 K  |    5576 K  |\n","|       from small pool |     225    |     239    |     682 K  |     681 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      87    |     165    |   57777 K  |   57777 K  |\n","|       from large pool |      13    |      64    |   38385 K  |   38385 K  |\n","|       from small pool |      74    |     120    |   19392 K  |   19392 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:69/82 batch:703/8961 epoch:1/10\n","full seq: The second edition of the festival featured a series of movie premieres.Ģġġġġġġġġġ\n","pref seq: The second edition of the festival featured a series of movie premier\n","next tok:                                                                     e\n","pred tok:                                                                     Ģ\n","Completed batch.\n","epoch:1/10 batch:703/8961 batch_size:160 loss:2.4783732891082764 time_for_batch_instance:65.89861512184143 total_batch_time:76931.01816511154 running_batch_average:109.43245827185142\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 671854 KiB |   5314 MiB |   3016 TiB |   3016 TiB |\n","|       from large pool | 217248 KiB |   4876 MiB |   3007 TiB |   3007 TiB |\n","|       from small pool | 454606 KiB |    472 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 671854 KiB |   5314 MiB |   3016 TiB |   3016 TiB |\n","|       from large pool | 217248 KiB |   4876 MiB |   3007 TiB |   3007 TiB |\n","|       from small pool | 454606 KiB |    472 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |   5298 MiB |   3007 TiB |   3007 TiB |\n","|       from large pool | 213248 KiB |   4864 MiB |   2998 TiB |   2998 TiB |\n","|       from small pool | 450193 KiB |    468 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1870 MiB |   5732 MiB | 682666 GiB | 682664 GiB |\n","|       from large pool |   1422 MiB |   5268 MiB | 681333 GiB | 681331 GiB |\n","|       from small pool |    448 MiB |    476 MiB |   1333 GiB |   1333 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1213 MiB |   1381 MiB |   1053 TiB |   1053 TiB |\n","|       from large pool |   1209 MiB |   1377 MiB |   1043 TiB |   1043 TiB |\n","|       from small pool |      4 MiB |     22 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  120851 K  |  120832 K  |\n","|       from large pool |      98    |     248    |   71147 K  |   71147 K  |\n","|       from small pool |   18777    |   18924    |   49704 K  |   49685 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  120851 K  |  120832 K  |\n","|       from large pool |      98    |     248    |   71147 K  |   71147 K  |\n","|       from small pool |   18777    |   18924    |   49704 K  |   49685 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     238    |     315    |    6263 K  |    6263 K  |\n","|       from large pool |      14    |      83    |    5580 K  |    5580 K  |\n","|       from small pool |     224    |     238    |     682 K  |     682 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      88    |     152    |   57831 K  |   57831 K  |\n","|       from large pool |      17    |      49    |   38422 K  |   38422 K  |\n","|       from small pool |      71    |     118    |   19408 K  |   19408 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:57/100 batch:704/8961 epoch:1/10\n","full seq: Fadil Hoxha, 32, left Kosovo in September 2009 with his wife and four children.Ģġġġġġġġġġġġġġġġġġġġġ\n","pref seq: Fadil Hoxha, 32, left Kosovo in September 2009 with his w\n","next tok:                                                         i\n","pred tok:                                                         Ģ\n","Completed batch.\n","epoch:1/10 batch:704/8961 batch_size:159 loss:2.7112314701080322 time_for_batch_instance:82.00328922271729 total_batch_time:77013.02145433426 running_batch_average:109.39349638399753\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 669102 KiB |   6281 MiB |   3018 TiB |   3018 TiB |\n","|       from large pool | 214496 KiB |   5840 MiB |   3009 TiB |   3009 TiB |\n","|       from small pool | 454606 KiB |    474 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 669102 KiB |   6281 MiB |   3018 TiB |   3018 TiB |\n","|       from large pool | 214496 KiB |   5840 MiB |   3009 TiB |   3009 TiB |\n","|       from small pool | 454606 KiB |    474 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |   6256 MiB |   3009 TiB |   3009 TiB |\n","|       from large pool | 213248 KiB |   5819 MiB |   3000 TiB |   3000 TiB |\n","|       from small pool | 450193 KiB |    469 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1702 MiB |   6660 MiB | 683064 GiB | 683062 GiB |\n","|       from large pool |   1250 MiB |   6194 MiB | 681729 GiB | 681728 GiB |\n","|       from small pool |    452 MiB |    478 MiB |   1334 GiB |   1334 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1048 MiB |   1393 MiB |   1054 TiB |   1054 TiB |\n","|       from large pool |   1040 MiB |   1386 MiB |   1044 TiB |   1044 TiB |\n","|       from small pool |      8 MiB |     22 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  120979 K  |  120960 K  |\n","|       from large pool |      98    |     248    |   71221 K  |   71221 K  |\n","|       from small pool |   18777    |   18924    |   49758 K  |   49739 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  120979 K  |  120960 K  |\n","|       from large pool |      98    |     248    |   71221 K  |   71221 K  |\n","|       from small pool |   18777    |   18924    |   49758 K  |   49739 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     239    |     315    |    6269 K  |    6269 K  |\n","|       from large pool |      13    |      82    |    5586 K  |    5586 K  |\n","|       from small pool |     226    |     239    |     683 K  |     683 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      99    |     172    |   57889 K  |   57889 K  |\n","|       from large pool |      20    |      69    |   38460 K  |   38460 K  |\n","|       from small pool |      79    |     122    |   19428 K  |   19428 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:43/117 batch:705/8961 epoch:1/10\n","full seq: So it was good to see that the demonstration was well-organised, well-managed and well-policed.\"Ģġġġġġġġġġġġġġġġġġġġġ\n","pref seq: So it was good to see that the demonstratio\n","next tok:                                           n\n","pred tok:                                            \n","Completed batch.\n","epoch:1/10 batch:705/8961 batch_size:158 loss:1.9876394271850586 time_for_batch_instance:95.9928936958313 total_batch_time:77109.01434803009 running_batch_average:109.3744884369221\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 675265 KiB |   7193 MiB |   3021 TiB |   3021 TiB |\n","|       from large pool | 220659 KiB |   6751 MiB |   3012 TiB |   3012 TiB |\n","|       from small pool | 454606 KiB |    474 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 675265 KiB |   7193 MiB |   3021 TiB |   3021 TiB |\n","|       from large pool | 220659 KiB |   6751 MiB |   3012 TiB |   3012 TiB |\n","|       from small pool | 454606 KiB |    474 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |   7182 MiB |   3012 TiB |   3012 TiB |\n","|       from large pool | 213248 KiB |   6744 MiB |   3003 TiB |   3003 TiB |\n","|       from small pool | 450193 KiB |    469 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1738 MiB |   7598 MiB | 683630 GiB | 683628 GiB |\n","|       from large pool |   1288 MiB |   7132 MiB | 682293 GiB | 682292 GiB |\n","|       from small pool |    450 MiB |    478 MiB |   1336 GiB |   1336 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1078 MiB |   1511 MiB |   1055 TiB |   1055 TiB |\n","|       from large pool |   1072 MiB |   1504 MiB |   1045 TiB |   1045 TiB |\n","|       from small pool |      6 MiB |     21 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  121130 K  |  121111 K  |\n","|       from large pool |      98    |     248    |   71309 K  |   71308 K  |\n","|       from small pool |   18777    |   18924    |   49821 K  |   49802 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  121130 K  |  121111 K  |\n","|       from large pool |      98    |     248    |   71309 K  |   71308 K  |\n","|       from small pool |   18777    |   18924    |   49821 K  |   49802 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     239    |     317    |    6277 K  |    6277 K  |\n","|       from large pool |      14    |      84    |    5593 K  |    5593 K  |\n","|       from small pool |     225    |     239    |     684 K  |     684 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      86    |     186    |   57971 K  |   57971 K  |\n","|       from large pool |      11    |      83    |   38519 K  |   38519 K  |\n","|       from small pool |      75    |     121    |   19452 K  |   19452 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:69/184 batch:706/8961 epoch:1/10\n","full seq: The justice ministry says the information access law has been delayed because of the need to adopt constitutional amendments, which should be in place by November.Ģġġġġġġġġġġġġġġġġġġġġ\n","pref seq: The justice ministry says the information access law has been delayed\n","next tok:                                                                      \n","pred tok:                                                                     w\n","Completed batch.\n","epoch:1/10 batch:706/8961 batch_size:157 loss:1.3052332401275635 time_for_batch_instance:153.6386103630066 total_batch_time:77262.6529583931 running_batch_average:109.43718549347464\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 671991 KiB |  10933 MiB |   3027 TiB |   3027 TiB |\n","|       from large pool | 217385 KiB |  10485 MiB |   3018 TiB |   3018 TiB |\n","|       from small pool | 454606 KiB |    478 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 671991 KiB |  10933 MiB |   3027 TiB |   3027 TiB |\n","|       from large pool | 217385 KiB |  10485 MiB |   3018 TiB |   3018 TiB |\n","|       from small pool | 454606 KiB |    478 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  10912 MiB |   3019 TiB |   3019 TiB |\n","|       from large pool | 213248 KiB |  10468 MiB |   3009 TiB |   3009 TiB |\n","|       from small pool | 450193 KiB |    473 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1538 MiB |  11460 MiB | 685083 GiB | 685081 GiB |\n","|       from large pool |   1088 MiB |  10996 MiB | 683743 GiB | 683742 GiB |\n","|       from small pool |    450 MiB |    482 MiB |   1339 GiB |   1338 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |    881 MiB |   1590 MiB |   1057 TiB |   1057 TiB |\n","|       from large pool |    875 MiB |   1580 MiB |   1047 TiB |   1047 TiB |\n","|       from small pool |      6 MiB |     25 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  121369 K  |  121350 K  |\n","|       from large pool |      98    |     248    |   71448 K  |   71448 K  |\n","|       from small pool |   18777    |   18924    |   49921 K  |   49902 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  121369 K  |  121350 K  |\n","|       from large pool |      98    |     248    |   71448 K  |   71448 K  |\n","|       from small pool |   18777    |   18924    |   49921 K  |   49902 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     240    |     318    |    6289 K  |    6289 K  |\n","|       from large pool |      15    |      86    |    5604 K  |    5604 K  |\n","|       from small pool |     225    |     241    |     685 K  |     685 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      89    |     168    |   58098 K  |   58098 K  |\n","|       from large pool |      15    |      63    |   38605 K  |   38605 K  |\n","|       from small pool |      74    |     121    |   19492 K  |   19492 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:54/83 batch:707/8961 epoch:1/10\n","full seq: They construct barriers and constantly check the water levels.Ģġġġġġġġġġġġġġġġġġġġġ\n","pref seq: They construct barriers and constantly check the water\n","next tok:                                                       \n","pred tok:                                                      b\n","Completed batch.\n","epoch:1/10 batch:707/8961 batch_size:157 loss:4.814706325531006 time_for_batch_instance:66.57005548477173 total_batch_time:77329.22301387787 running_batch_average:109.37655306064762\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 669824 KiB |   5245 MiB |   3029 TiB |   3029 TiB |\n","|       from large pool | 215218 KiB |   4807 MiB |   3019 TiB |   3019 TiB |\n","|       from small pool | 454606 KiB |    471 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 669824 KiB |   5245 MiB |   3029 TiB |   3029 TiB |\n","|       from large pool | 215218 KiB |   4807 MiB |   3019 TiB |   3019 TiB |\n","|       from small pool | 454606 KiB |    471 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |   5226 MiB |   3020 TiB |   3020 TiB |\n","|       from large pool | 213248 KiB |   4792 MiB |   3011 TiB |   3011 TiB |\n","|       from small pool | 450193 KiB |    467 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1814 MiB |   5688 MiB | 685339 GiB | 685337 GiB |\n","|       from large pool |   1364 MiB |   5224 MiB | 683999 GiB | 683997 GiB |\n","|       from small pool |    450 MiB |    476 MiB |   1340 GiB |   1339 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1159 MiB |   1542 MiB |   1058 TiB |   1058 TiB |\n","|       from large pool |   1153 MiB |   1537 MiB |   1048 TiB |   1048 TiB |\n","|       from small pool |      6 MiB |     23 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  121475 K  |  121456 K  |\n","|       from large pool |      98    |     248    |   71509 K  |   71509 K  |\n","|       from small pool |   18777    |   18924    |   49966 K  |   49947 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  121475 K  |  121456 K  |\n","|       from large pool |      98    |     248    |   71509 K  |   71509 K  |\n","|       from small pool |   18777    |   18924    |   49966 K  |   49947 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     240    |     311    |    6294 K  |    6294 K  |\n","|       from large pool |      15    |      79    |    5608 K  |    5608 K  |\n","|       from small pool |     225    |     238    |     686 K  |     686 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      92    |     158    |   58153 K  |   58152 K  |\n","|       from large pool |      19    |      55    |   38642 K  |   38642 K  |\n","|       from small pool |      73    |     119    |   19510 K  |   19510 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:59/135 batch:708/8961 epoch:1/10\n","full seq: One of the interests of the country is that from a security consumer, KSF becomes a security provider,\" Ceku said.Ģġġġġġġġġġġġġġġġġġġġġ\n","pref seq: One of the interests of the country is that from a security\n","next tok:                                                            \n","pred tok:                                                           v\n","Completed batch.\n","epoch:1/10 batch:708/8961 batch_size:156 loss:4.422487735748291 time_for_batch_instance:111.42572379112244 total_batch_time:77440.64873766899 running_batch_average:109.37944736958897\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 670633 KiB |   8116 MiB |   3032 TiB |   3032 TiB |\n","|       from large pool | 216027 KiB |   7671 MiB |   3023 TiB |   3023 TiB |\n","|       from small pool | 454606 KiB |    475 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 670633 KiB |   8116 MiB |   3032 TiB |   3032 TiB |\n","|       from large pool | 216027 KiB |   7671 MiB |   3023 TiB |   3023 TiB |\n","|       from small pool | 454606 KiB |    475 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |   8106 MiB |   3023 TiB |   3023 TiB |\n","|       from large pool | 213248 KiB |   7666 MiB |   3014 TiB |   3014 TiB |\n","|       from small pool | 450193 KiB |    471 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1732 MiB |   8578 MiB | 686106 GiB | 686104 GiB |\n","|       from large pool |   1284 MiB |   8116 MiB | 684763 GiB | 684762 GiB |\n","|       from small pool |    448 MiB |    480 MiB |   1342 GiB |   1341 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1077 MiB |   1392 MiB |   1059 TiB |   1059 TiB |\n","|       from large pool |   1073 MiB |   1387 MiB |   1049 TiB |   1049 TiB |\n","|       from small pool |      4 MiB |     21 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  121650 K  |  121631 K  |\n","|       from large pool |      98    |     248    |   71610 K  |   71610 K  |\n","|       from small pool |   18777    |   18924    |   50039 K  |   50020 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  121650 K  |  121631 K  |\n","|       from large pool |      98    |     248    |   71610 K  |   71610 K  |\n","|       from small pool |   18777    |   18924    |   50039 K  |   50020 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     238    |     316    |    6303 K  |    6303 K  |\n","|       from large pool |      14    |      84    |    5616 K  |    5616 K  |\n","|       from small pool |     224    |     240    |     687 K  |     687 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      90    |     177    |   58241 K  |   58241 K  |\n","|       from large pool |      18    |      73    |   38702 K  |   38702 K  |\n","|       from small pool |      72    |     123    |   19538 K  |   19538 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:100/128 batch:709/8961 epoch:1/10\n","full seq: Croatian National Olympic Team President Zlatko Matesa is confident that the athletes will give their best.Ģġġġġġġġġġġġġġġġġġġġġ\n","pref seq: Croatian National Olympic Team President Zlatko Matesa is confident that the athletes will give thei\n","next tok:                                                                                                    r\n","pred tok:                                                                                                    b\n","Completed batch.\n","epoch:1/10 batch:709/8961 batch_size:156 loss:4.389340400695801 time_for_batch_instance:104.64374160766602 total_batch_time:77545.29247927666 running_batch_average:109.37276795384578\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 671981 KiB |   7697 MiB |   3035 TiB |   3035 TiB |\n","|       from large pool | 217375 KiB |   7255 MiB |   3026 TiB |   3026 TiB |\n","|       from small pool | 454606 KiB |    473 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 671981 KiB |   7697 MiB |   3035 TiB |   3035 TiB |\n","|       from large pool | 217375 KiB |   7255 MiB |   3026 TiB |   3026 TiB |\n","|       from small pool | 454606 KiB |    473 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |   7674 MiB |   3027 TiB |   3027 TiB |\n","|       from large pool | 213248 KiB |   7236 MiB |   3017 TiB |   3017 TiB |\n","|       from small pool | 450193 KiB |    469 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1400 MiB |   8112 MiB | 686787 GiB | 686786 GiB |\n","|       from large pool |    948 MiB |   7646 MiB | 685443 GiB | 685442 GiB |\n","|       from small pool |    452 MiB |    478 MiB |   1344 GiB |   1343 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 761618 KiB |   1380 MiB |   1060 TiB |   1060 TiB |\n","|       from large pool | 753376 KiB |   1372 MiB |   1050 TiB |   1050 TiB |\n","|       from small pool |   8242 KiB |     22 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  121815 K  |  121796 K  |\n","|       from large pool |      98    |     248    |   71706 K  |   71706 K  |\n","|       from small pool |   18777    |   18924    |   50108 K  |   50090 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  121815 K  |  121796 K  |\n","|       from large pool |      98    |     248    |   71706 K  |   71706 K  |\n","|       from small pool |   18777    |   18924    |   50108 K  |   50090 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     238    |     320    |    6312 K  |    6312 K  |\n","|       from large pool |      12    |      87    |    5624 K  |    5624 K  |\n","|       from small pool |     226    |     239    |     688 K  |     688 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      98    |     181    |   58315 K  |   58315 K  |\n","|       from large pool |      13    |      78    |   38751 K  |   38751 K  |\n","|       from small pool |      85    |     119    |   19564 K  |   19564 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:25/123 batch:710/8961 epoch:1/10\n","full seq: Prior to the suspension, Serbian companies had been exporting 95 per cent of their annual sugar production to the EU.Ģġġġġġ\n","pref seq: Prior to the suspension, \n","next tok:                         S\n","pred tok:                         b\n","Completed batch.\n","epoch:1/10 batch:710/8961 batch_size:156 loss:4.218931674957275 time_for_batch_instance:100.59286642074585 total_batch_time:77645.8853456974 running_batch_average:109.36040189534846\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 672571 KiB |   7505 MiB |   3038 TiB |   3038 TiB |\n","|       from large pool | 217965 KiB |   7063 MiB |   3029 TiB |   3029 TiB |\n","|       from small pool | 454606 KiB |    473 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 672571 KiB |   7505 MiB |   3038 TiB |   3038 TiB |\n","|       from large pool | 217965 KiB |   7063 MiB |   3029 TiB |   3029 TiB |\n","|       from small pool | 454606 KiB |    473 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |   7473 MiB |   3029 TiB |   3029 TiB |\n","|       from large pool | 213248 KiB |   7035 MiB |   3020 TiB |   3020 TiB |\n","|       from small pool | 450193 KiB |    469 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1574 MiB |   7878 MiB | 687423 GiB | 687421 GiB |\n","|       from large pool |   1122 MiB |   7412 MiB | 686077 GiB | 686076 GiB |\n","|       from small pool |    452 MiB |    478 MiB |   1346 GiB |   1345 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |    917 MiB |   1294 MiB |   1061 TiB |   1061 TiB |\n","|       from large pool |    909 MiB |   1285 MiB |   1051 TiB |   1051 TiB |\n","|       from small pool |      8 MiB |     22 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  121974 K  |  121955 K  |\n","|       from large pool |      98    |     248    |   71798 K  |   71798 K  |\n","|       from small pool |   18777    |   18924    |   50175 K  |   50156 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  121974 K  |  121955 K  |\n","|       from large pool |      98    |     248    |   71798 K  |   71798 K  |\n","|       from small pool |   18777    |   18924    |   50175 K  |   50156 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     239    |     318    |    6320 K  |    6320 K  |\n","|       from large pool |      13    |      85    |    5631 K  |    5631 K  |\n","|       from small pool |     226    |     239    |     689 K  |     688 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      89    |     159    |   58394 K  |   58394 K  |\n","|       from large pool |      12    |      56    |   38805 K  |   38805 K  |\n","|       from small pool |      77    |     119    |   19589 K  |   19588 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:107/252 batch:711/8961 epoch:1/10\n","full seq: \"Bearing in mind the toll that existing power plants have taken on the environment, the planned installation of new capacity must go hand-in-hand with efforts to improve the current environmental situation,\" it said in a statement.Ģġġġġġġġġġġġġġġġġġġġġ\n","pref seq: \"Bearing in mind the toll that existing power plants have taken on the environment, the planned installatio\n","next tok:                                                                                                           n\n","pred tok:                                                                                                           \"\n","Completed batch.\n","epoch:1/10 batch:711/8961 batch_size:155 loss:2.1279072761535645 time_for_batch_instance:212.94460797309875 total_batch_time:77858.8299536705 running_batch_average:109.50608994890366\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 671681 KiB |  14534 MiB |   3050 TiB |   3050 TiB |\n","|       from large pool | 217075 KiB |  14097 MiB |   3041 TiB |   3041 TiB |\n","|       from small pool | 454606 KiB |    470 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 671681 KiB |  14534 MiB |   3050 TiB |   3050 TiB |\n","|       from large pool | 217075 KiB |  14097 MiB |   3041 TiB |   3041 TiB |\n","|       from small pool | 454606 KiB |    470 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  14520 MiB |   3041 TiB |   3041 TiB |\n","|       from large pool | 213248 KiB |  14088 MiB |   3032 TiB |   3032 TiB |\n","|       from small pool | 450193 KiB |    466 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1400 MiB |  15152 MiB | 690198 GiB | 690197 GiB |\n","|       from large pool |    952 MiB |  14690 MiB | 688849 GiB | 688848 GiB |\n","|       from small pool |    448 MiB |    476 MiB |   1349 GiB |   1349 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 761919 KiB |   1885 MiB |   1065 TiB |   1065 TiB |\n","|       from large pool | 757773 KiB |   1880 MiB |   1055 TiB |   1055 TiB |\n","|       from small pool |   4146 KiB |     22 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  122302 K  |  122283 K  |\n","|       from large pool |      98    |     263    |   71997 K  |   71997 K  |\n","|       from small pool |   18777    |   18924    |   50304 K  |   50285 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  122302 K  |  122283 K  |\n","|       from large pool |      98    |     263    |   71997 K  |   71997 K  |\n","|       from small pool |   18777    |   18924    |   50304 K  |   50285 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     236    |     323    |    6338 K  |    6338 K  |\n","|       from large pool |      12    |      91    |    5647 K  |    5647 K  |\n","|       from small pool |     224    |     238    |     691 K  |     690 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      83    |     142    |   58522 K  |   58522 K  |\n","|       from large pool |      13    |      39    |   38882 K  |   38882 K  |\n","|       from small pool |      70    |     119    |   19639 K  |   19639 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:173/195 batch:712/8961 epoch:1/10\n","full seq: \"The Croatian authorities must mount a thorough investigation and bring those responsible for these murders to justice swiftly,\" the Committee to Protect Journalists said in a statement.Ģġġġġġġġġ\n","pref seq: \"The Croatian authorities must mount a thorough investigation and bring those responsible for these murders to justice swiftly,\" the Committee to Protect Journalists said in\n","next tok:                                                                                                                                                                              \n","pred tok:                                                                                                                                                                             z\n","Completed batch.\n","epoch:1/10 batch:712/8961 batch_size:155 loss:4.141850471496582 time_for_batch_instance:162.53381872177124 total_batch_time:78021.36377239227 running_batch_average:109.58056709605657\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 671792 KiB |  11424 MiB |   3057 TiB |   3057 TiB |\n","|       from large pool | 217186 KiB |  10990 MiB |   3048 TiB |   3048 TiB |\n","|       from small pool | 454606 KiB |    469 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 671792 KiB |  11424 MiB |   3057 TiB |   3057 TiB |\n","|       from large pool | 217186 KiB |  10990 MiB |   3048 TiB |   3048 TiB |\n","|       from small pool | 454606 KiB |    469 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  11393 MiB |   3048 TiB |   3048 TiB |\n","|       from large pool | 213248 KiB |  10963 MiB |   3039 TiB |   3039 TiB |\n","|       from small pool | 450193 KiB |    465 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1666 MiB |  11996 MiB | 691863 GiB | 691862 GiB |\n","|       from large pool |   1218 MiB |  11530 MiB | 690511 GiB | 690510 GiB |\n","|       from small pool |    448 MiB |    474 MiB |   1352 GiB |   1352 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1009 MiB |   1493 MiB |   1067 TiB |   1067 TiB |\n","|       from large pool |   1005 MiB |   1487 MiB |   1057 TiB |   1057 TiB |\n","|       from small pool |      4 MiB |     20 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  122556 K  |  122537 K  |\n","|       from large pool |      98    |     263    |   72147 K  |   72147 K  |\n","|       from small pool |   18777    |   18924    |   50408 K  |   50389 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  122556 K  |  122537 K  |\n","|       from large pool |      98    |     263    |   72147 K  |   72147 K  |\n","|       from small pool |   18777    |   18924    |   50408 K  |   50389 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     239    |     323    |    6352 K  |    6351 K  |\n","|       from large pool |      15    |      90    |    5659 K  |    5659 K  |\n","|       from small pool |     224    |     237    |     692 K  |     692 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      93    |     173    |   58642 K  |   58642 K  |\n","|       from large pool |      18    |      71    |   38959 K  |   38959 K  |\n","|       from small pool |      75    |     117    |   19683 K  |   19682 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:180/185 batch:713/8961 epoch:1/10\n","full seq: According to Holly Cartner, its Europe and Central Asia director, Serbia will find its EU bid hampered \"unless it starts taking these attacks a lot more seriously\".Ģġġġġġġġġġġġġġġġġġġġġ\n","pref seq: According to Holly Cartner, its Europe and Central Asia director, Serbia will find its EU bid hampered \"unless it starts taking these attacks a lot more seriously\".Ģġġġġġġġġġġġġġġġ\n","next tok:                                                                                                                                                                                    ġ\n","pred tok:                                                                                                                                                                                    ġ\n","Completed batch.\n","epoch:1/10 batch:713/8961 batch_size:155 loss:3.1947460174560547 time_for_batch_instance:154.20525121688843 total_batch_time:78175.56902360916 running_batch_average:109.64315431081229\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 674440 KiB |  10850 MiB |   3063 TiB |   3063 TiB |\n","|       from large pool | 219834 KiB |  10402 MiB |   3054 TiB |   3054 TiB |\n","|       from small pool | 454606 KiB |    477 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 674440 KiB |  10850 MiB |   3063 TiB |   3063 TiB |\n","|       from large pool | 219834 KiB |  10402 MiB |   3054 TiB |   3054 TiB |\n","|       from small pool | 454606 KiB |    477 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  10836 MiB |   3055 TiB |   3055 TiB |\n","|       from large pool | 213248 KiB |  10392 MiB |   3045 TiB |   3045 TiB |\n","|       from small pool | 450193 KiB |    473 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1708 MiB |  11440 MiB | 693359 GiB | 693358 GiB |\n","|       from large pool |   1258 MiB |  10976 MiB | 692004 GiB | 692003 GiB |\n","|       from small pool |    450 MiB |    482 MiB |   1354 GiB |   1354 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1049 MiB |   1650 MiB |   1069 TiB |   1069 TiB |\n","|       from large pool |   1043 MiB |   1643 MiB |   1059 TiB |   1059 TiB |\n","|       from small pool |      6 MiB |     23 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  122796 K  |  122777 K  |\n","|       from large pool |      98    |     248    |   72287 K  |   72287 K  |\n","|       from small pool |   18777    |   18924    |   50509 K  |   50490 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  122796 K  |  122777 K  |\n","|       from large pool |      98    |     248    |   72287 K  |   72287 K  |\n","|       from small pool |   18777    |   18924    |   50509 K  |   50490 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     240    |     320    |    6364 K  |    6364 K  |\n","|       from large pool |      15    |      88    |    5670 K  |    5670 K  |\n","|       from small pool |     225    |     241    |     693 K  |     693 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      98    |     192    |   58774 K  |   58774 K  |\n","|       from large pool |      16    |      87    |   39052 K  |   39052 K  |\n","|       from small pool |      82    |     123    |   19722 K  |   19722 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:68/245 batch:714/8961 epoch:1/10\n","full seq: Turkey's air and ground offensive in northern Iraq against the terrorist Kurdistan Workers' Party (PKK), the biggest such operation in a decade, continued in northern Iraq on Monday (February 25th) under international scrutiny.Ģġġġġġġġġġġġġġġġġġ\n","pref seq: Turkey's air and ground offensive in northern Iraq against the terro\n","next tok:                                                                    r\n","pred tok:                                                                    K\n","Completed batch.\n","epoch:1/10 batch:714/8961 batch_size:154 loss:1.143065094947815 time_for_batch_instance:206.35351943969727 total_batch_time:78381.92254304886 running_batch_average:109.778603001469\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 674682 KiB |  14198 MiB |   3074 TiB |   3074 TiB |\n","|       from large pool | 220076 KiB |  13762 MiB |   3065 TiB |   3065 TiB |\n","|       from small pool | 454606 KiB |    470 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 674682 KiB |  14198 MiB |   3074 TiB |   3074 TiB |\n","|       from large pool | 220076 KiB |  13762 MiB |   3065 TiB |   3065 TiB |\n","|       from small pool | 454606 KiB |    470 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  14161 MiB |   3066 TiB |   3066 TiB |\n","|       from large pool | 213248 KiB |  13728 MiB |   3056 TiB |   3056 TiB |\n","|       from small pool | 450193 KiB |    466 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1844 MiB |  14876 MiB | 695980 GiB | 695978 GiB |\n","|       from large pool |   1396 MiB |  14414 MiB | 694621 GiB | 694620 GiB |\n","|       from small pool |    448 MiB |    476 MiB |   1358 GiB |   1358 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1185 MiB |   1866 MiB |   1073 TiB |   1073 TiB |\n","|       from large pool |   1181 MiB |   1861 MiB |   1063 TiB |   1063 TiB |\n","|       from small pool |      4 MiB |     23 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  123115 K  |  123096 K  |\n","|       from large pool |      98    |     263    |   72480 K  |   72480 K  |\n","|       from small pool |   18777    |   18924    |   50634 K  |   50616 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  123115 K  |  123096 K  |\n","|       from large pool |      98    |     263    |   72480 K  |   72480 K  |\n","|       from small pool |   18777    |   18924    |   50634 K  |   50616 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     243    |     324    |    6381 K  |    6381 K  |\n","|       from large pool |      19    |      92    |    5686 K  |    5686 K  |\n","|       from small pool |     224    |     238    |     695 K  |     695 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      85    |     151    |   58913 K  |   58913 K  |\n","|       from large pool |      21    |      49    |   39140 K  |   39140 K  |\n","|       from small pool |      64    |     119    |   19773 K  |   19773 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:75/79 batch:715/8961 epoch:1/10\n","full seq: Moldovan women struggle for equal rights in political lifeĢġġġġġġġġġġġġġġġġġġġġ\n","pref seq: Moldovan women struggle for equal rights in political lifeĢġġġġġġġġġġġġġġġġ\n","next tok:                                                                           ġ\n","pred tok:                                                                           /\n","Completed batch.\n","epoch:1/10 batch:715/8961 batch_size:154 loss:4.499289512634277 time_for_batch_instance:63.28720450401306 total_batch_time:78445.20974755287 running_batch_average:109.71358006650752\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 681796 KiB |   4904 MiB |   3076 TiB |   3076 TiB |\n","|       from large pool | 227190 KiB |   4466 MiB |   3066 TiB |   3066 TiB |\n","|       from small pool | 454606 KiB |    470 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 681796 KiB |   4904 MiB |   3076 TiB |   3076 TiB |\n","|       from large pool | 227190 KiB |   4466 MiB |   3066 TiB |   3066 TiB |\n","|       from small pool | 454606 KiB |    470 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |   4878 MiB |   3067 TiB |   3067 TiB |\n","|       from large pool | 213248 KiB |   4445 MiB |   3058 TiB |   3058 TiB |\n","|       from small pool | 450193 KiB |    466 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1548 MiB |   5202 MiB | 696208 GiB | 696207 GiB |\n","|       from large pool |   1100 MiB |   4740 MiB | 694849 GiB | 694848 GiB |\n","|       from small pool |    448 MiB |    474 MiB |   1359 GiB |   1359 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |    882 MiB |   1323 MiB |   1074 TiB |   1074 TiB |\n","|       from large pool |    878 MiB |   1317 MiB |   1064 TiB |   1064 TiB |\n","|       from small pool |      4 MiB |     23 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  123216 K  |  123197 K  |\n","|       from large pool |      98    |     248    |   72538 K  |   72538 K  |\n","|       from small pool |   18777    |   18924    |   50677 K  |   50658 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  123216 K  |  123197 K  |\n","|       from large pool |      98    |     248    |   72538 K  |   72538 K  |\n","|       from small pool |   18777    |   18924    |   50677 K  |   50658 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     240    |     313    |    6386 K  |    6385 K  |\n","|       from large pool |      16    |      81    |    5690 K  |    5690 K  |\n","|       from small pool |     224    |     237    |     696 K  |     695 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      85    |     143    |   58958 K  |   58958 K  |\n","|       from large pool |      15    |      42    |   39168 K  |   39168 K  |\n","|       from small pool |      70    |     120    |   19790 K  |   19790 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:4/250 batch:716/8961 epoch:1/10\n","full seq: \"The special court had a good influence on the judiciary, and if we compare its practice with that of other courts, we will see a big difference in the number of confirmed judgments, in the number of those quality items,\" he said.Ģġġġġġġġġġġġġġġġġġġġ\n","pref seq: \"The\n","next tok:     \n","pred tok:    Ģ\n","Completed batch.\n","epoch:1/10 batch:716/8961 batch_size:153 loss:2.0917701721191406 time_for_batch_instance:211.0045268535614 total_batch_time:78656.21427440643 running_batch_average:109.85504786928273\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 673810 KiB |  14340 MiB |   3087 TiB |   3087 TiB |\n","|       from large pool | 219204 KiB |  13904 MiB |   3078 TiB |   3078 TiB |\n","|       from small pool | 454606 KiB |    470 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 673810 KiB |  14340 MiB |   3087 TiB |   3087 TiB |\n","|       from large pool | 219204 KiB |  13904 MiB |   3078 TiB |   3078 TiB |\n","|       from small pool | 454606 KiB |    470 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  14308 MiB |   3078 TiB |   3078 TiB |\n","|       from large pool | 213248 KiB |  13876 MiB |   3069 TiB |   3069 TiB |\n","|       from small pool | 450193 KiB |    466 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1742 MiB |  15054 MiB | 698965 GiB | 698964 GiB |\n","|       from large pool |   1292 MiB |  14590 MiB | 697602 GiB | 697601 GiB |\n","|       from small pool |    450 MiB |    476 MiB |   1363 GiB |   1362 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1083 MiB |   2008 MiB |   1077 TiB |   1077 TiB |\n","|       from large pool |   1077 MiB |   2004 MiB |   1067 TiB |   1067 TiB |\n","|       from small pool |      6 MiB |     22 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  123542 K  |  123523 K  |\n","|       from large pool |      98    |     263    |   72736 K  |   72736 K  |\n","|       from small pool |   18777    |   18924    |   50805 K  |   50787 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  123542 K  |  123523 K  |\n","|       from large pool |      98    |     263    |   72736 K  |   72736 K  |\n","|       from small pool |   18777    |   18924    |   50805 K  |   50787 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     242    |     325    |    6403 K  |    6403 K  |\n","|       from large pool |      17    |      93    |    5705 K  |    5705 K  |\n","|       from small pool |     225    |     238    |     697 K  |     697 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      85    |     172    |   59110 K  |   59110 K  |\n","|       from large pool |      16    |      69    |   39269 K  |   39269 K  |\n","|       from small pool |      69    |     118    |   19841 K  |   19841 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:31/250 batch:717/8961 epoch:1/10\n","full seq: Greek media reports cited officials as saying that the cocaine originated in Bolivia, the third largest cultivator of the coca bush following Colombia and Peru, according to the UN Office on Drugs and Crime's World Drugs Report 2009.Ģġġġġġġġġġġġġġġġġ\n","pref seq: Greek media reports cited offic\n","next tok:                               i\n","pred tok:                               ,\n","Completed batch.\n","epoch:1/10 batch:717/8961 batch_size:153 loss:1.0145732164382935 time_for_batch_instance:209.6726531982422 total_batch_time:78865.88692760468 running_batch_average:109.99426349735658\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 671344 KiB |  14419 MiB |   3098 TiB |   3098 TiB |\n","|       from large pool | 216738 KiB |  13982 MiB |   3089 TiB |   3089 TiB |\n","|       from small pool | 454606 KiB |    470 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 671344 KiB |  14419 MiB |   3098 TiB |   3098 TiB |\n","|       from large pool | 216738 KiB |  13982 MiB |   3089 TiB |   3089 TiB |\n","|       from small pool | 454606 KiB |    470 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  14385 MiB |   3090 TiB |   3090 TiB |\n","|       from large pool | 213248 KiB |  13953 MiB |   3080 TiB |   3080 TiB |\n","|       from small pool | 450193 KiB |    466 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1416 MiB |  15104 MiB | 701716 GiB | 701714 GiB |\n","|       from large pool |    968 MiB |  14640 MiB | 700349 GiB | 700348 GiB |\n","|       from small pool |    448 MiB |    476 MiB |   1366 GiB |   1366 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 778640 KiB |   1881 MiB |   1081 TiB |   1081 TiB |\n","|       from large pool | 774494 KiB |   1876 MiB |   1071 TiB |   1071 TiB |\n","|       from small pool |   4146 KiB |     21 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  123868 K  |  123849 K  |\n","|       from large pool |      98    |     263    |   72933 K  |   72933 K  |\n","|       from small pool |   18777    |   18924    |   50934 K  |   50915 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  123868 K  |  123849 K  |\n","|       from large pool |      98    |     263    |   72933 K  |   72933 K  |\n","|       from small pool |   18777    |   18924    |   50934 K  |   50915 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     237    |     323    |    6421 K  |    6421 K  |\n","|       from large pool |      13    |      91    |    5721 K  |    5721 K  |\n","|       from small pool |     224    |     238    |     699 K  |     699 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      85    |     160    |   59249 K  |   59249 K  |\n","|       from large pool |      14    |      58    |   39358 K  |   39358 K  |\n","|       from small pool |      71    |     118    |   19891 K  |   19890 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:114/182 batch:718/8961 epoch:1/10\n","full seq: \"This is a big day for Macedonia ... a new object will be constructed on one of the most beautiful sites that was neglected for many years,\" Mehazi said. [Tomislav Georgiev]Ģġġġġġġġġ\n","pref seq: \"This is a big day for Macedonia ... a new object will be constructed on one of the most beautiful sites that was \n","next tok:                                                                                                                  n\n","pred tok:                                                                                                                  K\n","Completed batch.\n","epoch:1/10 batch:718/8961 batch_size:153 loss:3.7744548320770264 time_for_batch_instance:150.6240885257721 total_batch_time:79016.51101613045 running_batch_average:110.05085099739617\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 671160 KiB |  10570 MiB |   3105 TiB |   3105 TiB |\n","|       from large pool | 216554 KiB |  10122 MiB |   3095 TiB |   3095 TiB |\n","|       from small pool | 454606 KiB |    476 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 671160 KiB |  10570 MiB |   3105 TiB |   3105 TiB |\n","|       from large pool | 216554 KiB |  10122 MiB |   3095 TiB |   3095 TiB |\n","|       from small pool | 454606 KiB |    476 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  10539 MiB |   3096 TiB |   3096 TiB |\n","|       from large pool | 213248 KiB |  10096 MiB |   3086 TiB |   3086 TiB |\n","|       from small pool | 450193 KiB |    472 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1514 MiB |  11084 MiB | 703134 GiB | 703133 GiB |\n","|       from large pool |   1066 MiB |  10620 MiB | 701765 GiB | 701764 GiB |\n","|       from small pool |    448 MiB |    482 MiB |   1369 GiB |   1369 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |    858 MiB |   1379 MiB |   1083 TiB |   1083 TiB |\n","|       from large pool |    854 MiB |   1373 MiB |   1073 TiB |   1073 TiB |\n","|       from small pool |      4 MiB |     22 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  124104 K  |  124085 K  |\n","|       from large pool |      98    |     248    |   73071 K  |   73071 K  |\n","|       from small pool |   18777    |   18924    |   51032 K  |   51014 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  124104 K  |  124085 K  |\n","|       from large pool |      98    |     248    |   73071 K  |   73071 K  |\n","|       from small pool |   18777    |   18924    |   51032 K  |   51014 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     238    |     318    |    6434 K  |    6433 K  |\n","|       from large pool |      14    |      86    |    5732 K  |    5732 K  |\n","|       from small pool |     224    |     241    |     701 K  |     700 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      89    |     155    |   59351 K  |   59350 K  |\n","|       from large pool |      17    |      49    |   39419 K  |   39419 K  |\n","|       from small pool |      72    |     122    |   19931 K  |   19931 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:65/147 batch:719/8961 epoch:1/10\n","full seq: Authorities in Shkodra inaugurated on Sunday (August 1st) a museum at the house where Mother Theresa lived in the early 1930s.Ģġġġġġġġġġġġġġġġġġġġġ\n","pref seq: Authorities in Shkodra inaugurated on Sunday (August 1st) a museu\n","next tok:                                                                 m\n","pred tok:                                                                 Ģ\n","Completed batch.\n","epoch:1/10 batch:719/8961 batch_size:153 loss:4.0013813972473145 time_for_batch_instance:120.43898606300354 total_batch_time:79136.95000219345 running_batch_average:110.0652990294763\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 670740 KiB |   8644 MiB |   3109 TiB |   3109 TiB |\n","|       from large pool | 216134 KiB |   8200 MiB |   3099 TiB |   3099 TiB |\n","|       from small pool | 454606 KiB |    474 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 670740 KiB |   8644 MiB |   3109 TiB |   3109 TiB |\n","|       from large pool | 216134 KiB |   8200 MiB |   3099 TiB |   3099 TiB |\n","|       from small pool | 454606 KiB |    474 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |   8619 MiB |   3100 TiB |   3100 TiB |\n","|       from large pool | 213248 KiB |   8179 MiB |   3090 TiB |   3090 TiB |\n","|       from small pool | 450193 KiB |    470 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1584 MiB |   9036 MiB | 704019 GiB | 704017 GiB |\n","|       from large pool |   1134 MiB |   8572 MiB | 702647 GiB | 702646 GiB |\n","|       from small pool |    450 MiB |    480 MiB |   1371 GiB |   1371 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |    928 MiB |   1612 MiB |   1085 TiB |   1085 TiB |\n","|       from large pool |    922 MiB |   1605 MiB |   1074 TiB |   1074 TiB |\n","|       from small pool |      6 MiB |     25 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  124294 K  |  124275 K  |\n","|       from large pool |      98    |     248    |   73182 K  |   73182 K  |\n","|       from small pool |   18777    |   18924    |   51112 K  |   51093 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  124294 K  |  124275 K  |\n","|       from large pool |      98    |     248    |   73182 K  |   73182 K  |\n","|       from small pool |   18777    |   18924    |   51112 K  |   51093 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     238    |     318    |    6443 K  |    6443 K  |\n","|       from large pool |      13    |      86    |    5741 K  |    5741 K  |\n","|       from small pool |     225    |     240    |     702 K  |     702 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      86    |     148    |   59424 K  |   59424 K  |\n","|       from large pool |      17    |      45    |   39463 K  |   39463 K  |\n","|       from small pool |      69    |     120    |   19961 K  |   19961 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:141/257 batch:720/8961 epoch:1/10\n","full seq: Besides promising his country's further participation in NATO-led international missions, Parvanov also expressed Bulgaria's readiness to play an active role in policy dialogue and in the Alliance's political and military transformation.Ģġġġġġġġġġġġġġġġġġġġ\n","pref seq: Besides promising his country's further participation in NATO-led international missions, Parvanov also expressed Bulgaria's readiness to pla\n","next tok:                                                                                                                                             y\n","pred tok:                                                                                                                                             Ģ\n","Completed batch.\n","epoch:1/10 batch:720/8961 batch_size:152 loss:0.8910741806030273 time_for_batch_instance:217.1375002861023 total_batch_time:79354.08750247955 running_batch_average:110.2140104201105\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 672723 KiB |  14611 MiB |   3121 TiB |   3121 TiB |\n","|       from large pool | 218117 KiB |  14175 MiB |   3111 TiB |   3111 TiB |\n","|       from small pool | 454606 KiB |    470 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 672723 KiB |  14611 MiB |   3121 TiB |   3121 TiB |\n","|       from large pool | 218117 KiB |  14175 MiB |   3111 TiB |   3111 TiB |\n","|       from small pool | 454606 KiB |    470 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  14601 MiB |   3112 TiB |   3112 TiB |\n","|       from large pool | 213248 KiB |  14168 MiB |   3102 TiB |   3102 TiB |\n","|       from small pool | 450193 KiB |    465 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1882 MiB |  15336 MiB | 706911 GiB | 706909 GiB |\n","|       from large pool |   1434 MiB |  14874 MiB | 705536 GiB | 705535 GiB |\n","|       from small pool |    448 MiB |    476 MiB |   1375 GiB |   1374 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1225 MiB |   1798 MiB |   1089 TiB |   1089 TiB |\n","|       from large pool |   1220 MiB |   1793 MiB |   1078 TiB |   1078 TiB |\n","|       from small pool |      4 MiB |     18 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  124629 K  |  124610 K  |\n","|       from large pool |      98    |     263    |   73385 K  |   73385 K  |\n","|       from small pool |   18777    |   18924    |   51244 K  |   51225 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  124629 K  |  124610 K  |\n","|       from large pool |      98    |     263    |   73385 K  |   73385 K  |\n","|       from small pool |   18777    |   18924    |   51244 K  |   51225 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     240    |     321    |    6462 K  |    6461 K  |\n","|       from large pool |      16    |      90    |    5757 K  |    5757 K  |\n","|       from small pool |     224    |     238    |     704 K  |     703 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      83    |     175    |   59613 K  |   59613 K  |\n","|       from large pool |      14    |      72    |   39601 K  |   39601 K  |\n","|       from small pool |      69    |     118    |   20012 K  |   20012 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:73/252 batch:721/8961 epoch:1/10\n","full seq: According to some analysts, however, Ankara's views on Libya are a departure from the proactive role it played during Egypt's demonstrations, when Turkey became the first country to demand that Egyptian leader Hosni Mubarak step down.Ģġġġġġġġġġġġġġġġġġ\n","pref seq: According to some analysts, however, Ankara's views on Libya are a depart\n","next tok:                                                                         u\n","pred tok:                                                                         ,\n","Completed batch.\n","epoch:1/10 batch:721/8961 batch_size:152 loss:1.0091123580932617 time_for_batch_instance:211.19614481925964 total_batch_time:79565.28364729881 running_batch_average:110.35406885894426\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 672801 KiB |  14430 MiB |   3132 TiB |   3132 TiB |\n","|       from large pool | 218195 KiB |  13993 MiB |   3123 TiB |   3123 TiB |\n","|       from small pool | 454606 KiB |    470 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 672801 KiB |  14430 MiB |   3132 TiB |   3132 TiB |\n","|       from large pool | 218195 KiB |  13993 MiB |   3123 TiB |   3123 TiB |\n","|       from small pool | 454606 KiB |    470 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  14404 MiB |   3123 TiB |   3123 TiB |\n","|       from large pool | 213248 KiB |  13971 MiB |   3114 TiB |   3114 TiB |\n","|       from small pool | 450193 KiB |    465 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2020 MiB |  15118 MiB | 709622 GiB | 709620 GiB |\n","|       from large pool |   1572 MiB |  14654 MiB | 708243 GiB | 708242 GiB |\n","|       from small pool |    448 MiB |    476 MiB |   1379 GiB |   1378 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1362 MiB |   2200 MiB |   1092 TiB |   1092 TiB |\n","|       from large pool |   1358 MiB |   2195 MiB |   1082 TiB |   1082 TiB |\n","|       from small pool |      4 MiB |     18 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  124958 K  |  124939 K  |\n","|       from large pool |      98    |     263    |   73584 K  |   73584 K  |\n","|       from small pool |   18777    |   18924    |   51373 K  |   51354 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  124958 K  |  124939 K  |\n","|       from large pool |      98    |     263    |   73584 K  |   73584 K  |\n","|       from small pool |   18777    |   18924    |   51373 K  |   51354 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     239    |     323    |    6479 K  |    6479 K  |\n","|       from large pool |      15    |      91    |    5773 K  |    5773 K  |\n","|       from small pool |     224    |     238    |     706 K  |     705 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      86    |     163    |   59754 K  |   59754 K  |\n","|       from large pool |      15    |      59    |   39691 K  |   39691 K  |\n","|       from small pool |      71    |     118    |   20063 K  |   20063 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:109/247 batch:722/8961 epoch:1/10\n","full seq: Bulgarian Foreign Minister Ivailo Kalfin hosted a meeting of the countries from the South East European Co-operation Process (SEECP) with the EU representative in the Kosovo talks, Wolfgang Ischinger, on Friday (September 28th).Ģġġġġġġġġġġġġġġġġġġ\n","pref seq: Bulgarian Foreign Minister Ivailo Kalfin hosted a meeting of the countries from the South East European Co-op\n","next tok:                                                                                                             e\n","pred tok:                                                                                                             ,\n","Completed batch.\n","epoch:1/10 batch:722/8961 batch_size:152 loss:1.3100051879882812 time_for_batch_instance:206.57674193382263 total_batch_time:79771.86038923264 running_batch_average:110.48734125932498\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 672788 KiB |  14114 MiB |   3143 TiB |   3143 TiB |\n","|       from large pool | 218182 KiB |  13677 MiB |   3134 TiB |   3134 TiB |\n","|       from small pool | 454606 KiB |    470 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 672788 KiB |  14114 MiB |   3143 TiB |   3143 TiB |\n","|       from large pool | 218182 KiB |  13677 MiB |   3134 TiB |   3134 TiB |\n","|       from small pool | 454606 KiB |    470 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  14093 MiB |   3134 TiB |   3134 TiB |\n","|       from large pool | 213248 KiB |  13661 MiB |   3125 TiB |   3125 TiB |\n","|       from small pool | 450193 KiB |    465 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2018 MiB |  14782 MiB | 712194 GiB | 712192 GiB |\n","|       from large pool |   1570 MiB |  14320 MiB | 710811 GiB | 710809 GiB |\n","|       from small pool |    448 MiB |    476 MiB |   1382 GiB |   1382 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1360 MiB |   2122 MiB |   1096 TiB |   1096 TiB |\n","|       from large pool |   1356 MiB |   2118 MiB |   1086 TiB |   1086 TiB |\n","|       from small pool |      4 MiB |     20 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  125280 K  |  125261 K  |\n","|       from large pool |      98    |     263    |   73779 K  |   73779 K  |\n","|       from small pool |   18777    |   18924    |   51500 K  |   51481 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  125280 K  |  125261 K  |\n","|       from large pool |      98    |     263    |   73779 K  |   73779 K  |\n","|       from small pool |   18777    |   18924    |   51500 K  |   51481 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     239    |     322    |    6496 K  |    6496 K  |\n","|       from large pool |      15    |      90    |    5788 K  |    5788 K  |\n","|       from small pool |     224    |     238    |     707 K  |     707 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      84    |     157    |   59921 K  |   59921 K  |\n","|       from large pool |      19    |      55    |   39807 K  |   39807 K  |\n","|       from small pool |      65    |     118    |   20114 K  |   20113 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:125/131 batch:723/8961 epoch:1/10\n","full seq: Officials in Pristina say that recognition of Kosovo's independence is necessary and must precede demarcation.Ģġġġġġġġġġġġġġġġġġġġġ\n","pref seq: Officials in Pristina say that recognition of Kosovo's independence is necessary and must precede demarcation.Ģġġġġġġġġġġġġġġ\n","next tok:                                                                                                                             ġ\n","pred tok:                                                                                                                             %\n","Completed batch.\n","epoch:1/10 batch:723/8961 batch_size:152 loss:4.987786769866943 time_for_batch_instance:106.93628358840942 total_batch_time:79878.79667282104 running_batch_average:110.48242969961417\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 671786 KiB |   7688 MiB |   3146 TiB |   3146 TiB |\n","|       from large pool | 217180 KiB |   7245 MiB |   3137 TiB |   3137 TiB |\n","|       from small pool | 454606 KiB |    474 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 671786 KiB |   7688 MiB |   3146 TiB |   3146 TiB |\n","|       from large pool | 217180 KiB |   7245 MiB |   3137 TiB |   3137 TiB |\n","|       from small pool | 454606 KiB |    474 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |   7657 MiB |   3138 TiB |   3138 TiB |\n","|       from large pool | 213248 KiB |   7218 MiB |   3128 TiB |   3128 TiB |\n","|       from small pool | 450193 KiB |    469 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1570 MiB |   8092 MiB | 712890 GiB | 712888 GiB |\n","|       from large pool |   1118 MiB |   7624 MiB | 711505 GiB | 711504 GiB |\n","|       from small pool |    452 MiB |    478 MiB |   1384 GiB |   1384 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |    913 MiB |   1521 MiB |   1097 TiB |   1097 TiB |\n","|       from large pool |    905 MiB |   1514 MiB |   1087 TiB |   1087 TiB |\n","|       from small pool |      8 MiB |     24 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  125449 K  |  125430 K  |\n","|       from large pool |      98    |     248    |   73877 K  |   73877 K  |\n","|       from small pool |   18777    |   18924    |   51571 K  |   51552 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  125449 K  |  125430 K  |\n","|       from large pool |      98    |     248    |   73877 K  |   73877 K  |\n","|       from small pool |   18777    |   18924    |   51571 K  |   51552 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     240    |     321    |    6505 K  |    6505 K  |\n","|       from large pool |      14    |      87    |    5796 K  |    5796 K  |\n","|       from small pool |     226    |     239    |     708 K  |     708 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      92    |     174    |   59992 K  |   59992 K  |\n","|       from large pool |      12    |      70    |   39852 K  |   39852 K  |\n","|       from small pool |      80    |     121    |   20140 K  |   20140 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:15/103 batch:724/8961 epoch:1/10\n","full seq: They allow the government the opportunity to secure additional funds at more competitive prices.Ģġġġġġġ\n","pref seq: They allow the \n","next tok:               g\n","pred tok:               Ģ\n","Completed batch.\n","epoch:1/10 batch:724/8961 batch_size:152 loss:4.289702415466309 time_for_batch_instance:83.20521473884583 total_batch_time:79962.00188755989 running_batch_average:110.44475398834238\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 670382 KiB |   6227 MiB |   3149 TiB |   3149 TiB |\n","|       from large pool | 215776 KiB |   5786 MiB |   3139 TiB |   3139 TiB |\n","|       from small pool | 454606 KiB |    472 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 670382 KiB |   6227 MiB |   3149 TiB |   3149 TiB |\n","|       from large pool | 215776 KiB |   5786 MiB |   3139 TiB |   3139 TiB |\n","|       from small pool | 454606 KiB |    472 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |   6208 MiB |   3140 TiB |   3140 TiB |\n","|       from large pool | 213248 KiB |   5771 MiB |   3130 TiB |   3130 TiB |\n","|       from small pool | 450193 KiB |    467 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1704 MiB |   6580 MiB | 713300 GiB | 713298 GiB |\n","|       from large pool |   1252 MiB |   6114 MiB | 711914 GiB | 711913 GiB |\n","|       from small pool |    452 MiB |    476 MiB |   1386 GiB |   1385 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1049 MiB |   1371 MiB |   1098 TiB |   1098 TiB |\n","|       from large pool |   1041 MiB |   1364 MiB |   1088 TiB |   1088 TiB |\n","|       from small pool |      8 MiB |     19 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  125581 K  |  125562 K  |\n","|       from large pool |      98    |     248    |   73954 K  |   73954 K  |\n","|       from small pool |   18777    |   18924    |   51627 K  |   51608 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  125581 K  |  125562 K  |\n","|       from large pool |      98    |     248    |   73954 K  |   73954 K  |\n","|       from small pool |   18777    |   18924    |   51627 K  |   51608 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     241    |     316    |    6511 K  |    6511 K  |\n","|       from large pool |      15    |      83    |    5802 K  |    5802 K  |\n","|       from small pool |     226    |     238    |     709 K  |     709 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      94    |     152    |   60051 K  |   60051 K  |\n","|       from large pool |      15    |      50    |   39890 K  |   39890 K  |\n","|       from small pool |      79    |     119    |   20160 K  |   20160 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:38/142 batch:725/8961 epoch:1/10\n","full seq: The prime ministers of eight Southeast European nations have agreed to launch negotiations on a regional trade agreement.Ģġġġġġġġġġġġġġġġġġġġġ\n","pref seq: The prime ministers of eight Southeast\n","next tok:                                       \n","pred tok:                                      Ģ\n","Completed batch.\n","epoch:1/10 batch:725/8961 batch_size:149 loss:3.9594480991363525 time_for_batch_instance:116.94877076148987 total_batch_time:80078.95065832138 running_batch_average:110.45372504596052\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 669970 KiB |   8169 MiB |   3152 TiB |   3152 TiB |\n","|       from large pool | 215364 KiB |   7725 MiB |   3143 TiB |   3143 TiB |\n","|       from small pool | 454606 KiB |    473 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 669970 KiB |   8169 MiB |   3152 TiB |   3152 TiB |\n","|       from large pool | 215364 KiB |   7725 MiB |   3143 TiB |   3143 TiB |\n","|       from small pool | 454606 KiB |    473 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |   8142 MiB |   3143 TiB |   3143 TiB |\n","|       from large pool | 213248 KiB |   7703 MiB |   3134 TiB |   3134 TiB |\n","|       from small pool | 450193 KiB |    469 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1722 MiB |   8586 MiB | 714097 GiB | 714095 GiB |\n","|       from large pool |   1270 MiB |   8120 MiB | 712709 GiB | 712707 GiB |\n","|       from small pool |    452 MiB |    476 MiB |   1388 GiB |   1387 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1067 MiB |   1567 MiB |   1099 TiB |   1099 TiB |\n","|       from large pool |   1059 MiB |   1560 MiB |   1089 TiB |   1089 TiB |\n","|       from small pool |      8 MiB |     23 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  125765 K  |  125746 K  |\n","|       from large pool |      98    |     248    |   74061 K  |   74061 K  |\n","|       from small pool |   18777    |   18924    |   51704 K  |   51685 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  125765 K  |  125746 K  |\n","|       from large pool |      98    |     248    |   74061 K  |   74061 K  |\n","|       from small pool |   18777    |   18924    |   51704 K  |   51685 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     239    |     317    |    6521 K  |    6521 K  |\n","|       from large pool |      13    |      84    |    5810 K  |    5810 K  |\n","|       from small pool |     226    |     238    |     710 K  |     710 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      93    |     153    |   60139 K  |   60139 K  |\n","|       from large pool |      16    |      49    |   39949 K  |   39949 K  |\n","|       from small pool |      77    |     119    |   20189 K  |   20189 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:93/139 batch:726/8961 epoch:1/10\n","full seq: But by accepting, it went againstrecommendations issued by the EU to the potential member countries in Eastern Europe.Ģġġġġġġġġġġġġġġġġġġġġ\n","pref seq: But by accepting, it went againstrecommendations issued by the EU to the potential member cou\n","next tok:                                                                                             n\n","pred tok:                                                                                             Ģ\n","Completed batch.\n","epoch:1/10 batch:726/8961 batch_size:149 loss:2.9643843173980713 time_for_batch_instance:113.35234475135803 total_batch_time:80192.30300307274 running_batch_average:110.45771763508641\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 670422 KiB |   7996 MiB |   3156 TiB |   3156 TiB |\n","|       from large pool | 215816 KiB |   7553 MiB |   3146 TiB |   3146 TiB |\n","|       from small pool | 454606 KiB |    473 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 670422 KiB |   7996 MiB |   3156 TiB |   3156 TiB |\n","|       from large pool | 215816 KiB |   7553 MiB |   3146 TiB |   3146 TiB |\n","|       from small pool | 454606 KiB |    473 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |   7982 MiB |   3147 TiB |   3147 TiB |\n","|       from large pool | 213248 KiB |   7543 MiB |   3137 TiB |   3137 TiB |\n","|       from small pool | 450193 KiB |    469 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1802 MiB |   8406 MiB | 714839 GiB | 714837 GiB |\n","|       from large pool |   1350 MiB |   7940 MiB | 713449 GiB | 713448 GiB |\n","|       from small pool |    452 MiB |    476 MiB |   1390 GiB |   1389 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1147 MiB |   1572 MiB |   1101 TiB |   1101 TiB |\n","|       from large pool |   1139 MiB |   1566 MiB |   1090 TiB |   1090 TiB |\n","|       from small pool |      8 MiB |     23 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  125945 K  |  125926 K  |\n","|       from large pool |      98    |     248    |   74165 K  |   74165 K  |\n","|       from small pool |   18777    |   18924    |   51779 K  |   51760 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  125945 K  |  125926 K  |\n","|       from large pool |      98    |     248    |   74165 K  |   74165 K  |\n","|       from small pool |   18777    |   18924    |   51779 K  |   51760 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     241    |     320    |    6530 K  |    6530 K  |\n","|       from large pool |      15    |      87    |    5818 K  |    5818 K  |\n","|       from small pool |     226    |     238    |     711 K  |     711 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      90    |     167    |   60234 K  |   60234 K  |\n","|       from large pool |      16    |      63    |   40016 K  |   40016 K  |\n","|       from small pool |      74    |     123    |   20218 K  |   20218 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:120/257 batch:727/8961 epoch:1/10\n","full seq: Mladjan Dinkic, president of United Regions of Serbia and former finance minister, said the state will be able to avoid significant losses initially because US Steel left net claims on their account to finance production for several months.Ģġġġġġġġġġġġġġġġġ\n","pref seq: Mladjan Dinkic, president of United Regions of Serbia and former finance minister, said the state will be able to avoid \n","next tok:                                                                                                                        s\n","pred tok:                                                                                                                        Ģ\n","Completed batch.\n","epoch:1/10 batch:727/8961 batch_size:148 loss:4.541086196899414 time_for_batch_instance:216.5096423625946 total_batch_time:80408.81264543533 running_batch_average:110.60359373512425\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 673391 KiB |  14392 MiB |   3168 TiB |   3168 TiB |\n","|       from large pool | 218785 KiB |  13956 MiB |   3158 TiB |   3158 TiB |\n","|       from small pool | 454606 KiB |    469 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 673391 KiB |  14392 MiB |   3168 TiB |   3168 TiB |\n","|       from large pool | 218785 KiB |  13956 MiB |   3158 TiB |   3158 TiB |\n","|       from small pool | 454606 KiB |    469 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  14381 MiB |   3159 TiB |   3159 TiB |\n","|       from large pool | 213248 KiB |  13948 MiB |   3149 TiB |   3149 TiB |\n","|       from small pool | 450193 KiB |    464 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1938 MiB |  15094 MiB | 717610 GiB | 717608 GiB |\n","|       from large pool |   1490 MiB |  14630 MiB | 716216 GiB | 716214 GiB |\n","|       from small pool |    448 MiB |    474 MiB |   1393 GiB |   1393 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1280 MiB |   1958 MiB |   1104 TiB |   1104 TiB |\n","|       from large pool |   1276 MiB |   1953 MiB |   1094 TiB |   1094 TiB |\n","|       from small pool |      4 MiB |     23 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  126280 K  |  126261 K  |\n","|       from large pool |      98    |     263    |   74368 K  |   74368 K  |\n","|       from small pool |   18777    |   18924    |   51911 K  |   51892 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  126280 K  |  126261 K  |\n","|       from large pool |      98    |     263    |   74368 K  |   74368 K  |\n","|       from small pool |   18777    |   18924    |   51911 K  |   51892 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     241    |     324    |    6548 K  |    6548 K  |\n","|       from large pool |      17    |      92    |    5834 K  |    5834 K  |\n","|       from small pool |     224    |     237    |     713 K  |     713 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      88    |     166    |   60376 K  |   60376 K  |\n","|       from large pool |      18    |      65    |   40106 K  |   40106 K  |\n","|       from small pool |      70    |     117    |   20269 K  |   20269 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:82/192 batch:728/8961 epoch:1/10\n","full seq: She added that the exact number of those children could not be determined due to the lack of a single international database and a high mortality rate among such children.Ģġġġġġġġġġġġġġġġġġġġġ\n","pref seq: She added that the exact number of those children could not be determined due to t\n","next tok:                                                                                  h\n","pred tok:                                                                                  -\n","Completed batch.\n","epoch:1/10 batch:728/8961 batch_size:147 loss:1.931375503540039 time_for_batch_instance:159.93585181236267 total_batch_time:80568.7484972477 running_batch_average:110.67135782588969\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 671926 KiB |  10695 MiB |   3174 TiB |   3174 TiB |\n","|       from large pool | 217320 KiB |  10247 MiB |   3165 TiB |   3165 TiB |\n","|       from small pool | 454606 KiB |    475 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 671926 KiB |  10695 MiB |   3174 TiB |   3174 TiB |\n","|       from large pool | 217320 KiB |  10247 MiB |   3165 TiB |   3165 TiB |\n","|       from small pool | 454606 KiB |    475 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  10675 MiB |   3165 TiB |   3165 TiB |\n","|       from large pool | 213248 KiB |  10232 MiB |   3156 TiB |   3156 TiB |\n","|       from small pool | 450193 KiB |    470 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1650 MiB |  11254 MiB | 719132 GiB | 719130 GiB |\n","|       from large pool |   1200 MiB |  10792 MiB | 717736 GiB | 717734 GiB |\n","|       from small pool |    450 MiB |    478 MiB |   1396 GiB |   1395 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |    993 MiB |   1633 MiB |   1107 TiB |   1107 TiB |\n","|       from large pool |    987 MiB |   1626 MiB |   1096 TiB |   1096 TiB |\n","|       from small pool |      6 MiB |     21 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  126529 K  |  126510 K  |\n","|       from large pool |      98    |     248    |   74514 K  |   74514 K  |\n","|       from small pool |   18777    |   18924    |   52015 K  |   51996 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  126529 K  |  126510 K  |\n","|       from large pool |      98    |     248    |   74514 K  |   74514 K  |\n","|       from small pool |   18777    |   18924    |   52015 K  |   51996 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     240    |     320    |    6561 K  |    6561 K  |\n","|       from large pool |      15    |      88    |    5846 K  |    5846 K  |\n","|       from small pool |     225    |     239    |     714 K  |     714 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      93    |     185    |   60489 K  |   60489 K  |\n","|       from large pool |      17    |      80    |   40179 K  |   40179 K  |\n","|       from small pool |      76    |     121    |   20310 K  |   20310 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:47/137 batch:729/8961 epoch:1/10\n","full seq: He added that the government would aim to accumulate 3 billion euros under a programme for partial sell-offs of public enterprises.Ģġġġġġ\n","pref seq: He added that the government would aim to accum\n","next tok:                                               u\n","pred tok:                                               Ģ\n","Completed batch.\n","epoch:1/10 batch:729/8961 batch_size:147 loss:2.8240509033203125 time_for_batch_instance:112.0953540802002 total_batch_time:80680.8438513279 running_batch_average:110.67331118151975\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 672327 KiB |   7843 MiB |   3178 TiB |   3178 TiB |\n","|       from large pool | 217721 KiB |   7400 MiB |   3168 TiB |   3168 TiB |\n","|       from small pool | 454606 KiB |    472 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 672327 KiB |   7843 MiB |   3178 TiB |   3178 TiB |\n","|       from large pool | 217721 KiB |   7400 MiB |   3168 TiB |   3168 TiB |\n","|       from small pool | 454606 KiB |    472 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |   7815 MiB |   3169 TiB |   3169 TiB |\n","|       from large pool | 213248 KiB |   7375 MiB |   3159 TiB |   3159 TiB |\n","|       from small pool | 450193 KiB |    468 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1780 MiB |   8234 MiB | 719845 GiB | 719843 GiB |\n","|       from large pool |   1328 MiB |   7768 MiB | 718446 GiB | 718445 GiB |\n","|       from small pool |    452 MiB |    476 MiB |   1398 GiB |   1397 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1123 MiB |   1716 MiB |   1108 TiB |   1108 TiB |\n","|       from large pool |   1115 MiB |   1708 MiB |   1098 TiB |   1098 TiB |\n","|       from small pool |      8 MiB |     24 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  126706 K  |  126687 K  |\n","|       from large pool |      98    |     248    |   74617 K  |   74616 K  |\n","|       from small pool |   18777    |   18924    |   52089 K  |   52070 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  126706 K  |  126687 K  |\n","|       from large pool |      98    |     248    |   74617 K  |   74616 K  |\n","|       from small pool |   18777    |   18924    |   52089 K  |   52070 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     240    |     318    |    6570 K  |    6570 K  |\n","|       from large pool |      14    |      85    |    5854 K  |    5854 K  |\n","|       from small pool |     226    |     238    |     715 K  |     715 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      91    |     168    |   60562 K  |   60562 K  |\n","|       from large pool |      13    |      65    |   40224 K  |   40224 K  |\n","|       from small pool |      78    |     120    |   20338 K  |   20338 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:45/110 batch:730/8961 epoch:1/10\n","full seq: Turkey's Parliament endorses an ambitious national development plan to meet EU standards.Ģġġġġġġġġġġġġġġġġġġġġ\n","pref seq: Turkey's Parliament endorses an ambitious nat\n","next tok:                                             i\n","pred tok:                                             :\n","Completed batch.\n","epoch:1/10 batch:730/8961 batch_size:147 loss:2.007462978363037 time_for_batch_instance:89.28607106208801 total_batch_time:80770.12992238998 running_batch_average:110.64401359231505\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 668980 KiB |   6375 MiB |   3180 TiB |   3180 TiB |\n","|       from large pool | 214374 KiB |   5934 MiB |   3170 TiB |   3170 TiB |\n","|       from small pool | 454606 KiB |    470 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 668980 KiB |   6375 MiB |   3180 TiB |   3180 TiB |\n","|       from large pool | 214374 KiB |   5934 MiB |   3170 TiB |   3170 TiB |\n","|       from small pool | 454606 KiB |    470 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |   6354 MiB |   3171 TiB |   3171 TiB |\n","|       from large pool | 213248 KiB |   5918 MiB |   3161 TiB |   3161 TiB |\n","|       from small pool | 450193 KiB |    466 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1918 MiB |   6718 MiB | 720282 GiB | 720281 GiB |\n","|       from large pool |   1466 MiB |   6250 MiB | 718883 GiB | 718881 GiB |\n","|       from small pool |    452 MiB |    474 MiB |   1399 GiB |   1399 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1264 MiB |   1544 MiB |   1109 TiB |   1109 TiB |\n","|       from large pool |   1256 MiB |   1535 MiB |   1098 TiB |   1098 TiB |\n","|       from small pool |      8 MiB |     22 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  126848 K  |  126829 K  |\n","|       from large pool |      98    |     248    |   74699 K  |   74698 K  |\n","|       from small pool |   18777    |   18924    |   52149 K  |   52130 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  126848 K  |  126829 K  |\n","|       from large pool |      98    |     248    |   74699 K  |   74698 K  |\n","|       from small pool |   18777    |   18924    |   52149 K  |   52130 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     240    |     317    |    6577 K  |    6576 K  |\n","|       from large pool |      14    |      83    |    5860 K  |    5860 K  |\n","|       from small pool |     226    |     237    |     716 K  |     716 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      98    |     162    |   60622 K  |   60622 K  |\n","|       from large pool |      16    |      61    |   40262 K  |   40262 K  |\n","|       from small pool |      82    |     120    |   20360 K  |   20360 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:80/83 batch:731/8961 epoch:1/10\n","full seq: At this moment, we should forgive each other instead of spreading hatred.\"Ģġġġġġġġġ\n","pref seq: At this moment, we should forgive each other instead of spreading hatred.\"Ģġġġġġ\n","next tok:                                                                                ġ\n","pred tok:                                                                                Ģ\n","Completed batch.\n","epoch:1/10 batch:731/8961 batch_size:147 loss:1.5775830745697021 time_for_batch_instance:66.62245392799377 total_batch_time:80836.75237631798 running_batch_average:110.58379258046234\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 671274 KiB |   4986 MiB |   3181 TiB |   3181 TiB |\n","|       from large pool | 216668 KiB |   4549 MiB |   3172 TiB |   3172 TiB |\n","|       from small pool | 454606 KiB |    469 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 671274 KiB |   4986 MiB |   3181 TiB |   3181 TiB |\n","|       from large pool | 216668 KiB |   4549 MiB |   3172 TiB |   3172 TiB |\n","|       from small pool | 454606 KiB |    469 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |   4968 MiB |   3172 TiB |   3172 TiB |\n","|       from large pool | 213248 KiB |   4534 MiB |   3163 TiB |   3163 TiB |\n","|       from small pool | 450193 KiB |    464 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1580 MiB |   5406 MiB | 720537 GiB | 720535 GiB |\n","|       from large pool |   1130 MiB |   4942 MiB | 719136 GiB | 719135 GiB |\n","|       from small pool |    450 MiB |    474 MiB |   1400 GiB |   1400 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |    924 MiB |   1298 MiB |   1109 TiB |   1109 TiB |\n","|       from large pool |    918 MiB |   1295 MiB |   1099 TiB |   1099 TiB |\n","|       from small pool |      6 MiB |     24 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  126954 K  |  126935 K  |\n","|       from large pool |      98    |     248    |   74760 K  |   74760 K  |\n","|       from small pool |   18777    |   18924    |   52194 K  |   52175 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  126954 K  |  126935 K  |\n","|       from large pool |      98    |     248    |   74760 K  |   74760 K  |\n","|       from small pool |   18777    |   18924    |   52194 K  |   52175 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     238    |     311    |    6582 K  |    6581 K  |\n","|       from large pool |      13    |      79    |    5864 K  |    5864 K  |\n","|       from small pool |     225    |     237    |     717 K  |     717 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      96    |     177    |   60681 K  |   60681 K  |\n","|       from large pool |      18    |      74    |   40303 K  |   40303 K  |\n","|       from small pool |      78    |     119    |   20377 K  |   20377 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:131/188 batch:732/8961 epoch:1/10\n","full seq: Meanwhile, German authorities have found traces of polonium 210 in several locations visited by Kovtun -- the flat of his ex-wife, in a car he used, and at his mother-in-law's home.Ģġġġġġġ\n","pref seq: Meanwhile, German authorities have found traces of polonium 210 in several locations visited by Kovtun -- the flat of his ex-wife, \n","next tok:                                                                                                                                   i\n","pred tok:                                                                                                                                   Ģ\n","Completed batch.\n","epoch:1/10 batch:732/8961 batch_size:146 loss:2.7219626903533936 time_for_batch_instance:156.45492911338806 total_batch_time:80993.20730543137 running_batch_average:110.6464580675292\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 670678 KiB |  10454 MiB |   3187 TiB |   3187 TiB |\n","|       from large pool | 216072 KiB |  10007 MiB |   3178 TiB |   3178 TiB |\n","|       from small pool | 454606 KiB |    480 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 670678 KiB |  10454 MiB |   3187 TiB |   3187 TiB |\n","|       from large pool | 216072 KiB |  10007 MiB |   3178 TiB |   3178 TiB |\n","|       from small pool | 454606 KiB |    480 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  10434 MiB |   3178 TiB |   3178 TiB |\n","|       from large pool | 213248 KiB |   9991 MiB |   3169 TiB |   3169 TiB |\n","|       from small pool | 450193 KiB |    476 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1626 MiB |  10986 MiB | 721996 GiB | 721994 GiB |\n","|       from large pool |   1176 MiB |  10522 MiB | 720593 GiB | 720591 GiB |\n","|       from small pool |    450 MiB |    482 MiB |   1403 GiB |   1402 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |    971 MiB |   1408 MiB |   1111 TiB |   1111 TiB |\n","|       from large pool |    964 MiB |   1402 MiB |   1101 TiB |   1101 TiB |\n","|       from small pool |      6 MiB |     29 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  127198 K  |  127179 K  |\n","|       from large pool |      98    |     248    |   74902 K  |   74902 K  |\n","|       from small pool |   18777    |   18924    |   52296 K  |   52277 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  127198 K  |  127179 K  |\n","|       from large pool |      98    |     248    |   74902 K  |   74902 K  |\n","|       from small pool |   18777    |   18924    |   52296 K  |   52277 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     239    |     322    |    6595 K  |    6594 K  |\n","|       from large pool |      14    |      90    |    5876 K  |    5876 K  |\n","|       from small pool |     225    |     241    |     718 K  |     718 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      92    |     169    |   60806 K  |   60806 K  |\n","|       from large pool |      16    |      63    |   40388 K  |   40388 K  |\n","|       from small pool |      76    |     122    |   20417 K  |   20417 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:105/142 batch:733/8961 epoch:1/10\n","full seq: Moisiu praised NATO's presence in Southeast Europe, emphasising its role in Bosnia and Herzegovina, Kosovo and Macedonia.Ģġġġġġġġġġġġġġġġġġġġġ\n","pref seq: Moisiu praised NATO's presence in Southeast Europe, emphasising its role in Bosnia and Herzegovina, Kosov\n","next tok:                                                                                                         o\n","pred tok:                                                                                                         '\n","Completed batch.\n","epoch:1/10 batch:733/8961 batch_size:146 loss:2.567058801651001 time_for_batch_instance:116.44311380386353 total_batch_time:81109.65041923523 running_batch_average:110.65436619268108\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 669946 KiB |   7962 MiB |   3191 TiB |   3191 TiB |\n","|       from large pool | 215340 KiB |   7519 MiB |   3181 TiB |   3181 TiB |\n","|       from small pool | 454606 KiB |    478 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 669946 KiB |   7962 MiB |   3191 TiB |   3191 TiB |\n","|       from large pool | 215340 KiB |   7519 MiB |   3181 TiB |   3181 TiB |\n","|       from small pool | 454606 KiB |    478 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |   7953 MiB |   3182 TiB |   3182 TiB |\n","|       from large pool | 213248 KiB |   7514 MiB |   3172 TiB |   3172 TiB |\n","|       from small pool | 450193 KiB |    473 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1838 MiB |   8374 MiB | 722756 GiB | 722754 GiB |\n","|       from large pool |   1386 MiB |   7906 MiB | 721351 GiB | 721349 GiB |\n","|       from small pool |    452 MiB |    480 MiB |   1405 GiB |   1405 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1183 MiB |   1579 MiB |   1113 TiB |   1113 TiB |\n","|       from large pool |   1175 MiB |   1571 MiB |   1102 TiB |   1102 TiB |\n","|       from small pool |      8 MiB |     25 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  127382 K  |  127363 K  |\n","|       from large pool |      98    |     248    |   75008 K  |   75008 K  |\n","|       from small pool |   18777    |   18924    |   52373 K  |   52354 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  127382 K  |  127363 K  |\n","|       from large pool |      98    |     248    |   75008 K  |   75008 K  |\n","|       from small pool |   18777    |   18924    |   52373 K  |   52354 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     240    |     315    |    6604 K  |    6603 K  |\n","|       from large pool |      14    |      82    |    5884 K  |    5884 K  |\n","|       from small pool |     226    |     240    |     719 K  |     719 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      95    |     182    |   60906 K  |   60906 K  |\n","|       from large pool |      17    |      79    |   40460 K  |   40460 K  |\n","|       from small pool |      78    |     121    |   20446 K  |   20446 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:107/133 batch:734/8961 epoch:1/10\n","full seq: Acting on the state prosecutor's orders, over 300 police officers participated in the sting, aptly dubbed \"Tax\".Ģġġġġġġġġġġġġġġġġġġġġ\n","pref seq: Acting on the state prosecutor's orders, over 300 police officers participated in the sting, aptly dubbed \"\n","next tok:                                                                                                           T\n","pred tok:                                                                                                           :\n","Completed batch.\n","epoch:1/10 batch:734/8961 batch_size:146 loss:2.097933530807495 time_for_batch_instance:108.69287371635437 total_batch_time:81218.34329295158 running_batch_average:110.65169385960706\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 673770 KiB |   7539 MiB |   3194 TiB |   3194 TiB |\n","|       from large pool | 219164 KiB |   7096 MiB |   3185 TiB |   3185 TiB |\n","|       from small pool | 454606 KiB |    477 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 673770 KiB |   7539 MiB |   3194 TiB |   3194 TiB |\n","|       from large pool | 219164 KiB |   7096 MiB |   3185 TiB |   3185 TiB |\n","|       from small pool | 454606 KiB |    477 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |   7520 MiB |   3185 TiB |   3185 TiB |\n","|       from large pool | 213248 KiB |   7081 MiB |   3176 TiB |   3176 TiB |\n","|       from small pool | 450193 KiB |    473 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1536 MiB |   7924 MiB | 723435 GiB | 723433 GiB |\n","|       from large pool |   1084 MiB |   7458 MiB | 722027 GiB | 722026 GiB |\n","|       from small pool |    452 MiB |    480 MiB |   1407 GiB |   1406 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |    878 MiB |   1331 MiB |   1114 TiB |   1114 TiB |\n","|       from large pool |    869 MiB |   1323 MiB |   1104 TiB |   1104 TiB |\n","|       from small pool |      8 MiB |     26 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  127554 K  |  127535 K  |\n","|       from large pool |      98    |     248    |   75108 K  |   75108 K  |\n","|       from small pool |   18777    |   18924    |   52445 K  |   52426 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  127554 K  |  127535 K  |\n","|       from large pool |      98    |     248    |   75108 K  |   75108 K  |\n","|       from small pool |   18777    |   18924    |   52445 K  |   52426 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     238    |     318    |    6612 K  |    6612 K  |\n","|       from large pool |      12    |      85    |    5892 K  |    5892 K  |\n","|       from small pool |     226    |     240    |     720 K  |     720 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      86    |     159    |   60994 K  |   60993 K  |\n","|       from large pool |      10    |      58    |   40520 K  |   40520 K  |\n","|       from small pool |      76    |     121    |   20473 K  |   20473 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:12/247 batch:735/8961 epoch:1/10\n","full seq: George Tzogopoulos, a research fellow at the Hellenic Foundation for European and Foreign Policy in Athens, told SETimes that Papademos \"is the best choice right now because he's very respected in Brussels and internationally.\"Ģġġġġġġġġġġġġġġġġġġġ\n","pref seq: George Tzogo\n","next tok:            p\n","pred tok:            f\n","Completed batch.\n","epoch:1/10 batch:735/8961 batch_size:145 loss:1.5047508478164673 time_for_batch_instance:207.70573496818542 total_batch_time:81426.04902791977 running_batch_average:110.7837401740405\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 670883 KiB |  13457 MiB |   3205 TiB |   3205 TiB |\n","|       from large pool | 216277 KiB |  13021 MiB |   3195 TiB |   3195 TiB |\n","|       from small pool | 454606 KiB |    473 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 670883 KiB |  13457 MiB |   3205 TiB |   3205 TiB |\n","|       from large pool | 216277 KiB |  13021 MiB |   3195 TiB |   3195 TiB |\n","|       from small pool | 454606 KiB |    473 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  13435 MiB |   3196 TiB |   3196 TiB |\n","|       from large pool | 213248 KiB |  13003 MiB |   3186 TiB |   3186 TiB |\n","|       from small pool | 450193 KiB |    469 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1942 MiB |  14122 MiB | 725957 GiB | 725955 GiB |\n","|       from large pool |   1494 MiB |  13660 MiB | 724546 GiB | 724544 GiB |\n","|       from small pool |    448 MiB |    476 MiB |   1411 GiB |   1410 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1286 MiB |   1707 MiB |   1118 TiB |   1118 TiB |\n","|       from large pool |   1282 MiB |   1702 MiB |   1107 TiB |   1107 TiB |\n","|       from small pool |      4 MiB |     21 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  127875 K  |  127857 K  |\n","|       from large pool |      98    |     263    |   75303 K  |   75302 K  |\n","|       from small pool |   18777    |   18924    |   52572 K  |   52554 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  127875 K  |  127857 K  |\n","|       from large pool |      98    |     263    |   75303 K  |   75302 K  |\n","|       from small pool |   18777    |   18924    |   52572 K  |   52554 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     243    |     323    |    6630 K  |    6630 K  |\n","|       from large pool |      19    |      92    |    5908 K  |    5908 K  |\n","|       from small pool |     224    |     238    |     722 K  |     722 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      96    |     172    |   61140 K  |   61140 K  |\n","|       from large pool |      26    |      70    |   40616 K  |   40615 K  |\n","|       from small pool |      70    |     120    |   20524 K  |   20524 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:113/183 batch:736/8961 epoch:1/10\n","full seq: \"We understand his decision,\" Sanader said, \"but I hope that the coalition will overcome this situation and continue forward as there is a lot of work to be done.Ģġġġġġġġġġġġġġġġġġġġġ\n","pref seq: \"We understand his decision,\" Sanader said, \"but I hope that the coalition will overcome this situation and conti\n","next tok:                                                                                                                 n\n","pred tok:                                                                                                                 ,\n","Completed batch.\n","epoch:1/10 batch:736/8961 batch_size:145 loss:3.345212936401367 time_for_batch_instance:150.75103664398193 total_batch_time:81576.80006456375 running_batch_average:110.83804356598336\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 669550 KiB |  10062 MiB |   3211 TiB |   3211 TiB |\n","|       from large pool | 214944 KiB |   9615 MiB |   3201 TiB |   3201 TiB |\n","|       from small pool | 454606 KiB |    479 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 669550 KiB |  10062 MiB |   3211 TiB |   3211 TiB |\n","|       from large pool | 214944 KiB |   9615 MiB |   3201 TiB |   3201 TiB |\n","|       from small pool | 454606 KiB |    479 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  10034 MiB |   3202 TiB |   3202 TiB |\n","|       from large pool | 213248 KiB |   9592 MiB |   3192 TiB |   3192 TiB |\n","|       from small pool | 450193 KiB |    475 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1614 MiB |  10576 MiB | 727314 GiB | 727312 GiB |\n","|       from large pool |   1164 MiB |  10114 MiB | 725900 GiB | 725899 GiB |\n","|       from small pool |    450 MiB |    482 MiB |   1413 GiB |   1413 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |    960 MiB |   1533 MiB |   1120 TiB |   1120 TiB |\n","|       from large pool |    954 MiB |   1526 MiB |   1109 TiB |   1109 TiB |\n","|       from small pool |      6 MiB |     25 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  128113 K  |  128094 K  |\n","|       from large pool |      98    |     248    |   75441 K  |   75441 K  |\n","|       from small pool |   18777    |   18924    |   52672 K  |   52653 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  128113 K  |  128094 K  |\n","|       from large pool |      98    |     248    |   75441 K  |   75441 K  |\n","|       from small pool |   18777    |   18924    |   52672 K  |   52653 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     239    |     320    |    6643 K  |    6642 K  |\n","|       from large pool |      14    |      89    |    5919 K  |    5919 K  |\n","|       from small pool |     225    |     241    |     723 K  |     723 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      95    |     177    |   61243 K  |   61243 K  |\n","|       from large pool |      18    |      71    |   40680 K  |   40680 K  |\n","|       from small pool |      77    |     125    |   20563 K  |   20563 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:90/132 batch:737/8961 epoch:1/10\n","full seq: It was the first between the two leaders since AKP won a landslide victory in Sunday's parliamentary elections.Ģġġġġġġġġġġġġġġġġġġġġ\n","pref seq: It was the first between the two leaders since AKP won a landslide victory in Sunday's par\n","next tok:                                                                                          l\n","pred tok:                                                                                          q\n","Completed batch.\n","epoch:1/10 batch:737/8961 batch_size:145 loss:2.8097329139709473 time_for_batch_instance:108.10777020454407 total_batch_time:81684.9078347683 running_batch_average:110.8343389888308\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 670884 KiB |   7446 MiB |   3214 TiB |   3214 TiB |\n","|       from large pool | 216278 KiB |   7003 MiB |   3204 TiB |   3204 TiB |\n","|       from small pool | 454606 KiB |    477 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 670884 KiB |   7446 MiB |   3214 TiB |   3214 TiB |\n","|       from large pool | 216278 KiB |   7003 MiB |   3204 TiB |   3204 TiB |\n","|       from small pool | 454606 KiB |    477 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |   7420 MiB |   3205 TiB |   3205 TiB |\n","|       from large pool | 213248 KiB |   6981 MiB |   3195 TiB |   3195 TiB |\n","|       from small pool | 450193 KiB |    473 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1748 MiB |   7818 MiB | 727954 GiB | 727952 GiB |\n","|       from large pool |   1296 MiB |   7350 MiB | 726539 GiB | 726537 GiB |\n","|       from small pool |    452 MiB |    480 MiB |   1415 GiB |   1414 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1092 MiB |   1679 MiB |   1121 TiB |   1121 TiB |\n","|       from large pool |   1084 MiB |   1668 MiB |   1110 TiB |   1110 TiB |\n","|       from small pool |      8 MiB |     25 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  128284 K  |  128265 K  |\n","|       from large pool |      98    |     248    |   75540 K  |   75539 K  |\n","|       from small pool |   18777    |   18924    |   52743 K  |   52725 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  128284 K  |  128265 K  |\n","|       from large pool |      98    |     248    |   75540 K  |   75539 K  |\n","|       from small pool |   18777    |   18924    |   52743 K  |   52725 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     239    |     317    |    6651 K  |    6651 K  |\n","|       from large pool |      13    |      83    |    5926 K  |    5926 K  |\n","|       from small pool |     226    |     240    |     724 K  |     724 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      90    |     158    |   61329 K  |   61329 K  |\n","|       from large pool |      14    |      54    |   40739 K  |   40739 K  |\n","|       from small pool |      76    |     122    |   20590 K  |   20590 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:86/98 batch:738/8961 epoch:1/10\n","full seq: Two members of the C-47's World War II crew and their families also attended.Ģġġġġġġġġġġġġġġġġġġġġ\n","pref seq: Two members of the C-47's World War II crew and their families also attended.Ģġġġġġġġġ\n","next tok:                                                                                      ġ\n","pred tok:                                                                                      [\n","Completed batch.\n","epoch:1/10 batch:738/8961 batch_size:144 loss:2.719599962234497 time_for_batch_instance:79.81389784812927 total_batch_time:81764.72173261642 running_batch_average:110.79230587075396\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 674627 KiB |   5639 MiB |   3216 TiB |   3216 TiB |\n","|       from large pool | 220021 KiB |   5200 MiB |   3206 TiB |   3206 TiB |\n","|       from small pool | 454606 KiB |    475 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 674627 KiB |   5639 MiB |   3216 TiB |   3216 TiB |\n","|       from large pool | 220021 KiB |   5200 MiB |   3206 TiB |   3206 TiB |\n","|       from small pool | 454606 KiB |    475 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |   5617 MiB |   3207 TiB |   3207 TiB |\n","|       from large pool | 213248 KiB |   5182 MiB |   3197 TiB |   3197 TiB |\n","|       from small pool | 450193 KiB |    470 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1478 MiB |   6058 MiB | 728307 GiB | 728306 GiB |\n","|       from large pool |   1026 MiB |   5592 MiB | 726890 GiB | 726889 GiB |\n","|       from small pool |    452 MiB |    478 MiB |   1416 GiB |   1416 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |    819 MiB |   1254 MiB |   1122 TiB |   1122 TiB |\n","|       from large pool |    811 MiB |   1247 MiB |   1111 TiB |   1111 TiB |\n","|       from small pool |      8 MiB |     24 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  128409 K  |  128390 K  |\n","|       from large pool |      98    |     248    |   75612 K  |   75612 K  |\n","|       from small pool |   18777    |   18924    |   52797 K  |   52778 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  128409 K  |  128390 K  |\n","|       from large pool |      98    |     248    |   75612 K  |   75612 K  |\n","|       from small pool |   18777    |   18924    |   52797 K  |   52778 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     241    |     319    |    6657 K  |    6657 K  |\n","|       from large pool |      15    |      86    |    5932 K  |    5932 K  |\n","|       from small pool |     226    |     239    |     725 K  |     725 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      98    |     169    |   61385 K  |   61385 K  |\n","|       from large pool |      20    |      66    |   40775 K  |   40775 K  |\n","|       from small pool |      78    |     120    |   20610 K  |   20610 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:64/77 batch:739/8961 epoch:1/10\n","full seq: Shops in Croatia are now open on Sundays. [Getty Images]Ģġġġġġġġġġġġġġġġġġġġġ\n","pref seq: Shops in Croatia are now open on Sundays. [Getty Images]Ģġġġġġġġ\n","next tok:                                                                ġ\n","pred tok:                                                                Ģ\n","Completed batch.\n","epoch:1/10 batch:739/8961 batch_size:144 loss:2.3788180351257324 time_for_batch_instance:61.66488695144653 total_batch_time:81826.38661956787 running_batch_average:110.7258276313503\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 672546 KiB |   4543 MiB |   3217 TiB |   3217 TiB |\n","|       from large pool | 217940 KiB |   4106 MiB |   3207 TiB |   3207 TiB |\n","|       from small pool | 454606 KiB |    473 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 672546 KiB |   4543 MiB |   3217 TiB |   3217 TiB |\n","|       from large pool | 217940 KiB |   4106 MiB |   3207 TiB |   3207 TiB |\n","|       from small pool | 454606 KiB |    473 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |   4533 MiB |   3208 TiB |   3208 TiB |\n","|       from large pool | 213248 KiB |   4100 MiB |   3198 TiB |   3198 TiB |\n","|       from small pool | 450193 KiB |    469 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1708 MiB |   4988 MiB | 728516 GiB | 728515 GiB |\n","|       from large pool |   1260 MiB |   4526 MiB | 727099 GiB | 727097 GiB |\n","|       from small pool |    448 MiB |    476 MiB |   1417 GiB |   1417 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1051 MiB |   1052 MiB |   1122 TiB |   1122 TiB |\n","|       from large pool |   1047 MiB |   1048 MiB |   1112 TiB |   1112 TiB |\n","|       from small pool |      4 MiB |     21 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  128507 K  |  128488 K  |\n","|       from large pool |      98    |     248    |   75668 K  |   75668 K  |\n","|       from small pool |   18777    |   18924    |   52838 K  |   52820 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  128507 K  |  128488 K  |\n","|       from large pool |      98    |     248    |   75668 K  |   75668 K  |\n","|       from small pool |   18777    |   18924    |   52838 K  |   52820 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     238    |     310    |    6662 K  |    6661 K  |\n","|       from large pool |      14    |      79    |    5936 K  |    5936 K  |\n","|       from small pool |     224    |     238    |     725 K  |     725 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      91    |     169    |   61437 K  |   61436 K  |\n","|       from large pool |      16    |      67    |   40810 K  |   40810 K  |\n","|       from small pool |      75    |     118    |   20626 K  |   20626 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:51/257 batch:740/8961 epoch:1/10\n","full seq: Third, regarding borders along the Aegean Sea -- a problem caused by disagreements over the definition of territorial waters -- Erdogan suggests \"new confidence-building measures and accelerating the ongoing technical talks on this issue\".Ģġġġġġġġġġġġġġġġġġ\n","pref seq: Third, regarding borders along the Aegean Sea -- a \n","next tok:                                                   p\n","pred tok:                                                   Ģ\n","Completed batch.\n","epoch:1/10 batch:740/8961 batch_size:142 loss:2.4738237857818604 time_for_batch_instance:216.80579948425293 total_batch_time:82043.19241905212 running_batch_average:110.86917894466504\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 674086 KiB |  13813 MiB |   3228 TiB |   3228 TiB |\n","|       from large pool | 219480 KiB |  13377 MiB |   3218 TiB |   3218 TiB |\n","|       from small pool | 454606 KiB |    473 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 674086 KiB |  13813 MiB |   3228 TiB |   3228 TiB |\n","|       from large pool | 219480 KiB |  13377 MiB |   3218 TiB |   3218 TiB |\n","|       from small pool | 454606 KiB |    473 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  13786 MiB |   3219 TiB |   3219 TiB |\n","|       from large pool | 213248 KiB |  13354 MiB |   3209 TiB |   3209 TiB |\n","|       from small pool | 450193 KiB |    468 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1424 MiB |  14472 MiB | 731225 GiB | 731223 GiB |\n","|       from large pool |    976 MiB |  14008 MiB | 729803 GiB | 729802 GiB |\n","|       from small pool |    448 MiB |    476 MiB |   1421 GiB |   1421 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 784089 KiB |   1860 MiB |   1126 TiB |   1126 TiB |\n","|       from large pool | 779943 KiB |   1855 MiB |   1115 TiB |   1115 TiB |\n","|       from small pool |   4146 KiB |     20 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  128842 K  |  128823 K  |\n","|       from large pool |      98    |     263    |   75871 K  |   75871 K  |\n","|       from small pool |   18777    |   18924    |   52971 K  |   52952 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  128842 K  |  128823 K  |\n","|       from large pool |      98    |     263    |   75871 K  |   75871 K  |\n","|       from small pool |   18777    |   18924    |   52971 K  |   52952 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     238    |     320    |    6680 K  |    6680 K  |\n","|       from large pool |      14    |      88    |    5952 K  |    5952 K  |\n","|       from small pool |     224    |     238    |     727 K  |     727 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      82    |     157    |   61621 K  |   61620 K  |\n","|       from large pool |      14    |      55    |   40941 K  |   40941 K  |\n","|       from small pool |      68    |     119    |   20679 K  |   20679 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:3/250 batch:741/8961 epoch:1/10\n","full seq: The head of Croatia's main opposition Social Democratic Party (SDP) condemned the country's authorities Monday (December 1st) over the arrest of a party activist who started a Facebook group critical of Prime Minister Ivo Sanader.Ģġġġġġġġġġġġġġġġġġġġ\n","pref seq: The\n","next tok:    \n","pred tok:   ġ\n","Completed batch.\n","epoch:1/10 batch:741/8961 batch_size:142 loss:3.984208106994629 time_for_batch_instance:209.46430087089539 total_batch_time:82252.65671992302 running_batch_average:111.00223578936979\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 670443 KiB |  13329 MiB |   3239 TiB |   3239 TiB |\n","|       from large pool | 215837 KiB |  12893 MiB |   3229 TiB |   3229 TiB |\n","|       from small pool | 454606 KiB |    472 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 670443 KiB |  13329 MiB |   3239 TiB |   3239 TiB |\n","|       from large pool | 215837 KiB |  12893 MiB |   3229 TiB |   3229 TiB |\n","|       from small pool | 454606 KiB |    472 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  13286 MiB |   3230 TiB |   3230 TiB |\n","|       from large pool | 213248 KiB |  12854 MiB |   3220 TiB |   3220 TiB |\n","|       from small pool | 450193 KiB |    468 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1428 MiB |  13952 MiB | 733756 GiB | 733755 GiB |\n","|       from large pool |    980 MiB |  13490 MiB | 732331 GiB | 732330 GiB |\n","|       from small pool |    448 MiB |    476 MiB |   1425 GiB |   1424 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |    773 MiB |   1837 MiB |   1130 TiB |   1130 TiB |\n","|       from large pool |    769 MiB |   1832 MiB |   1119 TiB |   1119 TiB |\n","|       from small pool |      4 MiB |     21 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  129168 K  |  129149 K  |\n","|       from large pool |      98    |     263    |   76068 K  |   76068 K  |\n","|       from small pool |   18777    |   18924    |   53099 K  |   53081 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  129168 K  |  129149 K  |\n","|       from large pool |      98    |     263    |   76068 K  |   76068 K  |\n","|       from small pool |   18777    |   18924    |   53099 K  |   53081 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     238    |     322    |    6698 K  |    6697 K  |\n","|       from large pool |      14    |      91    |    5968 K  |    5968 K  |\n","|       from small pool |     224    |     238    |     729 K  |     729 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      85    |     155    |   61793 K  |   61793 K  |\n","|       from large pool |      19    |      53    |   41062 K  |   41062 K  |\n","|       from small pool |      66    |     118    |   20731 K  |   20731 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:56/104 batch:742/8961 epoch:1/10\n","full seq: DUI's picks will also lead the ministries of local government, environment, economy and justice.Ģġġġġġġġ\n","pref seq: DUI's picks will also lead the ministries of local gover\n","next tok:                                                        n\n","pred tok:                                                        :\n","Completed batch.\n","epoch:1/10 batch:742/8961 batch_size:142 loss:3.6009113788604736 time_for_batch_instance:84.25265145301819 total_batch_time:82336.90937137604 running_batch_average:110.96618513662538\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 668591 KiB |   5905 MiB |   3241 TiB |   3241 TiB |\n","|       from large pool | 213985 KiB |   5465 MiB |   3231 TiB |   3231 TiB |\n","|       from small pool | 454606 KiB |    474 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 668591 KiB |   5905 MiB |   3241 TiB |   3241 TiB |\n","|       from large pool | 213985 KiB |   5465 MiB |   3231 TiB |   3231 TiB |\n","|       from small pool | 454606 KiB |    474 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |   5889 MiB |   3231 TiB |   3231 TiB |\n","|       from large pool | 213248 KiB |   5453 MiB |   3222 TiB |   3222 TiB |\n","|       from small pool | 450193 KiB |    470 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1746 MiB |   6250 MiB | 734151 GiB | 734149 GiB |\n","|       from large pool |   1294 MiB |   5784 MiB | 732724 GiB | 732723 GiB |\n","|       from small pool |    452 MiB |    478 MiB |   1426 GiB |   1426 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1093 MiB |   1228 MiB |   1130 TiB |   1130 TiB |\n","|       from large pool |   1085 MiB |   1221 MiB |   1120 TiB |   1120 TiB |\n","|       from small pool |      8 MiB |     23 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  129302 K  |  129283 K  |\n","|       from large pool |      98    |     248    |   76145 K  |   76145 K  |\n","|       from small pool |   18777    |   18924    |   53156 K  |   53137 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  129302 K  |  129283 K  |\n","|       from large pool |      98    |     248    |   76145 K  |   76145 K  |\n","|       from small pool |   18777    |   18924    |   53156 K  |   53137 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     239    |     315    |    6704 K  |    6704 K  |\n","|       from large pool |      13    |      82    |    5974 K  |    5974 K  |\n","|       from small pool |     226    |     239    |     730 K  |     730 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      98    |     169    |   61859 K  |   61859 K  |\n","|       from large pool |      23    |      67    |   41107 K  |   41107 K  |\n","|       from small pool |      75    |     120    |   20752 K  |   20752 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:71/133 batch:743/8961 epoch:1/10\n","full seq: This new security challenge was on the agenda at the June 8th-9th meeting of NATO defence ministers in Brussels.Ģġġġġġġġġġġġġġġġġġġġġ\n","pref seq: This new security challenge was on the agenda at the June 8th-9th meeti\n","next tok:                                                                       n\n","pred tok:                                                                       Ģ\n","Completed batch.\n","epoch:1/10 batch:743/8961 batch_size:140 loss:4.684062957763672 time_for_batch_instance:109.1590518951416 total_batch_time:82446.06842327118 running_batch_average:110.96375292499486\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 671744 KiB |   7261 MiB |   3244 TiB |   3244 TiB |\n","|       from large pool | 217138 KiB |   6818 MiB |   3234 TiB |   3234 TiB |\n","|       from small pool | 454606 KiB |    475 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 671744 KiB |   7261 MiB |   3244 TiB |   3244 TiB |\n","|       from large pool | 217138 KiB |   6818 MiB |   3234 TiB |   3234 TiB |\n","|       from small pool | 454606 KiB |    475 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |   7235 MiB |   3235 TiB |   3235 TiB |\n","|       from large pool | 213248 KiB |   6796 MiB |   3225 TiB |   3225 TiB |\n","|       from small pool | 450193 KiB |    471 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1592 MiB |   7626 MiB | 734778 GiB | 734777 GiB |\n","|       from large pool |   1138 MiB |   7158 MiB | 733349 GiB | 733348 GiB |\n","|       from small pool |    454 MiB |    480 MiB |   1428 GiB |   1428 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |    936 MiB |   1420 MiB |   1132 TiB |   1132 TiB |\n","|       from large pool |    925 MiB |   1409 MiB |   1121 TiB |   1121 TiB |\n","|       from small pool |     10 MiB |     24 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  129474 K  |  129455 K  |\n","|       from large pool |      98    |     248    |   76245 K  |   76245 K  |\n","|       from small pool |   18777    |   18924    |   53228 K  |   53209 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  129474 K  |  129455 K  |\n","|       from large pool |      98    |     248    |   76245 K  |   76245 K  |\n","|       from small pool |   18777    |   18924    |   53228 K  |   53209 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     241    |     315    |    6713 K  |    6712 K  |\n","|       from large pool |      14    |      81    |    5981 K  |    5981 K  |\n","|       from small pool |     227    |     240    |     731 K  |     731 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      89    |     160    |   61949 K  |   61949 K  |\n","|       from large pool |      12    |      58    |   41170 K  |   41170 K  |\n","|       from small pool |      77    |     121    |   20778 K  |   20778 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:74/177 batch:744/8961 epoch:1/10\n","full seq: The most flagrant irregularities are believed to have happened in Skenderaj/Srbica where the Central Election Commission (CEC) reported turnout of over 94%.Ģġġġġġġġġġġġġġġġġġġġġ\n","pref seq: The most flagrant irregularities are believed to have happened in Skendera\n","next tok:                                                                          j\n","pred tok:                                                                          Ģ\n","Completed batch.\n","epoch:1/10 batch:744/8961 batch_size:139 loss:4.802150249481201 time_for_batch_instance:147.37951135635376 total_batch_time:82593.44793462753 running_batch_average:111.01269883686497\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 669655 KiB |   9389 MiB |   3249 TiB |   3249 TiB |\n","|       from large pool | 215049 KiB |   8944 MiB |   3239 TiB |   3239 TiB |\n","|       from small pool | 454606 KiB |    477 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 669655 KiB |   9389 MiB |   3249 TiB |   3249 TiB |\n","|       from large pool | 215049 KiB |   8944 MiB |   3239 TiB |   3239 TiB |\n","|       from small pool | 454606 KiB |    477 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |   9380 MiB |   3240 TiB |   3240 TiB |\n","|       from large pool | 213248 KiB |   8938 MiB |   3230 TiB |   3230 TiB |\n","|       from small pool | 450193 KiB |    473 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1526 MiB |   9898 MiB | 735996 GiB | 735995 GiB |\n","|       from large pool |   1078 MiB |   9436 MiB | 734565 GiB | 734564 GiB |\n","|       from small pool |    448 MiB |    482 MiB |   1431 GiB |   1430 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |    872 MiB |   1294 MiB |   1134 TiB |   1134 TiB |\n","|       from large pool |    867 MiB |   1290 MiB |   1123 TiB |   1123 TiB |\n","|       from small pool |      4 MiB |     24 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  129703 K  |  129684 K  |\n","|       from large pool |      98    |     248    |   76378 K  |   76378 K  |\n","|       from small pool |   18777    |   18924    |   53324 K  |   53306 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  129703 K  |  129684 K  |\n","|       from large pool |      98    |     248    |   76378 K  |   76378 K  |\n","|       from small pool |   18777    |   18924    |   53324 K  |   53306 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     238    |     317    |    6725 K  |    6724 K  |\n","|       from large pool |      14    |      86    |    5992 K  |    5992 K  |\n","|       from small pool |     224    |     241    |     732 K  |     732 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      99    |     185    |   62077 K  |   62077 K  |\n","|       from large pool |      18    |      81    |   41260 K  |   41260 K  |\n","|       from small pool |      81    |     121    |   20817 K  |   20817 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:75/90 batch:745/8961 epoch:1/10\n","full seq: According to Osmanagic, there are three pyramids, interconnected through tunnels.Ģġġġġġġġġ\n","pref seq: According to Osmanagic, there are three pyramids, interconnected through tu\n","next tok:                                                                           n\n","pred tok:                                                                           f\n","Completed batch.\n","epoch:1/10 batch:745/8961 batch_size:139 loss:3.978308916091919 time_for_batch_instance:72.41963076591492 total_batch_time:82665.86756539345 running_batch_average:110.9608960609308\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 671810 KiB |   5058 MiB |   3251 TiB |   3251 TiB |\n","|       from large pool | 217204 KiB |   4620 MiB |   3241 TiB |   3241 TiB |\n","|       from small pool | 454606 KiB |    472 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 671810 KiB |   5058 MiB |   3251 TiB |   3251 TiB |\n","|       from large pool | 217204 KiB |   4620 MiB |   3241 TiB |   3241 TiB |\n","|       from small pool | 454606 KiB |    472 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |   5043 MiB |   3241 TiB |   3241 TiB |\n","|       from large pool | 213248 KiB |   4610 MiB |   3232 TiB |   3232 TiB |\n","|       from small pool | 450193 KiB |    467 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1634 MiB |   5450 MiB | 736274 GiB | 736273 GiB |\n","|       from large pool |   1186 MiB |   4988 MiB | 734842 GiB | 734841 GiB |\n","|       from small pool |    448 MiB |    476 MiB |   1432 GiB |   1432 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |    977 MiB |   1348 MiB |   1134 TiB |   1134 TiB |\n","|       from large pool |    973 MiB |   1343 MiB |   1124 TiB |   1124 TiB |\n","|       from small pool |      4 MiB |     23 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  129818 K  |  129800 K  |\n","|       from large pool |      98    |     248    |   76445 K  |   76445 K  |\n","|       from small pool |   18777    |   18924    |   53373 K  |   53354 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  129818 K  |  129800 K  |\n","|       from large pool |      98    |     248    |   76445 K  |   76445 K  |\n","|       from small pool |   18777    |   18924    |   53373 K  |   53354 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     239    |     312    |    6730 K  |    6730 K  |\n","|       from large pool |      15    |      81    |    5997 K  |    5997 K  |\n","|       from small pool |     224    |     238    |     733 K  |     733 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      82    |     155    |   62139 K  |   62138 K  |\n","|       from large pool |      15    |      52    |   41303 K  |   41303 K  |\n","|       from small pool |      67    |     118    |   20835 K  |   20835 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:83/89 batch:746/8961 epoch:1/10\n","full seq: Montenegrin soldiers began training for their upcoming deployment. [Getty Images]Ģġġġġġġġ\n","pref seq: Montenegrin soldiers began training for their upcoming deployment. [Getty Images]Ģġ\n","next tok:                                                                                   ġ\n","pred tok:                                                                                   Ģ\n","Completed batch.\n","epoch:1/10 batch:746/8961 batch_size:139 loss:2.6956746578216553 time_for_batch_instance:71.53577971458435 total_batch_time:82737.40334510803 running_batch_average:110.90804737950138\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 672163 KiB |   5003 MiB |   3252 TiB |   3252 TiB |\n","|       from large pool | 217557 KiB |   4566 MiB |   3242 TiB |   3242 TiB |\n","|       from small pool | 454606 KiB |    472 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 672163 KiB |   5003 MiB |   3252 TiB |   3252 TiB |\n","|       from large pool | 217557 KiB |   4566 MiB |   3242 TiB |   3242 TiB |\n","|       from small pool | 454606 KiB |    472 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |   4993 MiB |   3243 TiB |   3243 TiB |\n","|       from large pool | 213248 KiB |   4560 MiB |   3233 TiB |   3233 TiB |\n","|       from small pool | 450193 KiB |    467 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1560 MiB |   5432 MiB | 736550 GiB | 736548 GiB |\n","|       from large pool |   1112 MiB |   4968 MiB | 735116 GiB | 735115 GiB |\n","|       from small pool |    448 MiB |    476 MiB |   1433 GiB |   1433 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |    903 MiB |   1182 MiB |   1135 TiB |   1135 TiB |\n","|       from large pool |    899 MiB |   1177 MiB |   1124 TiB |   1124 TiB |\n","|       from small pool |      4 MiB |     20 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  129932 K  |  129913 K  |\n","|       from large pool |      98    |     248    |   76510 K  |   76510 K  |\n","|       from small pool |   18777    |   18924    |   53421 K  |   53403 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  129932 K  |  129913 K  |\n","|       from large pool |      98    |     248    |   76510 K  |   76510 K  |\n","|       from small pool |   18777    |   18924    |   53421 K  |   53403 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     238    |     311    |    6735 K  |    6735 K  |\n","|       from large pool |      14    |      79    |    6001 K  |    6001 K  |\n","|       from small pool |     224    |     238    |     734 K  |     733 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      92    |     175    |   62201 K  |   62201 K  |\n","|       from large pool |      18    |      72    |   41347 K  |   41347 K  |\n","|       from small pool |      74    |     120    |   20853 K  |   20853 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:167/257 batch:747/8961 epoch:1/10\n","full seq: Co-ordination Commission Chairman Denis Oswald (front) and International Olympic Committee President Jacques Rogge (back) have repeatedly voiced their confidence in the ability of the ATHOC and Greece to mount a successful Olympic Games. [AFP]Ģġġġġġġġġġġġġġ\n","pref seq: Co-ordination Commission Chairman Denis Oswald (front) and International Olympic Committee President Jacques Rogge (back) have repeatedly voiced their confidence in th\n","next tok:                                                                                                                                                                       e\n","pred tok:                                                                                                                                                                       Ģ\n","Completed batch.\n","epoch:1/10 batch:747/8961 batch_size:137 loss:2.7089250087738037 time_for_batch_instance:216.7817780971527 total_batch_time:82954.18512320518 running_batch_average:111.04977928139918\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 670871 KiB |  13479 MiB |   3263 TiB |   3263 TiB |\n","|       from large pool | 216265 KiB |  13043 MiB |   3253 TiB |   3253 TiB |\n","|       from small pool | 454606 KiB |    471 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 670871 KiB |  13479 MiB |   3263 TiB |   3263 TiB |\n","|       from large pool | 216265 KiB |  13043 MiB |   3253 TiB |   3253 TiB |\n","|       from small pool | 454606 KiB |    471 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  13459 MiB |   3254 TiB |   3254 TiB |\n","|       from large pool | 213248 KiB |  13027 MiB |   3244 TiB |   3244 TiB |\n","|       from small pool | 450193 KiB |    467 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1476 MiB |  14156 MiB | 739186 GiB | 739185 GiB |\n","|       from large pool |   1028 MiB |  13692 MiB | 737748 GiB | 737747 GiB |\n","|       from small pool |    448 MiB |    476 MiB |   1437 GiB |   1437 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |    820 MiB |   1795 MiB |   1138 TiB |   1138 TiB |\n","|       from large pool |    816 MiB |   1790 MiB |   1128 TiB |   1128 TiB |\n","|       from small pool |      4 MiB |     21 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  130267 K  |  130248 K  |\n","|       from large pool |      98    |     263    |   76713 K  |   76713 K  |\n","|       from small pool |   18777    |   18924    |   53554 K  |   53535 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  130267 K  |  130248 K  |\n","|       from large pool |      98    |     263    |   76713 K  |   76713 K  |\n","|       from small pool |   18777    |   18924    |   53554 K  |   53535 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     241    |     323    |    6754 K  |    6753 K  |\n","|       from large pool |      17    |      91    |    6017 K  |    6017 K  |\n","|       from small pool |     224    |     238    |     736 K  |     735 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      94    |     153    |   62349 K  |   62349 K  |\n","|       from large pool |      23    |      50    |   41442 K  |   41442 K  |\n","|       from small pool |      71    |     119    |   20906 K  |   20906 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:90/251 batch:748/8961 epoch:1/10\n","full seq: The decision, he told SETimes, was hard on everyone, especially the children. \"I didn't risk spending around 13,000 euros, travelling through nightmare circumstances with my children, for a two year stay,\" he said with frustration.Ģġġġġġġġġġġġġġġġġġġġ\n","pref seq: The decision, he told SETimes, was hard on everyone, especially the children. \"I didn't ri\n","next tok:                                                                                          s\n","pred tok:                                                                                          ;\n","Completed batch.\n","epoch:1/10 batch:748/8961 batch_size:137 loss:1.1272448301315308 time_for_batch_instance:210.1223611831665 total_batch_time:83164.30748438835 running_batch_average:111.18222925720367\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 670293 KiB |  12908 MiB |   3273 TiB |   3273 TiB |\n","|       from large pool | 215687 KiB |  12473 MiB |   3263 TiB |   3263 TiB |\n","|       from small pool | 454606 KiB |    471 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 670293 KiB |  12908 MiB |   3273 TiB |   3273 TiB |\n","|       from large pool | 215687 KiB |  12473 MiB |   3263 TiB |   3263 TiB |\n","|       from small pool | 454606 KiB |    471 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  12888 MiB |   3264 TiB |   3264 TiB |\n","|       from large pool | 213248 KiB |  12456 MiB |   3254 TiB |   3254 TiB |\n","|       from small pool | 450193 KiB |    466 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1676 MiB |  13544 MiB | 741640 GiB | 741638 GiB |\n","|       from large pool |   1226 MiB |  13080 MiB | 740199 GiB | 740197 GiB |\n","|       from small pool |    450 MiB |    476 MiB |   1441 GiB |   1440 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1021 MiB |   1779 MiB |   1142 TiB |   1142 TiB |\n","|       from large pool |   1015 MiB |   1774 MiB |   1131 TiB |   1131 TiB |\n","|       from small pool |      6 MiB |     22 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  130594 K  |  130576 K  |\n","|       from large pool |      98    |     263    |   76911 K  |   76911 K  |\n","|       from small pool |   18777    |   18924    |   53683 K  |   53664 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  130594 K  |  130576 K  |\n","|       from large pool |      98    |     263    |   76911 K  |   76911 K  |\n","|       from small pool |   18777    |   18924    |   53683 K  |   53664 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     239    |     321    |    6771 K  |    6771 K  |\n","|       from large pool |      14    |      88    |    6033 K  |    6033 K  |\n","|       from small pool |     225    |     238    |     737 K  |     737 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      87    |     173    |   62503 K  |   62503 K  |\n","|       from large pool |      18    |      71    |   41545 K  |   41545 K  |\n","|       from small pool |      69    |     120    |   20958 K  |   20958 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:145/151 batch:749/8961 epoch:1/10\n","full seq: It also activated a Citizenship Agency, initially established in 2009, in order to process documents at five territorial branches.Ģġġġġġġġġġġġġġġġġġġġġ\n","pref seq: It also activated a Citizenship Agency, initially established in 2009, in order to process documents at five territorial branches.Ģġġġġġġġġġġġġġġ\n","next tok:                                                                                                                                                 ġ\n","pred tok:                                                                                                                                                 [\n","Completed batch.\n","epoch:1/10 batch:749/8961 batch_size:136 loss:4.2950358390808105 time_for_batch_instance:124.47324252128601 total_batch_time:83288.78072690964 running_batch_average:111.19997426823717\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 674078 KiB |   7915 MiB |   3277 TiB |   3277 TiB |\n","|       from large pool | 219472 KiB |   7472 MiB |   3267 TiB |   3267 TiB |\n","|       from small pool | 454606 KiB |    474 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 674078 KiB |   7915 MiB |   3277 TiB |   3277 TiB |\n","|       from large pool | 219472 KiB |   7472 MiB |   3267 TiB |   3267 TiB |\n","|       from small pool | 454606 KiB |    474 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |   7887 MiB |   3268 TiB |   3268 TiB |\n","|       from large pool | 213248 KiB |   7449 MiB |   3258 TiB |   3258 TiB |\n","|       from small pool | 450193 KiB |    470 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1392 MiB |   8268 MiB | 742475 GiB | 742474 GiB |\n","|       from large pool |    942 MiB |   7802 MiB | 741032 GiB | 741031 GiB |\n","|       from small pool |    450 MiB |    478 MiB |   1443 GiB |   1443 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 751330 KiB |   1536 MiB |   1143 TiB |   1143 TiB |\n","|       from large pool | 745136 KiB |   1528 MiB |   1133 TiB |   1133 TiB |\n","|       from small pool |   6194 KiB |     23 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  130790 K  |  130771 K  |\n","|       from large pool |      98    |     248    |   77024 K  |   77024 K  |\n","|       from small pool |   18777    |   18924    |   53765 K  |   53746 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  130790 K  |  130771 K  |\n","|       from large pool |      98    |     248    |   77024 K  |   77024 K  |\n","|       from small pool |   18777    |   18924    |   53765 K  |   53746 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     237    |     317    |    6781 K  |    6781 K  |\n","|       from large pool |      12    |      83    |    6042 K  |    6042 K  |\n","|       from small pool |     225    |     239    |     739 K  |     738 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      90    |     149    |   62577 K  |   62577 K  |\n","|       from large pool |      14    |      46    |   41588 K  |   41588 K  |\n","|       from small pool |      76    |     120    |   20989 K  |   20989 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:9/128 batch:750/8961 epoch:1/10\n","full seq: The UN war crimes tribunal indicted Arkan in 1997 for involvement in the killings of hundreds of civilians.Ģġġġġġġġġġġġġġġġġġġġġ\n","pref seq: The UN wa\n","next tok:         r\n","pred tok:         ġ\n","Completed batch.\n","epoch:1/10 batch:750/8961 batch_size:136 loss:3.625182628631592 time_for_batch_instance:104.40344977378845 total_batch_time:83393.18417668343 running_batch_average:111.1909122355779\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 669981 KiB |   6773 MiB |   3280 TiB |   3280 TiB |\n","|       from large pool | 215375 KiB |   6333 MiB |   3270 TiB |   3270 TiB |\n","|       from small pool | 454606 KiB |    473 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 669981 KiB |   6773 MiB |   3280 TiB |   3280 TiB |\n","|       from large pool | 215375 KiB |   6333 MiB |   3270 TiB |   3270 TiB |\n","|       from small pool | 454606 KiB |    473 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |   6765 MiB |   3271 TiB |   3271 TiB |\n","|       from large pool | 213248 KiB |   6329 MiB |   3261 TiB |   3261 TiB |\n","|       from small pool | 450193 KiB |    468 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1536 MiB |   7156 MiB | 743051 GiB | 743049 GiB |\n","|       from large pool |   1086 MiB |   6690 MiB | 741605 GiB | 741604 GiB |\n","|       from small pool |    450 MiB |    476 MiB |   1445 GiB |   1444 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |    881 MiB |   1368 MiB |   1144 TiB |   1144 TiB |\n","|       from large pool |    875 MiB |   1362 MiB |   1134 TiB |   1134 TiB |\n","|       from small pool |      6 MiB |     23 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  130955 K  |  130936 K  |\n","|       from large pool |      98    |     248    |   77120 K  |   77120 K  |\n","|       from small pool |   18777    |   18924    |   53835 K  |   53816 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  130955 K  |  130936 K  |\n","|       from large pool |      98    |     248    |   77120 K  |   77120 K  |\n","|       from small pool |   18777    |   18924    |   53835 K  |   53816 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     238    |     319    |    6790 K  |    6790 K  |\n","|       from large pool |      13    |      86    |    6050 K  |    6050 K  |\n","|       from small pool |     225    |     238    |     740 K  |     739 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      89    |     182    |   62667 K  |   62667 K  |\n","|       from large pool |      18    |      80    |   41652 K  |   41652 K  |\n","|       from small pool |      71    |     119    |   21015 K  |   21015 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:38/101 batch:751/8961 epoch:1/10\n","full seq: Here dense shrubbery and trees made the exact borderline difficult to ascertain.Ģġġġġġġġġġġġġġġġġġġġġ\n","pref seq: Here dense shrubbery and trees made th\n","next tok:                                      e\n","pred tok:                                      ;\n","Completed batch.\n","epoch:1/10 batch:751/8961 batch_size:136 loss:2.846374988555908 time_for_batch_instance:81.83960223197937 total_batch_time:83475.0237789154 running_batch_average:111.15182926619894\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 670710 KiB |   5524 MiB |   3282 TiB |   3282 TiB |\n","|       from large pool | 216104 KiB |   5085 MiB |   3272 TiB |   3272 TiB |\n","|       from small pool | 454606 KiB |    472 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 670710 KiB |   5524 MiB |   3282 TiB |   3282 TiB |\n","|       from large pool | 216104 KiB |   5085 MiB |   3272 TiB |   3272 TiB |\n","|       from small pool | 454606 KiB |    472 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |   5484 MiB |   3272 TiB |   3272 TiB |\n","|       from large pool | 213248 KiB |   5049 MiB |   3263 TiB |   3263 TiB |\n","|       from small pool | 450193 KiB |    468 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1564 MiB |   5838 MiB | 743396 GiB | 743394 GiB |\n","|       from large pool |   1112 MiB |   5372 MiB | 741949 GiB | 741948 GiB |\n","|       from small pool |    452 MiB |    476 MiB |   1446 GiB |   1446 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |    909 MiB |   1118 MiB |   1145 TiB |   1145 TiB |\n","|       from large pool |    900 MiB |   1111 MiB |   1134 TiB |   1134 TiB |\n","|       from small pool |      8 MiB |     22 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  131085 K  |  131066 K  |\n","|       from large pool |      98    |     248    |   77195 K  |   77195 K  |\n","|       from small pool |   18777    |   18924    |   53889 K  |   53871 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  131085 K  |  131066 K  |\n","|       from large pool |      98    |     248    |   77195 K  |   77195 K  |\n","|       from small pool |   18777    |   18924    |   53889 K  |   53871 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     239    |     314    |    6796 K  |    6796 K  |\n","|       from large pool |      13    |      81    |    6055 K  |    6055 K  |\n","|       from small pool |     226    |     238    |     740 K  |     740 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      93    |     152    |   62729 K  |   62729 K  |\n","|       from large pool |      19    |      50    |   41693 K  |   41693 K  |\n","|       from small pool |      74    |     118    |   21035 K  |   21035 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:23/253 batch:752/8961 epoch:1/10\n","full seq: Following a one-hour closed-door discussion Thursday, the foreign ministers of the Contact Group, comprising Britain, France, Germany, Italy, Russia and the United States, called for a quick settlement to end the current political limbo.Ģġġġġġġġġġġġġġġġ\n","pref seq: Following a one-hour cl\n","next tok:                       o\n","pred tok:                       ;\n","Completed batch.\n","epoch:1/10 batch:752/8961 batch_size:135 loss:0.8704858422279358 time_for_batch_instance:213.0420229434967 total_batch_time:83688.0658018589 running_batch_average:111.28732154502514\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 671377 KiB |  13055 MiB |   3292 TiB |   3292 TiB |\n","|       from large pool | 216771 KiB |  12620 MiB |   3282 TiB |   3282 TiB |\n","|       from small pool | 454606 KiB |    470 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 671377 KiB |  13055 MiB |   3292 TiB |   3292 TiB |\n","|       from large pool | 216771 KiB |  12620 MiB |   3282 TiB |   3282 TiB |\n","|       from small pool | 454606 KiB |    470 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  13010 MiB |   3283 TiB |   3283 TiB |\n","|       from large pool | 213248 KiB |  12578 MiB |   3273 TiB |   3273 TiB |\n","|       from small pool | 450193 KiB |    466 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1482 MiB |  13692 MiB | 745893 GiB | 745892 GiB |\n","|       from large pool |   1034 MiB |  13230 MiB | 744443 GiB | 744442 GiB |\n","|       from small pool |    448 MiB |    474 MiB |   1450 GiB |   1450 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |    826 MiB |   1826 MiB |   1149 TiB |   1149 TiB |\n","|       from large pool |    822 MiB |   1821 MiB |   1138 TiB |   1138 TiB |\n","|       from small pool |      4 MiB |     21 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  131414 K  |  131396 K  |\n","|       from large pool |      98    |     263    |   77394 K  |   77394 K  |\n","|       from small pool |   18777    |   18924    |   54020 K  |   54001 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  131414 K  |  131396 K  |\n","|       from large pool |      98    |     263    |   77394 K  |   77394 K  |\n","|       from small pool |   18777    |   18924    |   54020 K  |   54001 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     238    |     320    |    6814 K  |    6813 K  |\n","|       from large pool |      14    |      88    |    6071 K  |    6071 K  |\n","|       from small pool |     224    |     237    |     742 K  |     742 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      83    |     158    |   62909 K  |   62909 K  |\n","|       from large pool |      18    |      56    |   41821 K  |   41821 K  |\n","|       from small pool |      65    |     118    |   21087 K  |   21087 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Completed batch.\n","epoch:1/10 batch:753/8961 batch_size:135 loss:4.490992546081543 time_for_batch_instance:113.41145896911621 total_batch_time:83801.47726082802 running_batch_average:111.29014244465873\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 672347 KiB |   7339 MiB |   3296 TiB |   3296 TiB |\n","|       from large pool | 217741 KiB |   6897 MiB |   3286 TiB |   3286 TiB |\n","|       from small pool | 454606 KiB |    474 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 672347 KiB |   7339 MiB |   3296 TiB |   3296 TiB |\n","|       from large pool | 217741 KiB |   6897 MiB |   3286 TiB |   3286 TiB |\n","|       from small pool | 454606 KiB |    474 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |   7321 MiB |   3286 TiB |   3286 TiB |\n","|       from large pool | 213248 KiB |   6883 MiB |   3276 TiB |   3276 TiB |\n","|       from small pool | 450193 KiB |    470 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1690 MiB |   7740 MiB | 746562 GiB | 746561 GiB |\n","|       from large pool |   1238 MiB |   7274 MiB | 745110 GiB | 745109 GiB |\n","|       from small pool |    452 MiB |    478 MiB |   1452 GiB |   1452 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1033 MiB |   1495 MiB |   1150 TiB |   1150 TiB |\n","|       from large pool |   1025 MiB |   1488 MiB |   1140 TiB |   1140 TiB |\n","|       from small pool |      8 MiB |     24 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  131594 K  |  131575 K  |\n","|       from large pool |      98    |     248    |   77498 K  |   77498 K  |\n","|       from small pool |   18777    |   18924    |   54095 K  |   54077 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  131594 K  |  131575 K  |\n","|       from large pool |      98    |     248    |   77498 K  |   77498 K  |\n","|       from small pool |   18777    |   18924    |   54095 K  |   54077 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     240    |     319    |    6823 K  |    6822 K  |\n","|       from large pool |      14    |      86    |    6079 K  |    6079 K  |\n","|       from small pool |     226    |     239    |     743 K  |     743 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      88    |     158    |   62997 K  |   62997 K  |\n","|       from large pool |      13    |      56    |   41880 K  |   41880 K  |\n","|       from small pool |      75    |     123    |   21116 K  |   21116 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:67/119 batch:754/8961 epoch:1/10\n","full seq: There are too many clients for a limited number of personnel and showrooms, as well as a limited number of cars.Ģġġġġġġ\n","pref seq: There are too many clients for a limited number of personnel and sh\n","next tok:                                                                   o\n","pred tok:                                                                   w\n","Completed batch.\n","epoch:1/10 batch:754/8961 batch_size:135 loss:4.297006130218506 time_for_batch_instance:96.63349080085754 total_batch_time:83898.11075162888 running_batch_average:111.27070391462716\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 670841 KiB |   6376 MiB |   3298 TiB |   3298 TiB |\n","|       from large pool | 216235 KiB |   5936 MiB |   3288 TiB |   3288 TiB |\n","|       from small pool | 454606 KiB |    472 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 670841 KiB |   6376 MiB |   3298 TiB |   3298 TiB |\n","|       from large pool | 216235 KiB |   5936 MiB |   3288 TiB |   3288 TiB |\n","|       from small pool | 454606 KiB |    472 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |   6352 MiB |   3289 TiB |   3289 TiB |\n","|       from large pool | 213248 KiB |   5917 MiB |   3279 TiB |   3279 TiB |\n","|       from small pool | 450193 KiB |    468 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1856 MiB |   6698 MiB | 747043 GiB | 747042 GiB |\n","|       from large pool |   1404 MiB |   6232 MiB | 745589 GiB | 745588 GiB |\n","|       from small pool |    452 MiB |    476 MiB |   1454 GiB |   1453 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1200 MiB |   1518 MiB |   1151 TiB |   1151 TiB |\n","|       from large pool |   1192 MiB |   1512 MiB |   1140 TiB |   1140 TiB |\n","|       from small pool |      8 MiB |     23 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  131747 K  |  131729 K  |\n","|       from large pool |      98    |     248    |   77587 K  |   77587 K  |\n","|       from small pool |   18777    |   18924    |   54160 K  |   54141 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  131747 K  |  131729 K  |\n","|       from large pool |      98    |     248    |   77587 K  |   77587 K  |\n","|       from small pool |   18777    |   18924    |   54160 K  |   54141 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     240    |     316    |    6830 K  |    6830 K  |\n","|       from large pool |      14    |      83    |    6086 K  |    6086 K  |\n","|       from small pool |     226    |     238    |     744 K  |     744 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |     101    |     162    |   63060 K  |   63060 K  |\n","|       from large pool |      21    |      61    |   41920 K  |   41920 K  |\n","|       from small pool |      80    |     121    |   21140 K  |   21140 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:37/110 batch:755/8961 epoch:1/10\n","full seq: During the four years of implementation, employment programmes supported the creation of 1,742 companies.Ģġġġġ\n","pref seq: During the four years of implementati\n","next tok:                                     o\n","pred tok:                                     .\n","Completed batch.\n","epoch:1/10 batch:755/8961 batch_size:135 loss:4.285708904266357 time_for_batch_instance:88.99414992332458 total_batch_time:83987.1049015522 running_batch_average:111.24119854510225\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 669745 KiB |   5943 MiB |   3300 TiB |   3300 TiB |\n","|       from large pool | 215139 KiB |   5503 MiB |   3290 TiB |   3290 TiB |\n","|       from small pool | 454606 KiB |    472 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 669745 KiB |   5943 MiB |   3300 TiB |   3300 TiB |\n","|       from large pool | 215139 KiB |   5503 MiB |   3290 TiB |   3290 TiB |\n","|       from small pool | 454606 KiB |    472 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |   5917 MiB |   3291 TiB |   3291 TiB |\n","|       from large pool | 213248 KiB |   5482 MiB |   3281 TiB |   3281 TiB |\n","|       from small pool | 450193 KiB |    468 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1750 MiB |   6254 MiB | 747442 GiB | 747440 GiB |\n","|       from large pool |   1298 MiB |   5788 MiB | 745986 GiB | 745985 GiB |\n","|       from small pool |    452 MiB |    476 MiB |   1455 GiB |   1455 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1095 MiB |   1424 MiB |   1152 TiB |   1152 TiB |\n","|       from large pool |   1087 MiB |   1417 MiB |   1141 TiB |   1141 TiB |\n","|       from small pool |      8 MiB |     23 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  131889 K  |  131870 K  |\n","|       from large pool |      98    |     248    |   77669 K  |   77669 K  |\n","|       from small pool |   18777    |   18924    |   54220 K  |   54201 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  131889 K  |  131870 K  |\n","|       from large pool |      98    |     248    |   77669 K  |   77669 K  |\n","|       from small pool |   18777    |   18924    |   54220 K  |   54201 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     239    |     314    |    6837 K  |    6837 K  |\n","|       from large pool |      13    |      81    |    6091 K  |    6091 K  |\n","|       from small pool |     226    |     238    |     745 K  |     745 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      94    |     151    |   63127 K  |   63126 K  |\n","|       from large pool |      19    |      49    |   41964 K  |   41964 K  |\n","|       from small pool |      75    |     119    |   21162 K  |   21162 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:96/100 batch:756/8961 epoch:1/10\n","full seq: A country in great need of progress and foreign investments cannot afford that.Ģġġġġġġġġġġġġġġġġġġġġ\n","pref seq: A country in great need of progress and foreign investments cannot afford that.Ģġġġġġġġġġġġġġġġġ\n","next tok:                                                                                                ġ\n","pred tok:                                                                                                [\n","Completed batch.\n","epoch:1/10 batch:756/8961 batch_size:135 loss:3.633296489715576 time_for_batch_instance:80.50824785232544 total_batch_time:84067.61314940453 running_batch_average:111.20054649392134\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 674551 KiB |   5425 MiB |   3302 TiB |   3302 TiB |\n","|       from large pool | 219945 KiB |   4986 MiB |   3292 TiB |   3292 TiB |\n","|       from small pool | 454606 KiB |    472 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 674551 KiB |   5425 MiB |   3302 TiB |   3302 TiB |\n","|       from large pool | 219945 KiB |   4986 MiB |   3292 TiB |   3292 TiB |\n","|       from small pool | 454606 KiB |    472 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |   5400 MiB |   3292 TiB |   3292 TiB |\n","|       from large pool | 213248 KiB |   4965 MiB |   3282 TiB |   3282 TiB |\n","|       from small pool | 450193 KiB |    468 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2246 MiB |   5860 MiB | 747757 GiB | 747755 GiB |\n","|       from large pool |   1796 MiB |   5394 MiB | 746300 GiB | 746298 GiB |\n","|       from small pool |    450 MiB |    476 MiB |   1457 GiB |   1456 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1587 MiB |   1838 MiB |   1153 TiB |   1153 TiB |\n","|       from large pool |   1581 MiB |   1831 MiB |   1142 TiB |   1142 TiB |\n","|       from small pool |      6 MiB |     23 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  132017 K  |  131998 K  |\n","|       from large pool |      98    |     248    |   77743 K  |   77743 K  |\n","|       from small pool |   18777    |   18924    |   54274 K  |   54255 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  132017 K  |  131998 K  |\n","|       from large pool |      98    |     248    |   77743 K  |   77743 K  |\n","|       from small pool |   18777    |   18924    |   54274 K  |   54255 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     243    |     314    |    6843 K  |    6842 K  |\n","|       from large pool |      18    |      81    |    6097 K  |    6097 K  |\n","|       from small pool |     225    |     238    |     746 K  |     745 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      92    |     150    |   63181 K  |   63181 K  |\n","|       from large pool |      18    |      48    |   41999 K  |   41999 K  |\n","|       from small pool |      74    |     119    |   21182 K  |   21182 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:233/257 batch:757/8961 epoch:1/10\n","full seq: \"Threats against our national security are not isolated, [nor] specific problems to our respective countries,\" she said. \"The challenges faced by region are threats of transnational and global nature, which do not recognise state borders.\"Ģġġġġġġġġġġġġġġġġġ\n","pref seq: \"Threats against our national security are not isolated, [nor] specific problems to our respective countries,\" she said. \"The challenges faced by region are threats of transnational and global nature, which do not recognise state bor\n","next tok:                                                                                                                                                                                                                                         d\n","pred tok:                                                                                                                                                                                                                                         .\n","Completed batch.\n","epoch:1/10 batch:757/8961 batch_size:134 loss:1.4517474174499512 time_for_batch_instance:216.2483880519867 total_batch_time:84283.86153745651 running_batch_average:111.33931510892538\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 671645 KiB |  13027 MiB |   3312 TiB |   3312 TiB |\n","|       from large pool | 217039 KiB |  12591 MiB |   3302 TiB |   3302 TiB |\n","|       from small pool | 454606 KiB |    470 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 671645 KiB |  13027 MiB |   3312 TiB |   3312 TiB |\n","|       from large pool | 217039 KiB |  12591 MiB |   3302 TiB |   3302 TiB |\n","|       from small pool | 454606 KiB |    470 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  13008 MiB |   3303 TiB |   3303 TiB |\n","|       from large pool | 213248 KiB |  12577 MiB |   3293 TiB |   3293 TiB |\n","|       from small pool | 450193 KiB |    466 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1754 MiB |  13708 MiB | 750228 GiB | 750226 GiB |\n","|       from large pool |   1304 MiB |  13244 MiB | 748767 GiB | 748765 GiB |\n","|       from small pool |    450 MiB |    474 MiB |   1460 GiB |   1460 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1098 MiB |   2036 MiB |   1157 TiB |   1157 TiB |\n","|       from large pool |   1092 MiB |   2032 MiB |   1146 TiB |   1146 TiB |\n","|       from small pool |      6 MiB |     23 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  132352 K  |  132333 K  |\n","|       from large pool |      98    |     263    |   77945 K  |   77945 K  |\n","|       from small pool |   18777    |   18924    |   54406 K  |   54388 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  132352 K  |  132333 K  |\n","|       from large pool |      98    |     263    |   77945 K  |   77945 K  |\n","|       from small pool |   18777    |   18924    |   54406 K  |   54388 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     239    |     321    |    6860 K  |    6860 K  |\n","|       from large pool |      14    |      89    |    6112 K  |    6112 K  |\n","|       from small pool |     225    |     237    |     748 K  |     747 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      87    |     181    |   63373 K  |   63373 K  |\n","|       from large pool |      16    |      79    |   42138 K  |   42138 K  |\n","|       from small pool |      71    |     119    |   21235 K  |   21235 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:113/194 batch:758/8961 epoch:1/10\n","full seq: Ramush Haradinaj, a former prime minister who heads the Alliance for the Future of Kosovo, said officials were trying to make political hay out of a serious security breach.Ģġġġġġġġġġġġġġġġġġġġġ\n","pref seq: Ramush Haradinaj, a former prime minister who heads the Alliance for the Future of Kosovo, said officials were tr\n","next tok:                                                                                                                 y\n","pred tok:                                                                                                                 .\n","Completed batch.\n","epoch:1/10 batch:758/8961 batch_size:134 loss:2.296900510787964 time_for_batch_instance:160.09249210357666 total_batch_time:84443.95402956009 running_batch_average:111.40363328438006\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 671357 KiB |   9929 MiB |   3319 TiB |   3319 TiB |\n","|       from large pool | 216751 KiB |   9482 MiB |   3309 TiB |   3309 TiB |\n","|       from small pool | 454606 KiB |    477 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 671357 KiB |   9929 MiB |   3319 TiB |   3319 TiB |\n","|       from large pool | 216751 KiB |   9482 MiB |   3309 TiB |   3309 TiB |\n","|       from small pool | 454606 KiB |    477 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |   9880 MiB |   3309 TiB |   3309 TiB |\n","|       from large pool | 213248 KiB |   9437 MiB |   3299 TiB |   3299 TiB |\n","|       from small pool | 450193 KiB |    473 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1438 MiB |  10416 MiB | 751632 GiB | 751631 GiB |\n","|       from large pool |    988 MiB |   9952 MiB | 750169 GiB | 750168 GiB |\n","|       from small pool |    450 MiB |    482 MiB |   1463 GiB |   1463 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |    782 MiB |   1543 MiB |   1159 TiB |   1159 TiB |\n","|       from large pool |    776 MiB |   1535 MiB |   1148 TiB |   1148 TiB |\n","|       from small pool |      6 MiB |     25 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  132604 K  |  132586 K  |\n","|       from large pool |      98    |     248    |   78092 K  |   78092 K  |\n","|       from small pool |   18777    |   18924    |   54512 K  |   54493 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  132604 K  |  132586 K  |\n","|       from large pool |      98    |     248    |   78092 K  |   78092 K  |\n","|       from small pool |   18777    |   18924    |   54512 K  |   54493 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     239    |     319    |    6874 K  |    6873 K  |\n","|       from large pool |      14    |      87    |    6124 K  |    6124 K  |\n","|       from small pool |     225    |     241    |     749 K  |     749 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      91    |     166    |   63487 K  |   63487 K  |\n","|       from large pool |      16    |      61    |   42209 K  |   42209 K  |\n","|       from small pool |      75    |     122    |   21278 K  |   21278 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Completed batch.\n","epoch:1/10 batch:759/8961 batch_size:134 loss:2.2946317195892334 time_for_batch_instance:158.4029517173767 total_batch_time:84602.35698127747 running_batch_average:111.46555597006254\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 668930 KiB |   9821 MiB |   3325 TiB |   3325 TiB |\n","|       from large pool | 214324 KiB |   9376 MiB |   3315 TiB |   3315 TiB |\n","|       from small pool | 454606 KiB |    476 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 668930 KiB |   9821 MiB |   3325 TiB |   3325 TiB |\n","|       from large pool | 214324 KiB |   9376 MiB |   3315 TiB |   3315 TiB |\n","|       from small pool | 454606 KiB |    476 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |   9783 MiB |   3315 TiB |   3315 TiB |\n","|       from large pool | 213248 KiB |   9342 MiB |   3305 TiB |   3305 TiB |\n","|       from small pool | 450193 KiB |    471 MiB |      9 TiB |      9 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1704 MiB |  10326 MiB | 753013 GiB | 753012 GiB |\n","|       from large pool |   1256 MiB |   9864 MiB | 751547 GiB | 751546 GiB |\n","|       from small pool |    448 MiB |    480 MiB |   1466 GiB |   1465 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1050 MiB |   1439 MiB |   1161 TiB |   1161 TiB |\n","|       from large pool |   1046 MiB |   1434 MiB |   1150 TiB |   1150 TiB |\n","|       from small pool |      4 MiB |     20 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  132854 K  |  132835 K  |\n","|       from large pool |      98    |     248    |   78237 K  |   78237 K  |\n","|       from small pool |   18777    |   18924    |   54616 K  |   54597 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  132854 K  |  132835 K  |\n","|       from large pool |      98    |     248    |   78237 K  |   78237 K  |\n","|       from small pool |   18777    |   18924    |   54616 K  |   54597 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     239    |     320    |    6887 K  |    6887 K  |\n","|       from large pool |      15    |      89    |    6136 K  |    6136 K  |\n","|       from small pool |     224    |     240    |     750 K  |     750 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      97    |     155    |   63593 K  |   63593 K  |\n","|       from large pool |      20    |      52    |   42273 K  |   42273 K  |\n","|       from small pool |      77    |     121    |   21319 K  |   21319 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:158/257 batch:760/8961 epoch:1/10\n","full seq: Laslo Varga, the president of the Serbian Parliament's European Integration Committee said, the decision is a message to the international community and foreign investors that Serbia is \"on the way to becoming an orderly European country\".Ģġġġġġġġġġġġġġġġġġ\n","pref seq: Laslo Varga, the president of the Serbian Parliament's European Integration Committee said, the decision is a message to the international community and forei\n","next tok:                                                                                                                                                              g\n","pred tok:                                                                                                                                                              Ģ\n","Completed batch.\n","epoch:1/10 batch:760/8961 batch_size:133 loss:1.410099983215332 time_for_batch_instance:216.16755557060242 total_batch_time:84818.52453684807 running_batch_average:111.60332175901061\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 669137 KiB |  12948 MiB |   3335 TiB |   3335 TiB |\n","|       from large pool | 214531 KiB |  12513 MiB |   3325 TiB |   3325 TiB |\n","|       from small pool | 454606 KiB |    470 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 669137 KiB |  12948 MiB |   3335 TiB |   3335 TiB |\n","|       from large pool | 214531 KiB |  12513 MiB |   3325 TiB |   3325 TiB |\n","|       from small pool | 454606 KiB |    470 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  12916 MiB |   3326 TiB |   3326 TiB |\n","|       from large pool | 213248 KiB |  12484 MiB |   3316 TiB |   3316 TiB |\n","|       from small pool | 450193 KiB |    465 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1700 MiB |  13590 MiB | 755537 GiB | 755535 GiB |\n","|       from large pool |   1252 MiB |  13126 MiB | 754066 GiB | 754065 GiB |\n","|       from small pool |    448 MiB |    474 MiB |   1470 GiB |   1469 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1046 MiB |   1795 MiB |   1164 TiB |   1164 TiB |\n","|       from large pool |   1042 MiB |   1790 MiB |   1154 TiB |   1154 TiB |\n","|       from small pool |      4 MiB |     21 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  133189 K  |  133170 K  |\n","|       from large pool |      98    |     263    |   78440 K  |   78440 K  |\n","|       from small pool |   18777    |   18924    |   54749 K  |   54730 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  133189 K  |  133170 K  |\n","|       from large pool |      98    |     263    |   78440 K  |   78440 K  |\n","|       from small pool |   18777    |   18924    |   54749 K  |   54730 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     239    |     323    |    6905 K  |    6905 K  |\n","|       from large pool |      15    |      91    |    6152 K  |    6152 K  |\n","|       from small pool |     224    |     237    |     752 K  |     752 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      90    |     162    |   63739 K  |   63739 K  |\n","|       from large pool |      21    |      60    |   42366 K  |   42366 K  |\n","|       from small pool |      69    |     119    |   21372 K  |   21372 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:4/89 batch:761/8961 epoch:1/10\n","full seq: The delegation will attend the session that debates EU enlargement.Ģġġġġġġġġġġġġġġġġġġġġġ\n","pref seq: The \n","next tok:    d\n","pred tok:    ġ\n","Completed batch.\n","epoch:1/10 batch:761/8961 batch_size:133 loss:2.3938775062561035 time_for_batch_instance:71.49048662185669 total_batch_time:84890.01502346992 running_batch_average:111.55061106894865\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 673636 KiB |   4824 MiB |   3337 TiB |   3337 TiB |\n","|       from large pool | 219030 KiB |   4387 MiB |   3327 TiB |   3327 TiB |\n","|       from small pool | 454606 KiB |    470 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 673636 KiB |   4824 MiB |   3337 TiB |   3337 TiB |\n","|       from large pool | 219030 KiB |   4387 MiB |   3327 TiB |   3327 TiB |\n","|       from small pool | 454606 KiB |    470 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |   4803 MiB |   3327 TiB |   3327 TiB |\n","|       from large pool | 213248 KiB |   4370 MiB |   3317 TiB |   3317 TiB |\n","|       from small pool | 450193 KiB |    466 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1554 MiB |   5262 MiB | 755795 GiB | 755794 GiB |\n","|       from large pool |   1106 MiB |   4800 MiB | 754324 GiB | 754323 GiB |\n","|       from small pool |    448 MiB |    474 MiB |   1471 GiB |   1470 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |    896 MiB |   1417 MiB |   1165 TiB |   1165 TiB |\n","|       from large pool |    892 MiB |   1415 MiB |   1154 TiB |   1154 TiB |\n","|       from small pool |      4 MiB |     23 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  133303 K  |  133284 K  |\n","|       from large pool |      98    |     248    |   78505 K  |   78505 K  |\n","|       from small pool |   18777    |   18924    |   54797 K  |   54778 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  133303 K  |  133284 K  |\n","|       from large pool |      98    |     248    |   78505 K  |   78505 K  |\n","|       from small pool |   18777    |   18924    |   54797 K  |   54778 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     239    |     314    |    6910 K  |    6910 K  |\n","|       from large pool |      15    |      83    |    6157 K  |    6157 K  |\n","|       from small pool |     224    |     237    |     753 K  |     753 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      93    |     168    |   63792 K  |   63792 K  |\n","|       from large pool |      21    |      65    |   42402 K  |   42402 K  |\n","|       from small pool |      72    |     119    |   21390 K  |   21390 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:185/256 batch:762/8961 epoch:1/10\n","full seq: (Wall Street Journal, ZDNET - 14/06/11; Reuters, FT, The Telegraph, BBC, Guardian, Los Angeles Times, Financial Post, Security Week, PC Magazine, CNET, Hurriyet - 13/06/11; Time - 10/06/11; Zaman -- 09/06/11 - 13/06/11; FBI - 12/04/11)Ģġġġġġġġġġġġġġġġġġġġġ\n","pref seq: (Wall Street Journal, ZDNET - 14/06/11; Reuters, FT, The Telegraph, BBC, Guardian, Los Angeles Times, Financial Post, Security Week, PC Magazine, CNET, Hurriyet - 13/06/11; Time - 10/06\n","next tok:                                                                                                                                                                                         /\n","pred tok:                                                                                                                                                                                         Ģ\n","Completed batch.\n","epoch:1/10 batch:762/8961 batch_size:131 loss:1.30477774143219 time_for_batch_instance:214.9239158630371 total_batch_time:85104.93893933296 running_batch_average:111.68627157392777\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 668727 KiB |  12536 MiB |   3347 TiB |   3347 TiB |\n","|       from large pool | 214121 KiB |  12100 MiB |   3337 TiB |   3337 TiB |\n","|       from small pool | 454606 KiB |    469 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 668727 KiB |  12536 MiB |   3347 TiB |   3347 TiB |\n","|       from large pool | 214121 KiB |  12100 MiB |   3337 TiB |   3337 TiB |\n","|       from small pool | 454606 KiB |    469 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  12517 MiB |   3337 TiB |   3337 TiB |\n","|       from large pool | 213248 KiB |  12086 MiB |   3327 TiB |   3327 TiB |\n","|       from small pool | 450193 KiB |    465 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1454 MiB |  13128 MiB | 758209 GiB | 758208 GiB |\n","|       from large pool |   1004 MiB |  12664 MiB | 756734 GiB | 756733 GiB |\n","|       from small pool |    450 MiB |    474 MiB |   1474 GiB |   1474 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |    800 MiB |   1791 MiB |   1169 TiB |   1169 TiB |\n","|       from large pool |    794 MiB |   1786 MiB |   1158 TiB |   1158 TiB |\n","|       from small pool |      6 MiB |     25 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  133636 K  |  133617 K  |\n","|       from large pool |      98    |     263    |   78707 K  |   78707 K  |\n","|       from small pool |   18777    |   18924    |   54929 K  |   54910 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  133636 K  |  133617 K  |\n","|       from large pool |      98    |     263    |   78707 K  |   78707 K  |\n","|       from small pool |   18777    |   18924    |   54929 K  |   54910 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     240    |     323    |    6928 K  |    6928 K  |\n","|       from large pool |      15    |      91    |    6173 K  |    6173 K  |\n","|       from small pool |     225    |     237    |     755 K  |     754 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      90    |     150    |   63954 K  |   63954 K  |\n","|       from large pool |      21    |      47    |   42511 K  |   42511 K  |\n","|       from small pool |      69    |     118    |   21443 K  |   21443 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:116/255 batch:763/8961 epoch:1/10\n","full seq: The agreement was reached during an emergency meeting in Brussels on July 21st, roughly 14 months after Greek Prime Minister George Papandreou signed a deal on a three-year rescue package worth 110 billion euros with the EU and the IMF.Ģġġġġġġġġġġġġġġġġġġ\n","pref seq: The agreement was reached during an emergency meeting in Brussels on July 21st, roughly 14 months after Greek Prime \n","next tok:                                                                                                                    M\n","pred tok:                                                                                                                    X\n","Completed batch.\n","epoch:1/10 batch:763/8961 batch_size:131 loss:1.6723352670669556 time_for_batch_instance:212.29180812835693 total_batch_time:85317.23074746132 running_batch_average:111.81812679876975\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 668079 KiB |  12637 MiB |   3357 TiB |   3357 TiB |\n","|       from large pool | 213473 KiB |  12202 MiB |   3347 TiB |   3347 TiB |\n","|       from small pool | 454606 KiB |    469 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 668079 KiB |  12637 MiB |   3357 TiB |   3357 TiB |\n","|       from large pool | 213473 KiB |  12202 MiB |   3347 TiB |   3347 TiB |\n","|       from small pool | 454606 KiB |    469 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  12603 MiB |   3348 TiB |   3348 TiB |\n","|       from large pool | 213248 KiB |  12172 MiB |   3338 TiB |   3338 TiB |\n","|       from small pool | 450193 KiB |    465 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1682 MiB |  13262 MiB | 760638 GiB | 760636 GiB |\n","|       from large pool |   1232 MiB |  12798 MiB | 759159 GiB | 759158 GiB |\n","|       from small pool |    450 MiB |    474 MiB |   1478 GiB |   1478 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1029 MiB |   1758 MiB |   1172 TiB |   1172 TiB |\n","|       from large pool |   1023 MiB |   1753 MiB |   1161 TiB |   1161 TiB |\n","|       from small pool |      6 MiB |     21 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  133969 K  |  133950 K  |\n","|       from large pool |      98    |     263    |   78908 K  |   78908 K  |\n","|       from small pool |   18777    |   18924    |   55060 K  |   55042 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  133969 K  |  133950 K  |\n","|       from large pool |      98    |     263    |   78908 K  |   78908 K  |\n","|       from small pool |   18777    |   18924    |   55060 K  |   55042 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     239    |     322    |    6946 K  |    6946 K  |\n","|       from large pool |      14    |      90    |    6189 K  |    6189 K  |\n","|       from small pool |     225    |     237    |     757 K  |     756 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      90    |     151    |   64128 K  |   64128 K  |\n","|       from large pool |      22    |      50    |   42633 K  |   42633 K  |\n","|       from small pool |      68    |     117    |   21495 K  |   21495 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:138/254 batch:764/8961 epoch:1/10\n","full seq: In an exclusive interview with SETimes, Kosovo Foreign Minister Enver Hoxhaj calls for strict implementation of the Ahtisaari Plan, which he says offers the Serb minority \"the most advanced rights that a community can have in Europe\".Ģġġġġġġġġġġġġġġġġġġġ\n","pref seq: In an exclusive interview with SETimes, Kosovo Foreign Minister Enver Hoxhaj calls for strict implementation of the Ahtisaari Plan, which \n","next tok:                                                                                                                                          h\n","pred tok:                                                                                                                                          z\n","Completed batch.\n","epoch:1/10 batch:764/8961 batch_size:131 loss:3.812067747116089 time_for_batch_instance:212.09081625938416 total_batch_time:85529.3215637207 running_batch_average:111.94937377450354\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 670018 KiB |  12570 MiB |   3367 TiB |   3367 TiB |\n","|       from large pool | 215412 KiB |  12135 MiB |   3357 TiB |   3357 TiB |\n","|       from small pool | 454606 KiB |    469 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 670018 KiB |  12570 MiB |   3367 TiB |   3367 TiB |\n","|       from large pool | 215412 KiB |  12135 MiB |   3357 TiB |   3357 TiB |\n","|       from small pool | 454606 KiB |    469 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  12555 MiB |   3358 TiB |   3358 TiB |\n","|       from large pool | 213248 KiB |  12124 MiB |   3348 TiB |   3348 TiB |\n","|       from small pool | 450193 KiB |    465 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1660 MiB |  13176 MiB | 763048 GiB | 763047 GiB |\n","|       from large pool |   1212 MiB |  12712 MiB | 761566 GiB | 761565 GiB |\n","|       from small pool |    448 MiB |    474 MiB |   1482 GiB |   1481 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1005 MiB |   1727 MiB |   1176 TiB |   1176 TiB |\n","|       from large pool |   1001 MiB |   1722 MiB |   1165 TiB |   1165 TiB |\n","|       from small pool |      4 MiB |     21 MiB |     10 TiB |     10 TiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  134300 K  |  134281 K  |\n","|       from large pool |      98    |     263    |   79108 K  |   79108 K  |\n","|       from small pool |   18777    |   18924    |   55192 K  |   55173 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  134300 K  |  134281 K  |\n","|       from large pool |      98    |     263    |   79108 K  |   79108 K  |\n","|       from small pool |   18777    |   18924    |   55192 K  |   55173 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     237    |     321    |    6964 K  |    6964 K  |\n","|       from large pool |      13    |      89    |    6205 K  |    6205 K  |\n","|       from small pool |     224    |     237    |     758 K  |     758 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      82    |     151    |   64302 K  |   64302 K  |\n","|       from large pool |      16    |      48    |   42754 K  |   42754 K  |\n","|       from small pool |      66    |     118    |   21548 K  |   21548 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Next token prediction. step:66/185 batch:765/8961 epoch:1/10\n","full seq: The former Bosnian Serb leader was first charged with war crimes in July 1995 under a joint indictment against him and his wartime military commander, Ratko Mladic.Ģġġġġġġġġġġġġġġġġġġġġ\n","pref seq: The former Bosnian Serb leader was first charged with war crimes i\n","next tok:                                                                  n\n","pred tok:                                                                  w\n"]}],"source":["runner = Runner(runner_hyperparameters_name=\"SETimesByT5Vaswani2017Kocmi2018_0\")\n","\n","runner.load_dataset()\n","runner.load_model()\n","runner.load_trainer()\n","runner.run_trainer()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyNuhlxDf8G0QGS9BOK26tl4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}