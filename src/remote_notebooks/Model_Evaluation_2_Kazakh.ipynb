{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"L4","authorship_tag":"ABX9TyMzwOFuAdqRLT6kO38rupEN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9XLxa0tEyK7r","outputId":"b5746dc2-3328-4463-ae1e-787df5f3a01c","executionInfo":{"status":"ok","timestamp":1715990298542,"user_tz":240,"elapsed":292179,"user":{"displayName":"Matthew Johnson","userId":"09672185346885346735"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Initialized runner NewsCommentaryByT5Vaswani2017Kocmi2018_2 with parameters {'runner_hyperparameters_name': 'NewsCommentaryByT5Vaswani2017Kocmi2018_2', 'model_parameter_filepath': '/content/drive/MyDrive/CS685-NLP-GroupProject/Code/singleNotebookFromPythonFilesStructure/resources/saved_parameters/NewsCommentaryByT5Vaswani2017Kocmi2018_2-1715965581-model.params', 'datasets_filepath': '/content/drive/MyDrive/CS685-NLP-GroupProject/Code/singleNotebookFromPythonFilesStructure/resources/parsed_datasets/SMTNewsCommentary/SMTNewsCommentary_parsed-1715949808', 'output_filepath': '/content/drive/MyDrive/CS685-NLP-GroupProject/Code/singleNotebookFromPythonFilesStructure/resources/model_translations/NewsCommentaryByT5Vaswani2017Kocmi2018_2.json', 'model_hyperparameters': {'src_vocab_size': 150, 'tgt_vocab_size': 81, 'max_src_seq_len': 266, 'max_tgt_seq_len': 256, 'd_model': 128, 'nhead': 8, 'num_encoder_layers': 9, 'num_decoder_layers': 3, 'dim_feedforward': 1024, 'dropout': 0.1, 'activation': <function relu at 0x7f4294033be0>, 'custom_encoder': None, 'custom_decoder': None, 'layer_norm_eps': 1e-05, 'batch_first': True, 'norm_first': False, 'bias': True, 'device': None, 'dtype': None}}\n","Completed translation 0 of 427 at 1715990036.3002577\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      |  25328 KiB |  33668 KiB |  16875 MiB |  16850 MiB |\n","|       from large pool |   8320 KiB |   8320 KiB |      8 MiB |      0 MiB |\n","|       from small pool |  17008 KiB |  33668 KiB |  16867 MiB |  16850 MiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         |  25328 KiB |  33668 KiB |  16875 MiB |  16850 MiB |\n","|       from large pool |   8320 KiB |   8320 KiB |      8 MiB |      0 MiB |\n","|       from small pool |  17008 KiB |  33668 KiB |  16867 MiB |  16850 MiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      |  25259 KiB |  33599 KiB |  16870 MiB |  16846 MiB |\n","|       from large pool |   8320 KiB |   8320 KiB |      8 MiB |      0 MiB |\n","|       from small pool |  16939 KiB |  33599 KiB |  16862 MiB |  16846 MiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |  45056 KiB |  55296 KiB |  55296 KiB |  10240 KiB |\n","|       from large pool |  20480 KiB |  20480 KiB |  20480 KiB |      0 KiB |\n","|       from small pool |  24576 KiB |  34816 KiB |  34816 KiB |  10240 KiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |  19728 KiB |  19728 KiB |  17359 MiB |  17340 MiB |\n","|       from large pool |  12160 KiB |  12160 KiB |     11 MiB |      0 MiB |\n","|       from small pool |   7568 KiB |   8364 KiB |  17347 MiB |  17340 MiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |     440    |     620    |   76295    |   75855    |\n","|       from large pool |       1    |       1    |       1    |       0    |\n","|       from small pool |     439    |     619    |   76294    |   75855    |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |     440    |     620    |   76295    |   75855    |\n","|       from large pool |       1    |       1    |       1    |       0    |\n","|       from small pool |     439    |     619    |   76294    |   75855    |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      13    |      18    |      18    |       5    |\n","|       from large pool |       1    |       1    |       1    |       0    |\n","|       from small pool |      12    |      17    |      17    |       5    |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |       7    |      16    |   28953    |   28946    |\n","|       from large pool |       1    |       1    |       1    |       0    |\n","|       from small pool |       6    |      15    |   28952    |   28946    |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Translation0: {'source': 'Қазір жұрт технологияны да солай игеріп жатыр.Ģ', 'target': 'People engage with technology in similar ways.Ģ', 'translation': 'oWWZYZJYYZYZJYYZJYYYJZJJWJWYJWZZZZZJZJYYJYJWWZZZZJYYZWYJJZYZYJYYZJYZZZYZJYJZJJWWJJWZWYZJJZYWWJJWJYZZYJYJJZZYYJWWYZYYZWZJZYZZZWYJZZZZYZWWJZYYYJWZJWJWZWZZJJZZZWWZZZZZWJJWZWZJWZZZYJJWWYJWWYWYWWJWWZWZJZZJJYYYWYYYZZYYYYWZZWJZWZWZJZJWJZYZJYWJWZYYYZJZJJZWWYJWWYYJ'}\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/cuda/memory.py:330: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/cuda/memory.py:356: FutureWarning: torch.cuda.reset_max_memory_cached now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Completed translation 1 of 427 at 1715990039.6801567\n","Completed translation 2 of 427 at 1715990042.3220637\n","Completed translation 3 of 427 at 1715990042.928723\n","Completed translation 4 of 427 at 1715990045.5967114\n","Completed translation 5 of 427 at 1715990046.219757\n","Completed translation 6 of 427 at 1715990046.776359\n","Completed translation 7 of 427 at 1715990047.3132443\n","Completed translation 8 of 427 at 1715990047.867572\n","Completed translation 9 of 427 at 1715990048.4134865\n","Completed translation 10 of 427 at 1715990051.0486617\n","Completed translation 11 of 427 at 1715990051.5775697\n","Completed translation 12 of 427 at 1715990054.2076359\n","Completed translation 13 of 427 at 1715990056.8744092\n","Completed translation 14 of 427 at 1715990059.5560622\n","Completed translation 15 of 427 at 1715990060.1199212\n","Completed translation 16 of 427 at 1715990060.6450567\n","Completed translation 17 of 427 at 1715990061.173095\n","Completed translation 18 of 427 at 1715990061.7053516\n","Completed translation 19 of 427 at 1715990062.2406566\n","Completed translation 20 of 427 at 1715990062.8159435\n","Completed translation 21 of 427 at 1715990063.411263\n","Completed translation 22 of 427 at 1715990066.0315912\n","Completed translation 23 of 427 at 1715990068.6761012\n","Completed translation 24 of 427 at 1715990069.244615\n","Completed translation 25 of 427 at 1715990069.796857\n","Completed translation 26 of 427 at 1715990070.3558533\n","Completed translation 27 of 427 at 1715990072.9500237\n","Completed translation 28 of 427 at 1715990073.5477908\n","Completed translation 29 of 427 at 1715990074.077578\n","Completed translation 30 of 427 at 1715990074.6090589\n","Completed translation 31 of 427 at 1715990075.206883\n","Completed translation 32 of 427 at 1715990075.7477086\n","Completed translation 33 of 427 at 1715990076.3077796\n","Completed translation 34 of 427 at 1715990076.850877\n","Completed translation 35 of 427 at 1715990077.3859568\n","Completed translation 36 of 427 at 1715990077.9190466\n","Completed translation 37 of 427 at 1715990078.472443\n","Completed translation 38 of 427 at 1715990079.0701253\n","Completed translation 39 of 427 at 1715990079.6623943\n","Completed translation 40 of 427 at 1715990080.3805451\n","Completed translation 41 of 427 at 1715990080.92561\n","Completed translation 42 of 427 at 1715990081.4835207\n","Completed translation 43 of 427 at 1715990082.0601652\n","Completed translation 44 of 427 at 1715990082.5955496\n","Completed translation 45 of 427 at 1715990083.169454\n","Completed translation 46 of 427 at 1715990083.740744\n","Completed translation 47 of 427 at 1715990084.317795\n","Completed translation 48 of 427 at 1715990084.8609865\n","Completed translation 49 of 427 at 1715990085.4506087\n","Completed translation 50 of 427 at 1715990086.0004797\n","Completed translation 51 of 427 at 1715990086.622353\n","Completed translation 52 of 427 at 1715990087.1563346\n","Completed translation 53 of 427 at 1715990087.7195919\n","Completed translation 54 of 427 at 1715990088.2694561\n","Completed translation 55 of 427 at 1715990088.8472955\n","Completed translation 56 of 427 at 1715990089.4073567\n","Completed translation 57 of 427 at 1715990089.9542165\n","Completed translation 58 of 427 at 1715990090.4875546\n","Completed translation 59 of 427 at 1715990091.0407057\n","Completed translation 60 of 427 at 1715990091.5869079\n","Completed translation 61 of 427 at 1715990092.1621332\n","Completed translation 62 of 427 at 1715990092.7026067\n","Completed translation 63 of 427 at 1715990093.2498207\n","Completed translation 64 of 427 at 1715990093.8146257\n","Completed translation 65 of 427 at 1715990094.4235072\n","Completed translation 66 of 427 at 1715990094.977938\n","Completed translation 67 of 427 at 1715990095.5132568\n","Completed translation 68 of 427 at 1715990096.0400522\n","Completed translation 69 of 427 at 1715990096.6301844\n","Completed translation 70 of 427 at 1715990097.1937296\n","Completed translation 71 of 427 at 1715990097.7396207\n","Completed translation 72 of 427 at 1715990098.326318\n","Completed translation 73 of 427 at 1715990098.8887563\n","Completed translation 74 of 427 at 1715990099.465658\n","Completed translation 75 of 427 at 1715990100.0972219\n","Completed translation 76 of 427 at 1715990100.627022\n","Completed translation 77 of 427 at 1715990101.1808295\n","Completed translation 78 of 427 at 1715990101.72983\n","Completed translation 79 of 427 at 1715990102.2725003\n","Completed translation 80 of 427 at 1715990102.8492367\n","Completed translation 81 of 427 at 1715990103.4106069\n","Completed translation 82 of 427 at 1715990103.9745014\n","Completed translation 83 of 427 at 1715990104.5590978\n","Completed translation 84 of 427 at 1715990105.0998154\n","Completed translation 85 of 427 at 1715990105.7519863\n","Completed translation 86 of 427 at 1715990106.3326628\n","Completed translation 87 of 427 at 1715990106.8867326\n","Completed translation 88 of 427 at 1715990107.4332716\n","Completed translation 89 of 427 at 1715990107.9871845\n","Completed translation 90 of 427 at 1715990108.5298443\n","Completed translation 91 of 427 at 1715990109.068685\n","Completed translation 92 of 427 at 1715990109.6004405\n","Completed translation 93 of 427 at 1715990110.1725025\n","Completed translation 94 of 427 at 1715990110.758732\n","Completed translation 95 of 427 at 1715990111.3280783\n","Completed translation 96 of 427 at 1715990112.0171082\n","Completed translation 97 of 427 at 1715990112.57073\n","Completed translation 98 of 427 at 1715990113.1140563\n","Completed translation 99 of 427 at 1715990113.654921\n","Completed translation 100 of 427 at 1715990114.2180192\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      |  25328 KiB |  35741 KiB | 524320 MiB | 524295 MiB |\n","|       from large pool |   8320 KiB |   8320 KiB |      8 MiB |      0 MiB |\n","|       from small pool |  17008 KiB |  27421 KiB | 524312 MiB | 524295 MiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         |  25328 KiB |  35741 KiB | 524320 MiB | 524295 MiB |\n","|       from large pool |   8320 KiB |   8320 KiB |      8 MiB |      0 MiB |\n","|       from small pool |  17008 KiB |  27421 KiB | 524312 MiB | 524295 MiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      |  25259 KiB |  35663 KiB | 524195 MiB | 524170 MiB |\n","|       from large pool |   8320 KiB |   8320 KiB |      8 MiB |      0 MiB |\n","|       from small pool |  16939 KiB |  27343 KiB | 524187 MiB | 524170 MiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |  45056 KiB |  49152 KiB | 231424 KiB | 186368 KiB |\n","|       from large pool |  20480 KiB |  20480 KiB |  20480 KiB |      0 KiB |\n","|       from small pool |  24576 KiB |  28672 KiB | 210944 KiB | 186368 KiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |  19728 KiB |  21774 KiB | 527071 MiB | 527052 MiB |\n","|       from large pool |  12160 KiB |  12160 KiB |     11 MiB |      0 MiB |\n","|       from small pool |   7568 KiB |   9614 KiB | 527060 MiB | 527052 MiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |     440    |     622    |    2270 K  |    2269 K  |\n","|       from large pool |       1    |       1    |       0 K  |       0 K  |\n","|       from small pool |     439    |     621    |    2270 K  |    2269 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |     440    |     622    |    2270 K  |    2269 K  |\n","|       from large pool |       1    |       1    |       0 K  |       0 K  |\n","|       from small pool |     439    |     621    |    2270 K  |    2269 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      13    |      15    |     104    |      91    |\n","|       from large pool |       1    |       1    |       1    |       0    |\n","|       from small pool |      12    |      14    |     103    |      91    |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |       7    |      19    |     848 K  |     848 K  |\n","|       from large pool |       1    |       1    |       0 K  |       0 K  |\n","|       from small pool |       6    |      18    |     848 K  |     848 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Translation100: {'source': 'Компания 20 жылдық қызмет мерзімі ішінде Айлзға қатысты осындай сценарийді ұстанды.Ģ', 'target': 'The company followed essentially the same script with regard to Ailes during his 20-year tenure.Ģ', 'translation': 'KZJWZYJYYWJJZWZWYJJZJYWZJWZWWYYYYJZWZZZYZYWZWJWJWZJnĢ'}\n","Completed translation 101 of 427 at 1715990114.7883403\n","Completed translation 102 of 427 at 1715990115.3406713\n","Completed translation 103 of 427 at 1715990115.9521687\n","Completed translation 104 of 427 at 1715990116.5387936\n","Completed translation 105 of 427 at 1715990117.092759\n","Completed translation 106 of 427 at 1715990117.6655028\n","Completed translation 107 of 427 at 1715990118.1948247\n","Completed translation 108 of 427 at 1715990118.825252\n","Completed translation 109 of 427 at 1715990119.3949618\n","Completed translation 110 of 427 at 1715990119.941464\n","Completed translation 111 of 427 at 1715990120.578134\n","Completed translation 112 of 427 at 1715990121.113525\n","Completed translation 113 of 427 at 1715990121.6642787\n","Completed translation 114 of 427 at 1715990122.2696757\n","Completed translation 115 of 427 at 1715990122.8407855\n","Completed translation 116 of 427 at 1715990123.3810399\n","Completed translation 117 of 427 at 1715990123.9072416\n","Completed translation 118 of 427 at 1715990124.4837615\n","Completed translation 119 of 427 at 1715990125.0212762\n","Completed translation 120 of 427 at 1715990125.5787556\n","Completed translation 121 of 427 at 1715990126.1340084\n","Completed translation 122 of 427 at 1715990126.679021\n","Completed translation 123 of 427 at 1715990127.230227\n","Completed translation 124 of 427 at 1715990127.7701938\n","Completed translation 125 of 427 at 1715990128.3001752\n","Completed translation 126 of 427 at 1715990128.8520656\n","Completed translation 127 of 427 at 1715990129.44751\n","Completed translation 128 of 427 at 1715990130.0032327\n","Completed translation 129 of 427 at 1715990130.5817065\n","Completed translation 130 of 427 at 1715990131.159829\n","Completed translation 131 of 427 at 1715990131.7105265\n","Completed translation 132 of 427 at 1715990132.261392\n","Completed translation 133 of 427 at 1715990132.811333\n","Completed translation 134 of 427 at 1715990133.3564932\n","Completed translation 135 of 427 at 1715990133.886309\n","Completed translation 136 of 427 at 1715990134.425861\n","Completed translation 137 of 427 at 1715990134.9716864\n","Completed translation 138 of 427 at 1715990135.5156116\n","Completed translation 139 of 427 at 1715990136.0642636\n","Completed translation 140 of 427 at 1715990136.6224098\n","Completed translation 141 of 427 at 1715990137.154597\n","Completed translation 142 of 427 at 1715990137.7313445\n","Completed translation 143 of 427 at 1715990138.2740147\n","Completed translation 144 of 427 at 1715990138.8319397\n","Completed translation 145 of 427 at 1715990139.436168\n","Completed translation 146 of 427 at 1715990140.0621057\n","Completed translation 147 of 427 at 1715990140.5883276\n","Completed translation 148 of 427 at 1715990141.1296153\n","Completed translation 149 of 427 at 1715990141.688242\n","Completed translation 150 of 427 at 1715990142.2384546\n","Completed translation 151 of 427 at 1715990142.881198\n","Completed translation 152 of 427 at 1715990143.4274309\n","Completed translation 153 of 427 at 1715990143.9770057\n","Completed translation 154 of 427 at 1715990144.5591846\n","Completed translation 155 of 427 at 1715990145.1132286\n","Completed translation 156 of 427 at 1715990145.6638114\n","Completed translation 157 of 427 at 1715990146.2017078\n","Completed translation 158 of 427 at 1715990146.7348893\n","Completed translation 159 of 427 at 1715990147.345964\n","Completed translation 160 of 427 at 1715990147.9085803\n","Completed translation 161 of 427 at 1715990148.4517636\n","Completed translation 162 of 427 at 1715990149.012629\n","Completed translation 163 of 427 at 1715990149.558322\n","Completed translation 164 of 427 at 1715990150.1191664\n","Completed translation 165 of 427 at 1715990150.655204\n","Completed translation 166 of 427 at 1715990151.2106605\n","Completed translation 167 of 427 at 1715990151.74655\n","Completed translation 168 of 427 at 1715990152.3109963\n","Completed translation 169 of 427 at 1715990152.84939\n","Completed translation 170 of 427 at 1715990153.3845518\n","Completed translation 171 of 427 at 1715990153.9377546\n","Completed translation 172 of 427 at 1715990154.4766636\n","Completed translation 173 of 427 at 1715990155.0570202\n","Completed translation 174 of 427 at 1715990155.6200697\n","Completed translation 175 of 427 at 1715990156.1946948\n","Completed translation 176 of 427 at 1715990156.7460082\n","Completed translation 177 of 427 at 1715990157.3015223\n","Completed translation 178 of 427 at 1715990157.8651533\n","Completed translation 179 of 427 at 1715990158.4272928\n","Completed translation 180 of 427 at 1715990158.9978669\n","Completed translation 181 of 427 at 1715990159.5438845\n","Completed translation 182 of 427 at 1715990160.155583\n","Completed translation 183 of 427 at 1715990160.7036514\n","Completed translation 184 of 427 at 1715990161.2955458\n","Completed translation 185 of 427 at 1715990161.8316903\n","Completed translation 186 of 427 at 1715990162.375599\n","Completed translation 187 of 427 at 1715990162.955355\n","Completed translation 188 of 427 at 1715990163.60415\n","Completed translation 189 of 427 at 1715990164.2275636\n","Completed translation 190 of 427 at 1715990164.8216503\n","Completed translation 191 of 427 at 1715990165.3998718\n","Completed translation 192 of 427 at 1715990165.9422429\n","Completed translation 193 of 427 at 1715990166.500499\n","Completed translation 194 of 427 at 1715990167.0928664\n","Completed translation 195 of 427 at 1715990167.6335416\n","Completed translation 196 of 427 at 1715990168.2014785\n","Completed translation 197 of 427 at 1715990168.750318\n","Completed translation 198 of 427 at 1715990169.3133154\n","Completed translation 199 of 427 at 1715990169.8572028\n","Completed translation 200 of 427 at 1715990170.3973587\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      |  25328 KiB |  38505 KiB |    899 GiB |    899 GiB |\n","|       from large pool |   8320 KiB |   8320 KiB |      0 GiB |      0 GiB |\n","|       from small pool |  17008 KiB |  30185 KiB |    899 GiB |    899 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         |  25328 KiB |  38505 KiB |    899 GiB |    899 GiB |\n","|       from large pool |   8320 KiB |   8320 KiB |      0 GiB |      0 GiB |\n","|       from small pool |  17008 KiB |  30185 KiB |    899 GiB |    899 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      |  25259 KiB |  38414 KiB |    899 GiB |    899 GiB |\n","|       from large pool |   8320 KiB |   8320 KiB |      0 GiB |      0 GiB |\n","|       from small pool |  16939 KiB |  30094 KiB |    899 GiB |    899 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |  45056 KiB |  51200 KiB | 694272 KiB | 649216 KiB |\n","|       from large pool |  20480 KiB |  20480 KiB |  20480 KiB |      0 KiB |\n","|       from small pool |  24576 KiB |  30720 KiB | 673792 KiB | 649216 KiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |  19728 KiB |  23809 KiB |    912 GiB |    912 GiB |\n","|       from large pool |  12160 KiB |  12160 KiB |      0 GiB |      0 GiB |\n","|       from small pool |   7568 KiB |  11649 KiB |    912 GiB |    912 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |     440    |     620    |    3867 K  |    3867 K  |\n","|       from large pool |       1    |       1    |       0 K  |       0 K  |\n","|       from small pool |     439    |     619    |    3867 K  |    3867 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |     440    |     620    |    3867 K  |    3867 K  |\n","|       from large pool |       1    |       1    |       0 K  |       0 K  |\n","|       from small pool |     439    |     619    |    3867 K  |    3867 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      13    |      16    |     330    |     317    |\n","|       from large pool |       1    |       1    |       1    |       0    |\n","|       from small pool |      12    |      15    |     329    |     317    |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |       7    |      20    |    1506 K  |    1506 K  |\n","|       from large pool |       1    |       1    |       0 K  |       0 K  |\n","|       from small pool |       6    |      19    |    1506 K  |    1506 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Translation200: {'source': '1981 жылы билікке модернист Махатхир келген соң Ислам – PAS-тың UMNO-ға қарсы ең тиімді идеологиялық қаруына айналды.Ģ', 'target': \"When the modernist Mahathir came to power in 1981, Islamism became the PAS's most effective ideological weapon against the UMNO.Ģ\", 'translation': 'vWJZZYZWYWJWYWJZZYWZZJZYWYJWWYWWJWWJWZWJYZYJJWYYYWYsĢ'}\n","Completed translation 201 of 427 at 1715990170.9501662\n","Completed translation 202 of 427 at 1715990171.524415\n","Completed translation 203 of 427 at 1715990172.084025\n","Completed translation 204 of 427 at 1715990172.630121\n","Completed translation 205 of 427 at 1715990173.2229407\n","Completed translation 206 of 427 at 1715990173.8096247\n","Completed translation 207 of 427 at 1715990174.3391078\n","Completed translation 208 of 427 at 1715990175.0364792\n","Completed translation 209 of 427 at 1715990175.6452959\n","Completed translation 210 of 427 at 1715990176.2586846\n","Completed translation 211 of 427 at 1715990176.8072207\n","Completed translation 212 of 427 at 1715990177.4039497\n","Completed translation 213 of 427 at 1715990177.9887605\n","Completed translation 214 of 427 at 1715990178.5442343\n","Completed translation 215 of 427 at 1715990179.1287186\n","Completed translation 216 of 427 at 1715990179.6759822\n","Completed translation 217 of 427 at 1715990180.211087\n","Completed translation 218 of 427 at 1715990180.7534678\n","Completed translation 219 of 427 at 1715990181.2874904\n","Completed translation 220 of 427 at 1715990181.8949628\n","Completed translation 221 of 427 at 1715990182.4362972\n","Completed translation 222 of 427 at 1715990183.122936\n","Completed translation 223 of 427 at 1715990183.716519\n","Completed translation 224 of 427 at 1715990184.2666194\n","Completed translation 225 of 427 at 1715990184.8399708\n","Completed translation 226 of 427 at 1715990185.3796818\n","Completed translation 227 of 427 at 1715990185.9298248\n","Completed translation 228 of 427 at 1715990186.4643915\n","Completed translation 229 of 427 at 1715990187.0095963\n","Completed translation 230 of 427 at 1715990187.5823922\n","Completed translation 231 of 427 at 1715990188.2241387\n","Completed translation 232 of 427 at 1715990188.8218071\n","Completed translation 233 of 427 at 1715990189.4248462\n","Completed translation 234 of 427 at 1715990189.979255\n","Completed translation 235 of 427 at 1715990190.556707\n","Completed translation 236 of 427 at 1715990191.1200228\n","Completed translation 237 of 427 at 1715990191.6511376\n","Completed translation 238 of 427 at 1715990192.1879792\n","Completed translation 239 of 427 at 1715990192.714218\n","Completed translation 240 of 427 at 1715990193.3013813\n","Completed translation 241 of 427 at 1715990193.8530207\n","Completed translation 242 of 427 at 1715990194.3992124\n","Completed translation 243 of 427 at 1715990194.9482455\n","Completed translation 244 of 427 at 1715990195.4930775\n","Completed translation 245 of 427 at 1715990196.0345705\n","Completed translation 246 of 427 at 1715990196.6007996\n","Completed translation 247 of 427 at 1715990197.2011995\n","Completed translation 248 of 427 at 1715990197.7870336\n","Completed translation 249 of 427 at 1715990198.3991256\n","Completed translation 250 of 427 at 1715990198.9412327\n","Completed translation 251 of 427 at 1715990199.5049179\n","Completed translation 252 of 427 at 1715990200.0339797\n","Completed translation 253 of 427 at 1715990200.5687037\n","Completed translation 254 of 427 at 1715990201.1147308\n","Completed translation 255 of 427 at 1715990201.7422533\n","Completed translation 256 of 427 at 1715990202.322236\n","Completed translation 257 of 427 at 1715990202.8514173\n","Completed translation 258 of 427 at 1715990203.4032865\n","Completed translation 259 of 427 at 1715990203.9651127\n","Completed translation 260 of 427 at 1715990204.5070925\n","Completed translation 261 of 427 at 1715990205.0375638\n","Completed translation 262 of 427 at 1715990205.5867145\n","Completed translation 263 of 427 at 1715990206.1238558\n","Completed translation 264 of 427 at 1715990206.6716902\n","Completed translation 265 of 427 at 1715990207.2030392\n","Completed translation 266 of 427 at 1715990207.7421393\n","Completed translation 267 of 427 at 1715990208.2732127\n","Completed translation 268 of 427 at 1715990208.8194995\n","Completed translation 269 of 427 at 1715990209.378105\n","Completed translation 270 of 427 at 1715990209.91719\n","Completed translation 271 of 427 at 1715990210.4829879\n","Completed translation 272 of 427 at 1715990211.0607998\n","Completed translation 273 of 427 at 1715990211.6031148\n","Completed translation 274 of 427 at 1715990212.1501074\n","Completed translation 275 of 427 at 1715990212.7241302\n","Completed translation 276 of 427 at 1715990213.2791238\n","Completed translation 277 of 427 at 1715990213.862533\n","Completed translation 278 of 427 at 1715990214.4197168\n","Completed translation 279 of 427 at 1715990214.9715014\n","Completed translation 280 of 427 at 1715990215.5285144\n","Completed translation 281 of 427 at 1715990216.0752764\n","Completed translation 282 of 427 at 1715990216.6551058\n","Completed translation 283 of 427 at 1715990217.207417\n","Completed translation 284 of 427 at 1715990217.7325442\n","Completed translation 285 of 427 at 1715990218.2993836\n","Completed translation 286 of 427 at 1715990218.8230097\n","Completed translation 287 of 427 at 1715990219.3537543\n","Completed translation 288 of 427 at 1715990219.8919582\n","Completed translation 289 of 427 at 1715990220.431233\n","Completed translation 290 of 427 at 1715990221.0081172\n","Completed translation 291 of 427 at 1715990221.5544314\n","Completed translation 292 of 427 at 1715990222.0976388\n","Completed translation 293 of 427 at 1715990222.6287522\n","Completed translation 294 of 427 at 1715990223.211864\n","Completed translation 295 of 427 at 1715990223.7713206\n","Completed translation 296 of 427 at 1715990224.303828\n","Completed translation 297 of 427 at 1715990224.863247\n","Completed translation 298 of 427 at 1715990225.5107894\n","Completed translation 299 of 427 at 1715990226.0543907\n","Completed translation 300 of 427 at 1715990226.6108606\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      |  25328 KiB |  41099 KiB |   1311 GiB |   1311 GiB |\n","|       from large pool |   8320 KiB |   8320 KiB |      0 GiB |      0 GiB |\n","|       from small pool |  17008 KiB |  32779 KiB |   1311 GiB |   1311 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         |  25328 KiB |  41099 KiB |   1311 GiB |   1311 GiB |\n","|       from large pool |   8320 KiB |   8320 KiB |      0 GiB |      0 GiB |\n","|       from small pool |  17008 KiB |  32779 KiB |   1311 GiB |   1311 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      |  25259 KiB |  41012 KiB |   1311 GiB |   1311 GiB |\n","|       from large pool |   8320 KiB |   8320 KiB |      0 GiB |      0 GiB |\n","|       from small pool |  16939 KiB |  32692 KiB |   1311 GiB |   1311 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |  45056 KiB |  55296 KiB |   1396 MiB |   1352 MiB |\n","|       from large pool |  20480 KiB |  20480 KiB |     20 MiB |      0 MiB |\n","|       from small pool |  24576 KiB |  34816 KiB |   1376 MiB |   1352 MiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |  19728 KiB |  27794 KiB |   1342 GiB |   1342 GiB |\n","|       from large pool |  12160 KiB |  12160 KiB |      0 GiB |      0 GiB |\n","|       from small pool |   7568 KiB |  15634 KiB |   1342 GiB |   1342 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |     440    |     621    |    5466 K  |    5465 K  |\n","|       from large pool |       1    |       1    |       0 K  |       0 K  |\n","|       from small pool |     439    |     620    |    5466 K  |    5465 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |     440    |     621    |    5466 K  |    5465 K  |\n","|       from large pool |       1    |       1    |       0 K  |       0 K  |\n","|       from small pool |     439    |     620    |    5466 K  |    5465 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      13    |      18    |     689    |     676    |\n","|       from large pool |       1    |       1    |       1    |       0    |\n","|       from small pool |      12    |      17    |     688    |     676    |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |       7    |      21    |    2175 K  |    2175 K  |\n","|       from large pool |       1    |       1    |       0 K  |       0 K  |\n","|       from small pool |       6    |      20    |    2175 K  |    2175 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Translation300: {'source': 'ЛОНДОН – Жүйе құрушы орталық банктердің қорғанысты өзгерте бастауы 2018-2019 жылдары жаңа ақша-несие саясаты дәуірінің басталатынынан хабар берсе керек.Ģ', 'target': 'LONDON - The changing of the guard that is taking place at the systemically important central banks in 2018-2019 will mark the beginning of a new era of monetary policy.Ģ', 'translation': 'sYWYYWYJWZYYWZZJYZJZJWJWWYYWZWJZYWJYZJWJZJYYYZJWJWYtsĢ'}\n","Completed translation 301 of 427 at 1715990227.2127273\n","Completed translation 302 of 427 at 1715990227.7534697\n","Completed translation 303 of 427 at 1715990228.3316941\n","Completed translation 304 of 427 at 1715990228.94791\n","Completed translation 305 of 427 at 1715990229.5026474\n","Completed translation 306 of 427 at 1715990230.070268\n","Completed translation 307 of 427 at 1715990230.6163\n","Completed translation 308 of 427 at 1715990231.1725671\n","Completed translation 309 of 427 at 1715990231.7392125\n","Completed translation 310 of 427 at 1715990232.297136\n","Completed translation 311 of 427 at 1715990232.857198\n","Completed translation 312 of 427 at 1715990233.450412\n","Completed translation 313 of 427 at 1715990233.9966776\n","Completed translation 314 of 427 at 1715990234.5583987\n","Completed translation 315 of 427 at 1715990235.1066718\n","Completed translation 316 of 427 at 1715990235.6553416\n","Completed translation 317 of 427 at 1715990236.227502\n","Completed translation 318 of 427 at 1715990236.7865636\n","Completed translation 319 of 427 at 1715990237.4378493\n","Completed translation 320 of 427 at 1715990237.966134\n","Completed translation 321 of 427 at 1715990238.5310144\n","Completed translation 322 of 427 at 1715990239.0857797\n","Completed translation 323 of 427 at 1715990239.71087\n","Completed translation 324 of 427 at 1715990240.2591264\n","Completed translation 325 of 427 at 1715990240.8572593\n","Completed translation 326 of 427 at 1715990241.4502032\n","Completed translation 327 of 427 at 1715990242.0295749\n","Completed translation 328 of 427 at 1715990242.5984185\n","Completed translation 329 of 427 at 1715990243.1779807\n","Completed translation 330 of 427 at 1715990243.7297368\n","Completed translation 331 of 427 at 1715990244.272939\n","Completed translation 332 of 427 at 1715990244.8325698\n","Completed translation 333 of 427 at 1715990245.382071\n","Completed translation 334 of 427 at 1715990245.9430969\n","Completed translation 335 of 427 at 1715990246.5158017\n","Completed translation 336 of 427 at 1715990247.0522747\n","Completed translation 337 of 427 at 1715990247.6922066\n","Completed translation 338 of 427 at 1715990248.252055\n","Completed translation 339 of 427 at 1715990248.8196476\n","Completed translation 340 of 427 at 1715990249.353606\n","Completed translation 341 of 427 at 1715990249.9225574\n","Completed translation 342 of 427 at 1715990250.5272632\n","Completed translation 343 of 427 at 1715990251.1100836\n","Completed translation 344 of 427 at 1715990251.6648083\n","Completed translation 345 of 427 at 1715990252.2196872\n","Completed translation 346 of 427 at 1715990252.8272824\n","Completed translation 347 of 427 at 1715990253.4029799\n","Completed translation 348 of 427 at 1715990253.9422762\n","Completed translation 349 of 427 at 1715990254.557216\n","Completed translation 350 of 427 at 1715990255.1038764\n","Completed translation 351 of 427 at 1715990255.6389937\n","Completed translation 352 of 427 at 1715990256.2017775\n","Completed translation 353 of 427 at 1715990256.7981675\n","Completed translation 354 of 427 at 1715990257.387844\n","Completed translation 355 of 427 at 1715990257.9532008\n","Completed translation 356 of 427 at 1715990258.5099318\n","Completed translation 357 of 427 at 1715990259.1279006\n","Completed translation 358 of 427 at 1715990259.6750083\n","Completed translation 359 of 427 at 1715990260.279637\n","Completed translation 360 of 427 at 1715990260.823851\n","Completed translation 361 of 427 at 1715990261.3760889\n","Completed translation 362 of 427 at 1715990261.9250844\n","Completed translation 363 of 427 at 1715990262.4681978\n","Completed translation 364 of 427 at 1715990263.0409691\n","Completed translation 365 of 427 at 1715990263.5963156\n","Completed translation 366 of 427 at 1715990264.173223\n","Completed translation 367 of 427 at 1715990264.7591794\n","Completed translation 368 of 427 at 1715990265.333187\n","Completed translation 369 of 427 at 1715990265.8765311\n","Completed translation 370 of 427 at 1715990266.5033457\n","Completed translation 371 of 427 at 1715990267.0539036\n","Completed translation 372 of 427 at 1715990267.5980713\n","Completed translation 373 of 427 at 1715990268.1481686\n","Completed translation 374 of 427 at 1715990268.688492\n","Completed translation 375 of 427 at 1715990269.2212203\n","Completed translation 376 of 427 at 1715990269.7609081\n","Completed translation 377 of 427 at 1715990270.3329642\n","Completed translation 378 of 427 at 1715990270.8655648\n","Completed translation 379 of 427 at 1715990271.528219\n","Completed translation 380 of 427 at 1715990272.0995824\n","Completed translation 381 of 427 at 1715990272.6581974\n","Completed translation 382 of 427 at 1715990273.2112432\n","Completed translation 383 of 427 at 1715990273.7869954\n","Completed translation 384 of 427 at 1715990274.4444394\n","Completed translation 385 of 427 at 1715990275.0239825\n","Completed translation 386 of 427 at 1715990275.5686004\n","Completed translation 387 of 427 at 1715990276.1224418\n","Completed translation 388 of 427 at 1715990276.6981494\n","Completed translation 389 of 427 at 1715990277.2411685\n","Completed translation 390 of 427 at 1715990277.7836373\n","Completed translation 391 of 427 at 1715990278.3516145\n","Completed translation 392 of 427 at 1715990278.897472\n","Completed translation 393 of 427 at 1715990279.5379174\n","Completed translation 394 of 427 at 1715990280.0851257\n","Completed translation 395 of 427 at 1715990280.6382368\n","Completed translation 396 of 427 at 1715990281.2900815\n","Completed translation 397 of 427 at 1715990281.8325586\n","Completed translation 398 of 427 at 1715990282.3901486\n","Completed translation 399 of 427 at 1715990282.9736187\n","Completed translation 400 of 427 at 1715990283.5587428\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      |  25328 KiB |  45844 KiB |   1760 GiB |   1760 GiB |\n","|       from large pool |   8320 KiB |   8320 KiB |      0 GiB |      0 GiB |\n","|       from small pool |  17008 KiB |  37524 KiB |   1760 GiB |   1760 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         |  25328 KiB |  45844 KiB |   1760 GiB |   1760 GiB |\n","|       from large pool |   8320 KiB |   8320 KiB |      0 GiB |      0 GiB |\n","|       from small pool |  17008 KiB |  37524 KiB |   1760 GiB |   1760 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      |  25259 KiB |  45766 KiB |   1760 GiB |   1760 GiB |\n","|       from large pool |   8320 KiB |   8320 KiB |      0 GiB |      0 GiB |\n","|       from small pool |  16939 KiB |  37446 KiB |   1760 GiB |   1760 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |  45056 KiB |  59392 KiB |   2466 MiB |   2422 MiB |\n","|       from large pool |  20480 KiB |  20480 KiB |     20 MiB |      0 MiB |\n","|       from small pool |  24576 KiB |  38912 KiB |   2446 MiB |   2422 MiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |  19728 KiB |  29822 KiB |   1809 GiB |   1809 GiB |\n","|       from large pool |  12160 KiB |  12160 KiB |      0 GiB |      0 GiB |\n","|       from small pool |   7568 KiB |  17662 KiB |   1809 GiB |   1809 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |     440    |     622    |    7072 K  |    7072 K  |\n","|       from large pool |       1    |       1    |       0 K  |       0 K  |\n","|       from small pool |     439    |     621    |    7072 K  |    7072 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |     440    |     622    |    7072 K  |    7072 K  |\n","|       from large pool |       1    |       1    |       0 K  |       0 K  |\n","|       from small pool |     439    |     621    |    7072 K  |    7072 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      13    |      20    |    1224    |    1211    |\n","|       from large pool |       1    |       1    |       1    |       0    |\n","|       from small pool |      12    |      19    |    1223    |    1211    |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |       7    |      22    |    2806 K  |    2806 K  |\n","|       from large pool |       1    |       1    |       0 K  |       0 K  |\n","|       from small pool |       6    |      21    |    2806 K  |    2806 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Translation400: {'source': 'Сақтандырылмаған банк депозиттеріне байланысты тәуекелге бармай-ақ қолма-қол ақшаға оңай қол жеткізгісі келетін ұйымдарға Қазынашылықтың қысқа мерзімді вексельдері жетпегендіктен, бір түндік ипотекалық пул нарығы өркен жайды.Ģ', 'target': \"The overnight mortgage-pool market exists partly because there aren't enough short-term US Treasury bills available for businesses that want easy access to cash without the risk implied by uninsured bank deposits.Ģ\", 'translation': 'KWZZWJWZYWZZWWYWYJWJWZZJWWZWJWJYWYYZYJJYYJWYWZWYWWJstsĢ'}\n","Completed translation 401 of 427 at 1715990284.1301258\n","Completed translation 402 of 427 at 1715990284.6676817\n","Completed translation 403 of 427 at 1715990285.2269166\n","Completed translation 404 of 427 at 1715990285.7577722\n","Completed translation 405 of 427 at 1715990286.297132\n","Completed translation 406 of 427 at 1715990286.8639262\n","Completed translation 407 of 427 at 1715990287.4527457\n","Completed translation 408 of 427 at 1715990287.9952087\n","Completed translation 409 of 427 at 1715990288.5636783\n","Completed translation 410 of 427 at 1715990289.130614\n","Completed translation 411 of 427 at 1715990289.693821\n","Completed translation 412 of 427 at 1715990290.2965496\n","Completed translation 413 of 427 at 1715990290.9392161\n","Completed translation 414 of 427 at 1715990291.6293852\n","Completed translation 415 of 427 at 1715990292.2134132\n","Completed translation 416 of 427 at 1715990292.7516313\n","Completed translation 417 of 427 at 1715990293.3612661\n","Completed translation 418 of 427 at 1715990293.9105906\n","Completed translation 419 of 427 at 1715990294.479041\n","Completed translation 420 of 427 at 1715990295.036907\n","Completed translation 421 of 427 at 1715990295.5908504\n","Completed translation 422 of 427 at 1715990296.1188483\n","Completed translation 423 of 427 at 1715990296.6805227\n","Completed translation 424 of 427 at 1715990297.2286024\n","Completed translation 425 of 427 at 1715990297.8278832\n","Completed translation 426 of 427 at 1715990298.3953555\n","Translation426: {'source': 'Басқаша айтқанда, адам құқықтарын түсіндіруде мәдениет адамдардың көбі ойлағаннан әлдеқайда үлкен рөл атқарады, сондықтан адам құқықтарын қорғаушылар мәдени не діни тамыры тереңде жатқан әлдебір мәселе жөнінде үстірт пікір айтудан сақ болғаны жөн.Ģ', 'target': 'In other words, culture plays a much larger role in shaping interpretations of human rights than many realize, which implies that human-rights practitioners should be wary of passing judgment on any practice with deep cultural or religious roots.Ģ', 'translation': 'KYWZZYWZWJWZYZWZZWWZJWJYYZWYYYZYWYJJWZYWJJJZWWWYJZYttĢ'}\n"]}],"source":["from google.colab import drive\n","\n","import json\n","import random\n","import time\n","from typing import Optional\n","\n","import torch\n","import numpy as np\n","\n","drive.mount('/content/drive', force_remount=True)\n","root_filepath = '/content/drive/MyDrive/CS685-NLP-GroupProject/Code/singleNotebookFromPythonFilesStructure/'\n","is_remote_execution = True\n","torch.set_printoptions(threshold=100000, edgeitems=10000, linewidth=100000)\n","torch.device(\"cuda\")\n","\n","\n","# 16M Turkish\n","SETimesByT5Vaswani2017Kocmi2018_0 = {\n","    'runner_hyperparameters_name': 'SETimesByT5Vaswani2017Kocmi2018_0',\n","    'model_parameter_filepath': root_filepath + \"resources/saved_parameters/SETimesByT5Vaswani2017Kocmi2018_0-1715937924-model.params\",\n","    'datasets_filepath': root_filepath + \"resources/parsed_datasets/setimes/setimes_parsed-1715586293\",\n","    'output_filepath': root_filepath + \"resources/model_translations/SETimesByT5Vaswani2017Kocmi2018_0.json\",\n","    'model_hyperparameters': {\n","        'src_vocab_size': 0,\n","        'tgt_vocab_size': 81,\n","        'max_src_seq_len': 0,\n","        'max_tgt_seq_len': 256,\n","        'd_model': 256,\n","        'nhead': 8,\n","        # number of encoders is 3 times that of decoders, following Xue 2021 - ByT5 - Sec 3.1\n","        'num_encoder_layers': 9,\n","        'num_decoder_layers': 3,\n","        'dim_feedforward': 2048,\n","        'dropout': 0.1,\n","        'activation': torch.nn.functional.relu,\n","        'custom_encoder': None,\n","        'custom_decoder': None,\n","        'layer_norm_eps': 1e-5,\n","        'batch_first': True,\n","        'norm_first': False,\n","        'bias': True,\n","        'device': None,\n","        'dtype': None\n","    }\n","}\n","\n","# 15M Turkish\n","SETimesByT5Vaswani2017Kocmi2018_1 = {\n","    'runner_hyperparameters_name': 'SETimesByT5Vaswani2017Kocmi2018_1',\n","    'model_parameter_filepath': root_filepath + \"resources/saved_parameters/SETimesByT5Vaswani2017Kocmi2018_1-1715937961-model.params\",\n","    'datasets_filepath': root_filepath + \"resources/parsed_datasets/setimes/setimes_parsed-1715586974\",\n","    'output_filepath': root_filepath + \"resources/model_translations/SETimesByT5Vaswani2017Kocmi2018_1.json\",\n","    'model_hyperparameters': {\n","        'src_vocab_size': 0,\n","        'tgt_vocab_size': 81,\n","        'max_src_seq_len': 0,\n","        'max_tgt_seq_len': 256,\n","        'd_model': 256,\n","        'nhead': 8,\n","        # number of encoders is 3 times that of decoders, following Xue 2021 - ByT5 - Sec 3.1\n","        'num_encoder_layers': 9,\n","        'num_decoder_layers': 3,\n","        'dim_feedforward': 1796,\n","        'dropout': 0.1,\n","        'activation': torch.nn.functional.relu,\n","        'custom_encoder': None,\n","        'custom_decoder': None,\n","        'layer_norm_eps': 1e-5,\n","        'batch_first': True,\n","        'norm_first': False,\n","        'bias': True,\n","        'device': None,\n","        'dtype': None\n","    }\n","}\n","\n","# 4M Turkish\n","SETimesByT5Vaswani2017Kocmi2018_2 = {\n","    'runner_hyperparameters_name': 'SETimesByT5Vaswani2017Kocmi2018_2',\n","    'model_parameter_filepath': root_filepath + \"resources/saved_parameters/SETimesByT5Vaswani2017Kocmi2018_2-1715936459-model.params\",\n","    'datasets_filepath': root_filepath + \"resources/parsed_datasets/setimes/setimes_parsed-1715586361\",\n","    'output_filepath': root_filepath + \"resources/model_translations/SETimesByT5Vaswani2017Kocmi2018_2.json\",\n","    'model_hyperparameters': {\n","        'src_vocab_size': 0,\n","        'tgt_vocab_size': 81,\n","        'max_src_seq_len': 0,\n","        'max_tgt_seq_len': 256,\n","        'd_model': 128,\n","        'nhead': 8,\n","        # number of encoders is 3 times that of decoders, following Xue 2021 - ByT5 - Sec 3.1\n","        'num_encoder_layers': 9,\n","        'num_decoder_layers': 3,\n","        'dim_feedforward': 1024,\n","        'dropout': 0.1,\n","        'activation': torch.nn.functional.relu,\n","        'custom_encoder': None,\n","        'custom_decoder': None,\n","        'layer_norm_eps': 1e-5,\n","        'batch_first': True,\n","        'norm_first': False,\n","        'bias': True,\n","        'device': None,\n","        'dtype': None\n","    }\n","}\n","\n","# 16M Kazakh\n","NewsCommentaryByT5Vaswani2017Kocmi2018_0 = {\n","    'runner_hyperparameters_name': 'NewsCommentaryByT5Vaswani2017Kocmi2018_0',\n","    'model_parameter_filepath': root_filepath + \"resources/saved_parameters/NewsCommentaryByT5Vaswani2017Kocmi2018_0-1715965639-model.params\",\n","    'datasets_filepath': root_filepath + \"resources/parsed_datasets/SMTNewsCommentary/SMTNewsCommentary_parsed-1715949808\",\n","    'output_filepath': root_filepath + \"resources/model_translations/NewsCommentaryByT5Vaswani2017Kocmi2018_0.json\",\n","    'model_hyperparameters': {\n","        'src_vocab_size': 150,\n","        'tgt_vocab_size': 81,\n","        'max_src_seq_len': 266,\n","        'max_tgt_seq_len': 256,\n","        'd_model': 256,\n","        'nhead': 8,\n","        # number of encoders is 3 times that of decoders, following Xue 2021 - ByT5 - Sec 3.1\n","        'num_encoder_layers': 9,\n","        'num_decoder_layers': 3,\n","        'dim_feedforward': 2048,\n","        'dropout': 0.1,\n","        'activation': torch.nn.functional.relu,\n","        'custom_encoder': None,\n","        'custom_decoder': None,\n","        'layer_norm_eps': 1e-5,\n","        'batch_first': True,\n","        'norm_first': False,\n","        'bias': True,\n","        'device': None,\n","        'dtype': None\n","    }\n","}\n","\n","# 15M Kazakh\n","NewsCommentaryByT5Vaswani2017Kocmi2018_1 = {\n","    'runner_hyperparameters_name': 'NewsCommentaryByT5Vaswani2017Kocmi2018_1',\n","    'model_parameter_filepath': root_filepath + \"resources/saved_parameters/NewsCommentaryByT5Vaswani2017Kocmi2018_1-1715966141-model.params\",\n","    'datasets_filepath': root_filepath + \"resources/parsed_datasets/SMTNewsCommentary/SMTNewsCommentary_parsed-1715949808\",\n","    'output_filepath': root_filepath + \"resources/model_translations/NewsCommentaryByT5Vaswani2017Kocmi2018_1.json\",\n","    'model_hyperparameters': {\n","        'src_vocab_size': 150,\n","        'tgt_vocab_size': 81,\n","        'max_src_seq_len': 266,\n","        'max_tgt_seq_len': 256,\n","        'd_model': 256,\n","        'nhead': 8,\n","        # number of encoders is 3 times that of decoders, following Xue 2021 - ByT5 - Sec 3.1\n","        'num_encoder_layers': 9,\n","        'num_decoder_layers': 3,\n","        'dim_feedforward': 1796,\n","        'dropout': 0.1,\n","        'activation': torch.nn.functional.relu,\n","        'custom_encoder': None,\n","        'custom_decoder': None,\n","        'layer_norm_eps': 1e-5,\n","        'batch_first': True,\n","        'norm_first': False,\n","        'bias': True,\n","        'device': None,\n","        'dtype': None\n","    }\n","}\n","\n","# 4M Kazakh\n","NewsCommentaryByT5Vaswani2017Kocmi2018_2 = {\n","    'runner_hyperparameters_name': 'NewsCommentaryByT5Vaswani2017Kocmi2018_2',\n","    'model_parameter_filepath': root_filepath + \"resources/saved_parameters/NewsCommentaryByT5Vaswani2017Kocmi2018_2-1715965581-model.params\",\n","    'datasets_filepath': root_filepath + \"resources/parsed_datasets/SMTNewsCommentary/SMTNewsCommentary_parsed-1715949808\",\n","    'output_filepath': root_filepath + \"resources/model_translations/NewsCommentaryByT5Vaswani2017Kocmi2018_2.json\",\n","    'model_hyperparameters': {\n","        'src_vocab_size': 150,\n","        'tgt_vocab_size': 81,\n","        'max_src_seq_len': 266,\n","        'max_tgt_seq_len': 256,\n","        'd_model': 128,\n","        'nhead': 8,\n","        # number of encoders is 3 times that of decoders, following Xue 2021 - ByT5 - Sec 3.1\n","        'num_encoder_layers': 9,\n","        'num_decoder_layers': 3,\n","        'dim_feedforward': 1024,\n","        'dropout': 0.1,\n","        'activation': torch.nn.functional.relu,\n","        'custom_encoder': None,\n","        'custom_decoder': None,\n","        'layer_norm_eps': 1e-5,\n","        'batch_first': True,\n","        'norm_first': False,\n","        'bias': True,\n","        'device': None,\n","        'dtype': None\n","    }\n","}\n","\n","\n","class DatasetHolder:\n","\n","    def __init__(self):\n","        self.unknown_vocabulary_type = None\n","        self.padding_vocabulary_type = None\n","        self.end_of_sequence_type = None\n","        self.target_vocab = None\n","        self.target_vocab_array = None\n","        self.target_vocab_counts = None\n","        self.source_vocab = None\n","        self.source_vocab_array = None\n","        self.source_vocab_counts = None\n","        self.target_encodings = None\n","        self.target_encodings_train = None\n","        self.target_encodings_test = None\n","        self.source_encodings = None\n","        self.source_encodings_train = None\n","        self.source_encodings_test = None\n","        self.max_src_seq_obs = 0\n","        self.max_tgt_seq_obs = 0\n","\n","    def get_unknown_vocabulary_type(self):\n","        return self.unknown_vocabulary_type\n","\n","    def set_unknown_vocabulary_type(self, unknown_vocabulary_type):\n","        self.unknown_vocabulary_type = unknown_vocabulary_type\n","\n","    def get_padding_vocabulary_type(self):\n","        return self.padding_vocabulary_type\n","\n","    def set_padding_vocabulary_type(self, padding_vocabulary_type):\n","        self.padding_vocabulary_type = padding_vocabulary_type\n","\n","    def get_end_of_sequence_vocabulary_type(self):\n","        return self.end_of_sequence_type\n","\n","    def set_end_of_sequence_vocabulary_type(self, end_of_sequence_type):\n","        self.end_of_sequence_type = end_of_sequence_type\n","\n","    def get_target_vocab(self):\n","        return self.target_vocab\n","\n","    def set_target_vocab(self, target_vocab):\n","        self.target_vocab = target_vocab\n","\n","    def get_target_vocab_numpy(self):\n","        if self.target_vocab_array is None:\n","            self.target_vocab_array = np.array(self.target_vocab)\n","        return self.target_vocab_array\n","\n","    def get_target_vocab_counts(self):\n","        return self.target_vocab_counts\n","\n","    def set_target_vocab_counts(self, target_vocab_counts):\n","        self.target_vocab_counts = target_vocab_counts\n","\n","    def get_source_vocab(self):\n","        return self.source_vocab\n","\n","    def set_source_vocab(self, source_vocab):\n","        self.source_vocab = source_vocab\n","\n","    def get_source_vocab_numpy(self):\n","        if self.source_vocab_array is None:\n","            self.source_vocab_array = np.array(self.source_vocab)\n","        return self.source_vocab_array\n","\n","    def get_source_vocab_counts(self):\n","        return self.source_vocab_counts\n","\n","    def set_source_vocab_counts(self, source_vocab_counts):\n","        self.source_vocab_counts = source_vocab_counts\n","\n","    def get_target_encodings(self):\n","        return self.target_encodings\n","\n","    def set_target_encodings(self, target_encodings):\n","        del self.target_encodings\n","        self.target_encodings = target_encodings\n","        if is_remote_execution:\n","            torch.cuda.empty_cache()\n","\n","    def get_source_encodings(self):\n","        return self.source_encodings\n","\n","    def set_source_encodings(self, source_encodings):\n","        del self.source_encodings\n","        self.source_encodings = source_encodings\n","        if is_remote_execution:\n","            torch.cuda.empty_cache()\n","\n","    def get_target_encodings_train(self):\n","        return self.target_encodings_train\n","\n","    def set_target_encodings_train(self, target_encodings_train):\n","        del self.target_encodings_train\n","        self.target_encodings_train = target_encodings_train\n","        if is_remote_execution:\n","            torch.cuda.empty_cache()\n","\n","    def get_source_encodings_train(self):\n","        return self.source_encodings_train\n","\n","    def set_source_encodings_train(self, source_encodings_train):\n","        del self.source_encodings_train\n","        self.source_encodings_train = source_encodings_train\n","        if is_remote_execution:\n","            torch.cuda.empty_cache()\n","\n","    def get_target_encodings_test(self):\n","        return self.target_encodings_test\n","\n","    def set_target_encodings_test(self, target_encodings_test):\n","        del self.target_encodings_test\n","        self.target_encodings_test = target_encodings_test\n","        if is_remote_execution:\n","            torch.cuda.empty_cache()\n","\n","    def get_source_encodings_test(self):\n","        return self.source_encodings_test\n","\n","    def set_source_encodings_test(self, source_encodings_test):\n","        del self.source_encodings_test\n","        self.source_encodings_test = source_encodings_test\n","        if is_remote_execution:\n","            torch.cuda.empty_cache()\n","\n","    def get_max_src_seq_obs(self):\n","        return self.max_src_seq_obs\n","\n","    def set_max_src_seq_obs(self, max_src_seq_obs):\n","        self.max_src_seq_obs = max_src_seq_obs\n","\n","    def get_max_tgt_seq_obs(self):\n","        return self.max_tgt_seq_obs\n","\n","    def set_max_tgt_seq_obs(self, max_tgt_seq_obs):\n","        self.max_tgt_seq_obs = max_tgt_seq_obs\n","\n","# class name matches file name\n","class transformer_vaswani2017(torch.nn.Transformer):\n","\n","    def __init__(self,\n","                 model_hyperparameters):\n","        super().__init__(\n","            d_model=model_hyperparameters['d_model'],\n","            nhead=model_hyperparameters['nhead'],\n","            num_encoder_layers=model_hyperparameters['num_encoder_layers'],\n","            num_decoder_layers=model_hyperparameters['num_decoder_layers'],\n","            dim_feedforward=model_hyperparameters['dim_feedforward'],\n","            dropout=model_hyperparameters['dropout'],\n","            activation=model_hyperparameters['activation'],\n","            custom_encoder=model_hyperparameters['custom_encoder'],\n","            custom_decoder=model_hyperparameters['custom_decoder'],\n","            layer_norm_eps=model_hyperparameters['layer_norm_eps'],\n","            batch_first=model_hyperparameters['batch_first'],\n","            norm_first=model_hyperparameters['norm_first'],\n","            bias=model_hyperparameters['bias'],\n","            device=model_hyperparameters['device'],\n","            dtype=model_hyperparameters['dtype']\n","        )\n","        self.model_hyperparameters = model_hyperparameters\n","        # add one for the end of sequence token\n","        self.max_src_seq_len = model_hyperparameters['max_src_seq_len'] + 1\n","        self.max_tgt_seq_len = model_hyperparameters['max_tgt_seq_len'] + 1\n","        self.src_embeddings = torch.nn.Embedding(\n","            model_hyperparameters['src_vocab_size'],\n","            model_hyperparameters['d_model']\n","        )\n","        self.tgt_embeddings = torch.nn.Embedding(\n","            model_hyperparameters['tgt_vocab_size'],\n","            model_hyperparameters['d_model']\n","        )\n","        self.src_pos_enc = torch.nn.Embedding(\n","            self.max_src_seq_len,\n","            model_hyperparameters['d_model']\n","        ).requires_grad_(False)\n","        self.tgt_pos_enc = torch.nn.Embedding(\n","            self.max_tgt_seq_len,\n","            model_hyperparameters['d_model']\n","        ).requires_grad_(False)\n","        self.linear_output_projection_1 = torch.nn.Linear(\n","            self.max_tgt_seq_len,\n","            1,\n","            bias=False\n","        )\n","        self.linear_output_projection_2 = torch.nn.Linear(\n","            model_hyperparameters['d_model'],\n","            model_hyperparameters['tgt_vocab_size'],\n","            bias=False\n","        )\n","        self.logsoftmax_output = torch.nn.LogSoftmax(dim=1)\n","        self.model_hyperparameters = model_hyperparameters\n","        self.tgt_mask_cache = {}\n","        for i in range(0, self.max_tgt_seq_len + 1):\n","            tgt_mask = self.generate_square_subsequent_mask(i)\n","            if is_remote_execution:\n","                self.tgt_mask_cache[i] = tgt_mask.to(device=\"cuda\")\n","            self.tgt_mask_cache[i] = tgt_mask\n","        self.indices_cache = {}\n","        for i in range(0, max([self.max_src_seq_len, self.max_tgt_seq_len]) + 1):\n","            indices = torch.tensor(np.arange(0, i), dtype=torch.long)\n","            if is_remote_execution:\n","                indices = indices.to(device=\"cuda\")\n","            self.indices_cache[i] = indices\n","\n","    def forward(self,\n","                src: torch.Tensor,\n","                tgt: torch.Tensor,\n","                src_mask: Optional[torch.Tensor] = None,\n","                tgt_mask: Optional[torch.Tensor] = None,\n","                memory_mask: Optional[torch.Tensor] = None,\n","                src_key_padding_mask: Optional[torch.Tensor] = None,\n","                tgt_key_padding_mask: Optional[torch.Tensor] = None,\n","                memory_key_padding_mask: Optional[torch.Tensor] = None,\n","                src_is_causal: Optional[bool] = None,\n","                tgt_is_causal: Optional[bool] = True,\n","                memory_is_causal: bool = False) -> torch.Tensor:\n","        if len(src.shape) == 1:\n","            src = src.unsqueeze(dim=0)\n","        if len(tgt.shape) == 1:\n","            tgt = tgt.unsqueeze(dim=0)\n","        src_embedding_pos_enc = self.src_embeddings(src) + self.src_pos_enc(self.indices_cache[src.shape[1]])\n","        tgt_embedding_pos_enc = self.tgt_embeddings(tgt) + self.tgt_pos_enc(self.indices_cache[tgt.shape[1]])\n","        tgt_mask = self.tgt_mask_cache[tgt.shape[1]]\n","        transformer_output = super().forward(src_embedding_pos_enc, tgt_embedding_pos_enc, src_mask,\n","                                             tgt_mask, memory_mask, src_key_padding_mask,\n","                                             tgt_key_padding_mask, memory_key_padding_mask,\n","                                             src_is_causal, tgt_is_causal, memory_is_causal)\n","        transformer_output = torch.swapaxes(transformer_output, -1, -2)\n","        transformer_output = torch.nn.functional.pad(\n","            transformer_output,\n","            (0, self.max_tgt_seq_len - transformer_output.shape[2]),\n","            value=0\n","        )\n","        output = self.logsoftmax_output(\n","            self.linear_output_projection_2(\n","                torch.squeeze(\n","                    self.linear_output_projection_1(\n","                        transformer_output\n","                    ),\n","                    dim=2\n","                )\n","            )\n","        )\n","        del src_embedding_pos_enc\n","        del tgt_embedding_pos_enc\n","        del transformer_output\n","        return output\n","\n","    def freeze_target_embeddings(self):\n","        del self.tgt_embeddings\n","        self.tgt_embeddings = torch.nn.Embedding(\n","            self.model_hyperparameters['tgt_vocab_size'],\n","            self.model_hyperparameters['d_model']\n","        ).requires_grad_(False)\n","        del self.linear_output_projection_1\n","        self.linear_output_projection_1 = torch.nn.Linear(\n","            self.max_tgt_seq_len,\n","            1,\n","            bias=False\n","        ).requires_grad_(False)\n","        del self.linear_output_projection_2\n","        self.linear_output_projection_2 = torch.nn.Linear(\n","            self.model_hyperparameters['d_model'],\n","            self.model_hyperparameters['tgt_vocab_size'],\n","            bias=False\n","        ).requires_grad_(False)\n","\n","    def set_source_embeddings_for_transfer_learning(self, source_embeddings_dim):\n","        del self.src_embeddings\n","        self.src_embeddings = torch.nn.Embedding(\n","            source_embeddings_dim,\n","            self.model_hyperparameters['d_model']\n","        )\n","\n","\n","class Runner:\n","\n","    def __init__(self):\n","        self.runner_hyperparameters = NewsCommentaryByT5Vaswani2017Kocmi2018_2\n","        self.model_hyperparameters = self.runner_hyperparameters['model_hyperparameters']\n","        self.runner_hyperparameters_name = self.runner_hyperparameters['runner_hyperparameters_name']\n","        self.model_parameter_filepath = self.runner_hyperparameters['model_parameter_filepath']\n","        self.datasets_filepath = self.runner_hyperparameters['datasets_filepath']\n","        self.output_filepath = self.runner_hyperparameters['output_filepath']\n","        self.max_target_sequence_length = self.runner_hyperparameters['model_hyperparameters']['max_tgt_seq_len']\n","        self.dataset_holder: DatasetHolder = None\n","        self.model = None\n","        print(f\"Initialized runner {self.runner_hyperparameters_name} with parameters {self.runner_hyperparameters}\")\n","\n","    def load_dataset(self):\n","        self.dataset_holder = torch.load(self.datasets_filepath)\n","\n","    def load_model(self):\n","        self.model = transformer_vaswani2017(model_hyperparameters=self.model_hyperparameters)\n","        self.model.freeze_target_embeddings()\n","        if is_remote_execution:\n","            model_parameters = torch.load(self.model_parameter_filepath, map_location=torch.device('cuda'))\n","        else:\n","            model_parameters = torch.load(self.model_parameter_filepath, map_location=torch.device('cpu'))\n","        self.model.load_state_dict(model_parameters)\n","        if is_remote_execution:\n","            self.model.cuda()\n","        self.model.eval()\n","\n","    def evaluate_model(self):\n","        outputs = list()\n","        source_vocab_numpy = self.dataset_holder.get_source_vocab_numpy()\n","        target_vocab_numpy = self.dataset_holder.get_target_vocab_numpy()\n","        assert len(self.dataset_holder.get_source_encodings_test()) == len(self.dataset_holder.get_target_encodings_test())\n","        for i in range(0, len(self.dataset_holder.get_source_encodings_test())):\n","            if is_remote_execution:\n","                source_encoding = self.dataset_holder.get_source_encodings_test()[i].to(device=\"cuda\")\n","                target_encoding = self.dataset_holder.get_target_encodings_test()[i].to(device=\"cuda\")\n","            else:\n","                source_encoding = self.dataset_holder.get_source_encodings_test()[i].to(device=\"cpu\")\n","                target_encoding = self.dataset_holder.get_target_encodings_test()[i].to(device=\"cpu\")\n","            j = 0\n","            end_of_sequence = False\n","            while j < self.model_hyperparameters['max_tgt_seq_len'] and end_of_sequence == False:\n","                target_encoding_slice = torch.tensor_split(target_encoding, [j], dim=0)\n","                output_logits = self.model.forward(\n","                    source_encoding,\n","                    target_encoding_slice[0]\n","                ).detach().to(device=\"cpu\").flatten().numpy()\n","                output_logits_sort_pairs = list()\n","                for k in range(0, len(output_logits)):\n","                    output_logits_sort_pairs.append([output_logits[k], k])\n","                output_logits_sorted = sorted(output_logits_sort_pairs, key=lambda logit_pair: logit_pair[0], reverse=True)\n","                output_sort_index = 0\n","                # don't pick mark up characters or whitespace if first term\n","                if j == 0:\n","                    while output_logits_sorted[output_sort_index][1] in (0, 1, 2, 7):\n","                        output_sort_index = output_sort_index + 1\n","                else:\n","                    # don't repeat unknown, padding, or spaces\n","                    if (prediction_encoding[j-1] == 0\n","                            or prediction_encoding[j-1] == 1\n","                            or prediction_encoding[j-1] == 7):\n","                        while (output_logits_sorted[output_sort_index][1] == 0\n","                               or output_logits_sorted[output_sort_index][1] == 1\n","                               or output_logits_sorted[output_sort_index][1] == 7):\n","                            output_sort_index = output_sort_index + 1\n","                output_vocab_index = output_logits_sorted[output_sort_index][1]\n","                # index = output_vocab_index # always outputs \"Krrrr...<eos>\"\n","                index = min(random.randint(output_vocab_index, output_vocab_index + 3), len(output_logits_sorted))\n","                if j == 0:\n","                    prediction_encoding = torch.tensor([output_logits_sorted[index][1]], dtype=torch.float)\n","                else:\n","                    prediction_encoding = torch.cat([prediction_encoding, torch.tensor([output_logits_sorted[index][1]], dtype=torch.float)])\n","                if prediction_encoding[j] == self.dataset_holder.get_target_vocab().index(\n","                        self.dataset_holder.get_end_of_sequence_vocabulary_type()):\n","                    end_of_sequence = True\n","                j = j + 1\n","            decoded_source = np.take(source_vocab_numpy, source_encoding.detach().to(device=\"cpu\").flatten().numpy())\n","            decoded_target = np.take(target_vocab_numpy, target_encoding.detach().to(device=\"cpu\").flatten().numpy())\n","            decoded_translation = np.take(target_vocab_numpy, prediction_encoding.detach().to(device=\"cpu\", dtype=torch.int32).numpy())\n","            outputs.append({\n","                \"source\": \"\".join(decoded_source.tolist()),\n","                \"target\": \"\".join(decoded_target.tolist()),\n","                \"translation\": \"\".join(decoded_translation.tolist())\n","            })\n","            del source_encoding\n","            del target_encoding\n","            del prediction_encoding\n","            del target_encoding_slice\n","            del decoded_source\n","            del decoded_target\n","            del decoded_translation\n","            print(f\"Completed translation {i} of {len(self.dataset_holder.get_source_encodings_test())} at {time.time()}\")\n","            if is_remote_execution:\n","                torch.cuda.empty_cache()\n","                if i % 100 == 0:\n","                    print(f\"Memory usage summary:\")\n","                    print(f\"{torch.cuda.memory_summary()}\")\n","                    torch.cuda.reset_max_memory_allocated()\n","                    torch.cuda.reset_max_memory_cached()\n","                    torch.cuda.reset_peak_memory_stats()\n","            if i % 100 == 0 or i == len(self.dataset_holder.get_source_encodings_test()) - 1:\n","                print(f\"Translation{i}: {outputs[i]}\")\n","                output_file = open(self.output_filepath, \"w\")\n","                output_file.write(json.dumps(outputs, ensure_ascii=False, indent=1))\n","                output_file.close()\n","\n","\n","runner = Runner()\n","runner.load_dataset()\n","runner.load_model()\n","runner.evaluate_model()\n"]}]}