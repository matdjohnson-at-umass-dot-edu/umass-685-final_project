{"cells":[{"cell_type":"markdown","metadata":{"id":"XxChZLAKliXg"},"source":["Content taken from GitHub repository hosting the code:\n","\n","https://github.com/matthewjohnson42/umass-cs685-finalproject\n","\n","Substantial modifications made to adapt to Colab training environment."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24226,"status":"ok","timestamp":1715909639737,"user":{"displayName":"Matthew Johnson","userId":"09672185346885346735"},"user_tz":240},"id":"U0NG9bOzleFZ","outputId":"12035f0b-8967-4151-8a72-a8205c565aba"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":1}],"source":["from google.colab import drive\n","\n","import torch\n","import numpy as np\n","\n","import random\n","from typing import Optional\n","import time\n","import os\n","import gc\n","\n","\n","drive.mount('/content/drive', force_remount=True)\n","root_filepath = '/content/drive/MyDrive/CS685-NLP-GroupProject/Code/singleNotebookFromPythonFilesStructure/'\n","is_remote_execution = True\n","\n","torch.device(\"cuda\")"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":159,"status":"ok","timestamp":1715909639893,"user":{"displayName":"Matthew Johnson","userId":"09672185346885346735"},"user_tz":240},"id":"sllajv_0n2Vu"},"outputs":[],"source":["SETimesByT5Vaswani2017Kocmi2018_0 = {\n","    'dataset_transformer_name': 'dataset_transformer_setimesbyt5',\n","    'model_name': 'transformer_vaswani2017',\n","    'trainer_name': 'model_trainer_kocmi2018',\n","    'latest_param_filename_tag': '1715741500',\n","    # corresponds to dictionary 'get' calls in the dataset_loader constructor\n","    'dataset_transformer_hyperparameters': {\n","        'sentence_length_min_percentile': 5,\n","        'sentence_length_max_percentile': 95,\n","        'parsed_dataset_filename': 'setimes_parsed-1715586293'\n","    },\n","    # corresponds to dictionary 'get' calls in the model constructor\n","    'model_hyperparameters': {\n","        'd_model': 256,\n","        'nhead': 8,\n","        # number of encoders is 3 times that of decoders, following Xue 2021 - ByT5 - Sec 3.1\n","        'num_encoder_layers': 9,\n","        'num_decoder_layers': 3,\n","        'dim_feedforward': 2048,\n","        'dropout': 0.1,\n","        'activation': torch.nn.functional.relu,\n","        'custom_encoder': None,\n","        'custom_decoder': None,\n","        'layer_norm_eps': 1e-5,\n","        'batch_first': True,\n","        'norm_first': False,\n","        'bias': True,\n","        'device': None,\n","        'dtype': None\n","    },\n","    # corresponds to dictionary 'get' calls in the trainer constructor\n","    'trainer_hyperparameters': {\n","        # optimization and lr schedule following Kocmi 2018 - Trivial TL - Sec 3\n","        'optimizer_name': 'Adam',\n","        'lr_scheduler_name': 'ExponentialLR',\n","        'initial_lr': 0.001,\n","        'exp_decay': 0.5,\n","        'epochs': 10,\n","        'epoch_starting_index': 1,\n","        'batch_size_limit': 175,\n","        'element_difference_limit': 19,\n","        'batch_starting_index': 0\n","    }\n","}\n","\n","SETimesByT5Vaswani2017Kocmi2018_1 = {\n","    'dataset_transformer_name': 'dataset_transformer_setimesbyt5',\n","    'model_name': 'transformer_vaswani2017',\n","    'trainer_name': 'model_trainer_kocmi2018',\n","    'latest_param_filename_tag': '1715741441',\n","    # corresponds to dictionary 'get' calls in the dataset_loader constructor\n","    'dataset_transformer_hyperparameters': {\n","        'sentence_length_min_percentile': 5,\n","        'sentence_length_max_percentile': 95,\n","        'parsed_dataset_filename': 'setimes_parsed-1715586974'\n","    },\n","    # corresponds to dictionary 'get' calls in the model constructor\n","    'model_hyperparameters': {\n","        'd_model': 256,\n","        'nhead': 8,\n","        # number of encoders is 3 times that of decoders, following Xue 2021 - ByT5 - Sec 3.1\n","        'num_encoder_layers': 9,\n","        'num_decoder_layers': 3,\n","        'dim_feedforward': 1796,\n","        'dropout': 0.1,\n","        'activation': torch.nn.functional.relu,\n","        'custom_encoder': None,\n","        'custom_decoder': None,\n","        'layer_norm_eps': 1e-5,\n","        'batch_first': True,\n","        'norm_first': False,\n","        'bias': True,\n","        'device': None,\n","        'dtype': None\n","    },\n","    # corresponds to dictionary 'get' calls in the trainer constructor\n","    'trainer_hyperparameters': {\n","        # optimization and lr schedule following Kocmi 2018 - Trivial TL - Sec 3\n","        'optimizer_name': 'Adam',\n","        'lr_scheduler_name': 'ExponentialLR',\n","        'initial_lr': 0.001,\n","        'exp_decay': 0.5,\n","        'epochs': 10,\n","        'epoch_starting_index': 1,\n","        'batch_size_limit': 250,\n","        'element_difference_limit': 19,\n","        'batch_starting_index': 84\n","    }\n","}\n","\n","SETimesByT5Vaswani2017Kocmi2018_2 = {\n","    'dataset_transformer_name': 'dataset_transformer_setimesbyt5',\n","    'model_name': 'transformer_vaswani2017',\n","    'trainer_name': 'model_trainer_kocmi2018',\n","    'latest_param_filename_tag': '1715672061',\n","    # corresponds to dictionary 'get' calls in the dataset_loader constructor\n","    'dataset_transformer_hyperparameters': {\n","        'sentence_length_min_percentile': 5,\n","        'sentence_length_max_percentile': 95,\n","        'parsed_dataset_filename': 'setimes_parsed-1715586361'\n","    },\n","    # corresponds to dictionary 'get' calls in the model constructor\n","    'model_hyperparameters': {\n","        'd_model': 128,\n","        'nhead': 8,\n","        # number of encoders is 3 times that of decoders, following Xue 2021 - ByT5 - Sec 3.1\n","        'num_encoder_layers': 9,\n","        'num_decoder_layers': 3,\n","        'dim_feedforward': 1024,\n","        'dropout': 0.1,\n","        'activation': torch.nn.functional.relu,\n","        'custom_encoder': None,\n","        'custom_decoder': None,\n","        'layer_norm_eps': 1e-5,\n","        'batch_first': True,\n","        'norm_first': False,\n","        'bias': True,\n","        'device': None,\n","        'dtype': None\n","    },\n","    # corresponds to dictionary 'get' calls in the trainer constructor\n","    'trainer_hyperparameters': {\n","        # optimization and lr schedule following Kocmi 2018 - Trivial TL - Sec 3\n","        'optimizer_name': 'Adam',\n","        'lr_scheduler_name': 'ExponentialLR',\n","        'initial_lr': 0.001,\n","        'exp_decay': 0.5,\n","        'epochs': 10,\n","        'epoch_starting_index': 1,\n","        'batch_size_limit': 400,\n","        'element_difference_limit': 19,\n","        'batch_starting_index': 0\n","    }\n","}\n","\n","loss_weights_0 = torch.tensor([0, 0, 0.244293498, 0.354252208, 0.119055746, 0.129490827, 0.234447, 0.331966255, 0.062493498, 0.200436672, 0.128134531, 0.115730135, 0.114789455, 0.111928721, 0.120232896, 0.172708905, 0.091552235, 0.18382728, 0.167772254, 0.221570123, 0.26933557, 0.207267199, 0.161156936, 0.163208063, 0.206129376, 0.1923278, 0.246448966, 0.309805116, 0.312319847, 0.341492611, 0.287077958, 0.317765776, 0.282694925, 0.328107375, 0.305618951, 0.342956521, 0.33013427, 0.36810305, 0.29995848, 0.39787945, 0.36195021, 0.231575726, 0.238716465, 0.228047462, 0.589442629, 0.428540415, 0.349514641, 0.428583838, 0.372321337, 0.35910363, 0.314836573, 0.359830778, 0.329628544, 0.358553271, 0.38731315, 0.301171514, 0.414866271, 0.454463773, 0.410552656, 0.418645272, 0.489374491, 0.60674051, 0.415410876, 0.387694004, 0.469862412, 0.387466491, 0.404244134, 0.410692024, 0.3650963, 0.328332631, 0.362047807, 0.390990331, 0.407611852, 0.353090879, 0.519082435, 0.465516001, 0.382984849, 0.382904558, 0.417591599, 0.47406963, 0.513595183, 0.561900207, 0.600687916, 0.552947486, 0.672534847, 0.775971182, 0.728910416, 0.783069437, 0.726598021, 0.870987145, 0.761128877, 0.716818395, 0.708372474, 0.70507743, 0.731312344, 0.718124592, 0.931839821, 0.675783865, 0.863679642, 0.79786095, 0.870987145, 0.888835536, 0.845831251, 0.845831251, 0.870987145, 0.831986963, 0.817320914, 0.888835536, 0.82798286, 0.931839821, 0.900147142, 0.91399143, 0.91399143, 0.956995715, 0.931839821, 1, 0.900147142, 0.870987145, 0.870987145, 1, 0.900147142, 0.888835536, 0.956995715, 0.824221583, 1, 1, 0.956995715, 1, 0.931839821, 0.931839821, 0.956995715, 0.956995715, 0.956995715, 0.888835536, 0.931839821, 1, 0.900147142, 0.91399143, 0.956995715, 0.956995715, 0.956995715, 1, 1, 1, 0.900147142, 0.931839821, 0.900147142, 0.931839821, 0.956995715, 0.91399143, 1, 0.956995715, 1, 1, 1, 1, 1, 0.956995715, 1, 1, 1, 1, 1, 1, 1, 0.931839821, 1, 0.956995715, 1, 1, 0.956995715])\n","loss_weights_1 = torch.tensor([0, 0, 0.283786926, 0.387999164, 0.165094134, 0.174983875, 0.274455009, 0.366877881, 0.111487844, 0.242222071, 0.173698459, 0.16194232, 0.1610508, 0.158339569, 0.166209765, 0.215943364, 0.139027964, 0.226480689, 0.211264704, 0.262251081, 0.307520293, 0.248695632, 0.204995104, 0.206939038, 0.247617272, 0.23453697, 0.285829749, 0.345874889, 0.3482582, 0.375906387, 0.324335459, 0.353419523, 0.320181484, 0.363220667, 0.341907494, 0.377293793, 0.365141636, 0.401126157, 0.336542841, 0.429346435, 0.395294867, 0.271733788, 0.27850135, 0.268389913, 0.610898469, 0.458405049, 0.383509184, 0.458446203, 0.405123996, 0.39259705, 0.350643401, 0.393286196, 0.36466234, 0.392075452, 0.419332333, 0.337692481, 0.44544552, 0.482973645, 0.441357336, 0.449027029, 0.51605992, 0.627292358, 0.445961663, 0.419693282, 0.497567547, 0.419477659, 0.435378499, 0.44148942, 0.398276541, 0.363434152, 0.395387363, 0.422817343, 0.438570219, 0.386898527, 0.544215318, 0.493448281, 0.415230229, 0.415154135, 0.448028421, 0.501554895, 0.539014832, 0.584795422, 0.621556075, 0.576310573, 0.689648265, 0.78767899, 0.743077631, 0.794406288, 0.740886083, 0.877729392, 0.773612348, 0.731617543, 0.723613008, 0.720490164, 0.745354034, 0.732855478, 0.93540189, 0.692727489, 0.870803781, 0.808424792, 0.877729392, 0.894645021, 0.853888152, 0.853888152, 0.877729392, 0.84076737, 0.826867773, 0.894645021, 0.836972522, 0.93540189, 0.90536548, 0.918486261, 0.918486261, 0.959243131, 0.93540189, 1, 0.90536548, 0.877729392, 0.877729392, 1, 0.90536548, 0.894645021, 0.959243131, 0.833407811, 1, 1, 0.959243131, 1, 0.93540189, 0.93540189, 0.959243131, 0.959243131, 0.959243131, 0.894645021, 0.93540189, 1, 0.90536548, 0.918486261, 0.959243131, 0.959243131, 0.959243131, 1, 1, 1, 0.90536548, 0.93540189, 0.90536548, 0.93540189, 0.959243131, 0.918486261, 1, 0.959243131, 1, 1, 1, 1, 1, 0.959243131, 1, 1, 1, 1, 1, 1, 1, 0.93540189, 1, 0.959243131, 1, 1, 0.959243131])\n","\n","english_char_mappings = {\n","    ord(\" \"): ord(\" \"),\n","    ord(\"e\"): ord(\"e\"),\n","    ord(\"t\"): ord(\"t\"),\n","    ord(\"a\"): ord(\"a\"),\n","    ord(\"i\"): ord(\"i\"),\n","    ord(\"o\"): ord(\"o\"),\n","    ord(\"n\"): ord(\"n\"),\n","    ord(\"r\"): ord(\"r\"),\n","    ord(\"s\"): ord(\"s\"),\n","    ord(\"h\"): ord(\"h\"),\n","    ord(\"l\"): ord(\"l\"),\n","    ord(\"d\"): ord(\"d\"),\n","    ord(\"c\"): ord(\"c\"),\n","    ord(\"u\"): ord(\"u\"),\n","    ord(\"m\"): ord(\"m\"),\n","    ord(\"p\"): ord(\"p\"),\n","    ord(\"f\"): ord(\"f\"),\n","    ord(\"g\"): ord(\"g\"),\n","    ord(\"y\"): ord(\"y\"),\n","    ord(\"b\"): ord(\"b\"),\n","    ord(\"w\"): ord(\"w\"),\n","    ord(\"v\"): ord(\"v\"),\n","    ord(\",\"): ord(\",\"),\n","    ord(\".\"): ord(\".\"),\n","    ord(\"k\"): ord(\"k\"),\n","    ord(\"T\"): ord(\"T\"),\n","    ord(\"S\"): ord(\"S\"),\n","    ord(\"0\"): ord(\"0\"),\n","    ord(\"A\"): ord(\"A\"),\n","    ord(\"-\"): ord(\"-\"),\n","    ord(\"B\"): ord(\"B\"),\n","    ord(\"M\"): ord(\"M\"),\n","    ord(\"\\\"\"): ord(\"\\\"\"),\n","    ord(\"E\"): ord(\"E\"),\n","    ord(\"P\"): ord(\"P\"),\n","    ord(\"C\"): ord(\"C\"),\n","    ord(\"I\"): ord(\"I\"),\n","    ord(\"1\"): ord(\"1\"),\n","    ord(\"'\"): ord(\"'\"),\n","    ord(\"j\"): ord(\"j\"),\n","    ord(\"2\"): ord(\"2\"),\n","    ord(\"R\"): ord(\"R\"),\n","    ord(\"U\"): ord(\"U\"),\n","    ord(\"K\"): ord(\"K\"),\n","    ord(\"D\"): ord(\"D\"),\n","    ord(\"x\"): ord(\"x\"),\n","    ord(\"H\"): ord(\"H\"),\n","    ord(\"F\"): ord(\"F\"),\n","    ord(\"N\"): ord(\"N\"),\n","    ord(\"G\"): ord(\"G\"),\n","    ord(\"/\"): ord(\"/\"),\n","    ord(\"O\"): ord(\"O\"),\n","    ord(\")\"): ord(\")\"),\n","    ord(\"(\"): ord(\"(\"),\n","    ord(\"9\"): ord(\"9\"),\n","    ord(\"W\"): ord(\"W\"),\n","    ord(\"z\"): ord(\"z\"),\n","    ord(\"5\"): ord(\"5\"),\n","    ord(\"3\"): ord(\"3\"),\n","    ord(\"J\"): ord(\"J\"),\n","    ord(\"4\"): ord(\"4\"),\n","    ord(\"q\"): ord(\"q\"),\n","    ord(\"L\"): ord(\"L\"),\n","    ord(\"6\"): ord(\"6\"),\n","    ord(\"7\"): ord(\"7\"),\n","    ord(\"8\"): ord(\"8\"),\n","    ord(\"V\"): ord(\"V\"),\n","    ord(\"[\"): ord(\"[\"),\n","    ord(\"]\"): ord(\"]\"),\n","    ord(\":\"): ord(\":\"),\n","    ord(\"Z\"): ord(\"Z\"),\n","    ord(\"%\"): ord(\"%\"),\n","    ord(\"Y\"): ord(\"Y\"),\n","    ord(\";\"): ord(\";\"),\n","    ord(\"–\"): ord(\"-\"),\n","    ord(\"?\"): ord(\"?\"),\n","    ord(\"X\"): ord(\"X\"),\n","    ord(\"$\"): ord(\"$\"),\n","    ord(\"’\"): ord(\"'\"),\n","    ord(\"Q\"): ord(\"Q\"),\n","    ord(\"…\"): ord(\"\\u0120\"),\n","    ord(\"!\"): ord(\"\\u0120\"),\n","    ord(\"&\"): ord(\"\\u0120\"),\n","    ord(\"ć\"): ord(\"\\u0120\"),\n","    ord(\"”\"): ord(\"\\\"\"),\n","    ord(\"é\"): ord(\"\\u0120\"),\n","    ord(\"“\"): ord(\"\\\"\"),\n","    ord(\"ı\"): ord(\"\\u0120\"),\n","    ord(\"ü\"): ord(\"\\u0120\"),\n","    ord(\"+\"): ord(\"\\u0120\"),\n","    ord(\"ç\"): ord(\"\\u0120\"),\n","    ord(\"ˈ\"): ord(\"'\"),\n","    ord(\"ö\"): ord(\"\\u0120\"),\n","    ord(\"ë\"): ord(\"\\u0120\"),\n","    ord(\"Ç\"): ord(\"\\u0120\"),\n","    ord(\"ğ\"): ord(\"\\u0120\"),\n","    ord(\"č\"): ord(\"\\u0120\"),\n","    ord(\"š\"): ord(\"\\u0120\"),\n","    ord(\"‘\"): ord(\"'\"),\n","    ord(\"ž\"): ord(\"\\u0120\"),\n","    ord(\"*\"): ord(\"\\u0120\"),\n","    ord(\"ş\"): ord(\"\\u0120\"),\n","    ord(\"б\"): ord(\"\\u0120\"),\n","    ord(\"Š\"): ord(\"\\u0120\"),\n","    ord(\"İ\"): ord(\"\\u0120\"),\n","    ord(\"à\"): ord(\"\\u0120\"),\n","    ord(\"г\"): ord(\"\\u0120\"),\n","    ord(\"ï\"): ord(\"\\u0120\"),\n","    ord(\"Ü\"): ord(\"\\u0120\"),\n","    ord(\"—\"): ord(\"-\"),\n","    ord(\"€\"): ord(\"\\u0120\"),\n","    ord(\"Ö\"): ord(\"\\u0120\"),\n","    ord(\"đ\"): ord(\"\\u0120\"),\n","    ord(\"\\\\\"): ord(\"\\u0120\"),\n","    ord(\"Ι\"): ord(\"\\u0120\"),\n","    ord(\"Α\"): ord(\"A\"),\n","    ord(\"`\"): ord(\"'\"),\n","    ord(\"_\"): ord(\"\\u0120\"),\n","    ord(\"=\"): ord(\"\\u0120\"),\n","    ord(\"@\"): ord(\"\\u0120\"),\n","    ord(\"А\"): ord(\"A\"),\n","    ord(\"ó\"): ord(\"\\u0120\"),\n","    ord(\"í\"): ord(\"\\u0120\"),\n","    ord(\"â\"): ord(\"\\u0120\"),\n","    ord(\"\\x80\"): ord(\"\\u0120\"),\n","    ord(\"Ž\"): ord(\"\\u0120\"),\n","    ord(\"Κ\"): ord(\"K\"),\n","    ord(\"Ο\"): ord(\"O\"),\n","    ord(\"р\"): ord(\"p\"),\n","    ord(\"Ş\"): ord(\"\\u0120\"),\n","    ord(\"á\"): ord(\"\\u0120\"),\n","    ord(\"у\"): ord(\"y\"),\n","    ord(\"\\x93\"): ord(\"\\u0120\"),\n","    ord(\"°\"): ord(\"\\u0120\"),\n","    ord(\"<\"): ord(\"\\u0120\"),\n","    ord(\"½\"): ord(\"\\u0120\"),\n","    ord(\"Т\"): ord(\"T\"),\n","    ord(\"ø\"): ord(\"\\u0120\"),\n","    ord(\"Ε\"): ord(\"E\"),\n","    ord(\"#\"): ord(\"\\u0120\"),\n","    ord(\"ý\"): ord(\"\\u0120\"),\n","    ord(\"л\"): ord(\"\\u0120\"),\n","    ord(\"я\"): ord(\"\\u0120\"),\n","    ord(\"�\"): ord(\"\\u0120\"),\n","    ord(\"º\"): ord(\"\\u0120\"),\n","    ord(\"ä\"): ord(\"\\u0120\"),\n","    ord(\"е\"): ord(\"e\"),\n","    ord(\"о\"): ord(\"o\"),\n","    ord(\"Đ\"): ord(\"\\u0120\"),\n","    ord(\"è\"): ord(\"\\u0120\"),\n","    ord(\"¾\"): ord(\"\\u0120\"),\n","    ord(\"\\x96\"): ord(\"\\u0120\"),\n","    ord(\"æ\"): ord(\"\\u0120\"),\n","    ord(\">\"): ord(\"\\u0120\"),\n","    ord(\"¦\"): ord(\"\\u0120\"),\n","    ord(\"μ\"): ord(\"\\u0120\"),\n","    ord(\"Č\"): ord(\"\\u0120\"),\n","    ord(\"ñ\"): ord(\"\\u0120\"),\n","    ord(\"х\"): ord(\"x\"),\n","    ord(\"М\"): ord(\"M\"),\n","    ord(\"É\"): ord(\"\\u0120\"),\n","    ord(\"±\"): ord(\"\\u0120\"),\n","    ord(\"£\"): ord(\"\\u0120\"),\n","    ord(\"{\"): ord(\"\\u0120\"),\n","    ord(\"}\"): ord(\"\\u0120\"),\n","    ord(\"ъ\"): ord(\"\\u0120\"),\n","    ord(\"а\"): ord(\"\\u0120\"),\n","    ord(\"и\"): ord(\"\\u0120\")\n","}\n","\n","turkish_char_mappings = {\n","    ord(\" \"): ord(\" \"),\n","    ord(\"a\"): ord(\"a\"),\n","    ord(\"e\"): ord(\"e\"),\n","    ord(\"i\"): ord(\"i\"),\n","    ord(\"n\"): ord(\"n\"),\n","    ord(\"r\"): ord(\"r\"),\n","    ord(\"l\"): ord(\"l\"),\n","    ord(\"ı\"): ord(\"ı\"),\n","    ord(\"k\"): ord(\"k\"),\n","    ord(\"d\"): ord(\"d\"),\n","    ord(\"t\"): ord(\"t\"),\n","    ord(\"s\"): ord(\"s\"),\n","    ord(\"u\"): ord(\"u\"),\n","    ord(\"m\"): ord(\"m\"),\n","    ord(\"y\"): ord(\"y\"),\n","    ord(\"o\"): ord(\"o\"),\n","    ord(\"ü\"): ord(\"ü\"),\n","    ord(\"b\"): ord(\"b\"),\n","    ord(\"ş\"): ord(\"ş\"),\n","    ord(\"v\"): ord(\"v\"),\n","    ord(\"g\"): ord(\"g\"),\n","    ord(\"z\"): ord(\"z\"),\n","    ord(\"ç\"): ord(\"ç\"),\n","    ord(\"ğ\"): ord(\"ğ\"),\n","    ord(\".\"): ord(\".\"),\n","    ord(\",\"): ord(\",\"),\n","    ord(\"c\"): ord(\"c\"),\n","    ord(\"h\"): ord(\"h\"),\n","    ord(\"p\"): ord(\"p\"),\n","    ord(\"ö\"): ord(\"ö\"),\n","    ord(\"'\"): ord(\"'\"),\n","    ord(\"B\"): ord(\"B\"),\n","    ord(\"A\"): ord(\"A\"),\n","    ord(\"f\"): ord(\"f\"),\n","    ord(\"S\"): ord(\"S\"),\n","    ord(\"K\"): ord(\"K\"),\n","    ord(\"0\"): ord(\"0\"),\n","    ord(\"\\\"\"): ord(\"\\\"\"),\n","    ord(\"T\"): ord(\"T\"),\n","    ord(\"M\"): ord(\"M\"),\n","    ord(\"1\"): ord(\"1\"),\n","    ord(\"P\"): ord(\"P\"),\n","    ord(\"D\"): ord(\"D\"),\n","    ord(\"H\"): ord(\"H\"),\n","    ord(\"2\"): ord(\"2\"),\n","    ord(\"E\"): ord(\"E\"),\n","    ord(\"R\"): ord(\"R\"),\n","    ord(\"-\"): ord(\"-\"),\n","    ord(\"G\"): ord(\"G\"),\n","    ord(\"j\"): ord(\"j\"),\n","    ord(\"Y\"): ord(\"Y\"),\n","    ord(\"C\"): ord(\"C\"),\n","    ord(\"İ\"): ord(\"İ\"),\n","    ord(\"O\"): ord(\"O\"),\n","    ord(\"/\"): ord(\"/\"),\n","    ord(\"F\"): ord(\"F\"),\n","    ord(\"N\"): ord(\"N\"),\n","    ord(\"9\"): ord(\"9\"),\n","    ord(\"5\"): ord(\"5\"),\n","    ord(\"3\"): ord(\"3\"),\n","    ord(\"I\"): ord(\"I\"),\n","    ord(\"4\"): ord(\"4\"),\n","    ord(\"L\"): ord(\"L\"),\n","    ord(\"6\"): ord(\"6\"),\n","    ord(\")\"): ord(\")\"),\n","    ord(\"(\"): ord(\"(\"),\n","    ord(\"7\"): ord(\"7\"),\n","    ord(\"8\"): ord(\"8\"),\n","    ord(\"U\"): ord(\"U\"),\n","    ord(\"V\"): ord(\"V\"),\n","    ord(\":\"): ord(\":\"),\n","    ord(\"[\"): ord(\"[\"),\n","    ord(\"]\"): ord(\"]\"),\n","    ord(\"’\"): ord(\"'\"),\n","    ord(\"Z\"): ord(\"Z\"),\n","    ord(\"Ç\"): ord(\"Ç\"),\n","    ord(\"J\"): ord(\"J\"),\n","    ord(\"Ü\"): ord(\"Ü\"),\n","    ord(\"Ş\"): ord(\"Ş\"),\n","    ord(\"Ö\"): ord(\"Ö\"),\n","    ord(\"%\"): ord(\"%\"),\n","    ord(\";\"): ord(\";\"),\n","    ord(\"w\"): ord(\"w\"),\n","    ord(\"W\"): ord(\"W\"),\n","    ord(\"â\"): ord(\"â\"),\n","    ord(\"–\"): ord(\"-\"),\n","    ord(\"?\"): ord(\"?\"),\n","    ord(\"x\"): ord(\"x\"),\n","    ord(\"“\"): ord(\"\\\"\"),\n","    ord(\"”\"): ord(\"\\\"\"),\n","    ord(\"X\"): ord(\"X\"),\n","    ord(\"q\"): ord(\"q\"),\n","    ord(\"î\"): ord(\"\\u0120\"),\n","    ord(\"&\"): ord(\"\\u0120\"),\n","    ord(\"!\"): ord(\"\\u0120\"),\n","    ord(\"ð\"): ord(\"\\u0120\"),\n","    ord(\"Q\"): ord(\"\\u0120\"),\n","    ord(\"+\"): ord(\"\\u0120\"),\n","    ord(\"þ\"): ord(\"\\u0120\"),\n","    ord(\"‘\"): ord(\"'\"),\n","    ord(\"é\"): ord(\"\\u0120\"),\n","    ord(\"º\"): ord(\"\\u0120\"),\n","    ord(\"ë\"): ord(\"\\u0120\"),\n","    ord(\"…\"): ord(\"\\u0120\"),\n","    ord(\"б\"): ord(\"\\u0120\"),\n","    ord(\"*\"): ord(\"\\u0120\"),\n","    ord(\"=\"): ord(\"\\u0120\"),\n","    ord(\"`\"): ord(\"'\"),\n","    ord(\"ć\"): ord(\"\\u0120\"),\n","    ord(\"û\"): ord(\"\\u0120\"),\n","    ord(\"Ý\"): ord(\"\\u0120\"),\n","    ord(\"г\"): ord(\"\\u0120\"),\n","    ord(\"—\"): ord(\"\\u0120\"),\n","    ord(\"\\\\\"): ord(\"\\u0120\"),\n","    ord(\"°\"): ord(\"\\u0120\"),\n","    ord(\"@\"): ord(\"\\u0120\"),\n","    ord(\"č\"): ord(\"\\u0120\"),\n","    ord(\"ó\"): ord(\"\\u0120\"),\n","    ord(\"š\"): ord(\"\\u0120\"),\n","    ord(\"р\"): ord(\"\\u0120\"),\n","    ord(\"_\"): ord(\"\\u0120\"),\n","    ord(\"{\"): ord(\"\\u0120\"),\n","    ord(\"#\"): ord(\"\\u0120\"),\n","    ord(\"^\"): ord(\"\\u0120\"),\n","    ord(\">\"): ord(\"\\u0120\"),\n","    ord(\"$\"): ord(\"\\u0120\"),\n","    ord(\"đ\"): ord(\"\\u0120\"),\n","    ord(\"í\"): ord(\"\\u0120\"),\n","    ord(\"ø\"): ord(\"\\u0120\"),\n","    ord(\"Š\"): ord(\"\\u0120\"),\n","    ord(\"ž\"): ord(\"\\u0120\"),\n","    ord(\"Þ\"): ord(\"\\u0120\"),\n","    ord(\"л\"): ord(\"\\u0120\"),\n","    ord(\"я\"): ord(\"\\u0120\"),\n","    ord(\"}\"): ord(\"\\u0120\"),\n","    ord(\"±\"): ord(\"\\u0120\"),\n","    ord(\"½\"): ord(\"\\u0120\"),\n","    ord(\"¾\"): ord(\"\\u0120\"),\n","    ord(\"ª\"): ord(\"\\u0120\"),\n","    ord(\"á\"): ord(\"\\u0120\"),\n","    ord(\"É\"): ord(\"\\u0120\"),\n","    ord(\"è\"): ord(\"\\u0120\"),\n","    ord(\"Ğ\"): ord(\"\\u0120\"),\n","    ord(\"ï\"): ord(\"\\u0120\"),\n","    ord(\"ñ\"): ord(\"\\u0120\"),\n","    ord(\"ý\"): ord(\"\\u0120\"),\n","    ord(\"Ž\"): ord(\"\\u0120\"),\n","    ord(\"μ\"): ord(\"\\u0120\"),\n","    ord(\"а\"): ord(\"\\u0120\"),\n","    ord(\"и\"): ord(\"\\u0120\"),\n","    ord(\"у\"): ord(\"\\u0120\"),\n","    ord(\"х\"): ord(\"\\u0120\"),\n","    ord(\"ъ\"): ord(\"\\u0120\"),\n","}\n"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1715909639894,"user":{"displayName":"Matthew Johnson","userId":"09672185346885346735"},"user_tz":240},"id":"RJAevV6XnuW1"},"outputs":[],"source":["class DatasetHolder:\n","\n","    def __init__(self):\n","        self.unknown_vocabulary_type = None\n","        self.padding_vocabulary_type = None\n","        self.end_of_sequence_type = None\n","        self.target_vocab = None\n","        self.target_vocab_array = None\n","        self.target_vocab_counts = None\n","        self.source_vocab = None\n","        self.source_vocab_array = None\n","        self.source_vocab_counts = None\n","        self.target_encodings = None\n","        self.target_encodings_train = None\n","        self.target_encodings_test = None\n","        self.source_encodings = None\n","        self.source_encodings_train = None\n","        self.source_encodings_test = None\n","        self.max_src_seq_obs = 0\n","        self.max_tgt_seq_obs = 0\n","\n","    def get_unknown_vocabulary_type(self):\n","        return self.unknown_vocabulary_type\n","\n","    def set_unknown_vocabulary_type(self, unknown_vocabulary_type):\n","        self.unknown_vocabulary_type = unknown_vocabulary_type\n","\n","    def get_padding_vocabulary_type(self):\n","        return self.padding_vocabulary_type\n","\n","    def set_padding_vocabulary_type(self, padding_vocabulary_type):\n","        self.padding_vocabulary_type = padding_vocabulary_type\n","\n","    def get_end_of_sequence_vocabulary_type(self):\n","        return self.end_of_sequence_type\n","\n","    def set_end_of_sequence_vocabulary_type(self, end_of_sequence_type):\n","        self.end_of_sequence_type = end_of_sequence_type\n","\n","    def get_target_vocab(self):\n","        return self.target_vocab\n","\n","    def set_target_vocab(self, target_vocab):\n","        self.target_vocab = target_vocab\n","\n","    def get_target_vocab_numpy(self):\n","        if self.target_vocab_array is None:\n","            self.target_vocab_array = np.array(self.target_vocab)\n","        return self.target_vocab_array\n","\n","    def get_target_vocab_counts(self):\n","        return self.target_vocab_counts\n","\n","    def set_target_vocab_counts(self, target_vocab_counts):\n","        self.target_vocab_counts = target_vocab_counts\n","\n","    def get_source_vocab(self):\n","        return self.source_vocab\n","\n","    def set_source_vocab(self, source_vocab):\n","        self.source_vocab = source_vocab\n","\n","    def get_source_vocab_numpy(self):\n","        if self.source_vocab_array is None:\n","            self.source_vocab_array = np.array(self.source_vocab)\n","        return self.source_vocab_array\n","\n","    def get_source_vocab_counts(self):\n","        return self.source_vocab_counts\n","\n","    def set_source_vocab_counts(self, source_vocab_counts):\n","        self.source_vocab_counts = source_vocab_counts\n","\n","    def get_target_encodings(self):\n","        return self.target_encodings\n","\n","    def set_target_encodings(self, target_encodings):\n","        del self.target_encodings\n","        self.target_encodings = target_encodings\n","        if is_remote_execution:\n","            torch.cuda.empty_cache()\n","\n","    def get_source_encodings(self):\n","        return self.source_encodings\n","\n","    def set_source_encodings(self, source_encodings):\n","        del self.source_encodings\n","        self.source_encodings = source_encodings\n","        if is_remote_execution:\n","            torch.cuda.empty_cache()\n","\n","    def get_target_encodings_train(self):\n","        return self.target_encodings_train\n","\n","    def set_target_encodings_train(self, target_encodings_train):\n","        del self.target_encodings_train\n","        self.target_encodings_train = target_encodings_train\n","        if is_remote_execution:\n","            torch.cuda.empty_cache()\n","\n","    def get_source_encodings_train(self):\n","        return self.source_encodings_train\n","\n","    def set_source_encodings_train(self, source_encodings_train):\n","        del self.source_encodings_train\n","        self.source_encodings_train = source_encodings_train\n","        if is_remote_execution:\n","            torch.cuda.empty_cache()\n","\n","    def get_target_encodings_test(self):\n","        return self.target_encodings_test\n","\n","    def set_target_encodings_test(self, target_encodings_test):\n","        del self.target_encodings_test\n","        self.target_encodings_test = target_encodings_test\n","        if is_remote_execution:\n","            torch.cuda.empty_cache()\n","\n","    def get_source_encodings_test(self):\n","        return self.source_encodings_test\n","\n","    def set_source_encodings_test(self, source_encodings_test):\n","        del self.source_encodings_test\n","        self.source_encodings_test = source_encodings_test\n","        if is_remote_execution:\n","            torch.cuda.empty_cache()\n","\n","    def get_max_src_seq_obs(self):\n","        return self.max_src_seq_obs\n","\n","    def set_max_src_seq_obs(self, max_src_seq_obs):\n","        self.max_src_seq_obs = max_src_seq_obs\n","\n","    def get_max_tgt_seq_obs(self):\n","        return self.max_tgt_seq_obs\n","\n","    def set_max_tgt_seq_obs(self, max_tgt_seq_obs):\n","        self.max_tgt_seq_obs = max_tgt_seq_obs\n","\n","\n","# class name matches file name\n","class dataset_transformer_setimesbyt5():\n","\n","    def __init__(self,\n","                 datasets_directory=root_filepath+\"resources\",\n","                 raw_dataset_directory=\"raw_datasets/setimes\",\n","                 parsed_dataset_directory=\"parsed_datasets/setimes\",\n","                 ids_filename='SETIMES.en-tr.ids',\n","                 en_filename='SETIMES.en-tr.en',\n","                 tr_filename='SETIMES.en-tr.tr',\n","                 dataset_hyperparameters=None):\n","        self.datasets_directory = datasets_directory\n","        self.raw_dataset_directory = raw_dataset_directory\n","        self.parsed_dataset_directory = parsed_dataset_directory\n","        self.ids_filename = ids_filename\n","        self.en_filename = en_filename\n","        self.tr_filename = tr_filename\n","        self.parsed_dataset_filename = None\n","        if 'parsed_dataset_filename' in dataset_hyperparameters:\n","            self.parsed_dataset_filename = dataset_hyperparameters['parsed_dataset_filename']\n","        self.sentence_length_min_percentile = None\n","        if 'sentence_length_min_percentile' in dataset_hyperparameters:\n","            self.sentence_length_min_percentile = dataset_hyperparameters['sentence_length_min_percentile']\n","        self.sentence_length_max_percentile = None\n","        if 'sentence_length_max_percentile' in dataset_hyperparameters:\n","            self.sentence_length_max_percentile = dataset_hyperparameters['sentence_length_max_percentile']\n","\n","\n","    def read_dataset(self):\n","        dataset_holder = None\n","        if self.parsed_dataset_filename is not None:\n","            dataset_holder = torch.load(self.datasets_directory + \"/\"\n","                                        + self.parsed_dataset_directory + \"/\"\n","                                        + self.parsed_dataset_filename)\n","        else:\n","            target_sentences = list()\n","            source_sentences = list()\n","            index_file = open(self.datasets_directory + \"/\" + self.raw_dataset_directory + \"/\" + self.ids_filename)\n","            en_file = open(self.datasets_directory + \"/\" + self.raw_dataset_directory + \"/\" + self.en_filename)\n","            tr_file = open(self.datasets_directory + \"/\" + self.raw_dataset_directory + \"/\" + self.tr_filename)\n","            indices = list()\n","            en_sentences = list()\n","            tr_sentences = list()\n","            line_number = 1\n","            for line in index_file:\n","                line_segments = line.strip().split()\n","                if len(line_segments) != 4:\n","                    print(\"Line segmentation error on line \" + str(line_number))\n","                    print(\"Content: \" + line)\n","                    continue\n","                if line_segments[0].startswith(\"en\") and line_segments[1].startswith(\"tr\"):\n","                    indices.append((int(line_segments[2]), int(line_segments[3])))\n","                elif line_segments[0].startswith(\"tr\") and line_segments[1].startswith(\"en\"):\n","                    indices.append((int(line_segments[3]), int(line_segments[2])))\n","                else:\n","                    print(\"Index parsing error on line \" + str(line_number))\n","                    print(\"Content: \" + line)\n","                    continue\n","                line_number = line_number + 1\n","            for line in en_file:\n","                en_sentences.append(line.strip())\n","            for line in tr_file:\n","                tr_sentences.append(line.strip())\n","            for index in indices:\n","                target_sentences.append(en_sentences[index[0] - 1])\n","                source_sentences.append(tr_sentences[index[1] - 1])\n","            target_sentence_lengths = list()\n","            for sentence in target_sentences:\n","                target_sentence_lengths.append(len(sentence))\n","            source_sentence_lengths = list()\n","            for sentence in source_sentences:\n","                source_sentence_lengths.append(len(sentence))\n","            target_sentences_length_limited = list()\n","            source_sentences_length_limited = list()\n","            target_min_len = int(np.percentile(sorted(target_sentence_lengths), self.sentence_length_min_percentile))\n","            target_max_len = int(np.percentile(sorted(target_sentence_lengths), self.sentence_length_max_percentile))\n","            source_min_len = int(np.percentile(sorted(source_sentence_lengths), self.sentence_length_min_percentile))\n","            source_max_len = int(np.percentile(sorted(source_sentence_lengths), self.sentence_length_max_percentile))\n","            max_src_seq_obs = 0\n","            max_tgt_seq_obs = 0\n","            for i in range(0, len(target_sentences)):\n","                if (len(target_sentences[i]) > target_min_len and len(target_sentences[i]) <= target_max_len\n","                        and len(source_sentences[i]) > source_min_len and len(source_sentences[i]) <= source_max_len):\n","                    if len(source_sentences[i]) > max_src_seq_obs:\n","                        max_src_seq_obs = len(source_sentences[i])\n","                    if len(target_sentences[i]) > max_tgt_seq_obs:\n","                        max_tgt_seq_obs = len(target_sentences[i])\n","                    target_sentences_length_limited.append(target_sentences[i].translate(english_char_mappings))\n","                    source_sentences_length_limited.append(source_sentences[i].translate(turkish_char_mappings))\n","            dataset_holder = DatasetHolder()\n","            dataset_holder.set_max_src_seq_obs(max_src_seq_obs)\n","            dataset_holder.set_max_tgt_seq_obs(max_tgt_seq_obs)\n","            # encode to Pytorch tensors as raw UTF-8 character vocabulary\n","            # method replicated from Xue 2021 - ByT5 - Introduction, sec 3.1\n","            unknown_vocabulary_type = \"\\u0120\".encode('utf-8').decode('utf-8')\n","            padding_vocabulary_type = \"\\u0121\".encode('utf-8').decode('utf-8')\n","            end_of_sequence_vocabulary_type = \"\\u0122\".encode('utf-8').decode('utf-8')\n","            dataset_holder.set_unknown_vocabulary_type(unknown_vocabulary_type)\n","            dataset_holder.set_padding_vocabulary_type(padding_vocabulary_type)\n","            dataset_holder.set_end_of_sequence_vocabulary_type(end_of_sequence_vocabulary_type)\n","            target_vocab = list([unknown_vocabulary_type, padding_vocabulary_type, end_of_sequence_vocabulary_type])\n","            source_vocab = list([unknown_vocabulary_type, padding_vocabulary_type, end_of_sequence_vocabulary_type])\n","            target_encodings = list()\n","            source_encodings = list()\n","            for entry in target_sentences_length_limited:\n","                encoding = list()\n","                for character in entry:\n","                    if character not in target_vocab:\n","                        target_vocab.append(character)\n","                    encoding.append(target_vocab.index(character))\n","                encoding.append(target_vocab.index(end_of_sequence_vocabulary_type))\n","                target_encodings.append(torch.tensor(encoding))\n","            for entry in source_sentences_length_limited:\n","                encoding = list()\n","                for character in entry:\n","                    if character not in source_vocab:\n","                        source_vocab.append(character)\n","                    encoding.append(source_vocab.index(character))\n","                encoding.append(target_vocab.index(end_of_sequence_vocabulary_type))\n","                source_encodings.append(torch.tensor(encoding))\n","            # fix vocabulary indices using tuple type\n","            dataset_holder.set_target_vocab(tuple(target_vocab))\n","            dataset_holder.set_target_encodings(target_encodings)\n","            dataset_holder.set_source_vocab(tuple(source_vocab))\n","            dataset_holder.set_source_encodings(source_encodings)\n","            dataset_holder = DatasetUtils.create_dataset_segments(dataset_holder)\n","            torch.save(dataset_holder,\n","                       self.datasets_directory + \"/\" +\n","                       self.parsed_dataset_directory + \"/\" +\n","                       \"setimes_parsed-\" + str(int(time.time())))\n","        return dataset_holder\n","\n","\n","class Utils:\n","\n","    def __init__(self):\n","        pass\n","\n","    @staticmethod\n","    def load_python_object(object_path: str, object_attribute: str):\n","        path_segments = object_path.split('.')\n","        module = __import__(object_path)\n","        for segment in path_segments[1:]:\n","            module = getattr(module, segment)\n","        return getattr(module, object_attribute)\n","\n","\n","class DatasetUtils:\n","\n","    @staticmethod\n","    def shuffle_dataset(dataset_holder: DatasetHolder):\n","        new_source_encodings, new_target_encodings = (\n","            DatasetUtils.shuffle_lists(\n","                dataset_holder.get_source_encodings(),\n","                dataset_holder.get_target_encodings()\n","            )\n","        )\n","        dataset_holder.set_source_encodings(new_source_encodings)\n","        dataset_holder.set_target_encodings(new_target_encodings)\n","        return dataset_holder\n","\n","    @staticmethod\n","    def shuffle_training_dataset(dataset_holder: DatasetHolder):\n","        new_source_encodings, new_target_encodings = (\n","            DatasetUtils.shuffle_lists(\n","                dataset_holder.get_source_encodings_train(),\n","                dataset_holder.get_target_encodings_train()\n","            )\n","        )\n","        dataset_holder.set_source_encodings(new_source_encodings)\n","        dataset_holder.set_target_encodings(new_target_encodings)\n","        return dataset_holder\n","\n","    @staticmethod\n","    def shuffle_test_dataset(dataset_holder: DatasetHolder):\n","        new_source_encodings, new_target_encodings = (\n","            DatasetUtils.shuffle_lists(\n","                dataset_holder.get_source_encodings_test(),\n","                dataset_holder.get_target_encodings_test()\n","            )\n","        )\n","        dataset_holder.set_source_encodings(new_source_encodings)\n","        dataset_holder.set_target_encodings(new_target_encodings)\n","        return dataset_holder\n","\n","    @staticmethod\n","    def shuffle_lists(source_list, target_list):\n","        assert len(source_list) == len(target_list)\n","        list_element_shuffle_indices = list(range(0, len(source_list)))\n","        random.shuffle(list_element_shuffle_indices)\n","        new_source_list = list()\n","        new_target_list = list()\n","        for i in list_element_shuffle_indices:\n","            new_source_list.append(source_list[i])\n","            new_target_list.append(target_list[i])\n","        assert (len(new_source_list) == len(new_target_list)\n","                == len(source_list) == len(target_list))\n","        return new_source_list, new_target_list\n","\n","    @staticmethod\n","    def create_dataset_segments(dataset_holder: DatasetHolder):\n","        split_with_even_target_distribution = False\n","        iteration = 1\n","        best_split_target_encodings = None\n","        best_split_source_encodings = None\n","        best_split_deviation_from_desired = 1\n","        segments = 20\n","        split_size = len(dataset_holder.get_target_encodings()) // segments\n","        train_size = split_size * (segments - 1)\n","        while not split_with_even_target_distribution and iteration <= 100:\n","            segment_attempt_start = time.time()\n","            dataset_holder = DatasetUtils.shuffle_dataset(dataset_holder)\n","            target_encodings = dataset_holder.get_target_encodings()\n","            source_encodings = dataset_holder.get_source_encodings()\n","            train_set_target_enc = target_encodings[0:train_size]\n","            test_set_target_enc = target_encodings[train_size:]\n","            numpy_encodings = list()\n","            for encoding in train_set_target_enc:\n","                numpy_encodings.append(encoding.flatten().numpy())\n","            train_set_target_enc_cts = np.bincount(\n","                np.concatenate([\n","                    np.concatenate(numpy_encodings),\n","                    np.arange(0, 170)\n","                ])\n","            )\n","            numpy_encodings = list()\n","            for encoding in test_set_target_enc:\n","                numpy_encodings.append(encoding.flatten().numpy())\n","            test_set_target_enc_cts = np.bincount(\n","                np.concatenate([\n","                    np.concatenate(numpy_encodings),\n","                    np.arange(0, 170)\n","                ])\n","            )\n","            # terms with probability ~ 1%\n","            total_5 = train_set_target_enc_cts[5] + test_set_target_enc_cts[5]\n","            total_40 = train_set_target_enc_cts[40] + test_set_target_enc_cts[40]\n","            total_42 = train_set_target_enc_cts[42] + test_set_target_enc_cts[42]\n","            # top 3 terms\n","            total_7 = train_set_target_enc_cts[7] + test_set_target_enc_cts[7]\n","            total_15 = train_set_target_enc_cts[15] + test_set_target_enc_cts[15]\n","            total_12 = train_set_target_enc_cts[12] + test_set_target_enc_cts[12]\n","            train_dist_goal = (segments - 1)/segments\n","            test_dist_goal = (1 / segments)\n","            deviation_from_desired = (\n","                    np.abs(((segments - 2)/segments) - (train_set_target_enc_cts[5] / total_5)) +\n","                    np.abs(train_dist_goal - (train_set_target_enc_cts[40] / total_40)) +\n","                    np.abs(train_dist_goal - (train_set_target_enc_cts[42] / total_42)) +\n","                    np.abs(train_dist_goal - (train_set_target_enc_cts[7] / total_7)) +\n","                    np.abs(train_dist_goal - (train_set_target_enc_cts[15] / total_15)) +\n","                    np.abs(train_dist_goal - (train_set_target_enc_cts[12] / total_12)) +\n","                    np.abs(test_dist_goal - (test_set_target_enc_cts[5] / total_5)) +\n","                    np.abs(test_dist_goal - (test_set_target_enc_cts[40] / total_40)) +\n","                    np.abs(test_dist_goal - (test_set_target_enc_cts[42] / total_42)) +\n","                    np.abs(test_dist_goal - (test_set_target_enc_cts[7] / total_7)) +\n","                    np.abs(test_dist_goal - (test_set_target_enc_cts[15] / total_15)) +\n","                    np.abs(test_dist_goal - (test_set_target_enc_cts[12] / total_12))\n","            )\n","            if deviation_from_desired <= 12 * 0.0001:\n","                split_with_even_target_distribution = True\n","                best_split_target_encodings = target_encodings\n","                best_split_source_encodings = source_encodings\n","                print(f\"Found dataset split within tolerance for deviation from uniform distribution over characters\")\n","            if deviation_from_desired < best_split_deviation_from_desired:\n","                best_split_target_encodings = target_encodings\n","                best_split_source_encodings = source_encodings\n","                best_split_deviation_from_desired = deviation_from_desired\n","            segment_attempt_end = time.time()\n","            print(f\"Completed data split attempt. \"\n","                  f\"iteration:{iteration} \"\n","                  f\"best_split_deviation_from_desired:{best_split_deviation_from_desired} \"\n","                  f\"time_to_complete_attempt:{segment_attempt_end-segment_attempt_start}\")\n","            iteration = iteration + 1\n","        best_split_source_encodings_train = best_split_source_encodings[0:train_size]\n","        best_split_target_encodings_train = best_split_target_encodings[0:train_size]\n","        assert len(best_split_source_encodings_train) == len(best_split_target_encodings_train)\n","        train_split_encoding_length_sum_and_encoding_index_pairs = list()\n","        for i in range(0, len(best_split_source_encodings_train)):\n","            train_split_encoding_length_sum_and_encoding_index_pairs.append(\n","                list([\n","                    best_split_source_encodings_train[i].shape[0] + best_split_target_encodings_train[i].shape[0],\n","                    np.abs(best_split_source_encodings_train[i].shape[0] - best_split_target_encodings_train[i].shape[0]),\n","                    i\n","                ])\n","            )\n","        train_split_encoding_length_sum_and_encoding_index_pairs = sorted(\n","            train_split_encoding_length_sum_and_encoding_index_pairs,\n","            key=lambda pair: (pair[0], pair[1])\n","        )\n","        train_source_encs_length_sorted = list()\n","        train_target_encs_length_sorted = list()\n","        for encoding_length_sum_and_encoding_index_pair in train_split_encoding_length_sum_and_encoding_index_pairs:\n","            train_source_encs_length_sorted.append(best_split_source_encodings_train[encoding_length_sum_and_encoding_index_pair[2]])\n","            train_target_encs_length_sorted.append(best_split_target_encodings_train[encoding_length_sum_and_encoding_index_pair[2]])\n","        best_split_source_encodings_test = best_split_source_encodings[train_size:]\n","        best_split_target_encodings_test = best_split_target_encodings[train_size:]\n","        assert len(best_split_source_encodings_test) == len(best_split_target_encodings_test)\n","        test_split_encoding_length_sum_and_encoding_index_pairs = list()\n","        for i in range(0, len(best_split_source_encodings_test)):\n","            test_split_encoding_length_sum_and_encoding_index_pairs.append(\n","                list([\n","                    best_split_source_encodings_test[i].shape[0] + best_split_target_encodings_test[i].shape[0],\n","                    np.abs(best_split_source_encodings_test[i].shape[0] - best_split_target_encodings_test[i].shape[0]),\n","                    i\n","                ])\n","            )\n","        test_split_encoding_length_sum_and_encoding_index_pairs = sorted(\n","            test_split_encoding_length_sum_and_encoding_index_pairs,\n","            key=lambda pair: (pair[0], pair[1])\n","        )\n","        test_source_encs_length_sorted = list()\n","        test_target_encs_length_sorted = list()\n","        for encoding_length_sum_and_encoding_index_pair in test_split_encoding_length_sum_and_encoding_index_pairs:\n","            test_source_encs_length_sorted.append(best_split_source_encodings_test[encoding_length_sum_and_encoding_index_pair[2]])\n","            test_target_encs_length_sorted.append(best_split_target_encodings_test[encoding_length_sum_and_encoding_index_pair[2]])\n","        dataset_holder.set_source_encodings(best_split_source_encodings)\n","        dataset_holder.set_target_encodings(best_split_target_encodings)\n","        dataset_holder.set_source_encodings_train(train_source_encs_length_sorted)\n","        dataset_holder.set_target_encodings_train(train_target_encs_length_sorted)\n","        dataset_holder.set_source_encodings_test(test_source_encs_length_sorted)\n","        dataset_holder.set_target_encodings_test(test_target_encs_length_sorted)\n","        return dataset_holder\n","\n","    # use a dedicated padding token to pad batches as in Xue 2021 - ByT5 - Sec 3.1\n","    @staticmethod\n","    def prepare_batches(\n","            source_encodings,\n","            target_encodings,\n","            source_vocab,\n","            target_vocab,\n","            batch_size_limit: int,\n","            element_difference_limit: int,\n","            padding_value):\n","        assert len(source_encodings) == len(target_encodings)\n","        total_elements = len(source_encodings)\n","        source_encodings_batches = list()\n","        target_encodings_batches = list()\n","        source_encodings_tensors = list()\n","        target_encodings_tensors = list()\n","        encodings_index = 0\n","        while encodings_index < total_elements - 1:\n","            batch_size = 0\n","            batch_end_reached = False\n","            min_source_enc_len = source_encodings[encodings_index+batch_size].shape[0]\n","            max_source_enc_len = source_encodings[encodings_index+batch_size].shape[0]\n","            min_target_enc_len = target_encodings[encodings_index+batch_size].shape[0]\n","            max_target_enc_len = target_encodings[encodings_index+batch_size].shape[0]\n","            while not batch_end_reached:\n","                if (max(abs(source_encodings[encodings_index+batch_size].shape[0] - min_source_enc_len),\n","                        abs(source_encodings[encodings_index+batch_size].shape[0] - max_source_enc_len)) > element_difference_limit\n","                        or max(abs(target_encodings[encodings_index+batch_size].shape[0] - min_target_enc_len),\n","                               abs(target_encodings[encodings_index+batch_size].shape[0] - max_target_enc_len)) > element_difference_limit):\n","                    batch_end_reached = True\n","                if batch_size == batch_size_limit - 1:\n","                    batch_end_reached = True\n","                if encodings_index + batch_size + 1 < total_elements:\n","                    batch_size = batch_size + 1\n","                else:\n","                    batch_end_reached = True\n","            max_src_len_for_batch = 0\n","            max_tgt_len_for_batch = 0\n","            for batch_index in range(0, batch_size):\n","                if len(source_encodings[encodings_index+batch_index]) > max_src_len_for_batch:\n","                    max_src_len_for_batch = len(source_encodings[encodings_index+batch_index])\n","                if len(target_encodings[encodings_index+batch_index]) > max_tgt_len_for_batch:\n","                    max_tgt_len_for_batch = len(target_encodings[encodings_index+batch_index])\n","            for batch_index in range(0, batch_size):\n","                source_encoding = source_encodings[encodings_index]\n","                target_encoding = target_encodings[encodings_index]\n","                source_encodings_tensors.append(\n","                    torch.nn.functional.pad(\n","                        source_encoding,\n","                        (0, max_src_len_for_batch - len(source_encoding)),\n","                        value=source_vocab.index(padding_value)\n","                    )\n","                )\n","                target_encodings_tensors.append(\n","                    torch.nn.functional.pad(\n","                        target_encoding,\n","                        (0, max_tgt_len_for_batch - len(target_encoding)),\n","                        value=target_vocab.index(padding_value)\n","                    )\n","                )\n","                encodings_index = encodings_index + 1\n","            if batch_size > 0:\n","                source_batch = torch.stack(source_encodings_tensors)\n","                target_batch = torch.stack(target_encodings_tensors)\n","                source_encodings_batches.append(source_batch)\n","                target_encodings_batches.append(target_batch)\n","            source_encodings_tensors = list()\n","            target_encodings_tensors = list()\n","        target_encodings_batches_with_index = list()\n","        for i in range(0, len(target_encodings_batches)):\n","            target_encodings_batches_with_index.append(list([target_encodings_batches[i], i]))\n","        assert len(target_encodings_batches_with_index) == len(target_encodings_batches)\n","        target_encodings_batches_with_index_sorted = sorted(\n","            target_encodings_batches_with_index,\n","            key=lambda batch_pair: (-batch_pair[0].shape[0], -batch_pair[0].shape[1])\n","        )\n","        source_encodings_batches_sorted = list()\n","        target_encodings_batches_sorted = list()\n","        for i in range(0, len(target_encodings_batches_with_index_sorted)):\n","            source_encodings_batches_sorted.append(\n","                source_encodings_batches[target_encodings_batches_with_index_sorted[i][1]]\n","            )\n","            target_encodings_batches_sorted.append(\n","                target_encodings_batches[target_encodings_batches_with_index_sorted[i][1]]\n","            )\n","        del source_encodings_tensors\n","        del target_encodings_tensors\n","        del source_encodings_batches\n","        del target_encodings_batches\n","        del target_encodings_batches_with_index_sorted\n","        return source_encodings_batches_sorted, target_encodings_batches_sorted\n","\n","    @staticmethod\n","    def prepare_training_batches(\n","            dataset_holder: DatasetHolder,\n","            batch_size_limit: int,\n","            element_difference_limit: int):\n","        source_encodings_batches, target_encodings_batches = DatasetUtils.prepare_batches(\n","            dataset_holder.get_source_encodings_train(),\n","            dataset_holder.get_target_encodings_train(),\n","            dataset_holder.get_source_vocab(),\n","            dataset_holder.get_target_vocab(),\n","            batch_size_limit,\n","            element_difference_limit,\n","            dataset_holder.get_padding_vocabulary_type()\n","        )\n","\n","        source_vocab_counts = {}\n","        for source_encoding_batch in source_encodings_batches:\n","            for source_encoding in source_encoding_batch:\n","                for character in source_encoding:\n","                    if character.item() not in source_vocab_counts:\n","                        source_vocab_counts[character.item()] = 0\n","                    source_vocab_counts[character.item()] = source_vocab_counts[character.item()] + 1\n","        target_vocab_counts = {}\n","        for target_vocab_batch in target_encodings_batches:\n","            for target_encoding in target_vocab_batch:\n","                for character in target_encoding:\n","                    if character.item() not in target_vocab_counts:\n","                        target_vocab_counts[character.item()] = 0\n","                    target_vocab_counts[character.item()] = target_vocab_counts[character.item()] + 1\n","        dataset_holder.set_source_vocab_counts(source_vocab_counts)\n","        dataset_holder.set_target_vocab_counts(target_vocab_counts)\n","        return source_encodings_batches, target_encodings_batches\n","\n","    @staticmethod\n","    def decode_target_tensor(dataset_holder: DatasetHolder, tensor_to_decode):\n","        vocab = dataset_holder.get_target_vocab_numpy()\n","        decoded_tensor = np.take(vocab, tensor_to_decode.detach().to(device=\"cpu\").flatten().numpy())\n","        return \"\".join(decoded_tensor.tolist())\n","\n","    @staticmethod\n","    def decode_source_tensor(dataset_holder: DatasetHolder, tensor_to_decode):\n","        vocab = dataset_holder.get_source_vocab_numpy()\n","        decoded_tensor = np.take(vocab, tensor_to_decode.detach().to(device=\"cpu\").flatten().numpy())\n","        return \"\".join(decoded_tensor.tolist())\n","\n","\n","# class name matches file name\n","class transformer_vaswani2017(torch.nn.Transformer):\n","\n","    def __init__(self,\n","                 model_hyperparameters):\n","        super().__init__(\n","            d_model=model_hyperparameters['d_model'],\n","            nhead=model_hyperparameters['nhead'],\n","            num_encoder_layers=model_hyperparameters['num_encoder_layers'],\n","            num_decoder_layers=model_hyperparameters['num_decoder_layers'],\n","            dim_feedforward=model_hyperparameters['dim_feedforward'],\n","            dropout=model_hyperparameters['dropout'],\n","            activation=model_hyperparameters['activation'],\n","            custom_encoder=model_hyperparameters['custom_encoder'],\n","            custom_decoder=model_hyperparameters['custom_decoder'],\n","            layer_norm_eps=model_hyperparameters['layer_norm_eps'],\n","            batch_first=model_hyperparameters['batch_first'],\n","            norm_first=model_hyperparameters['norm_first'],\n","            bias=model_hyperparameters['bias'],\n","            device=model_hyperparameters['device'],\n","            dtype=model_hyperparameters['dtype']\n","        )\n","        # add one for the end of sequence token\n","        self.max_src_seq_len = model_hyperparameters['max_src_seq_len'] + 1\n","        self.max_tgt_seq_len = model_hyperparameters['max_tgt_seq_len'] + 1\n","        self.src_embeddings = torch.nn.Embedding(\n","            model_hyperparameters['src_vocab_size'],\n","            model_hyperparameters['d_model']\n","        )\n","        self.tgt_embeddings = torch.nn.Embedding(\n","            model_hyperparameters['tgt_vocab_size'],\n","            model_hyperparameters['d_model']\n","        )\n","        self.src_pos_enc = torch.nn.Embedding(\n","            self.max_src_seq_len,\n","            model_hyperparameters['d_model']\n","        ).requires_grad_(False)\n","        self.tgt_pos_enc = torch.nn.Embedding(\n","            self.max_tgt_seq_len,\n","            model_hyperparameters['d_model']\n","        ).requires_grad_(False)\n","        self.linear_output_projection_1 = torch.nn.Linear(\n","            self.max_tgt_seq_len,\n","            1,\n","            bias=False\n","        )\n","        self.linear_output_projection_2 = torch.nn.Linear(\n","            model_hyperparameters['d_model'],\n","            model_hyperparameters['tgt_vocab_size'],\n","            bias=False\n","        )\n","        self.logsoftmax_output = torch.nn.LogSoftmax(dim=1)\n","        self.model_hyperparameters = model_hyperparameters\n","        self.tgt_mask_cache = {}\n","        for i in range(1, self.max_tgt_seq_len + 1):\n","            tgt_mask = self.generate_square_subsequent_mask(i)\n","            if is_remote_execution:\n","                self.tgt_mask_cache[i] = tgt_mask.to(device=\"cuda\")\n","            self.tgt_mask_cache[i] = tgt_mask\n","        self.indices_cache = {}\n","        for i in range(1, max([self.max_src_seq_len, self.max_tgt_seq_len]) + 1):\n","            indices = torch.tensor(np.arange(0, i), dtype=torch.long)\n","            if is_remote_execution:\n","                indices = indices.to(device=\"cuda\")\n","            self.indices_cache[i] = indices\n","\n","    def forward(self,\n","                src: torch.Tensor,\n","                tgt: torch.Tensor,\n","                src_mask: Optional[torch.Tensor] = None,\n","                tgt_mask: Optional[torch.Tensor] = None,\n","                memory_mask: Optional[torch.Tensor] = None,\n","                src_key_padding_mask: Optional[torch.Tensor] = None,\n","                tgt_key_padding_mask: Optional[torch.Tensor] = None,\n","                memory_key_padding_mask: Optional[torch.Tensor] = None,\n","                src_is_causal: Optional[bool] = None,\n","                tgt_is_causal: Optional[bool] = True,\n","                memory_is_causal: bool = False) -> torch.Tensor:\n","        src_embedding_pos_enc = self.src_embeddings(src) + self.src_pos_enc(self.indices_cache[src.shape[1]])\n","        tgt_embedding_pos_enc = self.tgt_embeddings(tgt) + self.tgt_pos_enc(self.indices_cache[tgt.shape[1]])\n","        tgt_mask = self.tgt_mask_cache[tgt.shape[1]]\n","        transformer_output = super().forward(src_embedding_pos_enc, tgt_embedding_pos_enc, src_mask,\n","                                             tgt_mask, memory_mask, src_key_padding_mask,\n","                                             tgt_key_padding_mask, memory_key_padding_mask,\n","                                             src_is_causal, tgt_is_causal, memory_is_causal)\n","        transformer_output = torch.swapaxes(transformer_output, -1, -2)\n","        transformer_output = torch.nn.functional.pad(\n","            transformer_output,\n","            (0, self.max_tgt_seq_len - transformer_output.shape[2]),\n","            value=0\n","        )\n","        output = self.logsoftmax_output(\n","            self.linear_output_projection_2(\n","                torch.squeeze(\n","                    self.linear_output_projection_1(\n","                        transformer_output\n","                    ),\n","                    dim=2\n","                )\n","            )\n","        )\n","        del src_embedding_pos_enc\n","        del tgt_embedding_pos_enc\n","        del transformer_output\n","        return output\n","\n","\n","class model_trainer_kocmi2018():\n","\n","    def __init__(self,\n","                 trainer_hyperparameters=None,\n","                 model_parameter_directory=None,\n","                 trainer_parameter_directory=None,\n","                 runner_hyperparameters_name=None,\n","                 latest_param_filename_tag=None):\n","        self.trainer_hyperparameters = trainer_hyperparameters\n","        self.optimizer_name = self.trainer_hyperparameters['optimizer_name']\n","        self.initial_lr = self.trainer_hyperparameters['initial_lr']\n","        self.exp_decay = self.trainer_hyperparameters['exp_decay']\n","        self.lr_scheduler_name = self.trainer_hyperparameters['lr_scheduler_name']\n","        self.epochs = self.trainer_hyperparameters['epochs']\n","        self.epoch_starting_index = self.trainer_hyperparameters['epoch_starting_index']\n","        self.batch_size_limit = self.trainer_hyperparameters['batch_size_limit']\n","        self.element_difference_limit = self.trainer_hyperparameters['element_difference_limit']\n","        self.batch_starting_index = self.trainer_hyperparameters['batch_starting_index']\n","        self.model_parameter_directory = model_parameter_directory\n","        self.trainer_parameter_directory = trainer_parameter_directory\n","        self.runner_hyperparameters_name = runner_hyperparameters_name\n","        self.latest_param_filename_tag = latest_param_filename_tag\n","        self.dataset_holder = None\n","        self.model = None\n","        self.source_encoding_batches = None\n","        self.target_encoding_batches = None\n","        self.optimizer = None\n","        self.lr_scheduler = None\n","        self.loss_fcn = None\n","\n","    def init_trainer(self):\n","        self.source_encoding_batches, self.target_encoding_batches = (\n","            DatasetUtils.prepare_training_batches(\n","                self.dataset_holder,\n","                self.batch_size_limit,\n","                self.element_difference_limit\n","            )\n","        )\n","        # get_target_vocab_counts requires that training batches have been prepared\n","        # this ensures that vocab counts include padding and eos tokens\n","        loss_weights = list()\n","        for vocab_term in self.dataset_holder.get_target_vocab():\n","            loss_weights.append(\n","                1 / self.dataset_holder.get_target_vocab_counts()[\n","                    self.dataset_holder.get_target_vocab().index(vocab_term)\n","                ]\n","            )\n","        # set padding to have 0 weight\n","        loss_weights[\n","            self.dataset_holder.get_target_vocab().index(self.dataset_holder.get_padding_vocabulary_type())] = 0\n","        loss_weights = torch.tensor(loss_weights, dtype=torch.float)\n","        if is_remote_execution:\n","            torch.cuda.empty_cache()\n","            self.model.cuda()\n","            loss_weights = loss_weights.to(device=\"cuda\")\n","        self.loss_fcn = torch.nn.NLLLoss(weight=loss_weights)\n","        _optimizer_class_ = Utils.load_python_object('torch.optim', self.optimizer_name)\n","        self.optimizer = _optimizer_class_(self.model.parameters(), lr=self.initial_lr)\n","        _lr_scheduler_class_ = Utils.load_python_object('torch.optim.lr_scheduler', self.lr_scheduler_name)\n","        # constructor call assumes that the scheduler is the ExponentialLR scheduler\n","        self.lr_scheduler = _lr_scheduler_class_(self.optimizer, self.exp_decay)\n","        scheduler_parameter_filepath = self.trainer_parameter_directory + \"/\" + self.runner_hyperparameters_name + \"-\" + self.latest_param_filename_tag + \"-scheduler.params\"\n","        scheduler_parameters = torch.load(scheduler_parameter_filepath)\n","        self.lr_scheduler.load_state_dict(scheduler_parameters)\n","        parameter_count = 0\n","        bytes_consumed = 0\n","        for parameter in self.model.parameters():\n","            if parameter.requires_grad:\n","                parameter_count = parameter_count + np.prod(parameter.data.shape)\n","                bytes_consumed = bytes_consumed + parameter.data.nbytes\n","        gb_consumed = bytes_consumed / 1024 / 1024 / 1024\n","        print(f\"Model trainer initialization complete.\"\n","              f\"Trainer will run on model with parameter count {parameter_count} \"\n","              f\"and parameter memory use {gb_consumed} GB\")\n","\n","    # pretraining is not used for monolingual english as described in Xue 2021 - ByT5 - Sec 3.1\n","    def run_trainer(self):\n","        assert self.epoch_starting_index < self.epochs\n","        for i in range(self.epoch_starting_index, self.epochs):\n","            while self.lr_scheduler.state_dict()['last_epoch'] > i:\n","                print(f\"Updating lr_scheduler: {self.lr_scheduler.state_dict()}\")\n","                self.lr_scheduler.step()\n","            epoch_start = time.time()\n","            print(f\"Beginning epoch {i+1} of {self.epochs} with scheduler {self.lr_scheduler.state_dict()}\")\n","            # if i > 0:\n","            #     self.source_encoding_batches, self.target_encoding_batches = DatasetUtils.shuffle_lists(\n","            #         self.source_encoding_batches, self.target_encoding_batches\n","            #     )\n","            source_batches = None\n","            target_batches = None\n","            if is_remote_execution:\n","                source_batches = list()\n","                target_batches = list()\n","                for batch in self.source_encoding_batches:\n","                    source_batches.append(batch.to(device=\"cuda\"))\n","                    del batch\n","                for batch in self.target_encoding_batches:\n","                    target_batches.append(batch.to(device=\"cuda\"))\n","                    del batch\n","                torch.cuda.empty_cache()\n","            else:\n","                source_batches = self.source_encoding_batches\n","                target_batches = self.target_encoding_batches\n","            assert len(source_batches) == len(target_batches)\n","            batch_ct = len(source_batches)\n","            batch_size = source_batches[0].shape[0]\n","            samples_passed = 0\n","            last_log = 0\n","            last_loss = 0\n","            note_step_prediction = False\n","            step_prediction_at_percentage_of_sample = 0\n","            total_batch_time = 0\n","            assert self.batch_starting_index < batch_ct\n","            for j in range(self.batch_starting_index, batch_ct):\n","                batch_start = time.time()\n","                batch_sequence_length = target_batches[j].shape[1]\n","                step_prediction_step_number = int(batch_sequence_length * step_prediction_at_percentage_of_sample)\n","                print(f\"Starting batch.\")\n","                print(f\"epoch:{i+1}/{self.epochs} batch:{j+1}/{batch_ct} batch_size:{target_batches[j].shape[0]}\")\n","                for k in range(1, batch_sequence_length-1):\n","                    target_batch_slices = torch.tensor_split(target_batches[j], [k], dim=1)\n","                    self.model.zero_grad()\n","                    output_logits = self.model.forward(\n","                        source_batches[j],\n","                        target_batch_slices[0]\n","                    )\n","                    next_word_indices = target_batch_slices[1][:, 0]\n","                    last_loss = self.loss_fcn(output_logits, next_word_indices)\n","                    last_loss.backward()\n","                    self.optimizer.step()\n","                    if note_step_prediction and k == step_prediction_step_number:\n","                        note_step_prediction = False\n","                        full_sequence = DatasetUtils.decode_target_tensor(self.dataset_holder, target_batches[j][0])\n","                        prefix_sequence = DatasetUtils.decode_target_tensor(\n","                            self.dataset_holder,\n","                            target_batch_slices[0][0]\n","                        )\n","                        next_token = DatasetUtils.decode_target_tensor(\n","                            self.dataset_holder,\n","                            next_word_indices[0]\n","                        )\n","                        predicted_token = DatasetUtils.decode_target_tensor(\n","                            self.dataset_holder,\n","                            torch.argmax(output_logits[0])\n","                        )\n","                        print(f\"Next token prediction. step:{k}/{batch_sequence_length} \"\n","                              f\"batch:{j+1}/{batch_ct} epoch:{i+1}/{self.epochs}\")\n","                        print(f\"full seq: {full_sequence}\")\n","                        print(f\"pref seq: {prefix_sequence}\")\n","                        print(f\"next tok: {next_token.rjust(k, ' ')}\")\n","                        print(f\"pred tok: {predicted_token.rjust(k, ' ')}\")\n","                        del full_sequence\n","                        del prefix_sequence\n","                        del next_token\n","                        del predicted_token\n","                    del target_batch_slices\n","                    del output_logits\n","                    del next_word_indices\n","                    last_loss = last_loss.detach()\n","                    gc.collect()\n","                    if is_remote_execution:\n","                        torch.cuda.empty_cache()\n","                batch_end = time.time()\n","                batch_time = batch_end - batch_start\n","                total_batch_time = total_batch_time + batch_time\n","                print(f\"Completed batch.\")\n","                print(f\"epoch:{i+1}/{self.epochs} batch:{j+1}/{batch_ct} batch_size:{target_batches[j].shape[0]} loss:{last_loss} \"\n","                      f\"time_for_batch_instance:{batch_time} total_batch_time:{total_batch_time} running_batch_average:{total_batch_time/(j+1)}\")\n","                samples_passed = samples_passed + batch_size\n","                if samples_passed - last_log > 100:\n","                    last_log = samples_passed\n","                    note_step_prediction = True\n","                    step_prediction_at_percentage_of_sample = random.random()\n","                    if is_remote_execution:\n","                        print(f\"Memory usage summary:\")\n","                        print(f\"{torch.cuda.memory_summary()}\")\n","                        torch.cuda.reset_max_memory_allocated()\n","                        torch.cuda.reset_max_memory_cached()\n","                        torch.cuda.reset_peak_memory_stats()\n","                    param_filename_tag = str(int(time.time()))\n","                    torch.save(\n","                        self.model.state_dict(),\n","                        self.model_parameter_directory + \"/\" + self.runner_hyperparameters_name + \"-\" + param_filename_tag + \"-model.params\"\n","                    )\n","                    torch.save(\n","                        self.lr_scheduler.state_dict(),\n","                        self.trainer_parameter_directory + \"/\" + self.runner_hyperparameters_name + \"-\" + param_filename_tag + \"-scheduler.params\"\n","                    )\n","                    torch.save(\n","                        f\"epoch:{i+1}/{self.epochs} batch:{j+1}/{batch_ct}\",\n","                        self.trainer_parameter_directory + \"/\" + self.runner_hyperparameters_name + \"-\" + param_filename_tag + \"-trainer.params\"\n","                    )\n","            del source_batches\n","            del target_batches\n","            gc.collect()\n","            if is_remote_execution:\n","                torch.cuda.empty_cache()\n","            self.lr_scheduler.step()\n","            epoch_end = time.time()\n","            print(f\"Completed epoch {i+1}/{self.epochs} in {(epoch_end - epoch_start) / 60 }m\")\n","            print(f\"epoch:{i+1}, batch:{j+1}/{batch_ct}, loss:{last_loss}\")\n","\n","    def get_dataset_holder(self):\n","        return self.dataset_holder\n","\n","    def set_dataset_holder(self, dataset_holder):\n","        self.dataset_holder = dataset_holder\n","\n","    def get_model(self):\n","        return self.model\n","\n","    def set_model(self, model):\n","        self.model = model\n","\n","\n","class Runner:\n","\n","    def __init__(self,\n","                 model_parameter_directory=root_filepath+\"resources/model_parameters\",\n","                 trainer_parameter_directory=root_filepath+\"resources/trainer_parameters\",\n","                 runner_hyperparameters_name=\"SETimesByT5Vaswani2017Kocmi2018_0\"):\n","        self.model_parameter_directory = model_parameter_directory\n","        self.trainer_parameter_directory = trainer_parameter_directory\n","        self.runner_hyperparameters_name = runner_hyperparameters_name\n","        self.runner_hyperparameters = SETimesByT5Vaswani2017Kocmi2018_0\n","        self.dataset_holder: DatasetHolder = None\n","        self.model = None\n","        self.trainer = None\n","        self.latest_param_filename_tag = None\n","        if 'latest_param_filename_tag' in self.runner_hyperparameters:\n","            self.latest_param_filename_tag = self.runner_hyperparameters['latest_param_filename_tag']\n","        print(f\"Initialized runner {runner_hyperparameters_name} with parameters {self.runner_hyperparameters}\")\n","\n","    def load_dataset(self):\n","        dataset_transformer_name = self.runner_hyperparameters.get('dataset_transformer_name')\n","        dataset_hyperparameters = self.runner_hyperparameters.get('dataset_transformer_hyperparameters')\n","        dataset_transformer = dataset_transformer_setimesbyt5(dataset_hyperparameters=dataset_hyperparameters)\n","        self.dataset_holder = dataset_transformer.read_dataset()\n","\n","    def load_model(self):\n","        model_hyperparameters = self.runner_hyperparameters.get('model_hyperparameters')\n","        model_hyperparameters['src_vocab_size'] = len(self.dataset_holder.get_source_vocab())\n","        model_hyperparameters['tgt_vocab_size'] = len(self.dataset_holder.get_target_vocab())\n","        model_hyperparameters['max_src_seq_len'] = self.dataset_holder.get_max_src_seq_obs()\n","        model_hyperparameters['max_tgt_seq_len'] = self.dataset_holder.get_max_tgt_seq_obs()\n","        model_parameter_filepath = self.model_parameter_directory + \"/\" + self.runner_hyperparameters_name + \"-\" + self.latest_param_filename_tag + \"-model.params\"\n","        self.model = transformer_vaswani2017(model_hyperparameters=model_hyperparameters)\n","        model_parameters = torch.load(model_parameter_filepath)\n","        self.model.load_state_dict(model_parameters)\n","\n","    def load_trainer(self):\n","        trainer_hyperparameters = self.runner_hyperparameters.get('trainer_hyperparameters')\n","        self.trainer = model_trainer_kocmi2018(\n","            trainer_hyperparameters=trainer_hyperparameters,\n","            model_parameter_directory=self.model_parameter_directory,\n","            trainer_parameter_directory=self.trainer_parameter_directory,\n","            runner_hyperparameters_name=self.runner_hyperparameters_name,\n","            latest_param_filename_tag=self.latest_param_filename_tag\n","        )\n","\n","    def run_trainer(self):\n","        self.trainer.set_dataset_holder(self.dataset_holder)\n","        self.trainer.set_model(self.model)\n","        self.trainer.init_trainer()\n","        self.trainer.run_trainer()\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1qcv-CZAnpo1","outputId":"4f4a5780-19ea-4ff3-8dd7-06020c65a548"},"outputs":[{"output_type":"stream","name":"stdout","text":["Initialized runner SETimesByT5Vaswani2017Kocmi2018_0 with parameters {'dataset_transformer_name': 'dataset_transformer_setimesbyt5', 'model_name': 'transformer_vaswani2017', 'trainer_name': 'model_trainer_kocmi2018', 'latest_param_filename_tag': '1715741500', 'dataset_transformer_hyperparameters': {'sentence_length_min_percentile': 5, 'sentence_length_max_percentile': 95, 'parsed_dataset_filename': 'setimes_parsed-1715586293'}, 'model_hyperparameters': {'d_model': 256, 'nhead': 8, 'num_encoder_layers': 9, 'num_decoder_layers': 3, 'dim_feedforward': 2048, 'dropout': 0.1, 'activation': <function relu at 0x7d0bb13ae9e0>, 'custom_encoder': None, 'custom_decoder': None, 'layer_norm_eps': 1e-05, 'batch_first': True, 'norm_first': False, 'bias': True, 'device': None, 'dtype': None}, 'trainer_hyperparameters': {'optimizer_name': 'Adam', 'lr_scheduler_name': 'ExponentialLR', 'initial_lr': 0.001, 'exp_decay': 0.5, 'epochs': 10, 'epoch_starting_index': 1, 'batch_size_limit': 175, 'element_difference_limit': 19, 'batch_starting_index': 0}}\n","Model trainer initialization complete.Trainer will run on model with parameter count 16637953 and parameter memory use 0.0619812048971653 GB\n","Beginning epoch 2 of 10 with scheduler {'gamma': 0.5, 'base_lrs': [0.001], 'last_epoch': 0, 'verbose': False, '_step_count': 1, '_get_lr_called_within_step': False, '_last_lr': [0.001]}\n","Starting batch.\n","epoch:2/10 batch:1/8961 batch_size:175\n","Completed batch.\n","epoch:2/10 batch:1/8961 batch_size:175 loss:4.500387668609619 time_for_batch_instance:276.06544399261475 total_batch_time:276.06544399261475 running_batch_average:276.06544399261475\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 671605 KiB |  17099 MiB |  14343 GiB |  14342 GiB |\n","|       from large pool | 216999 KiB |  16661 MiB |  14319 GiB |  14318 GiB |\n","|       from small pool | 454606 KiB |    470 MiB |     23 GiB |     23 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 671605 KiB |  17099 MiB |  14343 GiB |  14342 GiB |\n","|       from large pool | 216999 KiB |  16661 MiB |  14319 GiB |  14318 GiB |\n","|       from small pool | 454606 KiB |    470 MiB |     23 GiB |     23 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  17073 MiB |  14307 GiB |  14306 GiB |\n","|       from large pool | 213248 KiB |  16640 MiB |  14283 GiB |  14282 GiB |\n","|       from small pool | 450193 KiB |    465 MiB |     23 GiB |     23 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1406 MiB |  17890 MiB |   3428 GiB |   3426 GiB |\n","|       from large pool |    958 MiB |  17426 MiB |   3423 GiB |   3422 GiB |\n","|       from small pool |    448 MiB |    474 MiB |      4 GiB |      3 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 768139 KiB |   1888 MiB |   4579 GiB |   4578 GiB |\n","|       from large pool | 763993 KiB |   1880 MiB |   4553 GiB |   4552 GiB |\n","|       from small pool |   4146 KiB |     24 MiB |     26 GiB |     26 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |  354245    |  335370    |\n","|       from large pool |      98    |     263    |  204105    |  204007    |\n","|       from small pool |   18777    |   18924    |  150140    |  131363    |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |  354245    |  335370    |\n","|       from large pool |      98    |     263    |  204105    |  204007    |\n","|       from small pool |   18777    |   18924    |  150140    |  131363    |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     236    |     321    |   18627    |   18391    |\n","|       from large pool |      12    |      89    |   16513    |   16501    |\n","|       from small pool |     224    |     237    |    2114    |    1890    |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      79    |     143    |  144839    |  144760    |\n","|       from large pool |      12    |      40    |   92235    |   92223    |\n","|       from small pool |      67    |     119    |   52604    |   52537    |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:2/8961 batch_size:175\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/cuda/memory.py:330: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/cuda/memory.py:356: FutureWarning: torch.cuda.reset_max_memory_cached now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","|       from small pool |   18777    |   18924    |    4990 K  |    4971 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     237    |     323    |  690390    |  690153    |\n","|       from large pool |      13    |      91    |  617374    |  617361    |\n","|       from small pool |     224    |     237    |   73016    |   72792    |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      82    |     141    |    5965 K  |    5965 K  |\n","|       from large pool |      15    |      39    |    3995 K  |    3995 K  |\n","|       from small pool |      67    |     119    |    1969 K  |    1969 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:42/8961 batch_size:175\n","Next token prediction. step:73/221 batch:42/8961 epoch:2/10\n","full seq: The situation becomes even more complex for Serbia with Macedonia knocking on NATO's door and Bosnia and Herzegovina boasting of good co-operation with the Alliance through the Partnership for Peace (PfP).Ģġġġġġġġġġġġġġġġ\n","pref seq: The situation becomes even more complex for Serbia with Macedonia knockin\n","next tok:                                                                         g\n","pred tok:                                                                         C\n","Completed batch.\n","epoch:2/10 batch:42/8961 batch_size:175 loss:1.9519751071929932 time_for_batch_instance:234.0917854309082 total_batch_time:10576.75135397911 running_batch_average:251.8274131899788\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 672728 KiB |  14451 MiB | 505101 GiB | 505100 GiB |\n","|       from large pool | 218122 KiB |  14014 MiB | 504198 GiB | 504197 GiB |\n","|       from small pool | 454606 KiB |    468 MiB |    903 GiB |    903 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 672728 KiB |  14451 MiB | 505101 GiB | 505100 GiB |\n","|       from large pool | 218122 KiB |  14014 MiB | 504198 GiB | 504197 GiB |\n","|       from small pool | 454606 KiB |    468 MiB |    903 GiB |    903 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  14417 MiB | 503956 GiB | 503956 GiB |\n","|       from large pool | 213248 KiB |  13985 MiB | 503053 GiB | 503053 GiB |\n","|       from small pool | 450193 KiB |    464 MiB |    902 GiB |    902 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1422 MiB |  15134 MiB | 118836 GiB | 118835 GiB |\n","|       from large pool |    974 MiB |  14672 MiB | 118690 GiB | 118689 GiB |\n","|       from small pool |    448 MiB |    474 MiB |    145 GiB |    145 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 783400 KiB |   1960 MiB | 163423 GiB | 163422 GiB |\n","|       from large pool | 779254 KiB |   1955 MiB | 162451 GiB | 162451 GiB |\n","|       from small pool |   4146 KiB |     22 MiB |    971 GiB |    971 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   12981 K  |   12962 K  |\n","|       from large pool |      98    |     263    |    7878 K  |    7877 K  |\n","|       from small pool |   18777    |   18924    |    5103 K  |    5085 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   12981 K  |   12962 K  |\n","|       from large pool |      98    |     263    |    7878 K  |    7877 K  |\n","|       from small pool |   18777    |   18924    |    5103 K  |    5085 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     238    |     321    |  705995    |  705757    |\n","|       from large pool |      14    |      89    |  631330    |  631316    |\n","|       from small pool |     224    |     237    |   74665    |   74441    |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      81    |     162    |    6089 K  |    6089 K  |\n","|       from large pool |      14    |      59    |    4075 K  |    4075 K  |\n","|       from small pool |      67    |     118    |    2013 K  |    2013 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:43/8961 batch_size:175\n","Next token prediction. step:33/220 batch:43/8961 epoch:2/10\n","full seq: Combined with its strategic position and infrastructure, the Greek flag gives a great advantage to local charterers who want to have ships come under home country jurisdiction rather than international law.Ģġġġġġġġġġġġġġ\n","pref seq: Combined with its strategic posit\n","next tok:                                 i\n","pred tok:                                 h\n","Completed batch.\n","epoch:2/10 batch:43/8961 batch_size:175 loss:3.419517755508423 time_for_batch_instance:234.0578052997589 total_batch_time:10810.80915927887 running_batch_average:251.41416649485743\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 671696 KiB |  14376 MiB | 515399 GiB | 515398 GiB |\n","|       from large pool | 217090 KiB |  13939 MiB | 514475 GiB | 514475 GiB |\n","|       from small pool | 454606 KiB |    468 MiB |    923 GiB |    922 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 671696 KiB |  14376 MiB | 515399 GiB | 515398 GiB |\n","|       from large pool | 217090 KiB |  13939 MiB | 514475 GiB | 514475 GiB |\n","|       from small pool | 454606 KiB |    468 MiB |    923 GiB |    922 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  14354 MiB | 514231 GiB | 514231 GiB |\n","|       from large pool | 213248 KiB |  13922 MiB | 513309 GiB | 513308 GiB |\n","|       from small pool | 450193 KiB |    464 MiB |    922 GiB |    922 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1682 MiB |  15070 MiB | 121260 GiB | 121258 GiB |\n","|       from large pool |   1234 MiB |  14608 MiB | 121111 GiB | 121110 GiB |\n","|       from small pool |    448 MiB |    474 MiB |    149 GiB |    148 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1026 MiB |   1637 MiB | 166810 GiB | 166809 GiB |\n","|       from large pool |   1021 MiB |   1634 MiB | 165818 GiB | 165817 GiB |\n","|       from small pool |      4 MiB |     22 MiB |    992 GiB |    992 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   13268 K  |   13249 K  |\n","|       from large pool |      98    |     263    |    8051 K  |    8051 K  |\n","|       from small pool |   18777    |   18924    |    5216 K  |    5197 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   13268 K  |   13249 K  |\n","|       from large pool |      98    |     263    |    8051 K  |    8051 K  |\n","|       from small pool |   18777    |   18924    |    5216 K  |    5197 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     236    |     320    |  721560    |  721324    |\n","|       from large pool |      12    |      89    |  645257    |  645245    |\n","|       from small pool |     224    |     237    |   76303    |   76079    |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      79    |     168    |    6221 K  |    6221 K  |\n","|       from large pool |      14    |      65    |    4162 K  |    4162 K  |\n","|       from small pool |      65    |     119    |    2058 K  |    2058 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:44/8961 batch_size:175\n","Next token prediction. step:208/220 batch:44/8961 epoch:2/10\n","full seq: \"[The programme] is aimed at providing funds for modernisation and development in order to achieve the capability to contribute to the NATO task force,\" said Macedonian Defence Minister Vlado Buckovski. [AFP]Ģġġġġġġġġġġġ\n","pref seq: \"[The programme] is aimed at providing funds for modernisation and development in order to achieve the capability to contribute to the NATO task force,\" said Macedonian Defence Minister Vlado Buckovski. [AFP]\n","next tok:                                                                                                                                                                                                                Ģ\n","pred tok:                                                                                                                                                                                                                ġ\n","Completed batch.\n","epoch:2/10 batch:44/8961 batch_size:175 loss:1.0195778608322144 time_for_batch_instance:233.0909788608551 total_batch_time:11043.900138139725 running_batch_average:250.99773041226646\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 671696 KiB |  14376 MiB | 525697 GiB | 525696 GiB |\n","|       from large pool | 217090 KiB |  13939 MiB | 524753 GiB | 524753 GiB |\n","|       from small pool | 454606 KiB |    468 MiB |    943 GiB |    942 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 671696 KiB |  14376 MiB | 525697 GiB | 525696 GiB |\n","|       from large pool | 217090 KiB |  13939 MiB | 524753 GiB | 524753 GiB |\n","|       from small pool | 454606 KiB |    468 MiB |    943 GiB |    942 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  14354 MiB | 524507 GiB | 524506 GiB |\n","|       from large pool | 213248 KiB |  13922 MiB | 523564 GiB | 523564 GiB |\n","|       from small pool | 450193 KiB |    464 MiB |    942 GiB |    942 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1682 MiB |  15070 MiB | 123680 GiB | 123678 GiB |\n","|       from large pool |   1234 MiB |  14608 MiB | 123527 GiB | 123526 GiB |\n","|       from small pool |    448 MiB |    474 MiB |    152 GiB |    151 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1026 MiB |   1637 MiB | 170206 GiB | 170205 GiB |\n","|       from large pool |   1021 MiB |   1633 MiB | 169192 GiB | 169191 GiB |\n","|       from small pool |      4 MiB |     21 MiB |   1014 GiB |   1014 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   13554 K  |   13535 K  |\n","|       from large pool |      98    |     263    |    8225 K  |    8225 K  |\n","|       from small pool |   18777    |   18924    |    5329 K  |    5310 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   13554 K  |   13535 K  |\n","|       from large pool |      98    |     263    |    8225 K  |    8225 K  |\n","|       from small pool |   18777    |   18924    |    5329 K  |    5310 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     236    |     321    |  737129    |  736893    |\n","|       from large pool |      12    |      90    |  659185    |  659173    |\n","|       from small pool |     224    |     237    |   77944    |   77720    |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      79    |     168    |    6353 K  |    6353 K  |\n","|       from large pool |      14    |      65    |    4249 K  |    4249 K  |\n","|       from small pool |      65    |     119    |    2104 K  |    2104 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:45/8961 batch_size:175\n","Next token prediction. step:88/219 batch:45/8961 epoch:2/10\n","full seq: \"Other PIC members could not accept [the Russian] request as it would go against the entire philosophy, which is based upon results and not time,\" High Representative to BiH Miroslav Lajcak said afterward.Ģġġġġġġġġġġġġġ\n","pref seq: \"Other PIC members could not accept [the Russian] request as it would go against the ent\n","next tok:                                                                                        i\n","pred tok:                                                                                        q\n","Completed batch.\n","epoch:2/10 batch:45/8961 batch_size:175 loss:3.4846625328063965 time_for_batch_instance:232.10336017608643 total_batch_time:11276.003498315811 running_batch_average:250.57785551812913\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 672204 KiB |  14334 MiB | 535913 GiB | 535913 GiB |\n","|       from large pool | 217598 KiB |  13898 MiB | 534950 GiB | 534950 GiB |\n","|       from small pool | 454606 KiB |    468 MiB |    963 GiB |    962 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 672204 KiB |  14334 MiB | 535913 GiB | 535913 GiB |\n","|       from large pool | 217598 KiB |  13898 MiB | 534950 GiB | 534950 GiB |\n","|       from small pool | 454606 KiB |    468 MiB |    963 GiB |    962 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  14292 MiB | 534692 GiB | 534691 GiB |\n","|       from large pool | 213248 KiB |  13859 MiB | 533729 GiB | 533729 GiB |\n","|       from small pool | 450193 KiB |    464 MiB |    962 GiB |    962 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1402 MiB |  14984 MiB | 126032 GiB | 126030 GiB |\n","|       from large pool |    952 MiB |  14520 MiB | 125876 GiB | 125875 GiB |\n","|       from small pool |    450 MiB |    474 MiB |    155 GiB |    154 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 763443 KiB |   1895 MiB | 173692 GiB | 173691 GiB |\n","|       from large pool | 757249 KiB |   1883 MiB | 172656 GiB | 172656 GiB |\n","|       from small pool |   6194 KiB |     22 MiB |   1035 GiB |   1035 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   13839 K  |   13820 K  |\n","|       from large pool |      98    |     263    |    8398 K  |    8398 K  |\n","|       from small pool |   18777    |   18924    |    5441 K  |    5422 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   13839 K  |   13820 K  |\n","|       from large pool |      98    |     263    |    8398 K  |    8398 K  |\n","|       from small pool |   18777    |   18924    |    5441 K  |    5422 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     237    |     322    |     752 K  |     752 K  |\n","|       from large pool |      12    |      90    |     672 K  |     672 K  |\n","|       from small pool |     225    |     237    |      79 K  |      79 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      82    |     150    |    6482 K  |    6482 K  |\n","|       from large pool |      11    |      47    |    4333 K  |    4333 K  |\n","|       from small pool |      71    |     118    |    2148 K  |    2148 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:46/8961 batch_size:175\n","Next token prediction. step:109/218 batch:46/8961 epoch:2/10\n","full seq: The same \"ownership unbundling\" requirement would apply to companies from countries outside the 27-nation bloc, such as Russia, seeking to buy a controlling stake in gas pipelines or electricity power grids.Ģġġġġġġġġġġ\n","pref seq: The same \"ownership unbundling\" requirement would apply to companies from countries outside the 27-nation blo\n","next tok:                                                                                                             c\n","pred tok:                                                                                                             -\n","Completed batch.\n","epoch:2/10 batch:46/8961 batch_size:175 loss:1.06023108959198 time_for_batch_instance:230.9581654071808 total_batch_time:11506.961663722992 running_batch_average:250.1513405157172\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 673747 KiB |  14306 MiB | 546075 GiB | 546074 GiB |\n","|       from large pool | 219141 KiB |  13870 MiB | 545092 GiB | 545092 GiB |\n","|       from small pool | 454606 KiB |    468 MiB |    982 GiB |    982 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 673747 KiB |  14306 MiB | 546075 GiB | 546074 GiB |\n","|       from large pool | 219141 KiB |  13870 MiB | 545092 GiB | 545092 GiB |\n","|       from small pool | 454606 KiB |    468 MiB |    982 GiB |    982 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  14273 MiB | 544823 GiB | 544822 GiB |\n","|       from large pool | 213248 KiB |  13841 MiB | 543840 GiB | 543840 GiB |\n","|       from small pool | 450193 KiB |    464 MiB |    982 GiB |    981 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1958 MiB |  14974 MiB | 128413 GiB | 128411 GiB |\n","|       from large pool |   1508 MiB |  14510 MiB | 128255 GiB | 128253 GiB |\n","|       from small pool |    450 MiB |    474 MiB |    158 GiB |    158 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1300 MiB |   1935 MiB | 177085 GiB | 177084 GiB |\n","|       from large pool |   1293 MiB |   1930 MiB | 176029 GiB | 176028 GiB |\n","|       from small pool |      6 MiB |     22 MiB |   1056 GiB |   1056 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   14123 K  |   14104 K  |\n","|       from large pool |      98    |     263    |    8570 K  |    8570 K  |\n","|       from small pool |   18777    |   18924    |    5552 K  |    5534 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   14123 K  |   14104 K  |\n","|       from large pool |      98    |     263    |    8570 K  |    8570 K  |\n","|       from small pool |   18777    |   18924    |    5552 K  |    5534 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     243    |     323    |     767 K  |     767 K  |\n","|       from large pool |      18    |      91    |     686 K  |     686 K  |\n","|       from small pool |     225    |     237    |      81 K  |      80 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      88    |     150    |    6611 K  |    6611 K  |\n","|       from large pool |      17    |      48    |    4417 K  |    4417 K  |\n","|       from small pool |      71    |     118    |    2193 K  |    2193 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:47/8961 batch_size:175\n","Next token prediction. step:42/217 batch:47/8961 epoch:2/10\n","full seq: Quick action was taken because of the Kosovo issue: Serbia wants to enter the endgame of the Kosovo status process with a declaration that the province will \"forever remain an inalienable part of Serbia\".Ģġġġġġġġġġġġġ\n","pref seq: Quick action was taken because of the Koso\n","next tok:                                          v\n","pred tok:                                          g\n","Completed batch.\n","epoch:2/10 batch:47/8961 batch_size:175 loss:1.0232421159744263 time_for_batch_instance:229.3208999633789 total_batch_time:11736.28256368637 running_batch_average:249.7081396529015\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 673990 KiB |  14183 MiB | 556117 GiB | 556116 GiB |\n","|       from large pool | 219384 KiB |  13747 MiB | 555114 GiB | 555114 GiB |\n","|       from small pool | 454606 KiB |    468 MiB |   1002 GiB |   1001 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 673990 KiB |  14183 MiB | 556117 GiB | 556116 GiB |\n","|       from large pool | 219384 KiB |  13747 MiB | 555114 GiB | 555114 GiB |\n","|       from small pool | 454606 KiB |    468 MiB |   1002 GiB |   1001 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  14166 MiB | 554829 GiB | 554828 GiB |\n","|       from large pool | 213248 KiB |  13734 MiB | 553827 GiB | 553827 GiB |\n","|       from small pool | 450193 KiB |    464 MiB |   1001 GiB |   1001 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1846 MiB |  14882 MiB | 130764 GiB | 130762 GiB |\n","|       from large pool |   1398 MiB |  14420 MiB | 130602 GiB | 130600 GiB |\n","|       from small pool |    448 MiB |    474 MiB |    161 GiB |    161 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1187 MiB |   1935 MiB | 180340 GiB | 180339 GiB |\n","|       from large pool |   1183 MiB |   1930 MiB | 179263 GiB | 179262 GiB |\n","|       from small pool |      4 MiB |     21 MiB |   1077 GiB |   1077 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   14406 K  |   14387 K  |\n","|       from large pool |      98    |     263    |    8742 K  |    8741 K  |\n","|       from small pool |   18777    |   18924    |    5664 K  |    5645 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   14406 K  |   14387 K  |\n","|       from large pool |      98    |     263    |    8742 K  |    8741 K  |\n","|       from small pool |   18777    |   18924    |    5664 K  |    5645 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     239    |     321    |     783 K  |     782 K  |\n","|       from large pool |      15    |      89    |     700 K  |     700 K  |\n","|       from small pool |     224    |     237    |      82 K  |      82 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      78    |     164    |    6739 K  |    6739 K  |\n","|       from large pool |      14    |      62    |    4501 K  |    4501 K  |\n","|       from small pool |      64    |     118    |    2238 K  |    2238 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:48/8961 batch_size:175\n","Next token prediction. step:9/217 batch:48/8961 epoch:2/10\n","full seq: Krafts Food Romania will close its production unit in Brasov with 400 employees and partially relocate the jobs to Bulgaria, but Coca-Cola dismissed speculation about closing its units in Iasi and Oradea.Ģġġġġġġġġġġġġ\n","pref seq: Krafts Fo\n","next tok:         o\n","pred tok:         -\n","Completed batch.\n","epoch:2/10 batch:48/8961 batch_size:175 loss:0.907751202583313 time_for_batch_instance:229.5607135295868 total_batch_time:11965.843277215958 running_batch_average:249.2884016086658\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 673066 KiB |  14183 MiB | 566159 GiB | 566159 GiB |\n","|       from large pool | 218460 KiB |  13746 MiB | 565137 GiB | 565137 GiB |\n","|       from small pool | 454606 KiB |    468 MiB |   1022 GiB |   1021 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 673066 KiB |  14183 MiB | 566159 GiB | 566159 GiB |\n","|       from large pool | 218460 KiB |  13746 MiB | 565137 GiB | 565137 GiB |\n","|       from small pool | 454606 KiB |    468 MiB |   1022 GiB |   1021 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  14166 MiB | 564836 GiB | 564835 GiB |\n","|       from large pool | 213248 KiB |  13734 MiB | 563814 GiB | 563814 GiB |\n","|       from small pool | 450193 KiB |    464 MiB |   1021 GiB |   1020 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1608 MiB |  14866 MiB | 133112 GiB | 133111 GiB |\n","|       from large pool |   1160 MiB |  14404 MiB | 132947 GiB | 132946 GiB |\n","|       from small pool |    448 MiB |    474 MiB |    164 GiB |    164 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |    950 MiB |   1844 MiB | 183585 GiB | 183584 GiB |\n","|       from large pool |    946 MiB |   1841 MiB | 182486 GiB | 182485 GiB |\n","|       from small pool |      4 MiB |     22 MiB |   1098 GiB |   1098 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   14688 K  |   14669 K  |\n","|       from large pool |      98    |     263    |    8913 K  |    8913 K  |\n","|       from small pool |   18777    |   18924    |    5775 K  |    5756 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   14688 K  |   14669 K  |\n","|       from large pool |      98    |     263    |    8913 K  |    8913 K  |\n","|       from small pool |   18777    |   18924    |    5775 K  |    5756 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     238    |     317    |     798 K  |     798 K  |\n","|       from large pool |      14    |      86    |     713 K  |     713 K  |\n","|       from small pool |     224    |     237    |      84 K  |      84 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      78    |     164    |    6867 K  |    6867 K  |\n","|       from large pool |      14    |      62    |    4584 K  |    4584 K  |\n","|       from small pool |      64    |     118    |    2283 K  |    2282 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:49/8961 batch_size:175\n","Next token prediction. step:93/217 batch:49/8961 epoch:2/10\n","full seq: Solana began his two-day visit by meeting with Serbian Prime Minister Zoran Zivkovic, his deputy, Nebojsa Covic, and the foreign and defence ministers of Serbia-Montenegro, Goran Svilanovic and Boris Tadic.Ģġġġġġġġġġġ\n","pref seq: Solana began his two-day visit by meeting with Serbian Prime Minister Zoran Zivkovic, his dep\n","next tok:                                                                                             u\n","pred tok:                                                                                             -\n","Completed batch.\n","epoch:2/10 batch:49/8961 batch_size:175 loss:0.9972884654998779 time_for_batch_instance:229.3499310016632 total_batch_time:12195.19320821762 running_batch_average:248.88149404525757\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 675482 KiB |  14183 MiB | 576201 GiB | 576200 GiB |\n","|       from large pool | 220876 KiB |  13746 MiB | 575159 GiB | 575159 GiB |\n","|       from small pool | 454606 KiB |    468 MiB |   1041 GiB |   1041 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 675482 KiB |  14183 MiB | 576201 GiB | 576200 GiB |\n","|       from large pool | 220876 KiB |  13746 MiB | 575159 GiB | 575159 GiB |\n","|       from small pool | 454606 KiB |    468 MiB |   1041 GiB |   1041 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  14166 MiB | 574842 GiB | 574841 GiB |\n","|       from large pool | 213248 KiB |  13734 MiB | 573801 GiB | 573801 GiB |\n","|       from small pool | 450193 KiB |    464 MiB |   1041 GiB |   1040 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1868 MiB |  14886 MiB | 135470 GiB | 135469 GiB |\n","|       from large pool |   1420 MiB |  14424 MiB | 135303 GiB | 135301 GiB |\n","|       from small pool |    448 MiB |    474 MiB |    167 GiB |    167 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1208 MiB |   1666 MiB | 186836 GiB | 186834 GiB |\n","|       from large pool |   1204 MiB |   1661 MiB | 185716 GiB | 185715 GiB |\n","|       from small pool |      4 MiB |     21 MiB |   1119 GiB |   1119 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   14971 K  |   14952 K  |\n","|       from large pool |      98    |     263    |    9084 K  |    9084 K  |\n","|       from small pool |   18777    |   18924    |    5886 K  |    5867 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   14971 K  |   14952 K  |\n","|       from large pool |      98    |     263    |    9084 K  |    9084 K  |\n","|       from small pool |   18777    |   18924    |    5886 K  |    5867 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     241    |     321    |     813 K  |     813 K  |\n","|       from large pool |      17    |      90    |     727 K  |     727 K  |\n","|       from small pool |     224    |     237    |      85 K  |      85 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      80    |     166    |    6995 K  |    6995 K  |\n","|       from large pool |      16    |      64    |    4668 K  |    4668 K  |\n","|       from small pool |      64    |     118    |    2327 K  |    2327 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:50/8961 batch_size:175\n","Next token prediction. step:189/216 batch:50/8961 epoch:2/10\n","full seq: But Greece, which currently holds the six-month rotating presidency of the Council of Ministers and is a keen sponsor of Balkan development, plans to raise the subject at its Thessaloniki summit in June.Ģġġġġġġġġġġġġ\n","pref seq: But Greece, which currently holds the six-month rotating presidency of the Council of Ministers and is a keen sponsor of Balkan development, plans to raise the subject at its Thessaloniki s\n","next tok:                                                                                                                                                                                             u\n","pred tok:                                                                                                                                                                                             -\n","Completed batch.\n","epoch:2/10 batch:50/8961 batch_size:175 loss:0.8708951473236084 time_for_batch_instance:228.28372263908386 total_batch_time:12423.476930856705 running_batch_average:248.4695386171341\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 672915 KiB |  14131 MiB | 586138 GiB | 586137 GiB |\n","|       from large pool | 218309 KiB |  13695 MiB | 585077 GiB | 585076 GiB |\n","|       from small pool | 454606 KiB |    468 MiB |   1061 GiB |   1060 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 672915 KiB |  14131 MiB | 586138 GiB | 586137 GiB |\n","|       from large pool | 218309 KiB |  13695 MiB | 585077 GiB | 585076 GiB |\n","|       from small pool | 454606 KiB |    468 MiB |   1061 GiB |   1060 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  14104 MiB | 584760 GiB | 584759 GiB |\n","|       from large pool | 213248 KiB |  13672 MiB | 583699 GiB | 583699 GiB |\n","|       from small pool | 450193 KiB |    464 MiB |   1060 GiB |   1060 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1706 MiB |  14806 MiB | 137786 GiB | 137784 GiB |\n","|       from large pool |   1258 MiB |  14344 MiB | 137614 GiB | 137613 GiB |\n","|       from small pool |    448 MiB |    474 MiB |    171 GiB |    170 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1048 MiB |   1923 MiB | 190183 GiB | 190182 GiB |\n","|       from large pool |   1044 MiB |   1917 MiB | 189043 GiB | 189041 GiB |\n","|       from small pool |      4 MiB |     22 MiB |   1140 GiB |   1140 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   15252 K  |   15233 K  |\n","|       from large pool |      98    |     263    |    9255 K  |    9255 K  |\n","|       from small pool |   18777    |   18924    |    5996 K  |    5978 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   15252 K  |   15233 K  |\n","|       from large pool |      98    |     263    |    9255 K  |    9255 K  |\n","|       from small pool |   18777    |   18924    |    5996 K  |    5978 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     238    |     322    |     828 K  |     828 K  |\n","|       from large pool |      14    |      91    |     741 K  |     741 K  |\n","|       from small pool |     224    |     237    |      87 K  |      87 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      79    |     150    |    7143 K  |    7143 K  |\n","|       from large pool |      14    |      47    |    4771 K  |    4771 K  |\n","|       from small pool |      65    |     120    |    2372 K  |    2372 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:51/8961 batch_size:175\n","Next token prediction. step:199/215 batch:51/8961 epoch:2/10\n","full seq: (EurActiv, The New Anatolian, Turkish Daily News - 05/03/07; Journal of Turkish Weekly - 04/03/07; New Europe, Today's Zaman, The New Anatolian - 03/03/07; AP, EUobserver, Turkish Daily News - 02/03/07)Ģġġġġġġġġġġġġ\n","pref seq: (EurActiv, The New Anatolian, Turkish Daily News - 05/03/07; Journal of Turkish Weekly - 04/03/07; New Europe, Today's Zaman, The New Anatolian - 03/03/07; AP, EUobserver, Turkish Daily News - 02/03/\n","next tok:                                                                                                                                                                                                       0\n","pred tok:                                                                                                                                                                                                       Ģ\n","Completed batch.\n","epoch:2/10 batch:51/8961 batch_size:175 loss:0.6757454872131348 time_for_batch_instance:227.08844327926636 total_batch_time:12650.565374135971 running_batch_average:248.05030145364648\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 673744 KiB |  14064 MiB | 595980 GiB | 595979 GiB |\n","|       from large pool | 219138 KiB |  13628 MiB | 594899 GiB | 594899 GiB |\n","|       from small pool | 454606 KiB |    468 MiB |   1080 GiB |   1080 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 673744 KiB |  14064 MiB | 595980 GiB | 595979 GiB |\n","|       from large pool | 219138 KiB |  13628 MiB | 594899 GiB | 594899 GiB |\n","|       from small pool | 454606 KiB |    468 MiB |   1080 GiB |   1080 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  14041 MiB | 594589 GiB | 594588 GiB |\n","|       from large pool | 213248 KiB |  13609 MiB | 593509 GiB | 593508 GiB |\n","|       from small pool | 450193 KiB |    464 MiB |   1079 GiB |   1079 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1714 MiB |  14722 MiB | 140040 GiB | 140038 GiB |\n","|       from large pool |   1266 MiB |  14258 MiB | 139866 GiB | 139865 GiB |\n","|       from small pool |    448 MiB |    474 MiB |    174 GiB |    173 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1056 MiB |   1953 MiB | 193487 GiB | 193486 GiB |\n","|       from large pool |   1051 MiB |   1947 MiB | 192327 GiB | 192326 GiB |\n","|       from small pool |      4 MiB |     21 MiB |   1160 GiB |   1160 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   15532 K  |   15513 K  |\n","|       from large pool |      98    |     263    |    9424 K  |    9424 K  |\n","|       from small pool |   18777    |   18924    |    6107 K  |    6088 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   15532 K  |   15513 K  |\n","|       from large pool |      98    |     263    |    9424 K  |    9424 K  |\n","|       from small pool |   18777    |   18924    |    6107 K  |    6088 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     239    |     323    |     843 K  |     843 K  |\n","|       from large pool |      15    |      92    |     754 K  |     754 K  |\n","|       from small pool |     224    |     237    |      89 K  |      88 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      82    |     153    |    7291 K  |    7291 K  |\n","|       from large pool |      15    |      52    |    4874 K  |    4874 K  |\n","|       from small pool |      67    |     118    |    2416 K  |    2416 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:52/8961 batch_size:175\n","Next token prediction. step:98/214 batch:52/8961 epoch:2/10\n","full seq: He was reportedly notified about his dismissal over the telephone, with Boc describing his decision as a political one that had nothing to do with his performance as minister, according to The Sofia Echo.Ģġġġġġġġġġ\n","pref seq: He was reportedly notified about his dismissal over the telephone, with Boc describing his decisio\n","next tok:                                                                                                  n\n","pred tok:                                                                                                  (\n","Completed batch.\n","epoch:2/10 batch:52/8961 batch_size:175 loss:1.2163574695587158 time_for_batch_instance:225.72866296768188 total_batch_time:12876.294037103653 running_batch_average:247.62103917507025\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 672963 KiB |  14036 MiB | 605768 GiB | 605767 GiB |\n","|       from large pool | 218357 KiB |  13600 MiB | 604668 GiB | 604668 GiB |\n","|       from small pool | 454606 KiB |    468 MiB |   1099 GiB |   1099 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 672963 KiB |  14036 MiB | 605768 GiB | 605767 GiB |\n","|       from large pool | 218357 KiB |  13600 MiB | 604668 GiB | 604668 GiB |\n","|       from small pool | 454606 KiB |    468 MiB |   1099 GiB |   1099 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  14022 MiB | 604364 GiB | 604364 GiB |\n","|       from large pool | 213248 KiB |  13590 MiB | 603265 GiB | 603265 GiB |\n","|       from small pool | 450193 KiB |    464 MiB |   1099 GiB |   1098 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1702 MiB |  14712 MiB | 142338 GiB | 142336 GiB |\n","|       from large pool |   1254 MiB |  14250 MiB | 142161 GiB | 142160 GiB |\n","|       from small pool |    448 MiB |    474 MiB |    177 GiB |    176 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1044 MiB |   1656 MiB | 196711 GiB | 196710 GiB |\n","|       from large pool |   1040 MiB |   1652 MiB | 195530 GiB | 195529 GiB |\n","|       from small pool |      4 MiB |     22 MiB |   1181 GiB |   1181 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   15810 K  |   15791 K  |\n","|       from large pool |      98    |     263    |    9593 K  |    9593 K  |\n","|       from small pool |   18777    |   18924    |    6216 K  |    6198 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   15810 K  |   15791 K  |\n","|       from large pool |      98    |     263    |    9593 K  |    9593 K  |\n","|       from small pool |   18777    |   18924    |    6216 K  |    6198 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     238    |     321    |     859 K  |     858 K  |\n","|       from large pool |      14    |      90    |     768 K  |     768 K  |\n","|       from small pool |     224    |     237    |      90 K  |      90 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      81    |     151    |    7437 K  |    7437 K  |\n","|       from large pool |      16    |      48    |    4977 K  |    4977 K  |\n","|       from small pool |      65    |     118    |    2460 K  |    2460 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:53/8961 batch_size:175\n","Next token prediction. step:91/213 batch:53/8961 epoch:2/10\n","full seq: During the cross examination demonstration, CEELI criminal law liaison Erik Larson told the lawyers to remember two things: to think like a hunter and never ask questions they didn't know the answer to.Ģġġġġġġġġġġ\n","pref seq: During the cross examination demonstration, CEELI criminal law liaison Erik Larson told the\n","next tok:                                                                                            \n","pred tok:                                                                                           (\n","Completed batch.\n","epoch:2/10 batch:53/8961 batch_size:175 loss:1.0481691360473633 time_for_batch_instance:224.9240379333496 total_batch_time:13101.218075037003 running_batch_average:247.1927938686227\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 673119 KiB |  13974 MiB | 615473 GiB | 615472 GiB |\n","|       from large pool | 218513 KiB |  13537 MiB | 614354 GiB | 614353 GiB |\n","|       from small pool | 454606 KiB |    468 MiB |   1119 GiB |   1118 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 673119 KiB |  13974 MiB | 615473 GiB | 615472 GiB |\n","|       from large pool | 218513 KiB |  13537 MiB | 614354 GiB | 614353 GiB |\n","|       from small pool | 454606 KiB |    468 MiB |   1119 GiB |   1118 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  13960 MiB | 614053 GiB | 614052 GiB |\n","|       from large pool | 213248 KiB |  13528 MiB | 612934 GiB | 612934 GiB |\n","|       from small pool | 450193 KiB |    464 MiB |   1118 GiB |   1118 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1432 MiB |  14676 MiB | 144609 GiB | 144607 GiB |\n","|       from large pool |    984 MiB |  14214 MiB | 144429 GiB | 144428 GiB |\n","|       from small pool |    448 MiB |    474 MiB |    180 GiB |    179 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |    774 MiB |   1941 MiB | 199850 GiB | 199849 GiB |\n","|       from large pool |    770 MiB |   1936 MiB | 198648 GiB | 198647 GiB |\n","|       from small pool |      4 MiB |     21 MiB |   1202 GiB |   1202 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   16087 K  |   16068 K  |\n","|       from large pool |      98    |     263    |    9761 K  |    9761 K  |\n","|       from small pool |   18777    |   18924    |    6325 K  |    6307 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   16087 K  |   16068 K  |\n","|       from large pool |      98    |     263    |    9761 K  |    9761 K  |\n","|       from small pool |   18777    |   18924    |    6325 K  |    6307 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     238    |     321    |     874 K  |     873 K  |\n","|       from large pool |      14    |      89    |     781 K  |     781 K  |\n","|       from small pool |     224    |     237    |      92 K  |      92 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      83    |     166    |    7582 K  |    7582 K  |\n","|       from large pool |      16    |      63    |    5078 K  |    5078 K  |\n","|       from small pool |      67    |     118    |    2504 K  |    2504 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:54/8961 batch_size:175\n","Next token prediction. step:193/212 batch:54/8961 epoch:2/10\n","full seq: During separate visits to Belgrade this week, Russian Foreign Minister Sergei Lavrov and Chinese Deputy Prime Minister Hui Liangyu both said their countries were against imposing a solution on Serbia.Ģġġġġġġġġġġġ\n","pref seq: During separate visits to Belgrade this week, Russian Foreign Minister Sergei Lavrov and Chinese Deputy Prime Minister Hui Liangyu both said their countries were against imposing a solution on \n","next tok:                                                                                                                                                                                                 S\n","pred tok:                                                                                                                                                                                                 Ģ\n","Completed batch.\n","epoch:2/10 batch:54/8961 batch_size:175 loss:1.9647597074508667 time_for_batch_instance:224.10836482048035 total_batch_time:13325.326439857483 running_batch_average:246.76530444180523\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 673435 KiB |  13874 MiB | 625050 GiB | 625049 GiB |\n","|       from large pool | 218829 KiB |  13438 MiB | 623911 GiB | 623911 GiB |\n","|       from small pool | 454606 KiB |    468 MiB |   1138 GiB |   1137 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 673435 KiB |  13874 MiB | 625050 GiB | 625049 GiB |\n","|       from large pool | 218829 KiB |  13438 MiB | 623911 GiB | 623911 GiB |\n","|       from small pool | 454606 KiB |    468 MiB |   1138 GiB |   1137 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  13853 MiB | 623619 GiB | 623618 GiB |\n","|       from large pool | 213248 KiB |  13421 MiB | 622481 GiB | 622481 GiB |\n","|       from small pool | 450193 KiB |    464 MiB |   1137 GiB |   1137 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1560 MiB |  14524 MiB | 146850 GiB | 146849 GiB |\n","|       from large pool |   1112 MiB |  14060 MiB | 146667 GiB | 146666 GiB |\n","|       from small pool |    448 MiB |    474 MiB |    183 GiB |    183 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |    902 MiB |   1830 MiB | 203138 GiB | 203137 GiB |\n","|       from large pool |    898 MiB |   1825 MiB | 201915 GiB | 201914 GiB |\n","|       from small pool |      4 MiB |     20 MiB |   1222 GiB |   1222 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   16363 K  |   16344 K  |\n","|       from large pool |      98    |     263    |    9929 K  |    9928 K  |\n","|       from small pool |   18777    |   18924    |    6434 K  |    6415 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   16363 K  |   16344 K  |\n","|       from large pool |      98    |     263    |    9929 K  |    9928 K  |\n","|       from small pool |   18777    |   18924    |    6434 K  |    6415 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     239    |     322    |     889 K  |     888 K  |\n","|       from large pool |      15    |      90    |     795 K  |     795 K  |\n","|       from small pool |     224    |     237    |      93 K  |      93 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      80    |     152    |    7733 K  |    7733 K  |\n","|       from large pool |      15    |      51    |    5185 K  |    5185 K  |\n","|       from small pool |      65    |     119    |    2548 K  |    2548 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:55/8961 batch_size:175\n","Next token prediction. step:112/212 batch:55/8961 epoch:2/10\n","full seq: Dubai International Properties will assume 80 per cent of the estimated cost, while the municipality will take on 20 per cent -- the maximum allowed under regulations set by the Capital Markets Board.Ģġġġġġġġġġġġ\n","pref seq: Dubai International Properties will assume 80 per cent of the estimated cost, while the municipality will take o\n","next tok:                                                                                                                n\n","pred tok:                                                                                                                c\n","Completed batch.\n","epoch:2/10 batch:55/8961 batch_size:175 loss:1.3229479789733887 time_for_batch_instance:223.99970817565918 total_batch_time:13549.326148033142 running_batch_average:246.3513845096935\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 675498 KiB |  13942 MiB | 634677 GiB | 634676 GiB |\n","|       from large pool | 220892 KiB |  13506 MiB | 633519 GiB | 633519 GiB |\n","|       from small pool | 454606 KiB |    468 MiB |   1157 GiB |   1157 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 675498 KiB |  13942 MiB | 634677 GiB | 634676 GiB |\n","|       from large pool | 220892 KiB |  13506 MiB | 633519 GiB | 633519 GiB |\n","|       from small pool | 454606 KiB |    468 MiB |   1157 GiB |   1157 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  13897 MiB | 633220 GiB | 633219 GiB |\n","|       from large pool | 213248 KiB |  13465 MiB | 632063 GiB | 632063 GiB |\n","|       from small pool | 450193 KiB |    464 MiB |   1156 GiB |   1156 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1890 MiB |  14576 MiB | 149094 GiB | 149092 GiB |\n","|       from large pool |   1442 MiB |  14114 MiB | 148907 GiB | 148905 GiB |\n","|       from small pool |    448 MiB |    474 MiB |    186 GiB |    186 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1230 MiB |   1788 MiB | 206320 GiB | 206319 GiB |\n","|       from large pool |   1226 MiB |   1784 MiB | 205077 GiB | 205076 GiB |\n","|       from small pool |      4 MiB |     22 MiB |   1243 GiB |   1243 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   16639 K  |   16620 K  |\n","|       from large pool |      98    |     263    |   10096 K  |   10096 K  |\n","|       from small pool |   18777    |   18924    |    6543 K  |    6524 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   16639 K  |   16620 K  |\n","|       from large pool |      98    |     263    |   10096 K  |   10096 K  |\n","|       from small pool |   18777    |   18924    |    6543 K  |    6524 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     242    |     324    |     904 K  |     903 K  |\n","|       from large pool |      18    |      92    |     808 K  |     808 K  |\n","|       from small pool |     224    |     237    |      95 K  |      95 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      82    |     149    |    7876 K  |    7875 K  |\n","|       from large pool |      17    |      47    |    5284 K  |    5284 K  |\n","|       from small pool |      65    |     119    |    2591 K  |    2591 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:56/8961 batch_size:175\n","Next token prediction. step:128/212 batch:56/8961 epoch:2/10\n","full seq: A poll commissioned and published on Wednesday by daily Evenimentul Zilei showed that Basescu (33%) and Geona (30%) are likely to compete in the runoff, with the liberal Antonescu (18%) lagging behind.Ģġġġġġġġġġġ\n","pref seq: A poll commissioned and published on Wednesday by daily Evenimentul Zilei showed that Basescu (33%) and Geona (30%) are likely t\n","next tok:                                                                                                                                o\n","pred tok:                                                                                                                                ,\n","Completed batch.\n","epoch:2/10 batch:56/8961 batch_size:175 loss:0.9373061060905457 time_for_batch_instance:224.26474595069885 total_batch_time:13773.590893983841 running_batch_average:245.95698024971145\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 674400 KiB |  13875 MiB | 644254 GiB | 644253 GiB |\n","|       from large pool | 219794 KiB |  13439 MiB | 643077 GiB | 643077 GiB |\n","|       from small pool | 454606 KiB |    468 MiB |   1176 GiB |   1176 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 674400 KiB |  13875 MiB | 644254 GiB | 644253 GiB |\n","|       from large pool | 219794 KiB |  13439 MiB | 643077 GiB | 643077 GiB |\n","|       from small pool | 454606 KiB |    468 MiB |   1176 GiB |   1176 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  13853 MiB | 642786 GiB | 642786 GiB |\n","|       from large pool | 213248 KiB |  13421 MiB | 641610 GiB | 641610 GiB |\n","|       from small pool | 450193 KiB |    464 MiB |   1176 GiB |   1175 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1570 MiB |  14518 MiB | 151340 GiB | 151338 GiB |\n","|       from large pool |   1122 MiB |  14054 MiB | 151150 GiB | 151148 GiB |\n","|       from small pool |    448 MiB |    474 MiB |    189 GiB |    189 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |    911 MiB |   1674 MiB | 209602 GiB | 209601 GiB |\n","|       from large pool |    907 MiB |   1669 MiB | 208338 GiB | 208337 GiB |\n","|       from small pool |      4 MiB |     20 MiB |   1263 GiB |   1263 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   16915 K  |   16896 K  |\n","|       from large pool |      98    |     263    |   10263 K  |   10263 K  |\n","|       from small pool |   18777    |   18924    |    6651 K  |    6633 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   16915 K  |   16896 K  |\n","|       from large pool |      98    |     263    |   10263 K  |   10263 K  |\n","|       from small pool |   18777    |   18924    |    6651 K  |    6633 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     240    |     323    |     919 K  |     918 K  |\n","|       from large pool |      16    |      91    |     821 K  |     821 K  |\n","|       from small pool |     224    |     237    |      97 K  |      97 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      81    |     156    |    8026 K  |    8026 K  |\n","|       from large pool |      16    |      55    |    5390 K  |    5390 K  |\n","|       from small pool |      65    |     119    |    2635 K  |    2635 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:57/8961 batch_size:175\n","Next token prediction. step:21/212 batch:57/8961 epoch:2/10\n","full seq: According to Serbian Foreign Minister Vuk Jeremic, the abolition of the EU visa requirements introduced in 1991, when the former Yugoslavia began falling apart, was \"a victory for all Serbian citizens\".Ģġġġġġġġġġ\n","pref seq: According to Serbian \n","next tok:                     F\n","pred tok:                     V\n","Completed batch.\n","epoch:2/10 batch:57/8961 batch_size:175 loss:2.069842576980591 time_for_batch_instance:224.01979637145996 total_batch_time:13997.6106903553 running_batch_average:245.5721173746544\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 674400 KiB |  13875 MiB | 653831 GiB | 653831 GiB |\n","|       from large pool | 219794 KiB |  13439 MiB | 652635 GiB | 652635 GiB |\n","|       from small pool | 454606 KiB |    468 MiB |   1195 GiB |   1195 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 674400 KiB |  13875 MiB | 653831 GiB | 653831 GiB |\n","|       from large pool | 219794 KiB |  13439 MiB | 652635 GiB | 652635 GiB |\n","|       from small pool | 454606 KiB |    468 MiB |   1195 GiB |   1195 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  13853 MiB | 652352 GiB | 652352 GiB |\n","|       from large pool | 213248 KiB |  13421 MiB | 651157 GiB | 651157 GiB |\n","|       from small pool | 450193 KiB |    464 MiB |   1195 GiB |   1194 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1570 MiB |  14518 MiB | 153590 GiB | 153589 GiB |\n","|       from large pool |   1122 MiB |  14054 MiB | 153397 GiB | 153396 GiB |\n","|       from small pool |    448 MiB |    474 MiB |    193 GiB |    192 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |    911 MiB |   1697 MiB | 212868 GiB | 212867 GiB |\n","|       from large pool |    907 MiB |   1693 MiB | 211584 GiB | 211583 GiB |\n","|       from small pool |      4 MiB |     20 MiB |   1284 GiB |   1284 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   17191 K  |   17172 K  |\n","|       from large pool |      98    |     263    |   10430 K  |   10430 K  |\n","|       from small pool |   18777    |   18924    |    6760 K  |    6741 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   17191 K  |   17172 K  |\n","|       from large pool |      98    |     263    |   10430 K  |   10430 K  |\n","|       from small pool |   18777    |   18924    |    6760 K  |    6741 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     240    |     323    |     934 K  |     934 K  |\n","|       from large pool |      16    |      91    |     835 K  |     835 K  |\n","|       from small pool |     224    |     237    |      98 K  |      98 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      81    |     156    |    8176 K  |    8176 K  |\n","|       from large pool |      16    |      55    |    5497 K  |    5497 K  |\n","|       from small pool |      65    |     119    |    2679 K  |    2679 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:58/8961 batch_size:175\n","Next token prediction. step:32/209 batch:58/8961 epoch:2/10\n","full seq: Her routine had the highest technical difficulty level of the night, and she executed it with poise, receiving a score of 15.650 and edging past Shawn Johnson and Nastia Liukin of the United States.Ģġġġġġġġġġġ\n","pref seq: Her routine had the highest tech\n","next tok:                                n\n","pred tok:                                ,\n","Completed batch.\n","epoch:2/10 batch:58/8961 batch_size:175 loss:0.970321774482727 time_for_batch_instance:221.24327421188354 total_batch_time:14218.853964567184 running_batch_average:245.15265456150317\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 669570 KiB |  13709 MiB | 663167 GiB | 663167 GiB |\n","|       from large pool | 214964 KiB |  13273 MiB | 661953 GiB | 661952 GiB |\n","|       from small pool | 454606 KiB |    468 MiB |   1214 GiB |   1214 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 669570 KiB |  13709 MiB | 663167 GiB | 663167 GiB |\n","|       from large pool | 214964 KiB |  13273 MiB | 661953 GiB | 661952 GiB |\n","|       from small pool | 454606 KiB |    468 MiB |   1214 GiB |   1214 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  13665 MiB | 661659 GiB | 661659 GiB |\n","|       from large pool | 213248 KiB |  13233 MiB | 660445 GiB | 660445 GiB |\n","|       from small pool | 450193 KiB |    464 MiB |   1214 GiB |   1213 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1494 MiB |  14324 MiB | 155750 GiB | 155749 GiB |\n","|       from large pool |   1046 MiB |  13860 MiB | 155554 GiB | 155553 GiB |\n","|       from small pool |    448 MiB |    474 MiB |    196 GiB |    195 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |    840 MiB |   1673 MiB | 215851 GiB | 215850 GiB |\n","|       from large pool |    836 MiB |   1669 MiB | 214546 GiB | 214546 GiB |\n","|       from small pool |      4 MiB |     20 MiB |   1304 GiB |   1304 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   17463 K  |   17444 K  |\n","|       from large pool |      98    |     263    |   10595 K  |   10595 K  |\n","|       from small pool |   18777    |   18924    |    6867 K  |    6848 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   17463 K  |   17444 K  |\n","|       from large pool |      98    |     263    |   10595 K  |   10595 K  |\n","|       from small pool |   18777    |   18924    |    6867 K  |    6848 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     240    |     321    |     948 K  |     948 K  |\n","|       from large pool |      16    |      89    |     848 K  |     848 K  |\n","|       from small pool |     224    |     237    |     100 K  |     100 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      88    |     141    |    8285 K  |    8285 K  |\n","|       from large pool |      21    |      39    |    5563 K  |    5563 K  |\n","|       from small pool |      67    |     119    |    2722 K  |    2722 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:59/8961 batch_size:175\n","Next token prediction. step:48/209 batch:59/8961 epoch:2/10\n","full seq: An International Astronomical Union committee honoured Greek astronomer Kleomenis Tsiganis from the Aristotle University of Thessaloniki by naming an asteroid formerly known as 1999 RC221 after him.Ģġġġġġġġġġġ\n","pref seq: An International Astronomical Union committee ho\n","next tok:                                                n\n","pred tok:                                                ,\n","Completed batch.\n","epoch:2/10 batch:59/8961 batch_size:175 loss:0.5817813277244568 time_for_batch_instance:221.27421498298645 total_batch_time:14440.12817955017 running_batch_average:244.74793524661305\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 671060 KiB |  13710 MiB | 672504 GiB | 672503 GiB |\n","|       from large pool | 216454 KiB |  13274 MiB | 671270 GiB | 671270 GiB |\n","|       from small pool | 454606 KiB |    468 MiB |   1233 GiB |   1233 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 671060 KiB |  13710 MiB | 672504 GiB | 672503 GiB |\n","|       from large pool | 216454 KiB |  13274 MiB | 671270 GiB | 671270 GiB |\n","|       from small pool | 454606 KiB |    468 MiB |   1233 GiB |   1233 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  13665 MiB | 670966 GiB | 670966 GiB |\n","|       from large pool | 213248 KiB |  13233 MiB | 669733 GiB | 669733 GiB |\n","|       from small pool | 450193 KiB |    464 MiB |   1232 GiB |   1232 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1458 MiB |  14324 MiB | 157911 GiB | 157909 GiB |\n","|       from large pool |   1010 MiB |  13860 MiB | 157711 GiB | 157710 GiB |\n","|       from small pool |    448 MiB |    474 MiB |    199 GiB |    198 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |    802 MiB |   1692 MiB | 218811 GiB | 218811 GiB |\n","|       from large pool |    798 MiB |   1687 MiB | 217487 GiB | 217486 GiB |\n","|       from small pool |      4 MiB |     20 MiB |   1324 GiB |   1324 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   17735 K  |   17716 K  |\n","|       from large pool |      98    |     263    |   10760 K  |   10760 K  |\n","|       from small pool |   18777    |   18924    |    6974 K  |    6956 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   17735 K  |   17716 K  |\n","|       from large pool |      98    |     263    |   10760 K  |   10760 K  |\n","|       from small pool |   18777    |   18924    |    6974 K  |    6956 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     239    |     322    |     963 K  |     963 K  |\n","|       from large pool |      15    |      90    |     861 K  |     861 K  |\n","|       from small pool |     224    |     237    |     102 K  |     101 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      86    |     142    |    8394 K  |    8394 K  |\n","|       from large pool |      19    |      41    |    5629 K  |    5629 K  |\n","|       from small pool |      67    |     119    |    2765 K  |    2765 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:60/8961 batch_size:175\n","Next token prediction. step:112/209 batch:60/8961 epoch:2/10\n","full seq: The path to democracy began in the late 1980s when the government of Gligorie Gogovski -- the last single-party ruling body in the country -- opened widespread debate about moving in a new direction.Ģġġġġġġġġġ\n","pref seq: The path to democracy began in the late 1980s when the government of Gligorie Gogovski -- the last single-party \n","next tok:                                                                                                                r\n","pred tok:                                                                                                                (\n","Completed batch.\n","epoch:2/10 batch:60/8961 batch_size:175 loss:0.6847808957099915 time_for_batch_instance:220.53016448020935 total_batch_time:14660.65834403038 running_batch_average:244.34430573383966\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 670491 KiB |  13710 MiB | 681841 GiB | 681840 GiB |\n","|       from large pool | 215885 KiB |  13273 MiB | 680588 GiB | 680588 GiB |\n","|       from small pool | 454606 KiB |    468 MiB |   1252 GiB |   1252 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 670491 KiB |  13710 MiB | 681841 GiB | 681840 GiB |\n","|       from large pool | 215885 KiB |  13273 MiB | 680588 GiB | 680588 GiB |\n","|       from small pool | 454606 KiB |    468 MiB |   1252 GiB |   1252 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  13665 MiB | 680273 GiB | 680273 GiB |\n","|       from large pool | 213248 KiB |  13233 MiB | 679022 GiB | 679021 GiB |\n","|       from small pool | 450193 KiB |    464 MiB |   1251 GiB |   1251 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1456 MiB |  14322 MiB | 160072 GiB | 160071 GiB |\n","|       from large pool |   1008 MiB |  13858 MiB | 159869 GiB | 159868 GiB |\n","|       from small pool |    448 MiB |    474 MiB |    202 GiB |    202 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |    801 MiB |   1695 MiB | 221806 GiB | 221805 GiB |\n","|       from large pool |    797 MiB |   1690 MiB | 220461 GiB | 220460 GiB |\n","|       from small pool |      4 MiB |     20 MiB |   1345 GiB |   1345 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   18007 K  |   17988 K  |\n","|       from large pool |      98    |     263    |   10925 K  |   10925 K  |\n","|       from small pool |   18777    |   18924    |    7082 K  |    7063 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   18007 K  |   17988 K  |\n","|       from large pool |      98    |     263    |   10925 K  |   10925 K  |\n","|       from small pool |   18777    |   18924    |    7082 K  |    7063 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     240    |     323    |     978 K  |     977 K  |\n","|       from large pool |      16    |      91    |     874 K  |     874 K  |\n","|       from small pool |     224    |     237    |     103 K  |     103 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      89    |     142    |    8504 K  |    8504 K  |\n","|       from large pool |      22    |      41    |    5695 K  |    5695 K  |\n","|       from small pool |      67    |     119    |    2808 K  |    2808 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:61/8961 batch_size:175\n","Next token prediction. step:72/209 batch:61/8961 epoch:2/10\n","full seq: Greek Cypriot President Tassos Papadopoulos, who campaigned for a \"no\" vote in Saturday's twin referenda on the UN plan, has been quoted as saying the funds should be channeled through his government.Ģġġġġġġġġ\n","pref seq: Greek Cypriot President Tassos Papadopoulos, who campaigned for a \"no\" v\n","next tok:                                                                        o\n","pred tok:                                                                        f\n","Completed batch.\n","epoch:2/10 batch:61/8961 batch_size:175 loss:0.9790103435516357 time_for_batch_instance:221.0791881084442 total_batch_time:14881.737532138824 running_batch_average:243.96291036293155\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 669076 KiB |  13708 MiB | 691177 GiB | 691177 GiB |\n","|       from large pool | 214470 KiB |  13271 MiB | 689906 GiB | 689906 GiB |\n","|       from small pool | 454606 KiB |    468 MiB |   1271 GiB |   1271 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 669076 KiB |  13708 MiB | 691177 GiB | 691177 GiB |\n","|       from large pool | 214470 KiB |  13271 MiB | 689906 GiB | 689906 GiB |\n","|       from small pool | 454606 KiB |    468 MiB |   1271 GiB |   1271 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  13665 MiB | 689580 GiB | 689580 GiB |\n","|       from large pool | 213248 KiB |  13233 MiB | 688310 GiB | 688309 GiB |\n","|       from small pool | 450193 KiB |    464 MiB |   1270 GiB |   1270 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1462 MiB |  14328 MiB | 162244 GiB | 162242 GiB |\n","|       from large pool |   1014 MiB |  13864 MiB | 162038 GiB | 162037 GiB |\n","|       from small pool |    448 MiB |    474 MiB |    205 GiB |    205 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |    808 MiB |   1655 MiB | 224797 GiB | 224796 GiB |\n","|       from large pool |    804 MiB |   1651 MiB | 223431 GiB | 223431 GiB |\n","|       from small pool |      4 MiB |     20 MiB |   1365 GiB |   1365 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   18279 K  |   18260 K  |\n","|       from large pool |      98    |     263    |   11089 K  |   11089 K  |\n","|       from small pool |   18777    |   18924    |    7189 K  |    7170 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   18279 K  |   18260 K  |\n","|       from large pool |      98    |     263    |   11089 K  |   11089 K  |\n","|       from small pool |   18777    |   18924    |    7189 K  |    7170 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     241    |     324    |     992 K  |     992 K  |\n","|       from large pool |      17    |      92    |     887 K  |     887 K  |\n","|       from small pool |     224    |     237    |     105 K  |     105 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      93    |     144    |    8614 K  |    8614 K  |\n","|       from large pool |      26    |      42    |    5762 K  |    5762 K  |\n","|       from small pool |      67    |     119    |    2851 K  |    2851 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:62/8961 batch_size:175\n","Next token prediction. step:173/208 batch:62/8961 epoch:2/10\n","full seq: \"I thought it would be easier to watch this movie, but many things reminded me about my war fate; it reminded me of the town I left, and the violence that my family experienced,\" said Selma Fejzic.Ģġġġġġġġġġġ\n","pref seq: \"I thought it would be easier to watch this movie, but many things reminded me about my war fate; it reminded me of the town I left, and the violence that my family experien\n","next tok:                                                                                                                                                                             c\n","pred tok:                                                                                                                                                                             L\n","Completed batch.\n","epoch:2/10 batch:62/8961 batch_size:175 loss:0.9604615569114685 time_for_batch_instance:220.12705278396606 total_batch_time:15101.86458492279 running_batch_average:243.5784610471418\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 671382 KiB |  13631 MiB | 700423 GiB | 700423 GiB |\n","|       from large pool | 216776 KiB |  13195 MiB | 699133 GiB | 699133 GiB |\n","|       from small pool | 454606 KiB |    468 MiB |   1290 GiB |   1289 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 671382 KiB |  13631 MiB | 700423 GiB | 700423 GiB |\n","|       from large pool | 216776 KiB |  13195 MiB | 699133 GiB | 699133 GiB |\n","|       from small pool | 454606 KiB |    468 MiB |   1290 GiB |   1289 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  13602 MiB | 698802 GiB | 698801 GiB |\n","|       from large pool | 213248 KiB |  13170 MiB | 697512 GiB | 697512 GiB |\n","|       from small pool | 450193 KiB |    464 MiB |   1289 GiB |   1289 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1760 MiB |  14294 MiB | 164401 GiB | 164399 GiB |\n","|       from large pool |   1312 MiB |  13832 MiB | 164192 GiB | 164191 GiB |\n","|       from small pool |    448 MiB |    474 MiB |    208 GiB |    208 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1104 MiB |   1892 MiB | 227858 GiB | 227857 GiB |\n","|       from large pool |   1100 MiB |   1887 MiB | 226472 GiB | 226471 GiB |\n","|       from small pool |      4 MiB |     20 MiB |   1385 GiB |   1385 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   18549 K  |   18530 K  |\n","|       from large pool |      98    |     263    |   11253 K  |   11253 K  |\n","|       from small pool |   18777    |   18924    |    7295 K  |    7277 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   18549 K  |   18530 K  |\n","|       from large pool |      98    |     263    |   11253 K  |   11253 K  |\n","|       from small pool |   18777    |   18924    |    7295 K  |    7277 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     242    |     324    |    1007 K  |    1007 K  |\n","|       from large pool |      18    |      93    |     900 K  |     900 K  |\n","|       from small pool |     224    |     237    |     106 K  |     106 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      90    |     173    |    8740 K  |    8740 K  |\n","|       from large pool |      24    |      71    |    5846 K  |    5846 K  |\n","|       from small pool |      66    |     119    |    2894 K  |    2894 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:63/8961 batch_size:175\n","Next token prediction. step:197/207 batch:63/8961 epoch:2/10\n","full seq: \"It goes without saying that we condemn this attack,\" the AP quoted Spyros Vouyias, a deputy public works minister, as telling private Skai television. \"Violence does not solve anyone's problems.\"Ģġġġġġġġġġġ\n","pref seq: \"It goes without saying that we condemn this attack,\" the AP quoted Spyros Vouyias, a deputy public works minister, as telling private Skai television. \"Violence does not solve anyone's problems.\"Ģ\n","next tok:                                                                                                                                                                                                     ġ\n","pred tok:                                                                                                                                                                                                     Ģ\n","Completed batch.\n","epoch:2/10 batch:63/8961 batch_size:175 loss:1.410217523574829 time_for_batch_instance:219.05778098106384 total_batch_time:15320.922365903854 running_batch_average:243.1892439032358\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 670274 KiB |  13591 MiB | 709596 GiB | 709595 GiB |\n","|       from large pool | 215668 KiB |  13155 MiB | 708287 GiB | 708287 GiB |\n","|       from small pool | 454606 KiB |    468 MiB |   1308 GiB |   1308 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 670274 KiB |  13591 MiB | 709596 GiB | 709595 GiB |\n","|       from large pool | 215668 KiB |  13155 MiB | 708287 GiB | 708287 GiB |\n","|       from small pool | 454606 KiB |    468 MiB |   1308 GiB |   1308 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  13540 MiB | 707938 GiB | 707937 GiB |\n","|       from large pool | 213248 KiB |  13108 MiB | 706630 GiB | 706629 GiB |\n","|       from small pool | 450193 KiB |    464 MiB |   1308 GiB |   1307 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1768 MiB |  14236 MiB | 166529 GiB | 166527 GiB |\n","|       from large pool |   1320 MiB |  13772 MiB | 166317 GiB | 166315 GiB |\n","|       from small pool |    448 MiB |    474 MiB |    211 GiB |    211 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1113 MiB |   1960 MiB | 231025 GiB | 231024 GiB |\n","|       from large pool |   1109 MiB |   1955 MiB | 229620 GiB | 229619 GiB |\n","|       from small pool |      4 MiB |     20 MiB |   1405 GiB |   1405 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   18819 K  |   18800 K  |\n","|       from large pool |      98    |     263    |   11417 K  |   11416 K  |\n","|       from small pool |   18777    |   18924    |    7401 K  |    7383 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   18819 K  |   18800 K  |\n","|       from large pool |      98    |     263    |   11417 K  |   11416 K  |\n","|       from small pool |   18777    |   18924    |    7401 K  |    7383 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     242    |     323    |    1022 K  |    1022 K  |\n","|       from large pool |      18    |      91    |     913 K  |     913 K  |\n","|       from small pool |     224    |     237    |     108 K  |     108 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      93    |     150    |    8862 K  |    8862 K  |\n","|       from large pool |      23    |      48    |    5925 K  |    5925 K  |\n","|       from small pool |      70    |     117    |    2936 K  |    2936 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:64/8961 batch_size:175\n","Next token prediction. step:79/207 batch:64/8961 epoch:2/10\n","full seq: Coinciding with Serbia's Youth Day, for years Tito's birthday was celebrated in the former Yugoslavia by having relay runners carry a baton for weeks, which was then given to the leader on the 25th.Ģġġġġġġġġ\n","pref seq: Coinciding with Serbia's Youth Day, for years Tito's birthday was celebrated in\n","next tok:                                                                                \n","pred tok:                                                                               P\n","Completed batch.\n","epoch:2/10 batch:64/8961 batch_size:175 loss:1.0721434354782104 time_for_batch_instance:218.56875443458557 total_batch_time:15539.49112033844 running_batch_average:242.80454875528812\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 670274 KiB |  13591 MiB | 718769 GiB | 718768 GiB |\n","|       from large pool | 215668 KiB |  13155 MiB | 717441 GiB | 717441 GiB |\n","|       from small pool | 454606 KiB |    468 MiB |   1327 GiB |   1327 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 670274 KiB |  13591 MiB | 718769 GiB | 718768 GiB |\n","|       from large pool | 215668 KiB |  13155 MiB | 717441 GiB | 717441 GiB |\n","|       from small pool | 454606 KiB |    468 MiB |   1327 GiB |   1327 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  13540 MiB | 717074 GiB | 717073 GiB |\n","|       from large pool | 213248 KiB |  13108 MiB | 715747 GiB | 715747 GiB |\n","|       from small pool | 450193 KiB |    464 MiB |   1326 GiB |   1326 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1768 MiB |  14236 MiB | 168662 GiB | 168660 GiB |\n","|       from large pool |   1320 MiB |  13772 MiB | 168447 GiB | 168445 GiB |\n","|       from small pool |    448 MiB |    474 MiB |    215 GiB |    214 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1113 MiB |   1876 MiB | 234181 GiB | 234180 GiB |\n","|       from large pool |   1109 MiB |   1871 MiB | 232755 GiB | 232754 GiB |\n","|       from small pool |      4 MiB |     20 MiB |   1425 GiB |   1425 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   19088 K  |   19069 K  |\n","|       from large pool |      98    |     263    |   11580 K  |   11580 K  |\n","|       from small pool |   18777    |   18924    |    7508 K  |    7489 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   19088 K  |   19069 K  |\n","|       from large pool |      98    |     263    |   11580 K  |   11580 K  |\n","|       from small pool |   18777    |   18924    |    7508 K  |    7489 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     242    |     323    |    1037 K  |    1036 K  |\n","|       from large pool |      18    |      91    |     926 K  |     926 K  |\n","|       from small pool |     224    |     237    |     110 K  |     109 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      93    |     150    |    8983 K  |    8983 K  |\n","|       from large pool |      23    |      48    |    6003 K  |    6003 K  |\n","|       from small pool |      70    |     117    |    2979 K  |    2979 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:65/8961 batch_size:175\n","Next token prediction. step:80/205 batch:65/8961 epoch:2/10\n","full seq: According to Nazli, huge potential for co-operation exists in areas such as automobile production.\"To expand in America, Turkish investors need to show up in US neighbourhoods as well,\" he said.Ģġġġġġġġġġġ\n","pref seq: According to Nazli, huge potential for co-operation exists in areas such as auto\n","next tok:                                                                                m\n","pred tok:                                                                                V\n","Completed batch.\n","epoch:2/10 batch:65/8961 batch_size:175 loss:1.189141869544983 time_for_batch_instance:216.3166949748993 total_batch_time:15755.80781531334 running_batch_average:242.39704331251292\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 670618 KiB |  13443 MiB | 727773 GiB | 727772 GiB |\n","|       from large pool | 216012 KiB |  13007 MiB | 726427 GiB | 726426 GiB |\n","|       from small pool | 454606 KiB |    468 MiB |   1346 GiB |   1345 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 670618 KiB |  13443 MiB | 727773 GiB | 727772 GiB |\n","|       from large pool | 216012 KiB |  13007 MiB | 726427 GiB | 726426 GiB |\n","|       from small pool | 454606 KiB |    468 MiB |   1346 GiB |   1345 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  13414 MiB | 726041 GiB | 726040 GiB |\n","|       from large pool | 213248 KiB |  12983 MiB | 724695 GiB | 724695 GiB |\n","|       from small pool | 450193 KiB |    464 MiB |   1345 GiB |   1344 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2142 MiB |  14128 MiB | 170711 GiB | 170709 GiB |\n","|       from large pool |   1694 MiB |  13666 MiB | 170493 GiB | 170491 GiB |\n","|       from small pool |    448 MiB |    474 MiB |    218 GiB |    217 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1487 MiB |   1909 MiB | 237368 GiB | 237366 GiB |\n","|       from large pool |   1483 MiB |   1905 MiB | 235922 GiB | 235921 GiB |\n","|       from small pool |      4 MiB |     18 MiB |   1445 GiB |   1445 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   19355 K  |   19336 K  |\n","|       from large pool |      98    |     263    |   11741 K  |   11741 K  |\n","|       from small pool |   18777    |   18924    |    7613 K  |    7594 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   19355 K  |   19336 K  |\n","|       from large pool |      98    |     263    |   11741 K  |   11741 K  |\n","|       from small pool |   18777    |   18924    |    7613 K  |    7594 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     242    |     321    |    1051 K  |    1051 K  |\n","|       from large pool |      18    |      90    |     939 K  |     939 K  |\n","|       from small pool |     224    |     237    |     111 K  |     111 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      93    |     163    |    9105 K  |    9105 K  |\n","|       from large pool |      24    |      61    |    6084 K  |    6084 K  |\n","|       from small pool |      69    |     120    |    3021 K  |    3021 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:66/8961 batch_size:175\n","Next token prediction. step:81/205 batch:66/8961 epoch:2/10\n","full seq: According to media reports, Dragnea made his decision after three nominations he made were rejected both by his own Social Democratic Party (PSD) and its coalition partner, the Liberal Democrats.Ģġġġġġġġġġ\n","pref seq: According to media reports, Dragnea made his decision after three nominations he \n","next tok:                                                                                 m\n","pred tok:                                                                                 ,\n","Completed batch.\n","epoch:2/10 batch:66/8961 batch_size:175 loss:1.0768539905548096 time_for_batch_instance:216.5000114440918 total_batch_time:15972.307826757431 running_batch_average:242.00466404177925\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 670618 KiB |  13443 MiB | 736778 GiB | 736777 GiB |\n","|       from large pool | 216012 KiB |  13007 MiB | 735413 GiB | 735413 GiB |\n","|       from small pool | 454606 KiB |    468 MiB |   1364 GiB |   1364 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 670618 KiB |  13443 MiB | 736778 GiB | 736777 GiB |\n","|       from large pool | 216012 KiB |  13007 MiB | 735413 GiB | 735413 GiB |\n","|       from small pool | 454606 KiB |    468 MiB |   1364 GiB |   1364 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  13414 MiB | 735007 GiB | 735007 GiB |\n","|       from large pool | 213248 KiB |  12983 MiB | 733643 GiB | 733643 GiB |\n","|       from small pool | 450193 KiB |    464 MiB |   1363 GiB |   1363 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2142 MiB |  14128 MiB | 172760 GiB | 172758 GiB |\n","|       from large pool |   1694 MiB |  13666 MiB | 172539 GiB | 172537 GiB |\n","|       from small pool |    448 MiB |    474 MiB |    221 GiB |    220 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1487 MiB |   1909 MiB | 240534 GiB | 240533 GiB |\n","|       from large pool |   1483 MiB |   1905 MiB | 239069 GiB | 239067 GiB |\n","|       from small pool |      4 MiB |     18 MiB |   1465 GiB |   1465 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   19621 K  |   19602 K  |\n","|       from large pool |      98    |     263    |   11903 K  |   11903 K  |\n","|       from small pool |   18777    |   18924    |    7718 K  |    7699 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   19621 K  |   19602 K  |\n","|       from large pool |      98    |     263    |   11903 K  |   11903 K  |\n","|       from small pool |   18777    |   18924    |    7718 K  |    7699 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     242    |     321    |    1066 K  |    1065 K  |\n","|       from large pool |      18    |      90    |     952 K  |     952 K  |\n","|       from small pool |     224    |     237    |     113 K  |     112 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      93    |     163    |    9227 K  |    9227 K  |\n","|       from large pool |      24    |      61    |    6164 K  |    6164 K  |\n","|       from small pool |      69    |     120    |    3062 K  |    3062 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:67/8961 batch_size:175\n","Next token prediction. step:7/204 batch:67/8961 epoch:2/10\n","full seq: Nine days later, the Serbian authorities handed him over to The Hague tribunal to answer charges of genocide and war crimes, stemming from the 1992-1995 conflict in Bosnia and Herzegovina (BiH).Ģġġġġġġġġġ\n","pref seq: Nine da\n","next tok:       y\n","pred tok:       (\n","Completed batch.\n","epoch:2/10 batch:67/8961 batch_size:175 loss:1.0110434293746948 time_for_batch_instance:215.2485330104828 total_batch_time:16187.556359767914 running_batch_average:241.6053188025062\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 670092 KiB |  13366 MiB | 745669 GiB | 745668 GiB |\n","|       from large pool | 215486 KiB |  12930 MiB | 744286 GiB | 744286 GiB |\n","|       from small pool | 454606 KiB |    468 MiB |   1383 GiB |   1382 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 670092 KiB |  13366 MiB | 745669 GiB | 745668 GiB |\n","|       from large pool | 215486 KiB |  12930 MiB | 744286 GiB | 744286 GiB |\n","|       from small pool | 454606 KiB |    468 MiB |   1383 GiB |   1382 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  13352 MiB | 743890 GiB | 743889 GiB |\n","|       from large pool | 213248 KiB |  12920 MiB | 742507 GiB | 742507 GiB |\n","|       from small pool | 450193 KiB |    464 MiB |   1382 GiB |   1381 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1704 MiB |  14042 MiB | 174787 GiB | 174785 GiB |\n","|       from large pool |   1256 MiB |  13580 MiB | 174563 GiB | 174562 GiB |\n","|       from small pool |    448 MiB |    474 MiB |    224 GiB |    223 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1049 MiB |   1859 MiB | 243801 GiB | 243800 GiB |\n","|       from large pool |   1045 MiB |   1857 MiB | 242316 GiB | 242315 GiB |\n","|       from small pool |      4 MiB |     18 MiB |   1485 GiB |   1485 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   19887 K  |   19868 K  |\n","|       from large pool |      98    |     263    |   12063 K  |   12063 K  |\n","|       from small pool |   18777    |   18924    |    7823 K  |    7804 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   19887 K  |   19868 K  |\n","|       from large pool |      98    |     263    |   12063 K  |   12063 K  |\n","|       from small pool |   18777    |   18924    |    7823 K  |    7804 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     239    |     322    |    1080 K  |    1080 K  |\n","|       from large pool |      15    |      91    |     965 K  |     965 K  |\n","|       from small pool |     224    |     237    |     114 K  |     114 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      88    |     176    |    9374 K  |    9373 K  |\n","|       from large pool |      19    |      74    |    6269 K  |    6269 K  |\n","|       from small pool |      69    |     119    |    3104 K  |    3104 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:68/8961 batch_size:175\n","Next token prediction. step:148/204 batch:68/8961 epoch:2/10\n","full seq: However, Romanian Academic Society justice expert Laura Stefan told SETimes that she does not believe the verdict will have an impact on the EU, but it will send a message to domestic politicians.Ģġġġġġġġ\n","pref seq: However, Romanian Academic Society justice expert Laura Stefan told SETimes that she does not believe the verdict will have an impact on the EU, but\n","next tok:                                                                                                                                                     \n","pred tok:                                                                                                                                                    -\n","Completed batch.\n","epoch:2/10 batch:68/8961 batch_size:175 loss:1.8117097616195679 time_for_batch_instance:215.2927086353302 total_batch_time:16402.849068403244 running_batch_average:241.2183686529889\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 670092 KiB |  13366 MiB | 754560 GiB | 754559 GiB |\n","|       from large pool | 215486 KiB |  12930 MiB | 753158 GiB | 753158 GiB |\n","|       from small pool | 454606 KiB |    468 MiB |   1401 GiB |   1401 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 670092 KiB |  13366 MiB | 754560 GiB | 754559 GiB |\n","|       from large pool | 215486 KiB |  12930 MiB | 753158 GiB | 753158 GiB |\n","|       from small pool | 454606 KiB |    468 MiB |   1401 GiB |   1401 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  13352 MiB | 752772 GiB | 752772 GiB |\n","|       from large pool | 213248 KiB |  12920 MiB | 751371 GiB | 751371 GiB |\n","|       from small pool | 450193 KiB |    464 MiB |   1400 GiB |   1400 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1704 MiB |  14042 MiB | 176867 GiB | 176865 GiB |\n","|       from large pool |   1256 MiB |  13580 MiB | 176640 GiB | 176638 GiB |\n","|       from small pool |    448 MiB |    474 MiB |    227 GiB |    226 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1049 MiB |   1841 MiB | 246955 GiB | 246954 GiB |\n","|       from large pool |   1045 MiB |   1836 MiB | 245451 GiB | 245450 GiB |\n","|       from small pool |      4 MiB |     19 MiB |   1504 GiB |   1504 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   20152 K  |   20133 K  |\n","|       from large pool |      98    |     263    |   12224 K  |   12224 K  |\n","|       from small pool |   18777    |   18924    |    7927 K  |    7908 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   20152 K  |   20133 K  |\n","|       from large pool |      98    |     263    |   12224 K  |   12224 K  |\n","|       from small pool |   18777    |   18924    |    7927 K  |    7908 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     239    |     322    |    1095 K  |    1094 K  |\n","|       from large pool |      15    |      91    |     978 K  |     978 K  |\n","|       from small pool |     224    |     237    |     116 K  |     116 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      88    |     174    |    9521 K  |    9521 K  |\n","|       from large pool |      19    |      72    |    6375 K  |    6375 K  |\n","|       from small pool |      69    |     119    |    3146 K  |    3146 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:69/8961 batch_size:175\n","Next token prediction. step:102/204 batch:69/8961 epoch:2/10\n","full seq: While freedom of speech and of the press is embedded in Turkish laws as well, authorities continued to curtail their exercise by applying restrictions stipulated in the constitution or other laws.Ģġġġġġġġ\n","pref seq: While freedom of speech and of the press is embedded in Turkish laws as well, authorities continued to\n","next tok:                                                                                                       \n","pred tok:                                                                                                      (\n","Completed batch.\n","epoch:2/10 batch:69/8961 batch_size:175 loss:1.4309191703796387 time_for_batch_instance:215.13903260231018 total_batch_time:16617.988101005554 running_batch_average:240.84040726095006\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 670092 KiB |  13366 MiB | 763451 GiB | 763451 GiB |\n","|       from large pool | 215486 KiB |  12930 MiB | 762031 GiB | 762031 GiB |\n","|       from small pool | 454606 KiB |    468 MiB |   1420 GiB |   1419 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 670092 KiB |  13366 MiB | 763451 GiB | 763451 GiB |\n","|       from large pool | 215486 KiB |  12930 MiB | 762031 GiB | 762031 GiB |\n","|       from small pool | 454606 KiB |    468 MiB |   1420 GiB |   1419 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  13352 MiB | 761655 GiB | 761654 GiB |\n","|       from large pool | 213248 KiB |  12920 MiB | 760235 GiB | 760235 GiB |\n","|       from small pool | 450193 KiB |    464 MiB |   1419 GiB |   1418 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1704 MiB |  14042 MiB | 178945 GiB | 178943 GiB |\n","|       from large pool |   1256 MiB |  13580 MiB | 178715 GiB | 178714 GiB |\n","|       from small pool |    448 MiB |    474 MiB |    229 GiB |    229 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1049 MiB |   1841 MiB | 250106 GiB | 250105 GiB |\n","|       from large pool |   1045 MiB |   1836 MiB | 248582 GiB | 248581 GiB |\n","|       from small pool |      4 MiB |     18 MiB |   1524 GiB |   1524 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   20417 K  |   20398 K  |\n","|       from large pool |      98    |     263    |   12385 K  |   12385 K  |\n","|       from small pool |   18777    |   18924    |    8032 K  |    8013 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   20417 K  |   20398 K  |\n","|       from large pool |      98    |     263    |   12385 K  |   12385 K  |\n","|       from small pool |   18777    |   18924    |    8032 K  |    8013 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     239    |     322    |    1109 K  |    1109 K  |\n","|       from large pool |      15    |      91    |     991 K  |     991 K  |\n","|       from small pool |     224    |     237    |     117 K  |     117 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      88    |     174    |    9669 K  |    9669 K  |\n","|       from large pool |      19    |      72    |    6481 K  |    6481 K  |\n","|       from small pool |      69    |     119    |    3187 K  |    3187 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:70/8961 batch_size:175\n","Next token prediction. step:59/202 batch:70/8961 epoch:2/10\n","full seq: \"The solution proposed by the government, to freeze everything, will destroy NIS and will destroy the gasoline industry,\" he warns. \"Who is going to come here and invest under such conditions?Ģġġġġġġġġġ\n","pref seq: \"The solution proposed by the government, to freeze everyth\n","next tok:                                                           i\n","pred tok:                                                           (\n","Completed batch.\n","epoch:2/10 batch:70/8961 batch_size:175 loss:0.5838655233383179 time_for_batch_instance:213.21794366836548 total_batch_time:16831.20604467392 running_batch_average:240.44580063819885\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 671527 KiB |  13250 MiB | 772187 GiB | 772186 GiB |\n","|       from large pool | 216921 KiB |  12815 MiB | 770748 GiB | 770748 GiB |\n","|       from small pool | 454606 KiB |    468 MiB |   1438 GiB |   1437 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 671527 KiB |  13250 MiB | 772187 GiB | 772186 GiB |\n","|       from large pool | 216921 KiB |  12815 MiB | 770748 GiB | 770748 GiB |\n","|       from small pool | 454606 KiB |    468 MiB |   1438 GiB |   1437 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  13226 MiB | 770370 GiB | 770370 GiB |\n","|       from large pool | 213248 KiB |  12795 MiB | 768933 GiB | 768933 GiB |\n","|       from small pool | 450193 KiB |    464 MiB |   1437 GiB |   1437 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1762 MiB |  13926 MiB | 180942 GiB | 180940 GiB |\n","|       from large pool |   1314 MiB |  13464 MiB | 180709 GiB | 180707 GiB |\n","|       from small pool |    448 MiB |    474 MiB |    232 GiB |    232 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1106 MiB |   1893 MiB | 253200 GiB | 253199 GiB |\n","|       from large pool |   1102 MiB |   1888 MiB | 251656 GiB | 251655 GiB |\n","|       from small pool |      4 MiB |     18 MiB |   1543 GiB |   1543 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   20680 K  |   20661 K  |\n","|       from large pool |      98    |     263    |   12544 K  |   12544 K  |\n","|       from small pool |   18777    |   18924    |    8136 K  |    8117 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   20680 K  |   20661 K  |\n","|       from large pool |      98    |     263    |   12544 K  |   12544 K  |\n","|       from small pool |   18777    |   18924    |    8136 K  |    8117 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     242    |     324    |    1123 K  |    1123 K  |\n","|       from large pool |      18    |      93    |    1004 K  |    1004 K  |\n","|       from small pool |     224    |     237    |     119 K  |     119 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      90    |     172    |    9806 K  |    9806 K  |\n","|       from large pool |      24    |      70    |    6577 K  |    6577 K  |\n","|       from small pool |      66    |     119    |    3228 K  |    3228 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:71/8961 batch_size:175\n","Next token prediction. step:132/202 batch:71/8961 epoch:2/10\n","full seq: \"I think that it is important for Kosovo, it is important for the communities, to have Ġ [functional] community policing that is multiethnic,\" UNMIK chief Lamberto Zannier said. [Laura Hasani]Ģġġġġġġġġġ\n","pref seq: \"I think that it is important for Kosovo, it is important for the communities, to have Ġ [functional] community policing that is mul\n","next tok:                                                                                                                                    t\n","pred tok:                                                                                                                                    ,\n","Completed batch.\n","epoch:2/10 batch:71/8961 batch_size:175 loss:0.9326183199882507 time_for_batch_instance:213.06575274467468 total_batch_time:17044.271797418594 running_batch_average:240.06016616082528\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 670442 KiB |  13249 MiB | 780921 GiB | 780921 GiB |\n","|       from large pool | 215836 KiB |  12813 MiB | 779465 GiB | 779465 GiB |\n","|       from small pool | 454606 KiB |    468 MiB |   1456 GiB |   1456 GiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 670442 KiB |  13249 MiB | 780921 GiB | 780921 GiB |\n","|       from large pool | 215836 KiB |  12813 MiB | 779465 GiB | 779465 GiB |\n","|       from small pool | 454606 KiB |    468 MiB |   1456 GiB |   1456 GiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  13226 MiB | 779086 GiB | 779085 GiB |\n","|       from large pool | 213248 KiB |  12795 MiB | 777630 GiB | 777630 GiB |\n","|       from small pool | 450193 KiB |    464 MiB |   1455 GiB |   1455 GiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1968 MiB |  13922 MiB | 182983 GiB | 182981 GiB |\n","|       from large pool |   1520 MiB |  13460 MiB | 182747 GiB | 182745 GiB |\n","|       from small pool |    448 MiB |    474 MiB |    235 GiB |    235 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1313 MiB |   1677 MiB | 256121 GiB | 256120 GiB |\n","|       from large pool |   1309 MiB |   1672 MiB | 254557 GiB | 254556 GiB |\n","|       from small pool |      4 MiB |     18 MiB |   1563 GiB |   1563 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   20943 K  |   20924 K  |\n","|       from large pool |      98    |     263    |   12703 K  |   12703 K  |\n","|       from small pool |   18777    |   18924    |    8239 K  |    8220 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   20943 K  |   20924 K  |\n","|       from large pool |      98    |     263    |   12703 K  |   12703 K  |\n","|       from small pool |   18777    |   18924    |    8239 K  |    8220 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     239    |     320    |    1138 K  |    1138 K  |\n","|       from large pool |      15    |      89    |    1017 K  |    1017 K  |\n","|       from small pool |     224    |     237    |     120 K  |     120 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      87    |     167    |    9944 K  |    9944 K  |\n","|       from large pool |      21    |      66    |    6675 K  |    6675 K  |\n","|       from small pool |      66    |     119    |    3269 K  |    3269 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:72/8961 batch_size:175\n","Next token prediction. step:165/202 batch:72/8961 epoch:2/10\n","full seq: These include Austrian Airlines, Hungary's Malev, Greece's Olympic Airlines, Serbia's JAT, Italy's Alitalia, Slovenia's Adria Airways, Turkish Airlines, British Airways and Bulgaria's Hemus Air.Ģġġġġġġġ\n","pref seq: These include Austrian Airlines, Hungary's Malev, Greece's Olympic Airlines, Serbia's JAT, Italy's Alitalia, Slovenia's Adria Airways, Turkish Airlines, British Airw\n","next tok:                                                                                                                                                                     a\n","pred tok:                                                                                                                                                                     (\n","Completed batch.\n","epoch:2/10 batch:72/8961 batch_size:175 loss:2.2798280715942383 time_for_batch_instance:212.64664363861084 total_batch_time:17256.918441057205 running_batch_average:239.6794227924612\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 670442 KiB |  13249 MiB |    771 TiB |    771 TiB |\n","|       from large pool | 215836 KiB |  12813 MiB |    769 TiB |    769 TiB |\n","|       from small pool | 454606 KiB |    468 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 670442 KiB |  13249 MiB |    771 TiB |    771 TiB |\n","|       from large pool | 215836 KiB |  12813 MiB |    769 TiB |    769 TiB |\n","|       from small pool | 454606 KiB |    468 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  13226 MiB |    769 TiB |    769 TiB |\n","|       from large pool | 213248 KiB |  12795 MiB |    767 TiB |    767 TiB |\n","|       from small pool | 450193 KiB |    464 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1968 MiB |  13922 MiB | 185021 GiB | 185019 GiB |\n","|       from large pool |   1520 MiB |  13460 MiB | 184782 GiB | 184781 GiB |\n","|       from small pool |    448 MiB |    474 MiB |    238 GiB |    238 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1313 MiB |   1677 MiB | 259033 GiB | 259032 GiB |\n","|       from large pool |   1309 MiB |   1672 MiB | 257450 GiB | 257449 GiB |\n","|       from small pool |      4 MiB |     18 MiB |   1582 GiB |   1582 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   21206 K  |   21187 K  |\n","|       from large pool |      98    |     263    |   12862 K  |   12862 K  |\n","|       from small pool |   18777    |   18924    |    8343 K  |    8324 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   21206 K  |   21187 K  |\n","|       from large pool |      98    |     263    |   12862 K  |   12862 K  |\n","|       from small pool |   18777    |   18924    |    8343 K  |    8324 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     239    |     320    |    1152 K  |    1152 K  |\n","|       from large pool |      15    |      89    |    1030 K  |    1030 K  |\n","|       from small pool |     224    |     237    |     122 K  |     122 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      87    |     167    |   10083 K  |   10083 K  |\n","|       from large pool |      21    |      66    |    6772 K  |    6772 K  |\n","|       from small pool |      66    |     119    |    3310 K  |    3310 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:73/8961 batch_size:175\n","Next token prediction. step:142/201 batch:73/8961 epoch:2/10\n","full seq: Responding to a Greek request, NATO has agreed to provide security assistance during the Summer Olympics and the Paralympic Games, which Athens will host in August and September of this year.Ģġġġġġġġġġ\n","pref seq: Responding to a Greek request, NATO has agreed to provide security assistance during the Summer Olympics and the Paralympic Games, which Athen\n","next tok:                                                                                                                                              s\n","pred tok:                                                                                                                                              d\n","Completed batch.\n","epoch:2/10 batch:73/8961 batch_size:175 loss:0.7964271903038025 time_for_batch_instance:211.791836977005 total_batch_time:17468.71027803421 running_batch_average:239.2974010689618\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 674342 KiB |  13181 MiB |    779 TiB |    779 TiB |\n","|       from large pool | 219736 KiB |  12745 MiB |    778 TiB |    778 TiB |\n","|       from small pool | 454606 KiB |    468 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 674342 KiB |  13181 MiB |    779 TiB |    779 TiB |\n","|       from large pool | 219736 KiB |  12745 MiB |    778 TiB |    778 TiB |\n","|       from small pool | 454606 KiB |    468 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  13164 MiB |    777 TiB |    777 TiB |\n","|       from large pool | 213248 KiB |  12732 MiB |    776 TiB |    776 TiB |\n","|       from small pool | 450193 KiB |    464 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1780 MiB |  13874 MiB | 187021 GiB | 187019 GiB |\n","|       from large pool |   1332 MiB |  13412 MiB | 186779 GiB | 186778 GiB |\n","|       from small pool |    448 MiB |    474 MiB |    241 GiB |    241 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1121 MiB |   2152 MiB | 262074 GiB | 262073 GiB |\n","|       from large pool |   1117 MiB |   2146 MiB | 260471 GiB | 260470 GiB |\n","|       from small pool |      4 MiB |     18 MiB |   1602 GiB |   1602 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   21467 K  |   21448 K  |\n","|       from large pool |      98    |     263    |   13020 K  |   13020 K  |\n","|       from small pool |   18777    |   18924    |    8446 K  |    8427 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   21467 K  |   21448 K  |\n","|       from large pool |      98    |     263    |   13020 K  |   13020 K  |\n","|       from small pool |   18777    |   18924    |    8446 K  |    8427 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     243    |     324    |    1167 K  |    1166 K  |\n","|       from large pool |      19    |      93    |    1043 K  |    1043 K  |\n","|       from small pool |     224    |     237    |     123 K  |     123 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      87    |     176    |   10224 K  |   10224 K  |\n","|       from large pool |      21    |      75    |    6872 K  |    6872 K  |\n","|       from small pool |      66    |     118    |    3351 K  |    3351 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:74/8961 batch_size:175\n","Next token prediction. step:56/201 batch:74/8961 epoch:2/10\n","full seq: The SNS understands that the internet is the most efficient way to attract young people, who would rather log on to Facebook than read a newspaper or watch a political show on TV, Djuric said.Ģġġġġġġġġ\n","pref seq: The SNS understands that the internet is the most effici\n","next tok:                                                        e\n","pred tok:                                                        C\n","Completed batch.\n","epoch:2/10 batch:74/8961 batch_size:175 loss:0.9961230158805847 time_for_batch_instance:211.97208070755005 total_batch_time:17680.68235874176 running_batch_average:238.92813998299675\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 671758 KiB |  13181 MiB |    788 TiB |    788 TiB |\n","|       from large pool | 217152 KiB |  12745 MiB |    786 TiB |    786 TiB |\n","|       from small pool | 454606 KiB |    468 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 671758 KiB |  13181 MiB |    788 TiB |    788 TiB |\n","|       from large pool | 217152 KiB |  12745 MiB |    786 TiB |    786 TiB |\n","|       from small pool | 454606 KiB |    468 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  13164 MiB |    786 TiB |    786 TiB |\n","|       from large pool | 213248 KiB |  12732 MiB |    784 TiB |    784 TiB |\n","|       from small pool | 450193 KiB |    464 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1688 MiB |  13868 MiB | 189033 GiB | 189031 GiB |\n","|       from large pool |   1240 MiB |  13406 MiB | 188788 GiB | 188787 GiB |\n","|       from small pool |    448 MiB |    474 MiB |    244 GiB |    244 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1031 MiB |   1833 MiB | 265064 GiB | 265063 GiB |\n","|       from large pool |   1027 MiB |   1830 MiB | 263442 GiB | 263441 GiB |\n","|       from small pool |      4 MiB |     18 MiB |   1621 GiB |   1621 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   21728 K  |   21709 K  |\n","|       from large pool |      98    |     263    |   13179 K  |   13179 K  |\n","|       from small pool |   18777    |   18924    |    8549 K  |    8530 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   21728 K  |   21709 K  |\n","|       from large pool |      98    |     263    |   13179 K  |   13179 K  |\n","|       from small pool |   18777    |   18924    |    8549 K  |    8530 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     238    |     321    |    1181 K  |    1181 K  |\n","|       from large pool |      14    |      90    |    1056 K  |    1056 K  |\n","|       from small pool |     224    |     237    |     125 K  |     125 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      82    |     174    |   10365 K  |   10365 K  |\n","|       from large pool |      16    |      73    |    6973 K  |    6973 K  |\n","|       from small pool |      66    |     118    |    3392 K  |    3392 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:75/8961 batch_size:175\n","Next token prediction. step:181/201 batch:75/8961 epoch:2/10\n","full seq: The indictments come as the government is in the final stages of privatising a 75% stake in the company, with Croatia Telecom and Austrian Telecom the main contenders in the privatisation race.Ģġġġġġġġ\n","pref seq: The indictments come as the government is in the final stages of privatising a 75% stake in the company, with Croatia Telecom and Austrian Telecom the main contenders in the privati\n","next tok:                                                                                                                                                                                     s\n","pred tok:                                                                                                                                                                                     Ģ\n","Completed batch.\n","epoch:2/10 batch:75/8961 batch_size:175 loss:2.5096473693847656 time_for_batch_instance:211.81241512298584 total_batch_time:17892.494773864746 running_batch_average:238.56659698486328\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 671758 KiB |  13181 MiB |    796 TiB |    796 TiB |\n","|       from large pool | 217152 KiB |  12745 MiB |    794 TiB |    794 TiB |\n","|       from small pool | 454606 KiB |    468 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 671758 KiB |  13181 MiB |    796 TiB |    796 TiB |\n","|       from large pool | 217152 KiB |  12745 MiB |    794 TiB |    794 TiB |\n","|       from small pool | 454606 KiB |    468 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  13164 MiB |    794 TiB |    794 TiB |\n","|       from large pool | 213248 KiB |  12732 MiB |    793 TiB |    793 TiB |\n","|       from small pool | 450193 KiB |    464 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1688 MiB |  13868 MiB | 191047 GiB | 191046 GiB |\n","|       from large pool |   1240 MiB |  13406 MiB | 190799 GiB | 190798 GiB |\n","|       from small pool |    448 MiB |    474 MiB |    247 GiB |    247 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1031 MiB |   1833 MiB | 268032 GiB | 268031 GiB |\n","|       from large pool |   1027 MiB |   1830 MiB | 266391 GiB | 266390 GiB |\n","|       from small pool |      4 MiB |     18 MiB |   1641 GiB |   1641 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   21990 K  |   21971 K  |\n","|       from large pool |      98    |     263    |   13337 K  |   13337 K  |\n","|       from small pool |   18777    |   18924    |    8652 K  |    8634 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   21990 K  |   21971 K  |\n","|       from large pool |      98    |     263    |   13337 K  |   13337 K  |\n","|       from small pool |   18777    |   18924    |    8652 K  |    8634 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     238    |     321    |    1195 K  |    1195 K  |\n","|       from large pool |      14    |      90    |    1069 K  |    1069 K  |\n","|       from small pool |     224    |     237    |     126 K  |     126 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      82    |     174    |   10507 K  |   10507 K  |\n","|       from large pool |      16    |      73    |    7075 K  |    7075 K  |\n","|       from small pool |      66    |     118    |    3432 K  |    3432 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:76/8961 batch_size:175\n","Next token prediction. step:123/200 batch:76/8961 epoch:2/10\n","full seq: Elementary education professor Irene Jerina tells SETimes that Montenegro, as well as the entire Balkans, is still a patriarchal society where just the mention of this problem brings shame.Ģġġġġġġġġġġ\n","pref seq: Elementary education professor Irene Jerina tells SETimes that Montenegro, as well as the entire Balkans, is still a patria\n","next tok:                                                                                                                           r\n","pred tok:                                                                                                                           7\n","Completed batch.\n","epoch:2/10 batch:76/8961 batch_size:175 loss:4.326131343841553 time_for_batch_instance:211.46664762496948 total_batch_time:18103.961421489716 running_batch_average:238.21001870381204\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 671439 KiB |  13126 MiB |    804 TiB |    804 TiB |\n","|       from large pool | 216833 KiB |  12690 MiB |    803 TiB |    803 TiB |\n","|       from small pool | 454606 KiB |    468 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 671439 KiB |  13126 MiB |    804 TiB |    804 TiB |\n","|       from large pool | 216833 KiB |  12690 MiB |    803 TiB |    803 TiB |\n","|       from small pool | 454606 KiB |    468 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  13101 MiB |    802 TiB |    802 TiB |\n","|       from large pool | 213248 KiB |  12669 MiB |    801 TiB |    801 TiB |\n","|       from small pool | 450193 KiB |    464 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1622 MiB |  13762 MiB | 193038 GiB | 193036 GiB |\n","|       from large pool |   1174 MiB |  13300 MiB | 192787 GiB | 192786 GiB |\n","|       from small pool |    448 MiB |    474 MiB |    250 GiB |    250 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |    966 MiB |   1641 MiB | 271159 GiB | 271159 GiB |\n","|       from large pool |    962 MiB |   1638 MiB | 269499 GiB | 269498 GiB |\n","|       from small pool |      4 MiB |     18 MiB |   1660 GiB |   1660 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   22250 K  |   22231 K  |\n","|       from large pool |      98    |     263    |   13494 K  |   13494 K  |\n","|       from small pool |   18777    |   18924    |    8755 K  |    8736 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   22250 K  |   22231 K  |\n","|       from large pool |      98    |     263    |   13494 K  |   13494 K  |\n","|       from small pool |   18777    |   18924    |    8755 K  |    8736 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     240    |     321    |    1210 K  |    1210 K  |\n","|       from large pool |      16    |      90    |    1081 K  |    1081 K  |\n","|       from small pool |     224    |     237    |     128 K  |     128 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      84    |     158    |   10650 K  |   10650 K  |\n","|       from large pool |      19    |      57    |    7177 K  |    7177 K  |\n","|       from small pool |      65    |     118    |    3473 K  |    3473 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:77/8961 batch_size:175\n","Next token prediction. step:165/199 batch:77/8961 epoch:2/10\n","full seq: Turkish Energy Minister Taner Yildiz announced on Saturday (October 1st) that his country has decided to discontinue an existing contract for natural gas supplies with Russian giant Gazprom.Ģġġġġġġġġ\n","pref seq: Turkish Energy Minister Taner Yildiz announced on Saturday (October 1st) that his country has decided to discontinue an existing contract for natural gas supplies wi\n","next tok:                                                                                                                                                                     t\n","pred tok:                                                                                                                                                                     f\n","Completed batch.\n","epoch:2/10 batch:77/8961 batch_size:175 loss:1.3203703165054321 time_for_batch_instance:209.78013134002686 total_batch_time:18313.741552829742 running_batch_average:237.84079938739924\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 669914 KiB |  13068 MiB |    813 TiB |    813 TiB |\n","|       from large pool | 215308 KiB |  12632 MiB |    811 TiB |    811 TiB |\n","|       from small pool | 454606 KiB |    468 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 669914 KiB |  13068 MiB |    813 TiB |    813 TiB |\n","|       from large pool | 215308 KiB |  12632 MiB |    811 TiB |    811 TiB |\n","|       from small pool | 454606 KiB |    468 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  13038 MiB |    811 TiB |    811 TiB |\n","|       from large pool | 213248 KiB |  12607 MiB |    809 TiB |    809 TiB |\n","|       from small pool | 450193 KiB |    463 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2290 MiB |  13732 MiB | 195015 GiB | 195012 GiB |\n","|       from large pool |   1840 MiB |  13268 MiB | 194761 GiB | 194759 GiB |\n","|       from small pool |    450 MiB |    474 MiB |    253 GiB |    253 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1635 MiB |   1814 MiB | 274131 GiB | 274130 GiB |\n","|       from large pool |   1629 MiB |   1807 MiB | 272452 GiB | 272450 GiB |\n","|       from small pool |      6 MiB |     22 MiB |   1679 GiB |   1679 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   22509 K  |   22490 K  |\n","|       from large pool |      98    |     263    |   13651 K  |   13651 K  |\n","|       from small pool |   18777    |   18924    |    8857 K  |    8838 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   22509 K  |   22490 K  |\n","|       from large pool |      98    |     263    |   13651 K  |   13651 K  |\n","|       from small pool |   18777    |   18924    |    8857 K  |    8838 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     241    |     320    |    1224 K  |    1224 K  |\n","|       from large pool |      16    |      88    |    1094 K  |    1094 K  |\n","|       from small pool |     225    |     237    |     129 K  |     129 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      88    |     179    |   10800 K  |   10799 K  |\n","|       from large pool |      20    |      78    |    7286 K  |    7285 K  |\n","|       from small pool |      68    |     118    |    3514 K  |    3514 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:78/8961 batch_size:175\n","Next token prediction. step:5/199 batch:78/8961 epoch:2/10\n","full seq: (Euobserver, EurActiv, FT, Times - 26/11/08; AFP, Reuters, AP, DPA, BBC, International Herald Tribune, Euobserver, BNT, Sofia Echo, Dnevnik, Mediapool, News.bg, Focus news Agency - 25/11/08)Ģġġġġġġġġ\n","pref seq: (Euob\n","next tok:     s\n","pred tok:     ,\n","Completed batch.\n","epoch:2/10 batch:78/8961 batch_size:175 loss:1.307433009147644 time_for_batch_instance:210.1469864845276 total_batch_time:18523.88853931427 running_batch_average:237.4857505040291\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 669914 KiB |  13068 MiB |    821 TiB |    821 TiB |\n","|       from large pool | 215308 KiB |  12632 MiB |    819 TiB |    819 TiB |\n","|       from small pool | 454606 KiB |    468 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 669914 KiB |  13068 MiB |    821 TiB |    821 TiB |\n","|       from large pool | 215308 KiB |  12632 MiB |    819 TiB |    819 TiB |\n","|       from small pool | 454606 KiB |    468 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  13038 MiB |    819 TiB |    819 TiB |\n","|       from large pool | 213248 KiB |  12607 MiB |    817 TiB |    817 TiB |\n","|       from small pool | 450193 KiB |    463 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2290 MiB |  13732 MiB | 196993 GiB | 196990 GiB |\n","|       from large pool |   1840 MiB |  13268 MiB | 196736 GiB | 196734 GiB |\n","|       from small pool |    450 MiB |    474 MiB |    256 GiB |    256 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1635 MiB |   1814 MiB | 277102 GiB | 277100 GiB |\n","|       from large pool |   1629 MiB |   1807 MiB | 275403 GiB | 275402 GiB |\n","|       from small pool |      6 MiB |     20 MiB |   1698 GiB |   1698 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   22767 K  |   22749 K  |\n","|       from large pool |      98    |     263    |   13808 K  |   13807 K  |\n","|       from small pool |   18777    |   18924    |    8959 K  |    8941 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   22767 K  |   22749 K  |\n","|       from large pool |      98    |     263    |   13808 K  |   13807 K  |\n","|       from small pool |   18777    |   18924    |    8959 K  |    8941 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     241    |     321    |    1238 K  |    1238 K  |\n","|       from large pool |      16    |      88    |    1107 K  |    1107 K  |\n","|       from small pool |     225    |     237    |     131 K  |     131 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      88    |     179    |   10949 K  |   10949 K  |\n","|       from large pool |      20    |      78    |    7394 K  |    7394 K  |\n","|       from small pool |      68    |     118    |    3554 K  |    3554 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:79/8961 batch_size:175\n","Next token prediction. step:141/198 batch:79/8961 epoch:2/10\n","full seq: Kosovo Albanian leaders should make sure that there is no recurrence of interethnic violence in the province, EU leaders say in a draft statement expected to be released Friday (26 March).Ģġġġġġġġġġ\n","pref seq: Kosovo Albanian leaders should make sure that there is no recurrence of interethnic violence in the province, EU leaders say in a draft state\n","next tok:                                                                                                                                             m\n","pred tok:                                                                                                                                             (\n","Completed batch.\n","epoch:2/10 batch:79/8961 batch_size:175 loss:2.538923740386963 time_for_batch_instance:207.7764196395874 total_batch_time:18731.664958953857 running_batch_average:237.10968302473236\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 668955 KiB |  12994 MiB |    829 TiB |    829 TiB |\n","|       from large pool | 214349 KiB |  12559 MiB |    828 TiB |    828 TiB |\n","|       from small pool | 454606 KiB |    468 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 668955 KiB |  12994 MiB |    829 TiB |    829 TiB |\n","|       from large pool | 214349 KiB |  12559 MiB |    828 TiB |    828 TiB |\n","|       from small pool | 454606 KiB |    468 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  12975 MiB |    827 TiB |    827 TiB |\n","|       from large pool | 213248 KiB |  12544 MiB |    826 TiB |    826 TiB |\n","|       from small pool | 450193 KiB |    463 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2506 MiB |  13618 MiB | 198793 GiB | 198790 GiB |\n","|       from large pool |   2056 MiB |  13154 MiB | 198533 GiB | 198531 GiB |\n","|       from small pool |    450 MiB |    474 MiB |    259 GiB |    259 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1852 MiB |   2329 MiB | 280102 GiB | 280100 GiB |\n","|       from large pool |   1846 MiB |   2325 MiB | 278384 GiB | 278382 GiB |\n","|       from small pool |      6 MiB |     21 MiB |   1717 GiB |   1717 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   23025 K  |   23006 K  |\n","|       from large pool |      98    |     263    |   13963 K  |   13963 K  |\n","|       from small pool |   18777    |   18924    |    9061 K  |    9042 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   23025 K  |   23006 K  |\n","|       from large pool |      98    |     263    |   13963 K  |   13963 K  |\n","|       from small pool |   18777    |   18924    |    9061 K  |    9042 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     242    |     320    |    1251 K  |    1251 K  |\n","|       from large pool |      17    |      88    |    1119 K  |    1119 K  |\n","|       from small pool |     225    |     237    |     132 K  |     132 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      93    |     161    |   11063 K  |   11062 K  |\n","|       from large pool |      25    |      60    |    7468 K  |    7468 K  |\n","|       from small pool |      68    |     118    |    3594 K  |    3594 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:80/8961 batch_size:175\n","Next token prediction. step:131/198 batch:80/8961 epoch:2/10\n","full seq: Turkey has refrained from calling for Syrian President Bashar al-Assad to step aside, only going so far as to urge the regime to implement reforms and transition to a multi-party democracy.Ģġġġġġġġġ\n","pref seq: Turkey has refrained from calling for Syrian President Bashar al-Assad to step aside, only going so far as to urge the regime to im\n","next tok:                                                                                                                                   p\n","pred tok:                                                                                                                                   (\n","Completed batch.\n","epoch:2/10 batch:80/8961 batch_size:175 loss:1.1067019701004028 time_for_batch_instance:207.74408960342407 total_batch_time:18939.40904855728 running_batch_average:236.74261310696602\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 668955 KiB |  12994 MiB |    837 TiB |    837 TiB |\n","|       from large pool | 214349 KiB |  12559 MiB |    836 TiB |    836 TiB |\n","|       from small pool | 454606 KiB |    468 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 668955 KiB |  12994 MiB |    837 TiB |    837 TiB |\n","|       from large pool | 214349 KiB |  12559 MiB |    836 TiB |    836 TiB |\n","|       from small pool | 454606 KiB |    468 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  12975 MiB |    835 TiB |    835 TiB |\n","|       from large pool | 213248 KiB |  12544 MiB |    834 TiB |    834 TiB |\n","|       from small pool | 450193 KiB |    463 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2506 MiB |  13618 MiB | 200593 GiB | 200591 GiB |\n","|       from large pool |   2056 MiB |  13154 MiB | 200331 GiB | 200329 GiB |\n","|       from small pool |    450 MiB |    474 MiB |    262 GiB |    262 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1852 MiB |   2355 MiB | 283105 GiB | 283103 GiB |\n","|       from large pool |   1846 MiB |   2348 MiB | 281368 GiB | 281366 GiB |\n","|       from small pool |      6 MiB |     21 MiB |   1737 GiB |   1737 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   23282 K  |   23263 K  |\n","|       from large pool |      98    |     263    |   14119 K  |   14119 K  |\n","|       from small pool |   18777    |   18924    |    9163 K  |    9144 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   23282 K  |   23263 K  |\n","|       from large pool |      98    |     263    |   14119 K  |   14119 K  |\n","|       from small pool |   18777    |   18924    |    9163 K  |    9144 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     242    |     320    |    1265 K  |    1264 K  |\n","|       from large pool |      17    |      88    |    1130 K  |    1130 K  |\n","|       from small pool |     225    |     237    |     134 K  |     134 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      93    |     161    |   11177 K  |   11177 K  |\n","|       from large pool |      25    |      60    |    7542 K  |    7541 K  |\n","|       from small pool |      68    |     118    |    3635 K  |    3635 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:81/8961 batch_size:175\n","Next token prediction. step:82/196 batch:81/8961 epoch:2/10\n","full seq: After the government voted last year to approve the project, a US-Turkish company, Bechtel-Enka, began construction of the road, which will cost 600m euros and is to be completed by 2009.Ģġġġġġġġġ\n","pref seq: After the government voted last year to approve the project, a US-Turkish company,\n","next tok:                                                                                   \n","pred tok:                                                                                  (\n","Completed batch.\n","epoch:2/10 batch:81/8961 batch_size:175 loss:0.8657341003417969 time_for_batch_instance:205.77959847450256 total_batch_time:19145.188647031784 running_batch_average:236.36035366705906\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 668709 KiB |  12884 MiB |    845 TiB |    845 TiB |\n","|       from large pool | 214103 KiB |  12448 MiB |    844 TiB |    844 TiB |\n","|       from small pool | 454606 KiB |    468 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 668709 KiB |  12884 MiB |    845 TiB |    845 TiB |\n","|       from large pool | 214103 KiB |  12448 MiB |    844 TiB |    844 TiB |\n","|       from small pool | 454606 KiB |    468 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  12850 MiB |    843 TiB |    843 TiB |\n","|       from large pool | 213248 KiB |  12419 MiB |    842 TiB |    842 TiB |\n","|       from small pool | 450193 KiB |    463 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1708 MiB |  13490 MiB | 202435 GiB | 202434 GiB |\n","|       from large pool |   1258 MiB |  13026 MiB | 202170 GiB | 202169 GiB |\n","|       from small pool |    450 MiB |    474 MiB |    265 GiB |    264 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1054 MiB |   2119 MiB | 286128 GiB | 286127 GiB |\n","|       from large pool |   1048 MiB |   2110 MiB | 284372 GiB | 284371 GiB |\n","|       from small pool |      6 MiB |     22 MiB |   1755 GiB |   1755 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   23537 K  |   23518 K  |\n","|       from large pool |      98    |     263    |   14273 K  |   14273 K  |\n","|       from small pool |   18777    |   18924    |    9263 K  |    9245 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   23537 K  |   23518 K  |\n","|       from large pool |      98    |     263    |   14273 K  |   14273 K  |\n","|       from small pool |   18777    |   18924    |    9263 K  |    9245 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     240    |     322    |    1278 K  |    1278 K  |\n","|       from large pool |      15    |      90    |    1142 K  |    1142 K  |\n","|       from small pool |     225    |     237    |     135 K  |     135 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      90    |     149    |   11291 K  |   11291 K  |\n","|       from large pool |      20    |      48    |    7616 K  |    7616 K  |\n","|       from small pool |      70    |     119    |    3675 K  |    3675 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:82/8961 batch_size:175\n","Next token prediction. step:138/196 batch:82/8961 epoch:2/10\n","full seq: The law implements constitutional principles guaranteeing free access and the right to receive and transfer information, and requires information holders to operate in a transparent manner.Ģġġġġġġ\n","pref seq: The law implements constitutional principles guaranteeing free access and the right to receive and transfer information, and requires info\n","next tok:                                                                                                                                          r\n","pred tok:                                                                                                                                          (\n","Completed batch.\n","epoch:2/10 batch:82/8961 batch_size:175 loss:2.116790771484375 time_for_batch_instance:205.95938372612 total_batch_time:19351.148030757904 running_batch_average:235.98961013119396\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 668294 KiB |  12882 MiB |    853 TiB |    853 TiB |\n","|       from large pool | 213688 KiB |  12446 MiB |    852 TiB |    852 TiB |\n","|       from small pool | 454606 KiB |    468 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 668294 KiB |  12882 MiB |    853 TiB |    853 TiB |\n","|       from large pool | 213688 KiB |  12446 MiB |    852 TiB |    852 TiB |\n","|       from small pool | 454606 KiB |    468 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  12850 MiB |    851 TiB |    851 TiB |\n","|       from large pool | 213248 KiB |  12419 MiB |    850 TiB |    850 TiB |\n","|       from small pool | 450193 KiB |    463 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1450 MiB |  13486 MiB | 204334 GiB | 204333 GiB |\n","|       from large pool |   1000 MiB |  13022 MiB | 204066 GiB | 204065 GiB |\n","|       from small pool |    450 MiB |    474 MiB |    268 GiB |    267 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |    797 MiB |   1841 MiB | 289067 GiB | 289067 GiB |\n","|       from large pool |    791 MiB |   1836 MiB | 287293 GiB | 287292 GiB |\n","|       from small pool |      6 MiB |     20 MiB |   1774 GiB |   1774 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   23792 K  |   23773 K  |\n","|       from large pool |      98    |     263    |   14428 K  |   14427 K  |\n","|       from small pool |   18777    |   18924    |    9364 K  |    9345 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   23792 K  |   23773 K  |\n","|       from large pool |      98    |     263    |   14428 K  |   14427 K  |\n","|       from small pool |   18777    |   18924    |    9364 K  |    9345 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     240    |     324    |    1292 K  |    1292 K  |\n","|       from large pool |      15    |      91    |    1155 K  |    1154 K  |\n","|       from small pool |     225    |     237    |     137 K  |     137 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      91    |     151    |   11406 K  |   11406 K  |\n","|       from large pool |      21    |      50    |    7691 K  |    7691 K  |\n","|       from small pool |      70    |     119    |    3715 K  |    3715 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:83/8961 batch_size:175\n","Next token prediction. step:119/195 batch:83/8961 epoch:2/10\n","full seq: A concert by Macedonian pop singers marked the 40th anniversary of the devastating earthquake in Skopje that left 1,000 people dead and three-quarters of the city's inhabitants homeless.Ģġġġġġġġġ\n","pref seq: A concert by Macedonian pop singers marked the 40th anniversary of the devastating earthquake in Skopje that left 1,000\n","next tok:                                                                                                                        \n","pred tok:                                                                                                                       (\n","Completed batch.\n","epoch:2/10 batch:83/8961 batch_size:175 loss:1.0403032302856445 time_for_batch_instance:205.17390775680542 total_batch_time:19556.32193851471 running_batch_average:235.61833660861095\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 669045 KiB |  12799 MiB |    861 TiB |    861 TiB |\n","|       from large pool | 214439 KiB |  12363 MiB |    860 TiB |    860 TiB |\n","|       from small pool | 454606 KiB |    468 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 669045 KiB |  12799 MiB |    861 TiB |    861 TiB |\n","|       from large pool | 214439 KiB |  12363 MiB |    860 TiB |    860 TiB |\n","|       from small pool | 454606 KiB |    468 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  12787 MiB |    859 TiB |    859 TiB |\n","|       from large pool | 213248 KiB |  12356 MiB |    858 TiB |    858 TiB |\n","|       from small pool | 450193 KiB |    463 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1882 MiB |  13456 MiB | 206223 GiB | 206222 GiB |\n","|       from large pool |   1432 MiB |  12992 MiB | 205953 GiB | 205951 GiB |\n","|       from small pool |    450 MiB |    474 MiB |    270 GiB |    270 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1228 MiB |   1782 MiB | 291812 GiB | 291811 GiB |\n","|       from large pool |   1222 MiB |   1778 MiB | 290018 GiB | 290017 GiB |\n","|       from small pool |      6 MiB |     20 MiB |   1793 GiB |   1793 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   24046 K  |   24027 K  |\n","|       from large pool |      98    |     263    |   14581 K  |   14581 K  |\n","|       from small pool |   18777    |   18924    |    9464 K  |    9445 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   24046 K  |   24027 K  |\n","|       from large pool |      98    |     263    |   14581 K  |   14581 K  |\n","|       from small pool |   18777    |   18924    |    9464 K  |    9445 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     245    |     324    |    1305 K  |    1305 K  |\n","|       from large pool |      20    |      92    |    1167 K  |    1167 K  |\n","|       from small pool |     225    |     237    |     138 K  |     138 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      97    |     166    |   11523 K  |   11523 K  |\n","|       from large pool |      27    |      65    |    7769 K  |    7769 K  |\n","|       from small pool |      70    |     119    |    3754 K  |    3754 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:84/8961 batch_size:175\n","Next token prediction. step:47/195 batch:84/8961 epoch:2/10\n","full seq: Mimoza Kusari-Lila: This decision is entirely economic, and the government is closely working with the responsible structures not to politicise the situation by creating ethnic tensions.Ģġġġġġġġġ\n","pref seq: Mimoza Kusari-Lila: This decision is entirely e\n","next tok:                                               c\n","pred tok:                                               ,\n","Completed batch.\n","epoch:2/10 batch:84/8961 batch_size:175 loss:0.9801064729690552 time_for_batch_instance:205.28628659248352 total_batch_time:19761.608225107193 running_batch_average:235.25724077508562\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 668295 KiB |  12798 MiB |    869 TiB |    869 TiB |\n","|       from large pool | 213689 KiB |  12362 MiB |    868 TiB |    868 TiB |\n","|       from small pool | 454606 KiB |    468 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 668295 KiB |  12798 MiB |    869 TiB |    869 TiB |\n","|       from large pool | 213689 KiB |  12362 MiB |    868 TiB |    868 TiB |\n","|       from small pool | 454606 KiB |    468 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  12787 MiB |    867 TiB |    867 TiB |\n","|       from large pool | 213248 KiB |  12356 MiB |    866 TiB |    866 TiB |\n","|       from small pool | 450193 KiB |    463 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1682 MiB |  13456 MiB | 208112 GiB | 208110 GiB |\n","|       from large pool |   1232 MiB |  12992 MiB | 207838 GiB | 207837 GiB |\n","|       from small pool |    450 MiB |    474 MiB |    273 GiB |    273 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1029 MiB |   1782 MiB | 294563 GiB | 294562 GiB |\n","|       from large pool |   1023 MiB |   1778 MiB | 292751 GiB | 292750 GiB |\n","|       from small pool |      6 MiB |     21 MiB |   1812 GiB |   1812 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   24299 K  |   24280 K  |\n","|       from large pool |      98    |     263    |   14734 K  |   14734 K  |\n","|       from small pool |   18777    |   18924    |    9564 K  |    9546 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   24299 K  |   24280 K  |\n","|       from large pool |      98    |     263    |   14734 K  |   14734 K  |\n","|       from small pool |   18777    |   18924    |    9564 K  |    9546 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     245    |     324    |    1319 K  |    1319 K  |\n","|       from large pool |      20    |      92    |    1179 K  |    1179 K  |\n","|       from small pool |     225    |     237    |     140 K  |     139 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      97    |     166    |   11641 K  |   11641 K  |\n","|       from large pool |      27    |      65    |    7847 K  |    7847 K  |\n","|       from small pool |      70    |     119    |    3794 K  |    3794 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:85/8961 batch_size:175\n","Next token prediction. step:83/194 batch:85/8961 epoch:2/10\n","full seq: Allegations of irregularities surfaced in mid-July, when a group of Sliven municipal councilors uploaded on the Internet a documentary with English subtitles, entitled \"The New Mafia\".Ģġġġġġġġġġ\n","pref seq: Allegations of irregularities surfaced in mid-July, when a group of Sliven municipa\n","next tok:                                                                                   l\n","pred tok:                                                                                   (\n","Completed batch.\n","epoch:2/10 batch:85/8961 batch_size:175 loss:0.7416519522666931 time_for_batch_instance:203.88032221794128 total_batch_time:19965.488547325134 running_batch_average:234.8881005567663\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 670106 KiB |  12691 MiB |    877 TiB |    877 TiB |\n","|       from large pool | 215500 KiB |  12255 MiB |    876 TiB |    876 TiB |\n","|       from small pool | 454606 KiB |    468 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 670106 KiB |  12691 MiB |    877 TiB |    877 TiB |\n","|       from large pool | 215500 KiB |  12255 MiB |    876 TiB |    876 TiB |\n","|       from small pool | 454606 KiB |    468 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  12680 MiB |    875 TiB |    875 TiB |\n","|       from large pool | 213248 KiB |  12248 MiB |    874 TiB |    874 TiB |\n","|       from small pool | 450193 KiB |    463 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1450 MiB |  13280 MiB | 209951 GiB | 209949 GiB |\n","|       from large pool |   1000 MiB |  12816 MiB | 209674 GiB | 209673 GiB |\n","|       from small pool |    450 MiB |    474 MiB |    276 GiB |    275 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |    795 MiB |   1648 MiB | 297363 GiB | 297362 GiB |\n","|       from large pool |    789 MiB |   1643 MiB | 295532 GiB | 295531 GiB |\n","|       from small pool |      6 MiB |     20 MiB |   1831 GiB |   1831 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   24551 K  |   24532 K  |\n","|       from large pool |      98    |     263    |   14887 K  |   14887 K  |\n","|       from small pool |   18777    |   18924    |    9664 K  |    9645 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   24551 K  |   24532 K  |\n","|       from large pool |      98    |     263    |   14887 K  |   14887 K  |\n","|       from small pool |   18777    |   18924    |    9664 K  |    9645 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     239    |     322    |    1333 K  |    1332 K  |\n","|       from large pool |      14    |      90    |    1191 K  |    1191 K  |\n","|       from small pool |     225    |     237    |     141 K  |     141 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      88    |     156    |   11772 K  |   11772 K  |\n","|       from large pool |      18    |      55    |    7938 K  |    7938 K  |\n","|       from small pool |      70    |     119    |    3834 K  |    3834 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:86/8961 batch_size:175\n","Next token prediction. step:108/194 batch:86/8961 epoch:2/10\n","full seq: Describing the new US president as \"a man of great vision,\" British Prime Minister Gordon Brown said his inauguration marked a \"new chapter in both American... and the world's history\".Ģġġġġġġġġ\n","pref seq: Describing the new US president as \"a man of great vision,\" British Prime Minister Gordon Brown said his ina\n","next tok:                                                                                                            u\n","pred tok:                                                                                                            -\n","Completed batch.\n","epoch:2/10 batch:86/8961 batch_size:175 loss:0.9441511631011963 time_for_batch_instance:204.34106540679932 total_batch_time:20169.829612731934 running_batch_average:234.53290247362713\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 669301 KiB |  12777 MiB |    885 TiB |    885 TiB |\n","|       from large pool | 214695 KiB |  12341 MiB |    883 TiB |    883 TiB |\n","|       from small pool | 454606 KiB |    468 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 669301 KiB |  12777 MiB |    885 TiB |    885 TiB |\n","|       from large pool | 214695 KiB |  12341 MiB |    883 TiB |    883 TiB |\n","|       from small pool | 454606 KiB |    468 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  12768 MiB |    883 TiB |    883 TiB |\n","|       from large pool | 213248 KiB |  12336 MiB |    881 TiB |    881 TiB |\n","|       from small pool | 450193 KiB |    463 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1832 MiB |  13446 MiB | 211823 GiB | 211821 GiB |\n","|       from large pool |   1382 MiB |  12982 MiB | 211544 GiB | 211543 GiB |\n","|       from small pool |    450 MiB |    474 MiB |    279 GiB |    278 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1178 MiB |   1778 MiB | 300091 GiB | 300090 GiB |\n","|       from large pool |   1172 MiB |   1773 MiB | 298241 GiB | 298240 GiB |\n","|       from small pool |      6 MiB |     22 MiB |   1849 GiB |   1849 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   24803 K  |   24785 K  |\n","|       from large pool |      98    |     263    |   15039 K  |   15039 K  |\n","|       from small pool |   18777    |   18924    |    9764 K  |    9745 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   24803 K  |   24785 K  |\n","|       from large pool |      98    |     263    |   15039 K  |   15039 K  |\n","|       from small pool |   18777    |   18924    |    9764 K  |    9745 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     242    |     323    |    1346 K  |    1346 K  |\n","|       from large pool |      17    |      91    |    1203 K  |    1203 K  |\n","|       from small pool |     225    |     237    |     142 K  |     142 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      92    |     165    |   11889 K  |   11889 K  |\n","|       from large pool |      22    |      64    |    8015 K  |    8015 K  |\n","|       from small pool |      70    |     119    |    3873 K  |    3873 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:87/8961 batch_size:175\n","Next token prediction. step:54/194 batch:87/8961 epoch:2/10\n","full seq: The decision on the chapters emerged after a meeting in Prague between Turkey and the foreign ministers of the EU Troika, consisting of the past, current and future EU presidency holders.Ģġġġġġġ\n","pref seq: The decision on the chapters emerged after a meeting i\n","next tok:                                                      n\n","pred tok:                                                      G\n","Completed batch.\n","epoch:2/10 batch:87/8961 batch_size:175 loss:2.3272817134857178 time_for_batch_instance:204.59773421287537 total_batch_time:20374.42734694481 running_batch_average:234.18882007982538\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 669301 KiB |  12777 MiB |    893 TiB |    893 TiB |\n","|       from large pool | 214695 KiB |  12341 MiB |    891 TiB |    891 TiB |\n","|       from small pool | 454606 KiB |    468 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 669301 KiB |  12777 MiB |    893 TiB |    893 TiB |\n","|       from large pool | 214695 KiB |  12341 MiB |    891 TiB |    891 TiB |\n","|       from small pool | 454606 KiB |    468 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  12768 MiB |    891 TiB |    891 TiB |\n","|       from large pool | 213248 KiB |  12336 MiB |    889 TiB |    889 TiB |\n","|       from small pool | 450193 KiB |    463 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1832 MiB |  13446 MiB | 213695 GiB | 213693 GiB |\n","|       from large pool |   1382 MiB |  12982 MiB | 213413 GiB | 213412 GiB |\n","|       from small pool |    450 MiB |    474 MiB |    281 GiB |    281 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1178 MiB |   1778 MiB | 302800 GiB | 302799 GiB |\n","|       from large pool |   1172 MiB |   1773 MiB | 300931 GiB | 300930 GiB |\n","|       from small pool |      6 MiB |     22 MiB |   1868 GiB |   1868 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   25056 K  |   25037 K  |\n","|       from large pool |      98    |     263    |   15192 K  |   15192 K  |\n","|       from small pool |   18777    |   18924    |    9863 K  |    9845 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   25056 K  |   25037 K  |\n","|       from large pool |      98    |     263    |   15192 K  |   15192 K  |\n","|       from small pool |   18777    |   18924    |    9863 K  |    9845 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     242    |     323    |    1360 K  |    1360 K  |\n","|       from large pool |      17    |      91    |    1216 K  |    1216 K  |\n","|       from small pool |     225    |     237    |     144 K  |     144 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      92    |     165    |   12005 K  |   12005 K  |\n","|       from large pool |      22    |      64    |    8092 K  |    8092 K  |\n","|       from small pool |      70    |     119    |    3913 K  |    3913 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:88/8961 batch_size:175\n","Next token prediction. step:116/193 batch:88/8961 epoch:2/10\n","full seq: (Bloomberg, Standart - 31/07/09; Reuters, Dnevnik, Mediapool, Novinite, Focus - 30/07/09; AFP, Reuters - 29/07/09; Sofia Echo, Mediapool - 28/07/09; FT - 27/07/09; Novinite - 26/07/09)Ģġġġġġġġġ\n","pref seq: (Bloomberg, Standart - 31/07/09; Reuters, Dnevnik, Mediapool, Novinite, Focus - 30/07/09; AFP, Reuters - 29/07/09; S\n","next tok:                                                                                                                    o\n","pred tok:                                                                                                                    )\n","Completed batch.\n","epoch:2/10 batch:88/8961 batch_size:175 loss:0.6868575811386108 time_for_batch_instance:202.85092091560364 total_batch_time:20577.278267860413 running_batch_average:233.83270758932287\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 668649 KiB |  12637 MiB |    901 TiB |    901 TiB |\n","|       from large pool | 214043 KiB |  12201 MiB |    899 TiB |    899 TiB |\n","|       from small pool | 454606 KiB |    468 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 668649 KiB |  12637 MiB |    901 TiB |    901 TiB |\n","|       from large pool | 214043 KiB |  12201 MiB |    899 TiB |    899 TiB |\n","|       from small pool | 454606 KiB |    468 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  12616 MiB |    899 TiB |    899 TiB |\n","|       from large pool | 213248 KiB |  12184 MiB |    897 TiB |    897 TiB |\n","|       from small pool | 450193 KiB |    463 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1976 MiB |  13284 MiB | 215472 GiB | 215470 GiB |\n","|       from large pool |   1526 MiB |  12820 MiB | 215187 GiB | 215186 GiB |\n","|       from small pool |    450 MiB |    474 MiB |    284 GiB |    284 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1323 MiB |   2084 MiB | 305638 GiB | 305637 GiB |\n","|       from large pool |   1316 MiB |   2079 MiB | 303750 GiB | 303749 GiB |\n","|       from small pool |      6 MiB |     20 MiB |   1887 GiB |   1887 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   25307 K  |   25288 K  |\n","|       from large pool |      98    |     263    |   15344 K  |   15343 K  |\n","|       from small pool |   18777    |   18924    |    9963 K  |    9944 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   25307 K  |   25288 K  |\n","|       from large pool |      98    |     263    |   15344 K  |   15343 K  |\n","|       from small pool |   18777    |   18924    |    9963 K  |    9944 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     242    |     324    |    1373 K  |    1373 K  |\n","|       from large pool |      17    |      92    |    1227 K  |    1227 K  |\n","|       from small pool |     225    |     237    |     145 K  |     145 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      94    |     173    |   12143 K  |   12143 K  |\n","|       from large pool |      23    |      72    |    8191 K  |    8191 K  |\n","|       from small pool |      71    |     118    |    3952 K  |    3952 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:89/8961 batch_size:175\n","Next token prediction. step:119/193 batch:89/8961 epoch:2/10\n","full seq: The opposition Democratic Party of Serbia (DSS) said it is now clear that by claiming Kosovo and the EU integration are separate processes, Djelic deceived the Serbian public for years.Ģġġġġġġġ\n","pref seq: The opposition Democratic Party of Serbia (DSS) said it is now clear that by claiming Kosovo and the EU integration are\n","next tok:                                                                                                                        \n","pred tok:                                                                                                                       ,\n","Completed batch.\n","epoch:2/10 batch:89/8961 batch_size:175 loss:1.61130690574646 time_for_batch_instance:203.4398272037506 total_batch_time:20780.718095064163 running_batch_average:233.49121455128272\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 672004 KiB |  12748 MiB |    909 TiB |    909 TiB |\n","|       from large pool | 217398 KiB |  12313 MiB |    907 TiB |    907 TiB |\n","|       from small pool | 454606 KiB |    468 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 672004 KiB |  12748 MiB |    909 TiB |    909 TiB |\n","|       from large pool | 217398 KiB |  12313 MiB |    907 TiB |    907 TiB |\n","|       from small pool | 454606 KiB |    468 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  12705 MiB |    907 TiB |    907 TiB |\n","|       from large pool | 213248 KiB |  12274 MiB |    905 TiB |    905 TiB |\n","|       from small pool | 450193 KiB |    463 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1894 MiB |  13344 MiB | 217324 GiB | 217322 GiB |\n","|       from large pool |   1446 MiB |  12880 MiB | 217036 GiB | 217035 GiB |\n","|       from small pool |    448 MiB |    474 MiB |    287 GiB |    287 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1237 MiB |   1655 MiB | 308393 GiB | 308391 GiB |\n","|       from large pool |   1233 MiB |   1651 MiB | 306487 GiB | 306485 GiB |\n","|       from small pool |      4 MiB |     21 MiB |   1905 GiB |   1905 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   25557 K  |   25539 K  |\n","|       from large pool |      98    |     263    |   15495 K  |   15495 K  |\n","|       from small pool |   18777    |   18924    |   10062 K  |   10043 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   25557 K  |   25539 K  |\n","|       from large pool |      98    |     263    |   15495 K  |   15495 K  |\n","|       from small pool |   18777    |   18924    |   10062 K  |   10043 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     242    |     323    |    1387 K  |    1386 K  |\n","|       from large pool |      18    |      91    |    1239 K  |    1239 K  |\n","|       from small pool |     224    |     237    |     147 K  |     146 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      86    |     145    |   12253 K  |   12253 K  |\n","|       from large pool |      22    |      44    |    8261 K  |    8261 K  |\n","|       from small pool |      64    |     119    |    3991 K  |    3991 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:90/8961 batch_size:175\n","Next token prediction. step:103/192 batch:90/8961 epoch:2/10\n","full seq: \"However, it will not affect Belgrade's EU candidacy, because the candidacy depends on the dialogue with Pristina, i.e. primarily on the agreement on Pristina's regional representation.Ģġġġġġġ\n","pref seq: \"However, it will not affect Belgrade's EU candidacy, because the candidacy depends on the dialogue wit\n","next tok:                                                                                                       h\n","pred tok:                                                                                                       ,\n","Completed batch.\n","epoch:2/10 batch:90/8961 batch_size:175 loss:0.9695286154747009 time_for_batch_instance:201.46314024925232 total_batch_time:20982.181235313416 running_batch_average:233.13534705903794\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 669815 KiB |  12656 MiB |    916 TiB |    916 TiB |\n","|       from large pool | 215209 KiB |  12221 MiB |    915 TiB |    915 TiB |\n","|       from small pool | 454606 KiB |    468 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 669815 KiB |  12656 MiB |    916 TiB |    916 TiB |\n","|       from large pool | 215209 KiB |  12221 MiB |    915 TiB |    915 TiB |\n","|       from small pool | 454606 KiB |    468 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  12642 MiB |    914 TiB |    914 TiB |\n","|       from large pool | 213248 KiB |  12211 MiB |    913 TiB |    913 TiB |\n","|       from small pool | 450193 KiB |    463 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1714 MiB |  13260 MiB | 219122 GiB | 219121 GiB |\n","|       from large pool |   1264 MiB |  12796 MiB | 218832 GiB | 218831 GiB |\n","|       from small pool |    450 MiB |    474 MiB |    290 GiB |    289 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1059 MiB |   1877 MiB | 311174 GiB | 311173 GiB |\n","|       from large pool |   1053 MiB |   1873 MiB | 309250 GiB | 309249 GiB |\n","|       from small pool |      6 MiB |     22 MiB |   1924 GiB |   1924 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   25807 K  |   25788 K  |\n","|       from large pool |      98    |     263    |   15646 K  |   15646 K  |\n","|       from small pool |   18777    |   18924    |   10160 K  |   10142 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   25807 K  |   25788 K  |\n","|       from large pool |      98    |     263    |   15646 K  |   15646 K  |\n","|       from small pool |   18777    |   18924    |   10160 K  |   10142 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     240    |     322    |    1400 K  |    1400 K  |\n","|       from large pool |      15    |      90    |    1251 K  |    1251 K  |\n","|       from small pool |     225    |     237    |     148 K  |     148 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      88    |     156    |   12382 K  |   12382 K  |\n","|       from large pool |      19    |      55    |    8351 K  |    8351 K  |\n","|       from small pool |      69    |     119    |    4031 K  |    4031 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:91/8961 batch_size:175\n","Next token prediction. step:128/191 batch:91/8961 epoch:2/10\n","full seq: Europe's biggest war crimes case since the post-World War II trial in Nuremberg opened at the International Criminal Tribunal for the former Yugoslavia (ICTY) on February 12th, 2002.Ģġġġġġġġġ\n","pref seq: Europe's biggest war crimes case since the post-World War II trial in Nuremberg opened at the International Criminal Tribunal fo\n","next tok:                                                                                                                                r\n","pred tok:                                                                                                                                ,\n","Completed batch.\n","epoch:2/10 batch:91/8961 batch_size:175 loss:1.169693112373352 time_for_batch_instance:200.47101616859436 total_batch_time:21182.65225148201 running_batch_average:232.77639836793418\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 669642 KiB |  12567 MiB |    924 TiB |    924 TiB |\n","|       from large pool | 215036 KiB |  12131 MiB |    922 TiB |    922 TiB |\n","|       from small pool | 454606 KiB |    468 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 669642 KiB |  12567 MiB |    924 TiB |    924 TiB |\n","|       from large pool | 215036 KiB |  12131 MiB |    922 TiB |    922 TiB |\n","|       from small pool | 454606 KiB |    468 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  12534 MiB |    922 TiB |    922 TiB |\n","|       from large pool | 213248 KiB |  12103 MiB |    920 TiB |    920 TiB |\n","|       from small pool | 450193 KiB |    463 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1684 MiB |  13182 MiB | 220924 GiB | 220922 GiB |\n","|       from large pool |   1234 MiB |  12718 MiB | 220631 GiB | 220630 GiB |\n","|       from small pool |    450 MiB |    474 MiB |    292 GiB |    292 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1030 MiB |   1729 MiB | 313804 GiB | 313803 GiB |\n","|       from large pool |   1024 MiB |   1724 MiB | 311861 GiB | 311860 GiB |\n","|       from small pool |      6 MiB |     20 MiB |   1943 GiB |   1943 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   26055 K  |   26036 K  |\n","|       from large pool |      98    |     263    |   15796 K  |   15796 K  |\n","|       from small pool |   18777    |   18924    |   10259 K  |   10240 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   26055 K  |   26036 K  |\n","|       from large pool |      98    |     263    |   15796 K  |   15796 K  |\n","|       from small pool |   18777    |   18924    |   10259 K  |   10240 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     239    |     322    |    1413 K  |    1413 K  |\n","|       from large pool |      14    |      89    |    1263 K  |    1263 K  |\n","|       from small pool |     225    |     237    |     149 K  |     149 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      88    |     145    |   12503 K  |   12503 K  |\n","|       from large pool |      19    |      43    |    8433 K  |    8433 K  |\n","|       from small pool |      69    |     119    |    4070 K  |    4070 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:92/8961 batch_size:175\n","Next token prediction. step:64/191 batch:92/8961 epoch:2/10\n","full seq: According to studies, there are about 25,000 heroin consumers in Bucharest -- a city with a population of 2 million -- and at least a similar number in the rest of the country. [File]Ģġġġġġġġ\n","pref seq: According to studies, there are about 25,000 heroin consumers in\n","next tok:                                                                 \n","pred tok:                                                                ,\n","Completed batch.\n","epoch:2/10 batch:92/8961 batch_size:175 loss:0.9615994095802307 time_for_batch_instance:200.59306025505066 total_batch_time:21383.24531173706 running_batch_average:232.42657947540283\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 669642 KiB |  12567 MiB |    932 TiB |    932 TiB |\n","|       from large pool | 215036 KiB |  12131 MiB |    930 TiB |    930 TiB |\n","|       from small pool | 454606 KiB |    468 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 669642 KiB |  12567 MiB |    932 TiB |    932 TiB |\n","|       from large pool | 215036 KiB |  12131 MiB |    930 TiB |    930 TiB |\n","|       from small pool | 454606 KiB |    468 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  12534 MiB |    930 TiB |    930 TiB |\n","|       from large pool | 213248 KiB |  12103 MiB |    928 TiB |    928 TiB |\n","|       from small pool | 450193 KiB |    463 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1684 MiB |  13182 MiB | 222726 GiB | 222725 GiB |\n","|       from large pool |   1234 MiB |  12718 MiB | 222431 GiB | 222429 GiB |\n","|       from small pool |    450 MiB |    474 MiB |    295 GiB |    295 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1030 MiB |   1729 MiB | 316428 GiB | 316427 GiB |\n","|       from large pool |   1024 MiB |   1724 MiB | 314466 GiB | 314465 GiB |\n","|       from small pool |      6 MiB |     20 MiB |   1961 GiB |   1961 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   26304 K  |   26285 K  |\n","|       from large pool |      98    |     263    |   15946 K  |   15946 K  |\n","|       from small pool |   18777    |   18924    |   10357 K  |   10338 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   26304 K  |   26285 K  |\n","|       from large pool |      98    |     263    |   15946 K  |   15946 K  |\n","|       from small pool |   18777    |   18924    |   10357 K  |   10338 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     239    |     322    |    1427 K  |    1427 K  |\n","|       from large pool |      14    |      89    |    1276 K  |    1275 K  |\n","|       from small pool |     225    |     237    |     151 K  |     151 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      88    |     145    |   12623 K  |   12623 K  |\n","|       from large pool |      19    |      43    |    8514 K  |    8514 K  |\n","|       from small pool |      69    |     119    |    4109 K  |    4109 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:93/8961 batch_size:175\n","Next token prediction. step:42/190 batch:93/8961 epoch:2/10\n","full seq: Turkish State Minister Faruk Celik was in Pristina on Monday (August 10th) to attend commemorations of the 620th anniversary of the death of Sultan Murad I in the Battle of Kosovo.Ģġġġġġġġġġ\n","pref seq: Turkish State Minister Faruk Celik was in \n","next tok:                                          P\n","pred tok:                                          w\n","Completed batch.\n","epoch:2/10 batch:93/8961 batch_size:175 loss:3.115657091140747 time_for_batch_instance:199.31421160697937 total_batch_time:21582.55952334404 running_batch_average:232.0705325090757\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 668731 KiB |  12498 MiB |    939 TiB |    939 TiB |\n","|       from large pool | 214125 KiB |  12063 MiB |    937 TiB |    937 TiB |\n","|       from small pool | 454606 KiB |    468 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 668731 KiB |  12498 MiB |    939 TiB |    939 TiB |\n","|       from large pool | 214125 KiB |  12063 MiB |    937 TiB |    937 TiB |\n","|       from small pool | 454606 KiB |    468 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  12472 MiB |    937 TiB |    937 TiB |\n","|       from large pool | 213248 KiB |  12041 MiB |    935 TiB |    935 TiB |\n","|       from small pool | 450193 KiB |    463 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1416 MiB |  13124 MiB | 224488 GiB | 224486 GiB |\n","|       from large pool |    968 MiB |  12660 MiB | 224189 GiB | 224188 GiB |\n","|       from small pool |    448 MiB |    474 MiB |    298 GiB |    297 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 781252 KiB |   1744 MiB | 319116 GiB | 319115 GiB |\n","|       from large pool | 777106 KiB |   1739 MiB | 317136 GiB | 317135 GiB |\n","|       from small pool |   4146 KiB |     20 MiB |   1979 GiB |   1979 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   26551 K  |   26532 K  |\n","|       from large pool |      98    |     263    |   16096 K  |   16095 K  |\n","|       from small pool |   18777    |   18924    |   10454 K  |   10436 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   26551 K  |   26532 K  |\n","|       from large pool |      98    |     263    |   16096 K  |   16095 K  |\n","|       from small pool |   18777    |   18924    |   10454 K  |   10436 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     237    |     322    |    1440 K  |    1440 K  |\n","|       from large pool |      13    |      89    |    1287 K  |    1287 K  |\n","|       from small pool |     224    |     237    |     152 K  |     152 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      84    |     148    |   12747 K  |   12747 K  |\n","|       from large pool |      17    |      47    |    8599 K  |    8599 K  |\n","|       from small pool |      67    |     118    |    4147 K  |    4147 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:94/8961 batch_size:175\n","Completed batch.\n","epoch:2/10 batch:94/8961 batch_size:175 loss:2.541964292526245 time_for_batch_instance:200.6742033958435 total_batch_time:21783.233726739883 running_batch_average:231.7365290078711\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 668731 KiB |  12498 MiB |    947 TiB |    947 TiB |\n","|       from large pool | 214125 KiB |  12063 MiB |    945 TiB |    945 TiB |\n","|       from small pool | 454606 KiB |    468 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 668731 KiB |  12498 MiB |    947 TiB |    947 TiB |\n","|       from large pool | 214125 KiB |  12063 MiB |    945 TiB |    945 TiB |\n","|       from small pool | 454606 KiB |    468 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  12472 MiB |    945 TiB |    945 TiB |\n","|       from large pool | 213248 KiB |  12041 MiB |    943 TiB |    943 TiB |\n","|       from small pool | 450193 KiB |    463 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1452 MiB |  13126 MiB | 226272 GiB | 226271 GiB |\n","|       from large pool |   1004 MiB |  12662 MiB | 225971 GiB | 225970 GiB |\n","|       from small pool |    448 MiB |    474 MiB |    301 GiB |    300 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |    798 MiB |   1790 MiB | 321779 GiB | 321778 GiB |\n","|       from large pool |    794 MiB |   1785 MiB | 319780 GiB | 319780 GiB |\n","|       from small pool |      4 MiB |     23 MiB |   1998 GiB |   1998 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   26797 K  |   26779 K  |\n","|       from large pool |      98    |     263    |   16245 K  |   16245 K  |\n","|       from small pool |   18777    |   18924    |   10552 K  |   10533 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   26797 K  |   26779 K  |\n","|       from large pool |      98    |     263    |   16245 K  |   16245 K  |\n","|       from small pool |   18777    |   18924    |   10552 K  |   10533 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     239    |     323    |    1454 K  |    1453 K  |\n","|       from large pool |      15    |      90    |    1299 K  |    1299 K  |\n","|       from small pool |     224    |     237    |     154 K  |     153 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      88    |     150    |   12869 K  |   12869 K  |\n","|       from large pool |      21    |      49    |    8683 K  |    8683 K  |\n","|       from small pool |      67    |     118    |    4186 K  |    4186 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:95/8961 batch_size:175\n","Next token prediction. step:152/190 batch:95/8961 epoch:2/10\n","full seq: (AP, Cyprus Mail, Famagusta Gazette - 15/01/10; Cyprus Mail, Sofia Echo, International Press Institute - 14/01/10; AP, FT - 13/01/10; AP, AFP, BBC - 12/01/10; Reuters, DPA - 11/01/10)Ģġġġġġġ\n","pref seq: (AP, Cyprus Mail, Famagusta Gazette - 15/01/10; Cyprus Mail, Sofia Echo, International Press Institute - 14/01/10; AP, FT - 13/01/10; AP, AFP, BBC - 12/\n","next tok:                                                                                                                                                        0\n","pred tok:                                                                                                                                                        ,\n","Completed batch.\n","epoch:2/10 batch:95/8961 batch_size:175 loss:0.9055786728858948 time_for_batch_instance:199.82922983169556 total_batch_time:21983.06295657158 running_batch_average:231.40066270075346\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 668844 KiB |  12498 MiB |    954 TiB |    954 TiB |\n","|       from large pool | 214238 KiB |  12063 MiB |    952 TiB |    952 TiB |\n","|       from small pool | 454606 KiB |    468 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 668844 KiB |  12498 MiB |    954 TiB |    954 TiB |\n","|       from large pool | 214238 KiB |  12063 MiB |    952 TiB |    952 TiB |\n","|       from small pool | 454606 KiB |    468 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  12472 MiB |    952 TiB |    952 TiB |\n","|       from large pool | 213248 KiB |  12041 MiB |    950 TiB |    950 TiB |\n","|       from small pool | 450193 KiB |    463 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1412 MiB |  13120 MiB | 228066 GiB | 228065 GiB |\n","|       from large pool |    964 MiB |  12656 MiB | 227762 GiB | 227761 GiB |\n","|       from small pool |    448 MiB |    474 MiB |    303 GiB |    303 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 777043 KiB |   1540 MiB | 324411 GiB | 324410 GiB |\n","|       from large pool | 772897 KiB |   1536 MiB | 322394 GiB | 322394 GiB |\n","|       from small pool |   4146 KiB |     20 MiB |   2016 GiB |   2016 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   27044 K  |   27026 K  |\n","|       from large pool |      98    |     263    |   16394 K  |   16394 K  |\n","|       from small pool |   18777    |   18924    |   10650 K  |   10631 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   27044 K  |   27026 K  |\n","|       from large pool |      98    |     263    |   16394 K  |   16394 K  |\n","|       from small pool |   18777    |   18924    |   10650 K  |   10631 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     236    |     321    |    1467 K  |    1467 K  |\n","|       from large pool |      12    |      88    |    1312 K  |    1312 K  |\n","|       from small pool |     224    |     237    |     155 K  |     155 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      85    |     149    |   12993 K  |   12993 K  |\n","|       from large pool |      18    |      48    |    8768 K  |    8768 K  |\n","|       from small pool |      67    |     118    |    4225 K  |    4225 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:96/8961 batch_size:175\n","Next token prediction. step:153/189 batch:96/8961 epoch:2/10\n","full seq: (CNN, BBC, The New York Times, USA Today, Sky News, RFE/RL, VOA, Guardian, Zaman, Hurriyet, B92, Tanjug, The Sofia Echo, Sofia News Agency, Dnevnik.bg, Trend News Agency - 02/05/11)Ģġġġġġġġ\n","pref seq: (CNN, BBC, The New York Times, USA Today, Sky News, RFE/RL, VOA, Guardian, Zaman, Hurriyet, B92, Tanjug, The Sofia Echo, Sofia News Agency, Dnevnik.bg, T\n","next tok:                                                                                                                                                         r\n","pred tok:                                                                                                                                                         ,\n","Completed batch.\n","epoch:2/10 batch:96/8961 batch_size:175 loss:1.4369087219238281 time_for_batch_instance:199.34714818000793 total_batch_time:22182.410104751587 running_batch_average:231.0667719244957\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 669258 KiB |  12420 MiB |    962 TiB |    962 TiB |\n","|       from large pool | 214652 KiB |  11984 MiB |    960 TiB |    960 TiB |\n","|       from small pool | 454606 KiB |    468 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 669258 KiB |  12420 MiB |    962 TiB |    962 TiB |\n","|       from large pool | 214652 KiB |  11984 MiB |    960 TiB |    960 TiB |\n","|       from small pool | 454606 KiB |    468 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  12409 MiB |    960 TiB |    960 TiB |\n","|       from large pool | 213248 KiB |  11978 MiB |    958 TiB |    958 TiB |\n","|       from small pool | 450193 KiB |    463 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1870 MiB |  13054 MiB | 229840 GiB | 229838 GiB |\n","|       from large pool |   1422 MiB |  12588 MiB | 229533 GiB | 229532 GiB |\n","|       from small pool |    448 MiB |    474 MiB |    306 GiB |    305 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1216 MiB |   1723 MiB | 327085 GiB | 327084 GiB |\n","|       from large pool |   1212 MiB |   1718 MiB | 325050 GiB | 325049 GiB |\n","|       from small pool |      4 MiB |     20 MiB |   2034 GiB |   2034 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   27290 K  |   27271 K  |\n","|       from large pool |      98    |     263    |   16543 K  |   16542 K  |\n","|       from small pool |   18777    |   18924    |   10747 K  |   10728 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   27290 K  |   27271 K  |\n","|       from large pool |      98    |     263    |   16543 K  |   16542 K  |\n","|       from small pool |   18777    |   18924    |   10747 K  |   10728 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     241    |     322    |    1480 K  |    1480 K  |\n","|       from large pool |      17    |      90    |    1324 K  |    1324 K  |\n","|       from small pool |     224    |     237    |     156 K  |     156 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      87    |     179    |   13133 K  |   13133 K  |\n","|       from large pool |      20    |      77    |    8870 K  |    8870 K  |\n","|       from small pool |      67    |     118    |    4263 K  |    4263 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:97/8961 batch_size:175\n","Next token prediction. step:176/188 batch:97/8961 epoch:2/10\n","full seq: The ruling GERB party, however, continues to insist that the difficulties encountered in the election process were due to a lack of experience in holding two votes simultaneously.Ģġġġġġġġġ\n","pref seq: The ruling GERB party, however, continues to insist that the difficulties encountered in the election process were due to a lack of experience in holding two votes simultaneous\n","next tok:                                                                                                                                                                                l\n","pred tok:                                                                                                                                                                                ġ\n","Completed batch.\n","epoch:2/10 batch:97/8961 batch_size:175 loss:1.6735198497772217 time_for_batch_instance:197.944082736969 total_batch_time:22380.354187488556 running_batch_average:230.72530090194388\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 670116 KiB |  12388 MiB |    969 TiB |    969 TiB |\n","|       from large pool | 215510 KiB |  11952 MiB |    967 TiB |    967 TiB |\n","|       from small pool | 454606 KiB |    468 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 670116 KiB |  12388 MiB |    969 TiB |    969 TiB |\n","|       from large pool | 215510 KiB |  11952 MiB |    967 TiB |    967 TiB |\n","|       from small pool | 454606 KiB |    468 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  12346 MiB |    967 TiB |    967 TiB |\n","|       from large pool | 213248 KiB |  11915 MiB |    965 TiB |    965 TiB |\n","|       from small pool | 450193 KiB |    463 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1860 MiB |  12992 MiB | 231593 GiB | 231591 GiB |\n","|       from large pool |   1410 MiB |  12526 MiB | 231284 GiB | 231283 GiB |\n","|       from small pool |    450 MiB |    474 MiB |    309 GiB |    308 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1205 MiB |   1662 MiB | 329754 GiB | 329753 GiB |\n","|       from large pool |   1199 MiB |   1657 MiB | 327701 GiB | 327700 GiB |\n","|       from small pool |      6 MiB |     20 MiB |   2053 GiB |   2053 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   27534 K  |   27515 K  |\n","|       from large pool |      98    |     263    |   16690 K  |   16690 K  |\n","|       from small pool |   18777    |   18924    |   10844 K  |   10825 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   27534 K  |   27515 K  |\n","|       from large pool |      98    |     263    |   16690 K  |   16690 K  |\n","|       from small pool |   18777    |   18924    |   10844 K  |   10825 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     242    |     322    |    1494 K  |    1494 K  |\n","|       from large pool |      17    |      90    |    1336 K  |    1336 K  |\n","|       from small pool |     225    |     237    |     158 K  |     157 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      94    |     156    |   13266 K  |   13265 K  |\n","|       from large pool |      22    |      54    |    8964 K  |    8964 K  |\n","|       from small pool |      72    |     118    |    4301 K  |    4301 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:98/8961 batch_size:175\n","Next token prediction. step:48/188 batch:98/8961 epoch:2/10\n","full seq: Getting 90% of its gas supply from Russia, Serbia hopes that its inclusion in the South Stream project will result in cheaper power, thus paving the way for faster economic growth.Ģġġġġġġġ\n","pref seq: Getting 90% of its gas supply from Russia, Serbi\n","next tok:                                                a\n","pred tok:                                                s\n","Completed batch.\n","epoch:2/10 batch:98/8961 batch_size:175 loss:2.11833119392395 time_for_batch_instance:197.5085780620575 total_batch_time:22577.862765550613 running_batch_average:230.38635475051646\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 669800 KiB |  12388 MiB |    977 TiB |    977 TiB |\n","|       from large pool | 215194 KiB |  11952 MiB |    975 TiB |    975 TiB |\n","|       from small pool | 454606 KiB |    468 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 669800 KiB |  12388 MiB |    977 TiB |    977 TiB |\n","|       from large pool | 215194 KiB |  11952 MiB |    975 TiB |    975 TiB |\n","|       from small pool | 454606 KiB |    468 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  12346 MiB |    974 TiB |    974 TiB |\n","|       from large pool | 213248 KiB |  11915 MiB |    972 TiB |    972 TiB |\n","|       from small pool | 450193 KiB |    463 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1802 MiB |  13000 MiB | 233350 GiB | 233348 GiB |\n","|       from large pool |   1352 MiB |  12534 MiB | 233038 GiB | 233037 GiB |\n","|       from small pool |    450 MiB |    474 MiB |    311 GiB |    311 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1147 MiB |   1712 MiB | 332444 GiB | 332443 GiB |\n","|       from large pool |   1141 MiB |   1707 MiB | 330373 GiB | 330372 GiB |\n","|       from small pool |      6 MiB |     20 MiB |   2071 GiB |   2071 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   27779 K  |   27760 K  |\n","|       from large pool |      98    |     263    |   16838 K  |   16838 K  |\n","|       from small pool |   18777    |   18924    |   10940 K  |   10921 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   27779 K  |   27760 K  |\n","|       from large pool |      98    |     263    |   16838 K  |   16838 K  |\n","|       from small pool |   18777    |   18924    |   10940 K  |   10921 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     241    |     322    |    1507 K  |    1507 K  |\n","|       from large pool |      16    |      90    |    1348 K  |    1348 K  |\n","|       from small pool |     225    |     237    |     159 K  |     159 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      92    |     156    |   13397 K  |   13397 K  |\n","|       from large pool |      20    |      54    |    9057 K  |    9057 K  |\n","|       from small pool |      72    |     118    |    4339 K  |    4339 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:99/8961 batch_size:175\n","Next token prediction. step:77/188 batch:99/8961 epoch:2/10\n","full seq: Branimir Glavas, a parliamentary representative from the Croatian region of Slavonia, is the highest-ranking politician in the country to be officially investigated for war crimes.Ģġġġġġġġ\n","pref seq: Branimir Glavas, a parliamentary representative from the Croatian region of S\n","next tok:                                                                             l\n","pred tok:                                                                             C\n","Completed batch.\n","epoch:2/10 batch:99/8961 batch_size:175 loss:2.7521307468414307 time_for_batch_instance:197.49547290802002 total_batch_time:22775.358238458633 running_batch_average:230.0541236207943\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 669800 KiB |  12388 MiB |    984 TiB |    984 TiB |\n","|       from large pool | 215194 KiB |  11952 MiB |    982 TiB |    982 TiB |\n","|       from small pool | 454606 KiB |    468 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 669800 KiB |  12388 MiB |    984 TiB |    984 TiB |\n","|       from large pool | 215194 KiB |  11952 MiB |    982 TiB |    982 TiB |\n","|       from small pool | 454606 KiB |    468 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  12346 MiB |    982 TiB |    982 TiB |\n","|       from large pool | 213248 KiB |  11915 MiB |    980 TiB |    980 TiB |\n","|       from small pool | 450193 KiB |    463 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1804 MiB |  13002 MiB | 235101 GiB | 235099 GiB |\n","|       from large pool |   1354 MiB |  12536 MiB | 234787 GiB | 234786 GiB |\n","|       from small pool |    450 MiB |    474 MiB |    314 GiB |    313 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1149 MiB |   1714 MiB | 335130 GiB | 335129 GiB |\n","|       from large pool |   1143 MiB |   1709 MiB | 333040 GiB | 333039 GiB |\n","|       from small pool |      6 MiB |     24 MiB |   2089 GiB |   2089 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   28023 K  |   28004 K  |\n","|       from large pool |      98    |     263    |   16986 K  |   16985 K  |\n","|       from small pool |   18777    |   18924    |   11037 K  |   11018 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   28023 K  |   28004 K  |\n","|       from large pool |      98    |     263    |   16986 K  |   16985 K  |\n","|       from small pool |   18777    |   18924    |   11037 K  |   11018 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     241    |     322    |    1521 K  |    1521 K  |\n","|       from large pool |      16    |      90    |    1360 K  |    1360 K  |\n","|       from small pool |     225    |     237    |     160 K  |     160 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      92    |     157    |   13529 K  |   13529 K  |\n","|       from large pool |      20    |      55    |    9151 K  |    9151 K  |\n","|       from small pool |      72    |     118    |    4377 K  |    4377 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:100/8961 batch_size:175\n","Next token prediction. step:157/187 batch:100/8961 epoch:2/10\n","full seq: A move by the municipal authorities in Serbia's northern city of Novi Sad to name two streets after two wartime commanders prompted a protest from the OSCE on Thursday (April 5th).Ģġġġġġġ\n","pref seq: A move by the municipal authorities in Serbia's northern city of Novi Sad to name two streets after two wartime commanders prompted a protest from the OSCE o\n","next tok:                                                                                                                                                             n\n","pred tok:                                                                                                                                                             ;\n","Completed batch.\n","epoch:2/10 batch:100/8961 batch_size:175 loss:1.0142250061035156 time_for_batch_instance:196.45303869247437 total_batch_time:22971.811277151108 running_batch_average:229.71811277151107\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 671585 KiB |  12309 MiB |    991 TiB |    991 TiB |\n","|       from large pool | 216979 KiB |  11874 MiB |    989 TiB |    989 TiB |\n","|       from small pool | 454606 KiB |    468 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 671585 KiB |  12309 MiB |    991 TiB |    991 TiB |\n","|       from large pool | 216979 KiB |  11874 MiB |    989 TiB |    989 TiB |\n","|       from small pool | 454606 KiB |    468 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  12284 MiB |    989 TiB |    989 TiB |\n","|       from large pool | 213248 KiB |  11853 MiB |    987 TiB |    987 TiB |\n","|       from small pool | 450193 KiB |    463 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1436 MiB |  12874 MiB | 236803 GiB | 236801 GiB |\n","|       from large pool |    988 MiB |  12412 MiB | 236486 GiB | 236485 GiB |\n","|       from small pool |    448 MiB |    472 MiB |    316 GiB |    316 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |    780 MiB |   1876 MiB | 337602 GiB | 337601 GiB |\n","|       from large pool |    776 MiB |   1873 MiB | 335491 GiB | 335490 GiB |\n","|       from small pool |      4 MiB |     20 MiB |   2110 GiB |   2110 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   28266 K  |   28247 K  |\n","|       from large pool |      98    |     263    |   17129 K  |   17129 K  |\n","|       from small pool |   18777    |   18924    |   11136 K  |   11118 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   28266 K  |   28247 K  |\n","|       from large pool |      98    |     263    |   17129 K  |   17129 K  |\n","|       from small pool |   18777    |   18924    |   11136 K  |   11118 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     238    |     320    |    1534 K  |    1534 K  |\n","|       from large pool |      14    |      89    |    1372 K  |    1372 K  |\n","|       from small pool |     224    |     236    |     162 K  |     162 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      78    |     138    |   13627 K  |   13627 K  |\n","|       from large pool |      14    |      41    |    9208 K  |    9207 K  |\n","|       from small pool |      64    |     113    |    4419 K  |    4419 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:101/8961 batch_size:175\n","Next token prediction. step:23/186 batch:101/8961 epoch:2/10\n","full seq: Tariceanu said his visit was meant to find concrete solutions -- applied jointly -- to prevent crimes, such as the one last week, which can affect ties between the two countries.Ģġġġġġġġ\n","pref seq: Tariceanu said his visi\n","next tok:                       t\n","pred tok:                       ;\n","Completed batch.\n","epoch:2/10 batch:101/8961 batch_size:175 loss:0.7434052228927612 time_for_batch_instance:195.7918028831482 total_batch_time:23167.603080034256 running_batch_average:229.38220871321045\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 668787 KiB |  12254 MiB |    999 TiB |    999 TiB |\n","|       from large pool | 214181 KiB |  11818 MiB |    997 TiB |    997 TiB |\n","|       from small pool | 454606 KiB |    467 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 668787 KiB |  12254 MiB |    999 TiB |    999 TiB |\n","|       from large pool | 214181 KiB |  11818 MiB |    997 TiB |    997 TiB |\n","|       from small pool | 454606 KiB |    467 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  12221 MiB |    996 TiB |    996 TiB |\n","|       from large pool | 213248 KiB |  11790 MiB |    994 TiB |    994 TiB |\n","|       from small pool | 450193 KiB |    463 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1914 MiB |  12854 MiB | 238520 GiB | 238519 GiB |\n","|       from large pool |   1466 MiB |  12390 MiB | 238201 GiB | 238199 GiB |\n","|       from small pool |    448 MiB |    472 MiB |    319 GiB |    319 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1260 MiB |   1711 MiB | 340019 GiB | 340018 GiB |\n","|       from large pool |   1256 MiB |   1706 MiB | 337887 GiB | 337886 GiB |\n","|       from small pool |      4 MiB |     19 MiB |   2131 GiB |   2131 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   28508 K  |   28489 K  |\n","|       from large pool |      98    |     263    |   17272 K  |   17272 K  |\n","|       from small pool |   18777    |   18924    |   11235 K  |   11217 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   28508 K  |   28489 K  |\n","|       from large pool |      98    |     263    |   17272 K  |   17272 K  |\n","|       from small pool |   18777    |   18924    |   11235 K  |   11217 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     238    |     321    |    1547 K  |    1547 K  |\n","|       from large pool |      14    |      89    |    1384 K  |    1384 K  |\n","|       from small pool |     224    |     236    |     163 K  |     163 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      82    |     159    |   13730 K  |   13730 K  |\n","|       from large pool |      15    |      57    |    9271 K  |    9271 K  |\n","|       from small pool |      67    |     118    |    4459 K  |    4458 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:102/8961 batch_size:175\n","Next token prediction. step:127/186 batch:102/8961 epoch:2/10\n","full seq: Albanian Foreign Affairs Minister Ilir Meta described the recent declarations as contradictory to the process of regional integration and co-existence of the two main communities.Ģġġġġġġ\n","pref seq: Albanian Foreign Affairs Minister Ilir Meta described the recent declarations as contradictory to the process of regional integ\n","next tok:                                                                                                                               r\n","pred tok:                                                                                                                               ,\n","Completed batch.\n","epoch:2/10 batch:102/8961 batch_size:175 loss:1.8631477355957031 time_for_batch_instance:196.38496804237366 total_batch_time:23363.98804807663 running_batch_average:229.05870635369246\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 668678 KiB |  12254 MiB |   1006 TiB |   1006 TiB |\n","|       from large pool | 214072 KiB |  11819 MiB |   1004 TiB |   1004 TiB |\n","|       from small pool | 454606 KiB |    467 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 668678 KiB |  12254 MiB |   1006 TiB |   1006 TiB |\n","|       from large pool | 214072 KiB |  11819 MiB |   1004 TiB |   1004 TiB |\n","|       from small pool | 454606 KiB |    467 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  12221 MiB |   1003 TiB |   1003 TiB |\n","|       from large pool | 213248 KiB |  11790 MiB |   1002 TiB |   1002 TiB |\n","|       from small pool | 450193 KiB |    463 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1904 MiB |  12856 MiB | 240241 GiB | 240239 GiB |\n","|       from large pool |   1456 MiB |  12392 MiB | 239919 GiB | 239917 GiB |\n","|       from small pool |    448 MiB |    472 MiB |    322 GiB |    321 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1250 MiB |   1699 MiB | 342431 GiB | 342430 GiB |\n","|       from large pool |   1246 MiB |   1694 MiB | 340278 GiB | 340277 GiB |\n","|       from small pool |      4 MiB |     21 MiB |   2152 GiB |   2152 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   28749 K  |   28730 K  |\n","|       from large pool |      98    |     263    |   17414 K  |   17414 K  |\n","|       from small pool |   18777    |   18924    |   11334 K  |   11316 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   28749 K  |   28730 K  |\n","|       from large pool |      98    |     263    |   17414 K  |   17414 K  |\n","|       from small pool |   18777    |   18924    |   11334 K  |   11316 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     238    |     322    |    1561 K  |    1561 K  |\n","|       from large pool |      14    |      90    |    1396 K  |    1396 K  |\n","|       from small pool |     224    |     236    |     165 K  |     164 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      81    |     159    |   13831 K  |   13831 K  |\n","|       from large pool |      14    |      58    |    9332 K  |    9332 K  |\n","|       from small pool |      67    |     118    |    4498 K  |    4498 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:103/8961 batch_size:175\n","Next token prediction. step:105/185 batch:103/8961 epoch:2/10\n","full seq: They weren't fleeing political persecution, rather, they were poor people who believe that in the richer Western European countries, life would be eased by government subsidies.Ģġġġġġġġ\n","pref seq: They weren't fleeing political persecution, rather, they were poor people who believe that in the richer \n","next tok:                                                                                                         W\n","pred tok:                                                                                                         ,\n","Completed batch.\n","epoch:2/10 batch:103/8961 batch_size:175 loss:1.5228683948516846 time_for_batch_instance:194.73354268074036 total_batch_time:23558.72159075737 running_batch_average:228.7254523374502\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 668890 KiB |  12179 MiB |   1013 TiB |   1013 TiB |\n","|       from large pool | 214284 KiB |  11743 MiB |   1011 TiB |   1011 TiB |\n","|       from small pool | 454606 KiB |    467 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 668890 KiB |  12179 MiB |   1013 TiB |   1013 TiB |\n","|       from large pool | 214284 KiB |  11743 MiB |   1011 TiB |   1011 TiB |\n","|       from small pool | 454606 KiB |    467 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  12158 MiB |   1011 TiB |   1011 TiB |\n","|       from large pool | 213248 KiB |  11727 MiB |   1009 TiB |   1009 TiB |\n","|       from small pool | 450193 KiB |    463 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2164 MiB |  12782 MiB | 241852 GiB | 241850 GiB |\n","|       from large pool |   1716 MiB |  12318 MiB | 241527 GiB | 241525 GiB |\n","|       from small pool |    448 MiB |    472 MiB |    325 GiB |    324 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1510 MiB |   2040 MiB | 344954 GiB | 344952 GiB |\n","|       from large pool |   1506 MiB |   2037 MiB | 342780 GiB | 342778 GiB |\n","|       from small pool |      4 MiB |     21 MiB |   2173 GiB |   2173 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   28990 K  |   28971 K  |\n","|       from large pool |      98    |     263    |   17556 K  |   17556 K  |\n","|       from small pool |   18777    |   18924    |   11433 K  |   11414 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   28990 K  |   28971 K  |\n","|       from large pool |      98    |     263    |   17556 K  |   17556 K  |\n","|       from small pool |   18777    |   18924    |   11433 K  |   11414 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     239    |     320    |    1573 K  |    1573 K  |\n","|       from large pool |      15    |      88    |    1407 K  |    1407 K  |\n","|       from small pool |     224    |     236    |     166 K  |     166 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      82    |     167    |   13941 K  |   13941 K  |\n","|       from large pool |      15    |      66    |    9402 K  |    9402 K  |\n","|       from small pool |      67    |     119    |    4539 K  |    4539 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:104/8961 batch_size:175\n","Next token prediction. step:157/185 batch:104/8961 epoch:2/10\n","full seq: Meeting with EU officials on Monday (17 July), Serbian Prime Minister Vojislav Kostunica presented an Action Plan for achieving full co-operation with the UN war crimes tribunal.Ģġġġġġġ\n","pref seq: Meeting with EU officials on Monday (17 July), Serbian Prime Minister Vojislav Kostunica presented an Action Plan for achieving full co-operation with the UN\n","next tok:                                                                                                                                                              \n","pred tok:                                                                                                                                                             ,\n","Completed batch.\n","epoch:2/10 batch:104/8961 batch_size:175 loss:1.6907981634140015 time_for_batch_instance:194.89253759384155 total_batch_time:23753.61412835121 running_batch_average:228.40013584953087\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 668235 KiB |  12235 MiB |   1020 TiB |   1020 TiB |\n","|       from large pool | 213629 KiB |  11800 MiB |   1018 TiB |   1018 TiB |\n","|       from small pool | 454606 KiB |    467 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 668235 KiB |  12235 MiB |   1020 TiB |   1020 TiB |\n","|       from large pool | 213629 KiB |  11800 MiB |   1018 TiB |   1018 TiB |\n","|       from small pool | 454606 KiB |    467 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  12202 MiB |   1018 TiB |   1018 TiB |\n","|       from large pool | 213248 KiB |  11771 MiB |   1016 TiB |   1016 TiB |\n","|       from small pool | 450193 KiB |    463 MiB |      1 TiB |      1 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1660 MiB |  12850 MiB | 243560 GiB | 243558 GiB |\n","|       from large pool |   1212 MiB |  12386 MiB | 243232 GiB | 243231 GiB |\n","|       from small pool |    448 MiB |    472 MiB |    327 GiB |    327 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1007 MiB |   1711 MiB | 347360 GiB | 347359 GiB |\n","|       from large pool |   1003 MiB |   1706 MiB | 345165 GiB | 345164 GiB |\n","|       from small pool |      4 MiB |     19 MiB |   2194 GiB |   2194 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   29230 K  |   29211 K  |\n","|       from large pool |      98    |     263    |   17698 K  |   17698 K  |\n","|       from small pool |   18777    |   18924    |   11531 K  |   11512 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   29230 K  |   29211 K  |\n","|       from large pool |      98    |     263    |   17698 K  |   17698 K  |\n","|       from small pool |   18777    |   18924    |   11531 K  |   11512 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     237    |     321    |    1587 K  |    1586 K  |\n","|       from large pool |      13    |      89    |    1419 K  |    1419 K  |\n","|       from small pool |     224    |     236    |     167 K  |     167 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      82    |     159    |   14044 K  |   14044 K  |\n","|       from large pool |      16    |      57    |    9465 K  |    9465 K  |\n","|       from small pool |      66    |     118    |    4579 K  |    4579 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:105/8961 batch_size:175\n","Next token prediction. step:79/184 batch:105/8961 epoch:2/10\n","full seq: Papandreou says he will begin by splitting the economy ministry into two divisions -- finance and economics -- and tasking financial experts with focusing on specific problems.Ģġġġġġġġ\n","pref seq: Papandreou says he will begin by splitting the economy ministry into two divisi\n","next tok:                                                                               o\n","pred tok:                                                                               C\n","Completed batch.\n","epoch:2/10 batch:105/8961 batch_size:175 loss:1.3460018634796143 time_for_batch_instance:194.12472224235535 total_batch_time:23947.738850593567 running_batch_average:228.07370333898635\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 668845 KiB |  12133 MiB |   1027 TiB |   1027 TiB |\n","|       from large pool | 214239 KiB |  11698 MiB |   1025 TiB |   1025 TiB |\n","|       from small pool | 454606 KiB |    467 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 668845 KiB |  12133 MiB |   1027 TiB |   1027 TiB |\n","|       from large pool | 214239 KiB |  11698 MiB |   1025 TiB |   1025 TiB |\n","|       from small pool | 454606 KiB |    467 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  12096 MiB |   1025 TiB |   1025 TiB |\n","|       from large pool | 213248 KiB |  11665 MiB |   1023 TiB |   1023 TiB |\n","|       from small pool | 450193 KiB |    463 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1396 MiB |  12698 MiB | 245203 GiB | 245201 GiB |\n","|       from large pool |    948 MiB |  12234 MiB | 244872 GiB | 244871 GiB |\n","|       from small pool |    448 MiB |    472 MiB |    330 GiB |    329 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 760658 KiB |   1771 MiB | 349938 GiB | 349937 GiB |\n","|       from large pool | 756512 KiB |   1767 MiB | 347722 GiB | 347721 GiB |\n","|       from small pool |   4146 KiB |     19 MiB |   2215 GiB |   2215 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   29469 K  |   29450 K  |\n","|       from large pool |      98    |     263    |   17840 K  |   17839 K  |\n","|       from small pool |   18777    |   18924    |   11629 K  |   11610 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   29469 K  |   29450 K  |\n","|       from large pool |      98    |     263    |   17840 K  |   17839 K  |\n","|       from small pool |   18777    |   18924    |   11629 K  |   11610 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     236    |     320    |    1600 K  |    1599 K  |\n","|       from large pool |      12    |      88    |    1431 K  |    1431 K  |\n","|       from small pool |     224    |     236    |     169 K  |     168 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      79    |     149    |   14149 K  |   14149 K  |\n","|       from large pool |      11    |      48    |    9530 K  |    9530 K  |\n","|       from small pool |      68    |     119    |    4619 K  |    4619 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:106/8961 batch_size:175\n","Next token prediction. step:89/184 batch:106/8961 epoch:2/10\n","full seq: \"We have arrived at a point where we are tired of negotiating and need to make decisions,\" Unity Team Veton Surroi told a group in Vienna Saturday (October 27th). [Getty Images]Ģġġġġġġ\n","pref seq: \"We have arrived at a point where we are tired of negotiating and need to make decisions,\n","next tok:                                                                                         \"\n","pred tok:                                                                                         ,\n","Completed batch.\n","epoch:2/10 batch:106/8961 batch_size:175 loss:1.799871802330017 time_for_batch_instance:193.5416407585144 total_batch_time:24141.28049135208 running_batch_average:227.74792916369887\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 668703 KiB |  12132 MiB |   1034 TiB |   1034 TiB |\n","|       from large pool | 214097 KiB |  11697 MiB |   1032 TiB |   1032 TiB |\n","|       from small pool | 454606 KiB |    467 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 668703 KiB |  12132 MiB |   1034 TiB |   1034 TiB |\n","|       from large pool | 214097 KiB |  11697 MiB |   1032 TiB |   1032 TiB |\n","|       from small pool | 454606 KiB |    467 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  12096 MiB |   1032 TiB |   1032 TiB |\n","|       from large pool | 213248 KiB |  11665 MiB |   1030 TiB |   1030 TiB |\n","|       from small pool | 450193 KiB |    463 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1382 MiB |  12692 MiB | 246883 GiB | 246881 GiB |\n","|       from large pool |    934 MiB |  12228 MiB | 246550 GiB | 246549 GiB |\n","|       from small pool |    448 MiB |    472 MiB |    332 GiB |    332 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 746464 KiB |   1716 MiB | 352471 GiB | 352470 GiB |\n","|       from large pool | 742318 KiB |   1711 MiB | 350235 GiB | 350234 GiB |\n","|       from small pool |   4146 KiB |     21 MiB |   2236 GiB |   2236 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   29708 K  |   29689 K  |\n","|       from large pool |      98    |     263    |   17981 K  |   17981 K  |\n","|       from small pool |   18777    |   18924    |   11727 K  |   11708 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   29708 K  |   29689 K  |\n","|       from large pool |      98    |     263    |   17981 K  |   17981 K  |\n","|       from small pool |   18777    |   18924    |   11727 K  |   11708 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     235    |     320    |    1613 K  |    1613 K  |\n","|       from large pool |      11    |      89    |    1442 K  |    1442 K  |\n","|       from small pool |     224    |     236    |     170 K  |     170 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      81    |     150    |   14256 K  |   14256 K  |\n","|       from large pool |      13    |      48    |    9596 K  |    9596 K  |\n","|       from small pool |      68    |     119    |    4659 K  |    4659 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:107/8961 batch_size:175\n","Next token prediction. step:21/183 batch:107/8961 epoch:2/10\n","full seq: Cavic's statement came less than a month before NATO's summit in Istanbul, where BiH is hoping to be invited to join the Alliance's Partnership for Peace programme.Ģġġġġġġġġġġġġġġġġġġ\n","pref seq: Cavic's statement cam\n","next tok:                     e\n","pred tok:                     '\n","Completed batch.\n","epoch:2/10 batch:107/8961 batch_size:175 loss:2.1667137145996094 time_for_batch_instance:192.58973026275635 total_batch_time:24333.870221614838 running_batch_average:227.41934786555922\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 669381 KiB |  12054 MiB |   1041 TiB |   1041 TiB |\n","|       from large pool | 214775 KiB |  11619 MiB |   1039 TiB |   1039 TiB |\n","|       from small pool | 454606 KiB |    467 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 669381 KiB |  12054 MiB |   1041 TiB |   1041 TiB |\n","|       from large pool | 214775 KiB |  11619 MiB |   1039 TiB |   1039 TiB |\n","|       from small pool | 454606 KiB |    467 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  12033 MiB |   1039 TiB |   1039 TiB |\n","|       from large pool | 213248 KiB |  11602 MiB |   1037 TiB |   1037 TiB |\n","|       from small pool | 450193 KiB |    463 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1842 MiB |  12664 MiB | 248539 GiB | 248537 GiB |\n","|       from large pool |   1394 MiB |  12200 MiB | 248203 GiB | 248202 GiB |\n","|       from small pool |    448 MiB |    472 MiB |    335 GiB |    335 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1188 MiB |   1688 MiB | 354861 GiB | 354860 GiB |\n","|       from large pool |   1184 MiB |   1685 MiB | 352604 GiB | 352603 GiB |\n","|       from small pool |      4 MiB |     19 MiB |   2257 GiB |   2257 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   29946 K  |   29927 K  |\n","|       from large pool |      98    |     263    |   18121 K  |   18121 K  |\n","|       from small pool |   18777    |   18924    |   11824 K  |   11806 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   29946 K  |   29927 K  |\n","|       from large pool |      98    |     263    |   18121 K  |   18121 K  |\n","|       from small pool |   18777    |   18924    |   11824 K  |   11806 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     240    |     320    |    1626 K  |    1626 K  |\n","|       from large pool |      16    |      88    |    1454 K  |    1454 K  |\n","|       from small pool |     224    |     236    |     171 K  |     171 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      84    |     164    |   14363 K  |   14363 K  |\n","|       from large pool |      17    |      63    |    9664 K  |    9664 K  |\n","|       from small pool |      67    |     119    |    4699 K  |    4699 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:108/8961 batch_size:175\n","Next token prediction. step:176/183 batch:108/8961 epoch:2/10\n","full seq: President of the European Commission (EC) Romano Prodi is to finish his tenure in October, after which, rumour has it, he will be involved again on the Italian political scene.Ģġġġġġġ\n","pref seq: President of the European Commission (EC) Romano Prodi is to finish his tenure in October, after which, rumour has it, he will be involved again on the Italian political scene.\n","next tok:                                                                                                                                                                                Ģ\n","pred tok:                                                                                                                                                                                Ģ\n","Completed batch.\n","epoch:2/10 batch:108/8961 batch_size:175 loss:1.9059419631958008 time_for_batch_instance:192.70991826057434 total_batch_time:24526.580139875412 running_batch_average:227.09796425810566\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 669195 KiB |  12053 MiB |   1048 TiB |   1048 TiB |\n","|       from large pool | 214589 KiB |  11618 MiB |   1046 TiB |   1046 TiB |\n","|       from small pool | 454606 KiB |    467 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 669195 KiB |  12053 MiB |   1048 TiB |   1048 TiB |\n","|       from large pool | 214589 KiB |  11618 MiB |   1046 TiB |   1046 TiB |\n","|       from small pool | 454606 KiB |    467 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  12033 MiB |   1046 TiB |   1046 TiB |\n","|       from large pool | 213248 KiB |  11602 MiB |   1044 TiB |   1044 TiB |\n","|       from small pool | 450193 KiB |    463 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1834 MiB |  12664 MiB | 250195 GiB | 250193 GiB |\n","|       from large pool |   1386 MiB |  12200 MiB | 249857 GiB | 249856 GiB |\n","|       from small pool |    448 MiB |    472 MiB |    338 GiB |    337 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1180 MiB |   1681 MiB | 357246 GiB | 357245 GiB |\n","|       from large pool |   1176 MiB |   1678 MiB | 354968 GiB | 354967 GiB |\n","|       from small pool |      4 MiB |     19 MiB |   2278 GiB |   2278 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   30184 K  |   30165 K  |\n","|       from large pool |      98    |     263    |   18261 K  |   18261 K  |\n","|       from small pool |   18777    |   18924    |   11922 K  |   11903 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   30184 K  |   30165 K  |\n","|       from large pool |      98    |     263    |   18261 K  |   18261 K  |\n","|       from small pool |   18777    |   18924    |   11922 K  |   11903 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     240    |     321    |    1639 K  |    1639 K  |\n","|       from large pool |      16    |      89    |    1466 K  |    1466 K  |\n","|       from small pool |     224    |     236    |     173 K  |     172 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      84    |     165    |   14471 K  |   14471 K  |\n","|       from large pool |      17    |      64    |    9733 K  |    9733 K  |\n","|       from small pool |      67    |     119    |    4738 K  |    4738 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:109/8961 batch_size:175\n","Next token prediction. step:30/182 batch:109/8961 epoch:2/10\n","full seq: \"Audiences love Filminute,\" says the festival's executive director, John Ketchum. \"This year, the average rating for the entire collection is 4.4 (out of a possible 5 stars).Ģġġġġġġġ\n","pref seq: \"Audiences love Filminute,\" sa\n","next tok:                              y\n","pred tok:                              ,\n","Completed batch.\n","epoch:2/10 batch:109/8961 batch_size:175 loss:0.7431564927101135 time_for_batch_instance:190.80499625205994 total_batch_time:24717.385136127472 running_batch_average:226.76500124887588\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 670667 KiB |  11987 MiB |   1055 TiB |   1055 TiB |\n","|       from large pool | 216061 KiB |  11552 MiB |   1053 TiB |   1053 TiB |\n","|       from small pool | 454606 KiB |    467 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 670667 KiB |  11987 MiB |   1055 TiB |   1055 TiB |\n","|       from large pool | 216061 KiB |  11552 MiB |   1053 TiB |   1053 TiB |\n","|       from small pool | 454606 KiB |    467 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  11970 MiB |   1053 TiB |   1053 TiB |\n","|       from large pool | 213248 KiB |  11539 MiB |   1051 TiB |   1051 TiB |\n","|       from small pool | 450193 KiB |    463 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1826 MiB |  12604 MiB | 251796 GiB | 251795 GiB |\n","|       from large pool |   1378 MiB |  12142 MiB | 251456 GiB | 251454 GiB |\n","|       from small pool |    448 MiB |    472 MiB |    340 GiB |    340 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1171 MiB |   1779 MiB | 359686 GiB | 359685 GiB |\n","|       from large pool |   1167 MiB |   1775 MiB | 357387 GiB | 357386 GiB |\n","|       from small pool |      4 MiB |     21 MiB |   2298 GiB |   2298 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   30420 K  |   30401 K  |\n","|       from large pool |      98    |     263    |   18401 K  |   18401 K  |\n","|       from small pool |   18777    |   18924    |   12019 K  |   12000 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   30420 K  |   30401 K  |\n","|       from large pool |      98    |     263    |   18401 K  |   18401 K  |\n","|       from small pool |   18777    |   18924    |   12019 K  |   12000 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     239    |     319    |    1652 K  |    1651 K  |\n","|       from large pool |      15    |      88    |    1477 K  |    1477 K  |\n","|       from small pool |     224    |     236    |     174 K  |     174 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      81    |     160    |   14578 K  |   14578 K  |\n","|       from large pool |      16    |      59    |    9799 K  |    9799 K  |\n","|       from small pool |      65    |     117    |    4778 K  |    4778 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:110/8961 batch_size:175\n","Next token prediction. step:107/182 batch:110/8961 epoch:2/10\n","full seq: The largest Greek construction company, Aktor, submitted the lowest bid for building the third segment of the Thrace Highway, media in Athens reported on Wednesday (May 19th).Ģġġġġġġ\n","pref seq: The largest Greek construction company, Aktor, submitted the lowest bid for building the third segment of t\n","next tok:                                                                                                           h\n","pred tok:                                                                                                           ,\n","Completed batch.\n","epoch:2/10 batch:110/8961 batch_size:175 loss:1.0739572048187256 time_for_batch_instance:191.45742630958557 total_batch_time:24908.842562437057 running_batch_average:226.44402329488233\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 669765 KiB |  11947 MiB |   1062 TiB |   1062 TiB |\n","|       from large pool | 215159 KiB |  11512 MiB |   1060 TiB |   1060 TiB |\n","|       from small pool | 454606 KiB |    467 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 669765 KiB |  11947 MiB |   1062 TiB |   1062 TiB |\n","|       from large pool | 215159 KiB |  11512 MiB |   1060 TiB |   1060 TiB |\n","|       from small pool | 454606 KiB |    467 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  11926 MiB |   1060 TiB |   1060 TiB |\n","|       from large pool | 213248 KiB |  11495 MiB |   1058 TiB |   1058 TiB |\n","|       from small pool | 450193 KiB |    463 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1428 MiB |  12516 MiB | 253406 GiB | 253405 GiB |\n","|       from large pool |    980 MiB |  12054 MiB | 253063 GiB | 253062 GiB |\n","|       from small pool |    448 MiB |    472 MiB |    343 GiB |    342 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |    773 MiB |   1611 MiB | 362211 GiB | 362210 GiB |\n","|       from large pool |    769 MiB |   1606 MiB | 359892 GiB | 359891 GiB |\n","|       from small pool |      4 MiB |     19 MiB |   2319 GiB |   2319 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   30656 K  |   30638 K  |\n","|       from large pool |      98    |     263    |   18541 K  |   18540 K  |\n","|       from small pool |   18777    |   18924    |   12115 K  |   12097 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   30656 K  |   30638 K  |\n","|       from large pool |      98    |     263    |   18541 K  |   18540 K  |\n","|       from small pool |   18777    |   18924    |   12115 K  |   12097 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     238    |     320    |    1664 K  |    1664 K  |\n","|       from large pool |      14    |      89    |    1488 K  |    1488 K  |\n","|       from small pool |     224    |     236    |     175 K  |     175 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      77    |     151    |   14699 K  |   14699 K  |\n","|       from large pool |      12    |      49    |    9881 K  |    9881 K  |\n","|       from small pool |      65    |     119    |    4817 K  |    4817 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:111/8961 batch_size:175\n","Next token prediction. step:5/182 batch:111/8961 epoch:2/10\n","full seq: The newly founded Missing Persons Institute (MPI) unites Bosniak, Croat and Serb organisations, in the hopes of fostering inter-ethnic co-operation to find those still missing.Ģġġġġġ\n","pref seq: The n\n","next tok:     e\n","pred tok:     ,\n","Completed batch.\n","epoch:2/10 batch:111/8961 batch_size:175 loss:1.1116348505020142 time_for_batch_instance:191.17087244987488 total_batch_time:25100.013434886932 running_batch_average:226.12624716114354\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 669965 KiB |  12032 MiB |   1069 TiB |   1069 TiB |\n","|       from large pool | 215359 KiB |  11596 MiB |   1067 TiB |   1067 TiB |\n","|       from small pool | 454606 KiB |    467 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 669965 KiB |  12032 MiB |   1069 TiB |   1069 TiB |\n","|       from large pool | 215359 KiB |  11596 MiB |   1067 TiB |   1067 TiB |\n","|       from small pool | 454606 KiB |    467 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  12014 MiB |   1067 TiB |   1067 TiB |\n","|       from large pool | 213248 KiB |  11583 MiB |   1065 TiB |   1065 TiB |\n","|       from small pool | 450193 KiB |    463 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1716 MiB |  12650 MiB | 255062 GiB | 255060 GiB |\n","|       from large pool |   1268 MiB |  12186 MiB | 254716 GiB | 254714 GiB |\n","|       from small pool |    448 MiB |    472 MiB |    345 GiB |    345 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1061 MiB |   1600 MiB | 364600 GiB | 364599 GiB |\n","|       from large pool |   1057 MiB |   1596 MiB | 362260 GiB | 362259 GiB |\n","|       from small pool |      4 MiB |     22 MiB |   2340 GiB |   2340 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   30893 K  |   30874 K  |\n","|       from large pool |      98    |     263    |   18680 K  |   18680 K  |\n","|       from small pool |   18777    |   18924    |   12212 K  |   12193 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   30893 K  |   30874 K  |\n","|       from large pool |      98    |     263    |   18680 K  |   18680 K  |\n","|       from small pool |   18777    |   18924    |   12212 K  |   12193 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     238    |     320    |    1677 K  |    1677 K  |\n","|       from large pool |      14    |      88    |    1500 K  |    1500 K  |\n","|       from small pool |     224    |     236    |     177 K  |     176 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      85    |     164    |   14808 K  |   14808 K  |\n","|       from large pool |      16    |      63    |    9950 K  |    9950 K  |\n","|       from small pool |      69    |     119    |    4857 K  |    4857 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:112/8961 batch_size:175\n","Next token prediction. step:33/181 batch:112/8961 epoch:2/10\n","full seq: Just two days after the presidential election and the victory of pro-Western incumbent Boris Tadic, the Serbian government has entered its deepest political crisis so far.Ģġġġġġġġġġ\n","pref seq: Just two days after the president\n","next tok:                                 i\n","pred tok:                                 ,\n","Completed batch.\n","epoch:2/10 batch:112/8961 batch_size:175 loss:2.524458885192871 time_for_batch_instance:190.274427652359 total_batch_time:25290.28786253929 running_batch_average:225.8061416298151\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 671011 KiB |  11931 MiB |   1076 TiB |   1076 TiB |\n","|       from large pool | 216405 KiB |  11496 MiB |   1074 TiB |   1074 TiB |\n","|       from small pool | 454606 KiB |    467 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 671011 KiB |  11931 MiB |   1076 TiB |   1076 TiB |\n","|       from large pool | 216405 KiB |  11496 MiB |   1074 TiB |   1074 TiB |\n","|       from small pool | 454606 KiB |    467 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  11908 MiB |   1074 TiB |   1074 TiB |\n","|       from large pool | 213248 KiB |  11477 MiB |   1071 TiB |   1071 TiB |\n","|       from small pool | 450193 KiB |    463 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1420 MiB |  12516 MiB | 256676 GiB | 256675 GiB |\n","|       from large pool |    972 MiB |  12054 MiB | 256327 GiB | 256326 GiB |\n","|       from small pool |    448 MiB |    472 MiB |    348 GiB |    348 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 783069 KiB |   1774 MiB | 367035 GiB | 367034 GiB |\n","|       from large pool | 778923 KiB |   1771 MiB | 364674 GiB | 364674 GiB |\n","|       from small pool |   4146 KiB |     19 MiB |   2360 GiB |   2360 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   31128 K  |   31109 K  |\n","|       from large pool |      98    |     263    |   18819 K  |   18819 K  |\n","|       from small pool |   18777    |   18924    |   12308 K  |   12290 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   31128 K  |   31109 K  |\n","|       from large pool |      98    |     263    |   18819 K  |   18819 K  |\n","|       from small pool |   18777    |   18924    |   12308 K  |   12290 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     238    |     321    |    1690 K  |    1690 K  |\n","|       from large pool |      14    |      90    |    1511 K  |    1511 K  |\n","|       from small pool |     224    |     236    |     178 K  |     178 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      79    |     154    |   14929 K  |   14929 K  |\n","|       from large pool |      12    |      52    |   10033 K  |   10033 K  |\n","|       from small pool |      67    |     118    |    4896 K  |    4896 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:113/8961 batch_size:175\n","Next token prediction. step:59/181 batch:113/8961 epoch:2/10\n","full seq: In December, EU leaders gave the green light for opening membership negotiations with Croatia on 17 March, provided it co-operates fully with the ICTY and extradites Gotovina.Ģġġġġġ\n","pref seq: In December, EU leaders gave the green light for opening me\n","next tok:                                                           m\n","pred tok:                                                           ,\n","Completed batch.\n","epoch:2/10 batch:113/8961 batch_size:175 loss:2.0617716312408447 time_for_batch_instance:190.2729527950287 total_batch_time:25480.56081533432 running_batch_average:225.49168863127716\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 670038 KiB |  11931 MiB |   1083 TiB |   1083 TiB |\n","|       from large pool | 215432 KiB |  11496 MiB |   1081 TiB |   1081 TiB |\n","|       from small pool | 454606 KiB |    467 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 670038 KiB |  11931 MiB |   1083 TiB |   1083 TiB |\n","|       from large pool | 215432 KiB |  11496 MiB |   1081 TiB |   1081 TiB |\n","|       from small pool | 454606 KiB |    467 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  11908 MiB |   1080 TiB |   1080 TiB |\n","|       from large pool | 213248 KiB |  11477 MiB |   1078 TiB |   1078 TiB |\n","|       from small pool | 450193 KiB |    463 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1414 MiB |  12510 MiB | 258293 GiB | 258292 GiB |\n","|       from large pool |    966 MiB |  12048 MiB | 257942 GiB | 257941 GiB |\n","|       from small pool |    448 MiB |    472 MiB |    351 GiB |    350 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory | 777898 KiB |   1726 MiB | 369464 GiB | 369464 GiB |\n","|       from large pool | 773752 KiB |   1721 MiB | 367083 GiB | 367083 GiB |\n","|       from small pool |   4146 KiB |     19 MiB |   2381 GiB |   2381 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   31363 K  |   31344 K  |\n","|       from large pool |      98    |     263    |   18958 K  |   18958 K  |\n","|       from small pool |   18777    |   18924    |   12405 K  |   12386 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   31363 K  |   31344 K  |\n","|       from large pool |      98    |     263    |   18958 K  |   18958 K  |\n","|       from small pool |   18777    |   18924    |   12405 K  |   12386 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     237    |     320    |    1703 K  |    1703 K  |\n","|       from large pool |      13    |      89    |    1523 K  |    1523 K  |\n","|       from small pool |     224    |     236    |     179 K  |     179 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      81    |     154    |   15052 K  |   15052 K  |\n","|       from large pool |      14    |      52    |   10116 K  |   10116 K  |\n","|       from small pool |      67    |     119    |    4935 K  |    4935 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:114/8961 batch_size:175\n","Next token prediction. step:87/180 batch:114/8961 epoch:2/10\n","full seq: In its latest monitoring reports, the European Commission said Bulgaria and Romania have made enough progress to enter the EU as scheduled on January 1st, 2007.Ģġġġġġġġġġġġġġġġġġġġ\n","pref seq: In its latest monitoring reports, the European Commission said Bulgaria and Romania hav\n","next tok:                                                                                       e\n","pred tok:                                                                                       ,\n","Completed batch.\n","epoch:2/10 batch:114/8961 batch_size:175 loss:2.8586578369140625 time_for_batch_instance:188.66143012046814 total_batch_time:25669.22224545479 running_batch_average:225.1686161881999\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 670327 KiB |  11865 MiB |   1090 TiB |   1090 TiB |\n","|       from large pool | 215721 KiB |  11429 MiB |   1088 TiB |   1088 TiB |\n","|       from small pool | 454606 KiB |    467 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 670327 KiB |  11865 MiB |   1090 TiB |   1090 TiB |\n","|       from large pool | 215721 KiB |  11429 MiB |   1088 TiB |   1088 TiB |\n","|       from small pool | 454606 KiB |    467 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  11845 MiB |   1087 TiB |   1087 TiB |\n","|       from large pool | 213248 KiB |  11414 MiB |   1085 TiB |   1085 TiB |\n","|       from small pool | 450193 KiB |    463 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1904 MiB |  12484 MiB | 259897 GiB | 259895 GiB |\n","|       from large pool |   1456 MiB |  12022 MiB | 259543 GiB | 259542 GiB |\n","|       from small pool |    448 MiB |    472 MiB |    353 GiB |    353 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1249 MiB |   1718 MiB | 371847 GiB | 371846 GiB |\n","|       from large pool |   1245 MiB |   1715 MiB | 369446 GiB | 369445 GiB |\n","|       from small pool |      4 MiB |     19 MiB |   2401 GiB |   2401 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   31597 K  |   31578 K  |\n","|       from large pool |      98    |     263    |   19096 K  |   19096 K  |\n","|       from small pool |   18777    |   18924    |   12501 K  |   12482 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   31597 K  |   31578 K  |\n","|       from large pool |      98    |     263    |   19096 K  |   19096 K  |\n","|       from small pool |   18777    |   18924    |   12501 K  |   12482 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     239    |     320    |    1715 K  |    1715 K  |\n","|       from large pool |      15    |      89    |    1534 K  |    1534 K  |\n","|       from small pool |     224    |     236    |     181 K  |     180 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      83    |     176    |   15180 K  |   15180 K  |\n","|       from large pool |      16    |      74    |   10206 K  |   10206 K  |\n","|       from small pool |      67    |     119    |    4974 K  |    4974 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:115/8961 batch_size:175\n","Next token prediction. step:55/180 batch:115/8961 epoch:2/10\n","full seq: SETimes: Although there appears to be obvious tension within the coalition, how optimistic are you that the current LDK-PDK coalition will continue to function effectively?Ģġġġġġġġ\n","pref seq: SETimes: Although there appears to be obvious tension w\n","next tok:                                                       i\n","pred tok:                                                       k\n","Completed batch.\n","epoch:2/10 batch:115/8961 batch_size:175 loss:1.0093518495559692 time_for_batch_instance:189.38982272148132 total_batch_time:25858.61206817627 running_batch_average:224.85749624501105\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 670723 KiB |  11864 MiB |   1097 TiB |   1097 TiB |\n","|       from large pool | 216117 KiB |  11429 MiB |   1094 TiB |   1094 TiB |\n","|       from small pool | 454606 KiB |    467 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 670723 KiB |  11864 MiB |   1097 TiB |   1097 TiB |\n","|       from large pool | 216117 KiB |  11429 MiB |   1094 TiB |   1094 TiB |\n","|       from small pool | 454606 KiB |    467 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  11845 MiB |   1094 TiB |   1094 TiB |\n","|       from large pool | 213248 KiB |  11414 MiB |   1092 TiB |   1092 TiB |\n","|       from small pool | 450193 KiB |    463 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2162 MiB |  12486 MiB | 261501 GiB | 261499 GiB |\n","|       from large pool |   1714 MiB |  12024 MiB | 261145 GiB | 261143 GiB |\n","|       from small pool |    448 MiB |    472 MiB |    356 GiB |    355 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1506 MiB |   1727 MiB | 374290 GiB | 374289 GiB |\n","|       from large pool |   1502 MiB |   1724 MiB | 371868 GiB | 371867 GiB |\n","|       from small pool |      4 MiB |     19 MiB |   2421 GiB |   2421 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   31831 K  |   31812 K  |\n","|       from large pool |      98    |     263    |   19234 K  |   19234 K  |\n","|       from small pool |   18777    |   18924    |   12596 K  |   12578 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   31831 K  |   31812 K  |\n","|       from large pool |      98    |     263    |   19234 K  |   19234 K  |\n","|       from small pool |   18777    |   18924    |   12596 K  |   12578 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     241    |     320    |    1728 K  |    1728 K  |\n","|       from large pool |      17    |      89    |    1546 K  |    1546 K  |\n","|       from small pool |     224    |     236    |     182 K  |     182 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      84    |     177    |   15309 K  |   15309 K  |\n","|       from large pool |      17    |      75    |   10296 K  |   10296 K  |\n","|       from small pool |      67    |     119    |    5013 K  |    5012 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:116/8961 batch_size:175\n","Next token prediction. step:33/180 batch:116/8961 epoch:2/10\n","full seq: \"I am unemployed and have basic computer literacy, but it is mostly theoretical because I can access a computer only in an internet cafĠ,\" says Goran, a trainee from Skopje.Ģġġġġġġ\n","pref seq: \"I am unemployed and have basic c\n","next tok:                                 o\n","pred tok:                                 ,\n","Completed batch.\n","epoch:2/10 batch:116/8961 batch_size:175 loss:0.9526495933532715 time_for_batch_instance:189.2327139377594 total_batch_time:26047.84478211403 running_batch_average:224.55038605270715\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 670723 KiB |  11864 MiB |   1103 TiB |   1103 TiB |\n","|       from large pool | 216117 KiB |  11429 MiB |   1101 TiB |   1101 TiB |\n","|       from small pool | 454606 KiB |    467 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 670723 KiB |  11864 MiB |   1103 TiB |   1103 TiB |\n","|       from large pool | 216117 KiB |  11429 MiB |   1101 TiB |   1101 TiB |\n","|       from small pool | 454606 KiB |    467 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  11845 MiB |   1101 TiB |   1101 TiB |\n","|       from large pool | 213248 KiB |  11414 MiB |   1099 TiB |   1099 TiB |\n","|       from small pool | 450193 KiB |    463 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2162 MiB |  12486 MiB | 263110 GiB | 263108 GiB |\n","|       from large pool |   1714 MiB |  12024 MiB | 262751 GiB | 262749 GiB |\n","|       from small pool |    448 MiB |    472 MiB |    358 GiB |    358 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1506 MiB |   1727 MiB | 376738 GiB | 376736 GiB |\n","|       from large pool |   1502 MiB |   1724 MiB | 374295 GiB | 374294 GiB |\n","|       from small pool |      4 MiB |     19 MiB |   2442 GiB |   2442 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   32064 K  |   32045 K  |\n","|       from large pool |      98    |     263    |   19372 K  |   19372 K  |\n","|       from small pool |   18777    |   18924    |   12692 K  |   12673 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   32064 K  |   32045 K  |\n","|       from large pool |      98    |     263    |   19372 K  |   19372 K  |\n","|       from small pool |   18777    |   18924    |   12692 K  |   12673 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     241    |     320    |    1741 K  |    1741 K  |\n","|       from large pool |      17    |      89    |    1557 K  |    1557 K  |\n","|       from small pool |     224    |     236    |     183 K  |     183 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      84    |     177    |   15437 K  |   15437 K  |\n","|       from large pool |      17    |      75    |   10385 K  |   10385 K  |\n","|       from small pool |      67    |     119    |    5051 K  |    5051 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:117/8961 batch_size:175\n","Next token prediction. step:79/180 batch:117/8961 epoch:2/10\n","full seq: Croatia, Romania and Serbia agreed in Bucharest on Tuesday to establish a company that would develop a pan-European pipeline to transport Caspian oil to the European market.Ģġġġġġġ\n","pref seq: Croatia, Romania and Serbia agreed in Bucharest on Tuesday to establish a compa\n","next tok:                                                                               n\n","pred tok:                                                                               ;\n","Completed batch.\n","epoch:2/10 batch:117/8961 batch_size:175 loss:2.4111242294311523 time_for_batch_instance:189.5861747264862 total_batch_time:26237.430956840515 running_batch_average:224.25154663966254\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 670723 KiB |  11864 MiB |   1110 TiB |   1110 TiB |\n","|       from large pool | 216117 KiB |  11429 MiB |   1108 TiB |   1108 TiB |\n","|       from small pool | 454606 KiB |    467 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 670723 KiB |  11864 MiB |   1110 TiB |   1110 TiB |\n","|       from large pool | 216117 KiB |  11429 MiB |   1108 TiB |   1108 TiB |\n","|       from small pool | 454606 KiB |    467 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  11845 MiB |   1108 TiB |   1108 TiB |\n","|       from large pool | 213248 KiB |  11414 MiB |   1105 TiB |   1105 TiB |\n","|       from small pool | 450193 KiB |    463 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2162 MiB |  12486 MiB | 264719 GiB | 264717 GiB |\n","|       from large pool |   1714 MiB |  12024 MiB | 264357 GiB | 264356 GiB |\n","|       from small pool |    448 MiB |    472 MiB |    361 GiB |    360 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1506 MiB |   1727 MiB | 379181 GiB | 379179 GiB |\n","|       from large pool |   1502 MiB |   1724 MiB | 376718 GiB | 376717 GiB |\n","|       from small pool |      4 MiB |     19 MiB |   2462 GiB |   2462 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   32298 K  |   32279 K  |\n","|       from large pool |      98    |     263    |   19510 K  |   19510 K  |\n","|       from small pool |   18777    |   18924    |   12788 K  |   12769 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   32298 K  |   32279 K  |\n","|       from large pool |      98    |     263    |   19510 K  |   19510 K  |\n","|       from small pool |   18777    |   18924    |   12788 K  |   12769 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     241    |     320    |    1754 K  |    1753 K  |\n","|       from large pool |      17    |      89    |    1569 K  |    1569 K  |\n","|       from small pool |     224    |     236    |     185 K  |     184 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      84    |     177    |   15566 K  |   15566 K  |\n","|       from large pool |      17    |      75    |   10475 K  |   10475 K  |\n","|       from small pool |      67    |     119    |    5090 K  |    5090 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:118/8961 batch_size:175\n","Next token prediction. step:107/179 batch:118/8961 epoch:2/10\n","full seq: The existing parliamentary complex \"does not hold up to the standards of parliaments in EU countries or of those in the region\", Parliament Speaker Jozefina Topalli said.Ģġġġġġġġġ\n","pref seq: The existing parliamentary complex \"does not hold up to the standards of parliaments in EU countries or of \n","next tok:                                                                                                           t\n","pred tok:                                                                                                           N\n","Completed batch.\n","epoch:2/10 batch:118/8961 batch_size:175 loss:1.7419414520263672 time_for_batch_instance:188.05303978919983 total_batch_time:26425.483996629715 running_batch_average:223.9447796324552\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 670673 KiB |  11795 MiB |   1117 TiB |   1117 TiB |\n","|       from large pool | 216067 KiB |  11360 MiB |   1115 TiB |   1115 TiB |\n","|       from small pool | 454606 KiB |    467 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 670673 KiB |  11795 MiB |   1117 TiB |   1117 TiB |\n","|       from large pool | 216067 KiB |  11360 MiB |   1115 TiB |   1115 TiB |\n","|       from small pool | 454606 KiB |    467 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  11782 MiB |   1114 TiB |   1114 TiB |\n","|       from large pool | 213248 KiB |  11351 MiB |   1112 TiB |   1112 TiB |\n","|       from small pool | 450193 KiB |    463 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   2136 MiB |  12394 MiB | 266214 GiB | 266212 GiB |\n","|       from large pool |   1688 MiB |  11932 MiB | 265850 GiB | 265849 GiB |\n","|       from small pool |    448 MiB |    472 MiB |    363 GiB |    363 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1481 MiB |   2050 MiB | 381643 GiB | 381641 GiB |\n","|       from large pool |   1476 MiB |   2044 MiB | 379160 GiB | 379159 GiB |\n","|       from small pool |      4 MiB |     23 MiB |   2482 GiB |   2482 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   32531 K  |   32512 K  |\n","|       from large pool |      98    |     263    |   19647 K  |   19647 K  |\n","|       from small pool |   18777    |   18924    |   12883 K  |   12864 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   32531 K  |   32512 K  |\n","|       from large pool |      98    |     263    |   19647 K  |   19647 K  |\n","|       from small pool |   18777    |   18924    |   12883 K  |   12864 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     239    |     319    |    1766 K  |    1765 K  |\n","|       from large pool |      15    |      88    |    1579 K  |    1579 K  |\n","|       from small pool |     224    |     236    |     186 K  |     186 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      85    |     167    |   15687 K  |   15687 K  |\n","|       from large pool |      18    |      66    |   10557 K  |   10557 K  |\n","|       from small pool |      67    |     119    |    5129 K  |    5129 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:119/8961 batch_size:175\n","Next token prediction. step:134/179 batch:119/8961 epoch:2/10\n","full seq: An employment agreement follows, with the institution -- from universities and scientific centres within the EU or an associated country -- paying the researcher's salary.Ģġġġġġġġ\n","pref seq: An employment agreement follows, with the institution -- from universities and scientific centres within the EU or an associated count\n","next tok:                                                                                                                                      r\n","pred tok:                                                                                                                                      n\n","Completed batch.\n","epoch:2/10 batch:119/8961 batch_size:175 loss:2.1415364742279053 time_for_batch_instance:187.91561126708984 total_batch_time:26613.399607896805 running_batch_average:223.64201351173784\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 669952 KiB |  11796 MiB |   1124 TiB |   1124 TiB |\n","|       from large pool | 215346 KiB |  11361 MiB |   1121 TiB |   1121 TiB |\n","|       from small pool | 454606 KiB |    467 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 669952 KiB |  11796 MiB |   1124 TiB |   1124 TiB |\n","|       from large pool | 215346 KiB |  11361 MiB |   1121 TiB |   1121 TiB |\n","|       from small pool | 454606 KiB |    467 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  11782 MiB |   1121 TiB |   1121 TiB |\n","|       from large pool | 213248 KiB |  11351 MiB |   1119 TiB |   1119 TiB |\n","|       from small pool | 450193 KiB |    463 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1872 MiB |  12390 MiB | 267722 GiB | 267720 GiB |\n","|       from large pool |   1424 MiB |  11928 MiB | 267356 GiB | 267354 GiB |\n","|       from small pool |    448 MiB |    472 MiB |    366 GiB |    366 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1217 MiB |   2008 MiB | 384107 GiB | 384105 GiB |\n","|       from large pool |   1213 MiB |   2003 MiB | 381603 GiB | 381602 GiB |\n","|       from small pool |      4 MiB |     19 MiB |   2503 GiB |   2503 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   32763 K  |   32744 K  |\n","|       from large pool |      98    |     263    |   19784 K  |   19784 K  |\n","|       from small pool |   18777    |   18924    |   12978 K  |   12960 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   32763 K  |   32744 K  |\n","|       from large pool |      98    |     263    |   19784 K  |   19784 K  |\n","|       from small pool |   18777    |   18924    |   12978 K  |   12960 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     237    |     318    |    1778 K  |    1777 K  |\n","|       from large pool |      13    |      87    |    1590 K  |    1590 K  |\n","|       from small pool |     224    |     236    |     187 K  |     187 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      82    |     166    |   15807 K  |   15807 K  |\n","|       from large pool |      15    |      65    |   10639 K  |   10639 K  |\n","|       from small pool |      67    |     119    |    5168 K  |    5168 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:120/8961 batch_size:175\n","Next token prediction. step:87/178 batch:120/8961 epoch:2/10\n","full seq: General practitioners, gynecologists, pediatricians, occupational medicine and school medicine physicians got their clinics and the equipment and devices on concession.Ģġġġġġġġġġ\n","pref seq: General practitioners, gynecologists, pediatricians, occupational medicine and school m\n","next tok:                                                                                       e\n","pred tok:                                                                                       ,\n","Completed batch.\n","epoch:2/10 batch:120/8961 batch_size:175 loss:1.1803449392318726 time_for_batch_instance:187.134850025177 total_batch_time:26800.53445792198 running_batch_average:223.33778714934985\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 671159 KiB |  11751 MiB |   1130 TiB |   1130 TiB |\n","|       from large pool | 216553 KiB |  11316 MiB |   1128 TiB |   1128 TiB |\n","|       from small pool | 454606 KiB |    467 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 671159 KiB |  11751 MiB |   1130 TiB |   1130 TiB |\n","|       from large pool | 216553 KiB |  11316 MiB |   1128 TiB |   1128 TiB |\n","|       from small pool | 454606 KiB |    467 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  11720 MiB |   1128 TiB |   1128 TiB |\n","|       from large pool | 213248 KiB |  11289 MiB |   1125 TiB |   1125 TiB |\n","|       from small pool | 450193 KiB |    463 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1644 MiB |  12344 MiB | 269238 GiB | 269237 GiB |\n","|       from large pool |   1196 MiB |  11882 MiB | 268869 GiB | 268868 GiB |\n","|       from small pool |    448 MiB |    472 MiB |    369 GiB |    368 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |    988 MiB |   2027 MiB | 386562 GiB | 386561 GiB |\n","|       from large pool |    984 MiB |   2024 MiB | 384039 GiB | 384038 GiB |\n","|       from small pool |      4 MiB |     19 MiB |   2523 GiB |   2523 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   32994 K  |   32975 K  |\n","|       from large pool |      98    |     263    |   19921 K  |   19920 K  |\n","|       from small pool |   18777    |   18924    |   13073 K  |   13054 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   32994 K  |   32975 K  |\n","|       from large pool |      98    |     263    |   19921 K  |   19920 K  |\n","|       from small pool |   18777    |   18924    |   13073 K  |   13054 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     237    |     322    |    1790 K  |    1790 K  |\n","|       from large pool |      13    |      91    |    1601 K  |    1601 K  |\n","|       from small pool |     224    |     236    |     188 K  |     188 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      81    |     149    |   15925 K  |   15925 K  |\n","|       from large pool |      14    |      48    |   10718 K  |   10718 K  |\n","|       from small pool |      67    |     118    |    5207 K  |    5207 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:121/8961 batch_size:175\n","Next token prediction. step:4/178 batch:121/8961 epoch:2/10\n","full seq: \"We cannot overlook the fact that in only a month, political parties in Macedonia spend dozens million euros,\" said Zoran Jacev of Transparency Macedonia. [File]Ģġġġġġġġġġġġġġġġġ\n","pref seq: \"We \n","next tok:    c\n","pred tok:    ,\n","Completed batch.\n","epoch:2/10 batch:121/8961 batch_size:175 loss:1.9734746217727661 time_for_batch_instance:186.7817988395691 total_batch_time:26987.31625676155 running_batch_average:223.0356715434839\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 671159 KiB |  11750 MiB |   1137 TiB |   1137 TiB |\n","|       from large pool | 216553 KiB |  11315 MiB |   1135 TiB |   1135 TiB |\n","|       from small pool | 454606 KiB |    467 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 671159 KiB |  11750 MiB |   1137 TiB |   1137 TiB |\n","|       from large pool | 216553 KiB |  11315 MiB |   1135 TiB |   1135 TiB |\n","|       from small pool | 454606 KiB |    467 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  11720 MiB |   1134 TiB |   1134 TiB |\n","|       from large pool | 213248 KiB |  11289 MiB |   1132 TiB |   1132 TiB |\n","|       from small pool | 450193 KiB |    463 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1656 MiB |  12344 MiB | 270805 GiB | 270803 GiB |\n","|       from large pool |   1208 MiB |  11882 MiB | 270433 GiB | 270432 GiB |\n","|       from small pool |    448 MiB |    472 MiB |    371 GiB |    371 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1000 MiB |   1542 MiB | 388957 GiB | 388956 GiB |\n","|       from large pool |    996 MiB |   1539 MiB | 386414 GiB | 386413 GiB |\n","|       from small pool |      4 MiB |     19 MiB |   2543 GiB |   2543 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   33225 K  |   33206 K  |\n","|       from large pool |      98    |     263    |   20057 K  |   20057 K  |\n","|       from small pool |   18777    |   18924    |   13168 K  |   13149 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   33225 K  |   33206 K  |\n","|       from large pool |      98    |     263    |   20057 K  |   20057 K  |\n","|       from small pool |   18777    |   18924    |   13168 K  |   13149 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     238    |     323    |    1802 K  |    1802 K  |\n","|       from large pool |      14    |      92    |    1612 K  |    1612 K  |\n","|       from small pool |     224    |     236    |     190 K  |     190 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      81    |     148    |   16042 K  |   16042 K  |\n","|       from large pool |      14    |      47    |   10797 K  |   10797 K  |\n","|       from small pool |      67    |     119    |    5245 K  |    5245 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:122/8961 batch_size:175\n","Next token prediction. step:158/178 batch:122/8961 epoch:2/10\n","full seq: Croatia launched a military offensive, codenamed Operation Storm, on 4 August 1995 to regain control over the Krajina region, which was seized by Serb separatists in 1991.Ģġġġġġġ\n","pref seq: Croatia launched a military offensive, codenamed Operation Storm, on 4 August 1995 to regain control over the Krajina region, which was seized by Serb separat\n","next tok:                                                                                                                                                              i\n","pred tok:                                                                                                                                                              f\n","Completed batch.\n","epoch:2/10 batch:122/8961 batch_size:175 loss:0.8920378088951111 time_for_batch_instance:187.10612416267395 total_batch_time:27174.422380924225 running_batch_average:222.74116705675596\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 671159 KiB |  11750 MiB |   1144 TiB |   1144 TiB |\n","|       from large pool | 216553 KiB |  11315 MiB |   1141 TiB |   1141 TiB |\n","|       from small pool | 454606 KiB |    467 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 671159 KiB |  11750 MiB |   1144 TiB |   1144 TiB |\n","|       from large pool | 216553 KiB |  11315 MiB |   1141 TiB |   1141 TiB |\n","|       from small pool | 454606 KiB |    467 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  11720 MiB |   1141 TiB |   1141 TiB |\n","|       from large pool | 213248 KiB |  11289 MiB |   1139 TiB |   1139 TiB |\n","|       from small pool | 450193 KiB |    463 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1656 MiB |  12344 MiB | 272371 GiB | 272369 GiB |\n","|       from large pool |   1208 MiB |  11882 MiB | 271997 GiB | 271996 GiB |\n","|       from small pool |    448 MiB |    472 MiB |    374 GiB |    373 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1000 MiB |   1508 MiB | 391350 GiB | 391349 GiB |\n","|       from large pool |    996 MiB |   1503 MiB | 388787 GiB | 388786 GiB |\n","|       from small pool |      4 MiB |     19 MiB |   2563 GiB |   2563 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   33456 K  |   33438 K  |\n","|       from large pool |      98    |     263    |   20193 K  |   20193 K  |\n","|       from small pool |   18777    |   18924    |   13263 K  |   13244 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   33456 K  |   33438 K  |\n","|       from large pool |      98    |     263    |   20193 K  |   20193 K  |\n","|       from small pool |   18777    |   18924    |   13263 K  |   13244 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     238    |     323    |    1815 K  |    1815 K  |\n","|       from large pool |      14    |      92    |    1623 K  |    1623 K  |\n","|       from small pool |     224    |     236    |     191 K  |     191 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      81    |     148    |   16160 K  |   16160 K  |\n","|       from large pool |      14    |      47    |   10876 K  |   10876 K  |\n","|       from small pool |      67    |     119    |    5283 K  |    5283 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:123/8961 batch_size:175\n","Next token prediction. step:76/178 batch:123/8961 epoch:2/10\n","full seq: \"Biljana lived in a country in which, during the past quarter of a century, almost every day at least once you had to do your best in order to remain a decent human being.Ģġġġġġġ\n","pref seq: \"Biljana lived in a country in which, during the past quarter of a century, \n","next tok:                                                                            a\n","pred tok:                                                                            (\n","Completed batch.\n","epoch:2/10 batch:123/8961 batch_size:175 loss:1.8531118631362915 time_for_batch_instance:187.10578513145447 total_batch_time:27361.52816605568 running_batch_average:222.4514485045177\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 671159 KiB |  11750 MiB |   1150 TiB |   1150 TiB |\n","|       from large pool | 216553 KiB |  11315 MiB |   1148 TiB |   1148 TiB |\n","|       from small pool | 454606 KiB |    467 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 671159 KiB |  11750 MiB |   1150 TiB |   1150 TiB |\n","|       from large pool | 216553 KiB |  11315 MiB |   1148 TiB |   1148 TiB |\n","|       from small pool | 454606 KiB |    467 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  11720 MiB |   1148 TiB |   1148 TiB |\n","|       from large pool | 213248 KiB |  11289 MiB |   1145 TiB |   1145 TiB |\n","|       from small pool | 450193 KiB |    463 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1656 MiB |  12344 MiB | 273937 GiB | 273936 GiB |\n","|       from large pool |   1208 MiB |  11882 MiB | 273561 GiB | 273560 GiB |\n","|       from small pool |    448 MiB |    472 MiB |    376 GiB |    376 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1000 MiB |   1505 MiB | 393745 GiB | 393744 GiB |\n","|       from large pool |    996 MiB |   1500 MiB | 391162 GiB | 391161 GiB |\n","|       from small pool |      4 MiB |     19 MiB |   2583 GiB |   2583 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   33688 K  |   33669 K  |\n","|       from large pool |      98    |     263    |   20330 K  |   20330 K  |\n","|       from small pool |   18777    |   18924    |   13357 K  |   13339 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   33688 K  |   33669 K  |\n","|       from large pool |      98    |     263    |   20330 K  |   20330 K  |\n","|       from small pool |   18777    |   18924    |   13357 K  |   13339 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     238    |     323    |    1827 K  |    1827 K  |\n","|       from large pool |      14    |      92    |    1635 K  |    1635 K  |\n","|       from small pool |     224    |     236    |     192 K  |     192 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      81    |     148    |   16277 K  |   16277 K  |\n","|       from large pool |      14    |      47    |   10955 K  |   10955 K  |\n","|       from small pool |      67    |     119    |    5322 K  |    5322 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:124/8961 batch_size:175\n","Next token prediction. step:100/178 batch:124/8961 epoch:2/10\n","full seq: \"Regardless of what chapters are opened, regardless of what chapters are closed, we will integrate our legislation as soon as possible and we will wait,\" Ali Babacan said.Ģġġġġġġ\n","pref seq: \"Regardless of what chapters are opened, regardless of what chapters are closed, we will integrate o\n","next tok:                                                                                                    u\n","pred tok:                                                                                                    (\n","Completed batch.\n","epoch:2/10 batch:124/8961 batch_size:175 loss:1.2806715965270996 time_for_batch_instance:187.13791251182556 total_batch_time:27548.666078567505 running_batch_average:222.16666192393149\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 671159 KiB |  11750 MiB |   1157 TiB |   1157 TiB |\n","|       from large pool | 216553 KiB |  11315 MiB |   1155 TiB |   1155 TiB |\n","|       from small pool | 454606 KiB |    467 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 671159 KiB |  11750 MiB |   1157 TiB |   1157 TiB |\n","|       from large pool | 216553 KiB |  11315 MiB |   1155 TiB |   1155 TiB |\n","|       from small pool | 454606 KiB |    467 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  11720 MiB |   1154 TiB |   1154 TiB |\n","|       from large pool | 213248 KiB |  11289 MiB |   1152 TiB |   1152 TiB |\n","|       from small pool | 450193 KiB |    463 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1656 MiB |  12344 MiB | 275504 GiB | 275502 GiB |\n","|       from large pool |   1208 MiB |  11882 MiB | 275125 GiB | 275124 GiB |\n","|       from small pool |    448 MiB |    472 MiB |    379 GiB |    378 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1000 MiB |   1577 MiB | 396138 GiB | 396137 GiB |\n","|       from large pool |    996 MiB |   1573 MiB | 393534 GiB | 393533 GiB |\n","|       from small pool |      4 MiB |     19 MiB |   2603 GiB |   2603 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   33919 K  |   33900 K  |\n","|       from large pool |      98    |     263    |   20466 K  |   20466 K  |\n","|       from small pool |   18777    |   18924    |   13452 K  |   13433 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   33919 K  |   33900 K  |\n","|       from large pool |      98    |     263    |   20466 K  |   20466 K  |\n","|       from small pool |   18777    |   18924    |   13452 K  |   13433 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     238    |     323    |    1840 K  |    1840 K  |\n","|       from large pool |      14    |      92    |    1646 K  |    1646 K  |\n","|       from small pool |     224    |     236    |     194 K  |     193 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      81    |     148    |   16394 K  |   16394 K  |\n","|       from large pool |      14    |      47    |   11034 K  |   11034 K  |\n","|       from small pool |      67    |     119    |    5360 K  |    5360 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:125/8961 batch_size:175\n","Next token prediction. step:49/178 batch:125/8961 epoch:2/10\n","full seq: \"The way the Albanian government is acting is the best,\" Ahtisaari said. \"They (the Albanian authorities) are following actively the situation and are willing to assist us.Ģġġġġġ\n","pref seq: \"The way the Albanian government is acting is the\n","next tok:                                                  \n","pred tok:                                                 w\n","Completed batch.\n","epoch:2/10 batch:125/8961 batch_size:175 loss:1.2511683702468872 time_for_batch_instance:187.1589469909668 total_batch_time:27735.82502555847 running_batch_average:221.88660020446778\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 671159 KiB |  11750 MiB |   1164 TiB |   1164 TiB |\n","|       from large pool | 216553 KiB |  11315 MiB |   1161 TiB |   1161 TiB |\n","|       from small pool | 454606 KiB |    467 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 671159 KiB |  11750 MiB |   1164 TiB |   1164 TiB |\n","|       from large pool | 216553 KiB |  11315 MiB |   1161 TiB |   1161 TiB |\n","|       from small pool | 454606 KiB |    467 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  11720 MiB |   1161 TiB |   1161 TiB |\n","|       from large pool | 213248 KiB |  11289 MiB |   1159 TiB |   1159 TiB |\n","|       from small pool | 450193 KiB |    463 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1656 MiB |  12344 MiB | 277070 GiB | 277068 GiB |\n","|       from large pool |   1208 MiB |  11882 MiB | 276688 GiB | 276687 GiB |\n","|       from small pool |    448 MiB |    472 MiB |    381 GiB |    381 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   1000 MiB |   1508 MiB | 398531 GiB | 398530 GiB |\n","|       from large pool |    996 MiB |   1503 MiB | 395907 GiB | 395906 GiB |\n","|       from small pool |      4 MiB |     19 MiB |   2623 GiB |   2623 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   34150 K  |   34131 K  |\n","|       from large pool |      98    |     263    |   20603 K  |   20603 K  |\n","|       from small pool |   18777    |   18924    |   13547 K  |   13528 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   34150 K  |   34131 K  |\n","|       from large pool |      98    |     263    |   20603 K  |   20603 K  |\n","|       from small pool |   18777    |   18924    |   13547 K  |   13528 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     238    |     323    |    1852 K  |    1852 K  |\n","|       from large pool |      14    |      92    |    1657 K  |    1657 K  |\n","|       from small pool |     224    |     236    |     195 K  |     195 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      81    |     148    |   16512 K  |   16512 K  |\n","|       from large pool |      14    |      47    |   11113 K  |   11113 K  |\n","|       from small pool |      67    |     119    |    5398 K  |    5398 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:126/8961 batch_size:175\n","Next token prediction. step:91/177 batch:126/8961 epoch:2/10\n","full seq: Hartmann also said she expects the newly indicted generals to appear before The Hague tribunal soon and for Zagreb to take the needed steps in Gotovina's case.Ģġġġġġġġġġġġġġġġġġ\n","pref seq: Hartmann also said she expects the newly indicted generals to appear before The Hague tribu\n","next tok:                                                                                           n\n","pred tok:                                                                                           J\n","Completed batch.\n","epoch:2/10 batch:126/8961 batch_size:175 loss:3.273214101791382 time_for_batch_instance:187.14744091033936 total_batch_time:27922.97246646881 running_batch_average:221.61089259102232\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 672266 KiB |  11675 MiB |   1170 TiB |   1170 TiB |\n","|       from large pool | 217660 KiB |  11240 MiB |   1168 TiB |   1168 TiB |\n","|       from small pool | 454606 KiB |    467 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 672266 KiB |  11675 MiB |   1170 TiB |   1170 TiB |\n","|       from large pool | 217660 KiB |  11240 MiB |   1168 TiB |   1168 TiB |\n","|       from small pool | 454606 KiB |    467 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  11657 MiB |   1167 TiB |   1167 TiB |\n","|       from large pool | 213248 KiB |  11226 MiB |   1165 TiB |   1165 TiB |\n","|       from small pool | 450193 KiB |    463 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1554 MiB |  12238 MiB | 278617 GiB | 278616 GiB |\n","|       from large pool |   1106 MiB |  11774 MiB | 278233 GiB | 278232 GiB |\n","|       from small pool |    448 MiB |    472 MiB |    384 GiB |    383 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |    897 MiB |   1538 MiB | 401012 GiB | 401011 GiB |\n","|       from large pool |    893 MiB |   1528 MiB | 398368 GiB | 398367 GiB |\n","|       from small pool |      4 MiB |     20 MiB |   2643 GiB |   2643 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   34380 K  |   34361 K  |\n","|       from large pool |      98    |     263    |   20738 K  |   20738 K  |\n","|       from small pool |   18777    |   18924    |   13641 K  |   13622 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   34380 K  |   34361 K  |\n","|       from large pool |      98    |     263    |   20738 K  |   20738 K  |\n","|       from small pool |   18777    |   18924    |   13641 K  |   13622 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     240    |     321    |    1865 K  |    1865 K  |\n","|       from large pool |      16    |      89    |    1668 K  |    1668 K  |\n","|       from small pool |     224    |     236    |     196 K  |     196 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      83    |     157    |   16634 K  |   16634 K  |\n","|       from large pool |      14    |      56    |   11197 K  |   11197 K  |\n","|       from small pool |      69    |     117    |    5437 K  |    5437 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:127/8961 batch_size:175\n","Next token prediction. step:57/177 batch:127/8961 epoch:2/10\n","full seq: Bosnia and Herzegovina (BiH) institutions have failed to approve the 2008 state budget law on time, said IMF representative to BiH Graham Slack on Tuesday (January 15th).Ģġġġġġġ\n","pref seq: Bosnia and Herzegovina (BiH) institutions have failed to \n","next tok:                                                         a\n","pred tok:                                                         M\n","Completed batch.\n","epoch:2/10 batch:127/8961 batch_size:175 loss:0.9256206750869751 time_for_batch_instance:186.47919082641602 total_batch_time:28109.451657295227 running_batch_average:221.33426501807264\n","Memory usage summary:\n","|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      | 672266 KiB |  11675 MiB |   1177 TiB |   1177 TiB |\n","|       from large pool | 217660 KiB |  11240 MiB |   1174 TiB |   1174 TiB |\n","|       from small pool | 454606 KiB |    467 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Active memory         | 672266 KiB |  11675 MiB |   1177 TiB |   1177 TiB |\n","|       from large pool | 217660 KiB |  11240 MiB |   1174 TiB |   1174 TiB |\n","|       from small pool | 454606 KiB |    467 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| Requested memory      | 663441 KiB |  11657 MiB |   1174 TiB |   1174 TiB |\n","|       from large pool | 213248 KiB |  11226 MiB |   1172 TiB |   1172 TiB |\n","|       from small pool | 450193 KiB |    463 MiB |      2 TiB |      2 TiB |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1554 MiB |  12238 MiB | 280164 GiB | 280163 GiB |\n","|       from large pool |   1106 MiB |  11774 MiB | 279777 GiB | 279776 GiB |\n","|       from small pool |    448 MiB |    472 MiB |    386 GiB |    386 GiB |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |    897 MiB |   1533 MiB | 403496 GiB | 403495 GiB |\n","|       from large pool |    893 MiB |   1530 MiB | 400832 GiB | 400831 GiB |\n","|       from small pool |      4 MiB |     20 MiB |   2663 GiB |   2663 GiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |   18875    |   19046    |   34610 K  |   34591 K  |\n","|       from large pool |      98    |     263    |   20874 K  |   20874 K  |\n","|       from small pool |   18777    |   18924    |   13735 K  |   13716 K  |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |   18875    |   19046    |   34610 K  |   34591 K  |\n","|       from large pool |      98    |     263    |   20874 K  |   20874 K  |\n","|       from small pool |   18777    |   18924    |   13735 K  |   13716 K  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |     240    |     321    |    1877 K  |    1877 K  |\n","|       from large pool |      16    |      89    |    1679 K  |    1679 K  |\n","|       from small pool |     224    |     236    |     198 K  |     197 K  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      83    |     157    |   16757 K  |   16757 K  |\n","|       from large pool |      14    |      56    |   11281 K  |   11281 K  |\n","|       from small pool |      69    |     117    |    5476 K  |    5476 K  |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n","Starting batch.\n","epoch:2/10 batch:128/8961 batch_size:175\n"]}],"source":["runner = Runner(runner_hyperparameters_name=\"SETimesByT5Vaswani2017Kocmi2018_0\")\n","\n","runner.load_dataset()\n","runner.load_model()\n","runner.load_trainer()\n","runner.run_trainer()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyMrZFUssxnOAUGZZR52DJ50"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}